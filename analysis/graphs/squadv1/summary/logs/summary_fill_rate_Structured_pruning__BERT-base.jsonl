{"fill_rate": 0.2689344618055556, "f1": 86.14732314693939, "meta": {"annotate": "26", "cat_fun_name": "is_new_xp", "checkpoint": {"config": {"_name_or_path": "bert-base-uncased", "architectures": ["BertForQuestionAnswering"], "attention_probs_dropout_prob": 0.1, "gradient_checkpointing": false, "hidden_act": "gelu", "hidden_dropout_prob": 0.1, "hidden_size": 768, "initializer_range": 0.02, "intermediate_size": 3072, "layer_norm_eps": 1e-12, "max_position_embeddings": 512, "model_type": "bert", "num_attention_heads": 12, "num_hidden_layers": 12, "pad_token_id": 0, "position_embedding_type": "absolute", "type_vocab_size": 2, "vocab_size": 30522}, "eval_metrics": {"exact_match": 78.31598864711448, "f1": 86.14732314693939}, "path": "/data_2to/devel_data/nn_pruning/output/squad_test3/hp_od-output__squad_test3_es-steps_nte20_ls250_est5000_rn-output__squad_test3_dpm-sigmoied_threshold:1d_alt_apme-sigmoied_threshold_aowd0_bm1_it0_fw10_r-l1_rfl2.5_al0.00156_dtnop-csarron__bert-base-uncased-squad-v1/checkpoint-90000", "sparse_args": {"ampere_pruning_method": "disabled", "attention_block_cols": 768, "attention_block_rows": 64, "attention_lambda": 0.00156, "attention_output_with_dense": 0, "attention_pruning_method": "sigmoied_threshold", "bias_mask": true, "dense_block_cols": 1, "dense_block_rows": 1, "dense_lambda": 1.0, "dense_pruning_method": "sigmoied_threshold:1d_alt", "distil_alpha_ce": 0.1, "distil_alpha_teacher": 0.9, "distil_teacher_name_or_path": "csarron/bert-base-uncased-squad-v1", "distil_temperature": 2.0, "final_ampere_temperature": 20.0, "final_threshold": 0.1, "final_warmup": 10, "initial_ampere_temperature": 0.0, "initial_threshold": 0, "initial_warmup": 1, "mask_init": "constant", "mask_scale": 0.0, "mask_scores_learning_rate": 0.01, "regularization": "l1", "regularization_final_lambda": 2.5}, "speed": {"cuda_eval_elapsed_time": 13.55481234741211, "eval_elapsed_time": 20.70654077688232}, "speedup": 2.847283460382213, "stats": {"layers": {"0": {"linear_attention_nnz": 1474560, "linear_attention_total": 2359296, "linear_dense_nnz": 1430016, "linear_dense_total": 4718592, "linear_nnz": 2904576, "linear_total": 7077888, "nnz": 2911523, "total": 7087872}, "1": {"linear_attention_nnz": 786432, "linear_attention_total": 2359296, "linear_dense_nnz": 1582080, "linear_dense_total": 4718592, "linear_nnz": 2368512, "linear_total": 7077888, "nnz": 2374918, "total": 7087872}, "10": {"linear_attention_nnz": 491520, "linear_attention_total": 2359296, "linear_dense_nnz": 499200, "linear_dense_total": 4718592, "linear_nnz": 990720, "linear_total": 7077888, "nnz": 996037, "total": 7087872}, "11": {"linear_attention_nnz": 294912, "linear_attention_total": 2359296, "linear_dense_nnz": 812544, "linear_dense_total": 4718592, "linear_nnz": 1107456, "linear_total": 7077888, "nnz": 1112849, "total": 7087872}, "2": {"linear_attention_nnz": 1179648, "linear_attention_total": 2359296, "linear_dense_nnz": 1904640, "linear_dense_total": 4718592, "linear_nnz": 3084288, "linear_total": 7077888, "nnz": 3091288, "total": 7087872}, "3": {"linear_attention_nnz": 884736, "linear_attention_total": 2359296, "linear_dense_nnz": 1715712, "linear_dense_total": 4718592, "linear_nnz": 2600448, "linear_total": 7077888, "nnz": 2607005, "total": 7087872}, "4": {"linear_attention_nnz": 589824, "linear_attention_total": 2359296, "linear_dense_nnz": 1654272, "linear_dense_total": 4718592, "linear_nnz": 2244096, "linear_total": 7077888, "nnz": 2250293, "total": 7087872}, "5": {"linear_attention_nnz": 393216, "linear_attention_total": 2359296, "linear_dense_nnz": 1703424, "linear_dense_total": 4718592, "linear_nnz": 2096640, "linear_total": 7077888, "nnz": 2102741, "total": 7087872}, "6": {"linear_attention_nnz": 589824, "linear_attention_total": 2359296, "linear_dense_nnz": 1320960, "linear_dense_total": 4718592, "linear_nnz": 1910784, "linear_total": 7077888, "nnz": 1916828, "total": 7087872}, "7": {"linear_attention_nnz": 393216, "linear_attention_total": 2359296, "linear_dense_nnz": 1082880, "linear_dense_total": 4718592, "linear_nnz": 1476096, "linear_total": 7077888, "nnz": 1481793, "total": 7087872}, "8": {"linear_attention_nnz": 786432, "linear_attention_total": 2359296, "linear_dense_nnz": 748032, "linear_dense_total": 4718592, "linear_nnz": 1534464, "linear_total": 7077888, "nnz": 1540327, "total": 7087872}, "9": {"linear_attention_nnz": 196608, "linear_attention_total": 2359296, "linear_dense_nnz": 327168, "linear_dense_total": 4718592, "linear_nnz": 523776, "linear_total": 7077888, "nnz": 528789, "total": 7087872}}, "linear_nnz": 22841856, "linear_sparsity": 73.10655381944444, "linear_total": 84934656, "nnz": 46753113, "pruned_heads": {"0": [0, 1, 2, 10, 11], "1": [0, 1, 2, 3, 4, 5, 6, 7], "10": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "11": [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "2": [1, 4, 5, 7, 8, 11], "3": [1, 2, 3, 4, 6, 7, 10, 11], "4": [1, 2, 3, 4, 5, 6, 8, 9, 10, 11], "5": [0, 1, 2, 3, 4, 5, 6, 8, 10, 11], "6": [0, 1, 2, 3, 4, 6, 7, 8, 10], "7": [0, 1, 2, 3, 5, 6, 7, 8, 10, 11], "8": [0, 1, 2, 3, 4, 7, 8, 9], "9": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]}, "total": 108893186, "total_sparsity": 57.06516200196401}, "training_args": {"_n_gpu": -1, "adafactor": false, "adam_beta1": 0.9, "adam_beta2": 0.999, "adam_epsilon": 1e-08, "dataloader_drop_last": false, "dataloader_num_workers": 0, "dataloader_pin_memory": true, "ddp_find_unused_parameters": null, "debug": false, "deepspeed": null, "disable_tqdm": false, "do_eval": 1, "do_predict": false, "do_train": 1, "eval_accumulation_steps": null, "eval_steps": 5000, "evaluation_strategy": "steps", "fp16": false, "fp16_backend": "auto", "fp16_full_eval": false, "fp16_opt_level": "O1", "gradient_accumulation_steps": 1, "greater_is_better": null, "group_by_length": false, "ignore_data_skip": false, "label_names": null, "label_smoothing_factor": 0.0, "learning_rate": 3e-05, "load_best_model_at_end": false, "local_rank": -1, "logging_dir": "output/squad_test3", "logging_first_step": false, "logging_steps": 250, "logging_strategy": "steps", "lr_scheduler_type": "linear", "max_grad_norm": 1.0, "max_steps": -1, "metric_for_best_model": null, "no_cuda": false, "num_train_epochs": 20, "optimize_model_before_eval": "disabled", "output_dir": "output/squad_test3", "overwrite_output_dir": 1, "past_index": -1, "per_device_eval_batch_size": 8, "per_device_train_batch_size": 16, "per_gpu_eval_batch_size": null, "per_gpu_train_batch_size": null, "prediction_loss_only": false, "remove_unused_columns": true, "report_to": null, "run_name": "output/squad_test3", "save_steps": 5000, "save_strategy": "steps", "save_total_limit": 5, "seed": 17, "sharded_ddp": "", "skip_memory_metrics": false, "tpu_metrics_debug": false, "tpu_num_cores": null, "warmup_ratio": 0.0, "warmup_steps": 5400, "weight_decay": 0.0}, "unopt_eval_metrics": {"exact_match": 79.27152317880795, "f1": 86.82791223756466}}, "f1": 86.14732314693939, "fill_rate": 0.2689344618055556, "speedup": 2.847283460382213}}
{"fill_rate": 0.16608796296296302, "f1": 85.90050035022541, "meta": {"annotate": "16", "cat_fun_name": "is_new_xp", "checkpoint": {"config": {"_name_or_path": "bert-base-uncased", "architectures": ["BertForQuestionAnswering"], "attention_probs_dropout_prob": 0.1, "gradient_checkpointing": false, "hidden_act": "gelu", "hidden_dropout_prob": 0.1, "hidden_size": 768, "initializer_range": 0.02, "intermediate_size": 3072, "layer_norm_eps": 1e-12, "max_position_embeddings": 512, "model_type": "bert", "num_attention_heads": 12, "num_hidden_layers": 12, "pad_token_id": 0, "position_embedding_type": "absolute", "type_vocab_size": 2, "vocab_size": 30522}, "eval_metrics": {"exact_match": 77.94701986754967, "f1": 85.90050035022541}, "path": "/data_2to/devel_data/nn_pruning/output/squad_test3/hp_od-output__squad_test3_es-steps_nte20_ls250_est5000_rn-output__squad_test3_dpm-sigmoied_threshold:1d_alt_apme-sigmoied_threshold_aowd0_it0_fw10_r-l1_rfl10.0_al0.00156_dtnop-csarron__bert-base-uncased-squad-v1/checkpoint-100000", "sparse_args": {"ampere_pruning_method": "disabled", "attention_block_cols": 768, "attention_block_rows": 64, "attention_lambda": 0.00156, "attention_output_with_dense": 0, "attention_pruning_method": "sigmoied_threshold", "dense_block_cols": 1, "dense_block_rows": 1, "dense_lambda": 1.0, "dense_pruning_method": "sigmoied_threshold:1d_alt", "distil_alpha_ce": 0.1, "distil_alpha_teacher": 0.9, "distil_teacher_name_or_path": "csarron/bert-base-uncased-squad-v1", "distil_temperature": 2.0, "final_ampere_temperature": 20.0, "final_threshold": 0.1, "final_warmup": 10, "initial_ampere_temperature": 0.0, "initial_threshold": 0, "initial_warmup": 1, "mask_init": "constant", "mask_scale": 0.0, "mask_scores_learning_rate": 0.01, "regularization": "l1", "regularization_final_lambda": 10.0}, "speed": {"cuda_eval_elapsed_time": 11.486401634216309, "eval_elapsed_time": 18.590640037320554}, "speedup": 3.3600072707194957, "stats": {"layers": {"0": {"linear_attention_nnz": 1376256, "linear_attention_total": 2359296, "linear_dense_nnz": 293376, "linear_dense_total": 4718592, "linear_nnz": 1669632, "linear_total": 7077888, "nnz": 1679616, "total": 7087872}, "1": {"linear_attention_nnz": 491520, "linear_attention_total": 2359296, "linear_dense_nnz": 422400, "linear_dense_total": 4718592, "linear_nnz": 913920, "linear_total": 7077888, "nnz": 923904, "total": 7087872}, "10": {"linear_attention_nnz": 589824, "linear_attention_total": 2359296, "linear_dense_nnz": 118272, "linear_dense_total": 4718592, "linear_nnz": 708096, "linear_total": 7077888, "nnz": 718080, "total": 7087872}, "11": {"linear_attention_nnz": 393216, "linear_attention_total": 2359296, "linear_dense_nnz": 225792, "linear_dense_total": 4718592, "linear_nnz": 619008, "linear_total": 7077888, "nnz": 628992, "total": 7087872}, "2": {"linear_attention_nnz": 1376256, "linear_attention_total": 2359296, "linear_dense_nnz": 592896, "linear_dense_total": 4718592, "linear_nnz": 1969152, "linear_total": 7077888, "nnz": 1979136, "total": 7087872}, "3": {"linear_attention_nnz": 1081344, "linear_attention_total": 2359296, "linear_dense_nnz": 631296, "linear_dense_total": 4718592, "linear_nnz": 1712640, "linear_total": 7077888, "nnz": 1722624, "total": 7087872}, "4": {"linear_attention_nnz": 884736, "linear_attention_total": 2359296, "linear_dense_nnz": 674304, "linear_dense_total": 4718592, "linear_nnz": 1559040, "linear_total": 7077888, "nnz": 1569024, "total": 7087872}, "5": {"linear_attention_nnz": 589824, "linear_attention_total": 2359296, "linear_dense_nnz": 629760, "linear_dense_total": 4718592, "linear_nnz": 1219584, "linear_total": 7077888, "nnz": 1229568, "total": 7087872}, "6": {"linear_attention_nnz": 786432, "linear_attention_total": 2359296, "linear_dense_nnz": 471552, "linear_dense_total": 4718592, "linear_nnz": 1257984, "linear_total": 7077888, "nnz": 1267968, "total": 7087872}, "7": {"linear_attention_nnz": 540672, "linear_attention_total": 2359296, "linear_dense_nnz": 414720, "linear_dense_total": 4718592, "linear_nnz": 955392, "linear_total": 7077888, "nnz": 965376, "total": 7087872}, "8": {"linear_attention_nnz": 835584, "linear_attention_total": 2359296, "linear_dense_nnz": 254976, "linear_dense_total": 4718592, "linear_nnz": 1090560, "linear_total": 7077888, "nnz": 1100544, "total": 7087872}, "9": {"linear_attention_nnz": 344064, "linear_attention_total": 2359296, "linear_dense_nnz": 87552, "linear_dense_total": 4718592, "linear_nnz": 431616, "linear_total": 7077888, "nnz": 441600, "total": 7087872}}, "linear_nnz": 14106624, "linear_sparsity": 83.3912037037037, "linear_total": 84934656, "nnz": 38065154, "pruned_heads": {"0": [0, 1, 2, 10, 11], "1": [0, 1, 2, 3, 4, 5, 6, 7, 8, 10], "10": [0, 1, 2, 4, 5, 6, 7, 8, 9, 10], "11": [0, 2, 3, 4, 5, 6, 8, 9, 10, 11], "2": [1, 4, 5, 7, 8], "3": [1, 2, 3, 4, 6, 7, 10], "4": [1, 2, 3, 4, 8, 9, 10, 11], "5": [0, 1, 2, 3, 4, 5, 8, 10, 11], "6": [0, 1, 2, 3, 4, 7, 8, 10], "7": [0, 1, 2, 3, 5, 6, 7, 8, 10, 11], "8": [0, 1, 2, 3, 4, 7, 8, 9], "9": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]}, "total": 108893186, "total_sparsity": 65.04358500448319}, "training_args": {"_n_gpu": -1, "adafactor": false, "adam_beta1": 0.9, "adam_beta2": 0.999, "adam_epsilon": 1e-08, "dataloader_drop_last": false, "dataloader_num_workers": 0, "dataloader_pin_memory": true, "ddp_find_unused_parameters": null, "debug": false, "deepspeed": null, "disable_tqdm": false, "do_eval": 1, "do_predict": false, "do_train": 1, "eval_accumulation_steps": null, "eval_steps": 5000, "evaluation_strategy": "steps", "fp16": false, "fp16_backend": "auto", "fp16_full_eval": false, "fp16_opt_level": "O1", "gradient_accumulation_steps": 1, "greater_is_better": null, "group_by_length": false, "ignore_data_skip": false, "label_names": null, "label_smoothing_factor": 0.0, "learning_rate": 3e-05, "load_best_model_at_end": false, "local_rank": -1, "logging_dir": "output/squad_test3", "logging_first_step": false, "logging_steps": 250, "logging_strategy": "steps", "lr_scheduler_type": "linear", "max_grad_norm": 1.0, "max_steps": -1, "metric_for_best_model": null, "no_cuda": false, "num_train_epochs": 20, "optimize_model_before_eval": "disabled", "output_dir": "output/squad_test3", "overwrite_output_dir": 1, "past_index": -1, "per_device_eval_batch_size": 8, "per_device_train_batch_size": 16, "per_gpu_eval_batch_size": null, "per_gpu_train_batch_size": null, "prediction_loss_only": false, "remove_unused_columns": true, "report_to": null, "run_name": "output/squad_test3", "save_steps": 5000, "save_strategy": "steps", "save_total_limit": 5, "seed": 17, "sharded_ddp": "", "skip_memory_metrics": false, "tpu_metrics_debug": false, "tpu_num_cores": null, "warmup_ratio": 0.0, "warmup_steps": 5400, "weight_decay": 0.0}, "unopt_eval_metrics": {"exact_match": 78.29706717123936, "f1": 86.2625032125089}}, "f1": 85.90050035022541, "fill_rate": 0.16608796296296302, "speedup": 3.3600072707194957}}
{"fill_rate": 0.14585141782407407, "f1": 84.83470649534952, "meta": {"annotate": "14", "cat_fun_name": "is_new_xp", "checkpoint": {"config": {"_name_or_path": "bert-base-uncased", "architectures": ["BertForQuestionAnswering"], "attention_probs_dropout_prob": 0.1, "gradient_checkpointing": false, "hidden_act": "gelu", "hidden_dropout_prob": 0.1, "hidden_size": 768, "initializer_range": 0.02, "intermediate_size": 3072, "layer_norm_eps": 1e-12, "max_position_embeddings": 512, "model_type": "bert", "num_attention_heads": 12, "num_hidden_layers": 12, "pad_token_id": 0, "position_embedding_type": "absolute", "type_vocab_size": 2, "vocab_size": 30522}, "eval_metrics": {"exact_match": 76.75496688741723, "f1": 84.83470649534952}, "path": "/data_2to/devel_data/nn_pruning/output/squad_test3/hp_od-output__squad_test3_es-steps_nte20_ls250_est5000_rn-output__squad_test3_dpm-sigmoied_threshold:1d_alt_apme-sigmoied_threshold_aowd0_it0_fw10_r-l1_rfl14.9999_al0.05_dtnop-csarron__bert-base-uncased-squad-v1/checkpoint-80000", "sparse_args": {"ampere_pruning_method": "disabled", "attention_block_cols": 768, "attention_block_rows": 64, "attention_lambda": 0.05, "attention_output_with_dense": 0, "attention_pruning_method": "sigmoied_threshold", "dense_block_cols": 1, "dense_block_rows": 1, "dense_lambda": 1.0, "dense_pruning_method": "sigmoied_threshold:1d_alt", "distil_alpha_ce": 0.1, "distil_alpha_teacher": 0.9, "distil_teacher_name_or_path": "csarron/bert-base-uncased-squad-v1", "distil_temperature": 2.0, "final_ampere_temperature": 20.0, "final_threshold": 0.1, "final_warmup": 10, "initial_ampere_temperature": 0.0, "initial_threshold": 0, "initial_warmup": 1, "mask_init": "constant", "mask_scale": 0.0, "mask_scores_learning_rate": 0.01, "regularization": "l1", "regularization_final_lambda": 14.9999}, "speed": {"cuda_eval_elapsed_time": 10.789498657226563, "eval_elapsed_time": 17.89066500775516}, "speedup": 3.5770330236355736, "stats": {"layers": {"0": {"linear_attention_nnz": 1474560, "linear_attention_total": 2359296, "linear_dense_nnz": 247296, "linear_dense_total": 4718592, "linear_nnz": 1721856, "linear_total": 7077888, "nnz": 1731840, "total": 7087872}, "1": {"linear_attention_nnz": 638976, "linear_attention_total": 2359296, "linear_dense_nnz": 311808, "linear_dense_total": 4718592, "linear_nnz": 950784, "linear_total": 7077888, "nnz": 960768, "total": 7087872}, "10": {"linear_attention_nnz": 491520, "linear_attention_total": 2359296, "linear_dense_nnz": 122880, "linear_dense_total": 4718592, "linear_nnz": 614400, "linear_total": 7077888, "nnz": 624384, "total": 7087872}, "11": {"linear_attention_nnz": 196608, "linear_attention_total": 2359296, "linear_dense_nnz": 175104, "linear_dense_total": 4718592, "linear_nnz": 371712, "linear_total": 7077888, "nnz": 381696, "total": 7087872}, "2": {"linear_attention_nnz": 1376256, "linear_attention_total": 2359296, "linear_dense_nnz": 480768, "linear_dense_total": 4718592, "linear_nnz": 1857024, "linear_total": 7077888, "nnz": 1867008, "total": 7087872}, "3": {"linear_attention_nnz": 786432, "linear_attention_total": 2359296, "linear_dense_nnz": 491520, "linear_dense_total": 4718592, "linear_nnz": 1277952, "linear_total": 7077888, "nnz": 1287936, "total": 7087872}, "4": {"linear_attention_nnz": 884736, "linear_attention_total": 2359296, "linear_dense_nnz": 552960, "linear_dense_total": 4718592, "linear_nnz": 1437696, "linear_total": 7077888, "nnz": 1447680, "total": 7087872}, "5": {"linear_attention_nnz": 589824, "linear_attention_total": 2359296, "linear_dense_nnz": 523776, "linear_dense_total": 4718592, "linear_nnz": 1113600, "linear_total": 7077888, "nnz": 1123584, "total": 7087872}, "6": {"linear_attention_nnz": 589824, "linear_attention_total": 2359296, "linear_dense_nnz": 425472, "linear_dense_total": 4718592, "linear_nnz": 1015296, "linear_total": 7077888, "nnz": 1025280, "total": 7087872}, "7": {"linear_attention_nnz": 393216, "linear_attention_total": 2359296, "linear_dense_nnz": 337920, "linear_dense_total": 4718592, "linear_nnz": 731136, "linear_total": 7077888, "nnz": 741120, "total": 7087872}, "8": {"linear_attention_nnz": 786432, "linear_attention_total": 2359296, "linear_dense_nnz": 213504, "linear_dense_total": 4718592, "linear_nnz": 999936, "linear_total": 7077888, "nnz": 1009920, "total": 7087872}, "9": {"linear_attention_nnz": 196608, "linear_attention_total": 2359296, "linear_dense_nnz": 99840, "linear_dense_total": 4718592, "linear_nnz": 296448, "linear_total": 7077888, "nnz": 306432, "total": 7087872}}, "linear_nnz": 12387840, "linear_sparsity": 85.4148582175926, "linear_total": 84934656, "nnz": 36346370, "pruned_heads": {"0": [0, 1, 2, 10, 11], "1": [0, 1, 3, 4, 5, 6, 7, 8, 10], "10": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "11": [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "2": [1, 4, 5, 7, 8], "3": [1, 2, 3, 4, 6, 7, 10, 11], "4": [1, 2, 3, 4, 6, 8, 9, 11], "5": [0, 1, 2, 3, 4, 5, 8, 10, 11], "6": [0, 1, 2, 3, 4, 6, 7, 8, 10], "7": [0, 1, 2, 3, 5, 6, 7, 8, 10, 11], "8": [0, 1, 2, 3, 4, 7, 8, 9], "9": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]}, "total": 108893186, "total_sparsity": 66.62199781720042}, "training_args": {"_n_gpu": -1, "adafactor": false, "adam_beta1": 0.9, "adam_beta2": 0.999, "adam_epsilon": 1e-08, "dataloader_drop_last": false, "dataloader_num_workers": 0, "dataloader_pin_memory": true, "ddp_find_unused_parameters": null, "debug": false, "deepspeed": null, "disable_tqdm": false, "do_eval": 1, "do_predict": false, "do_train": 1, "eval_accumulation_steps": null, "eval_steps": 5000, "evaluation_strategy": "steps", "fp16": false, "fp16_backend": "auto", "fp16_full_eval": false, "fp16_opt_level": "O1", "gradient_accumulation_steps": 1, "greater_is_better": null, "group_by_length": false, "ignore_data_skip": false, "label_names": null, "label_smoothing_factor": 0.0, "learning_rate": 3e-05, "load_best_model_at_end": false, "local_rank": -1, "logging_dir": "output/squad_test3", "logging_first_step": false, "logging_steps": 250, "logging_strategy": "steps", "lr_scheduler_type": "linear", "max_grad_norm": 1.0, "max_steps": -1, "metric_for_best_model": null, "no_cuda": false, "num_train_epochs": 20, "optimize_model_before_eval": "disabled", "output_dir": "output/squad_test3", "overwrite_output_dir": 1, "past_index": -1, "per_device_eval_batch_size": 8, "per_device_train_batch_size": 16, "per_gpu_eval_batch_size": null, "per_gpu_train_batch_size": null, "prediction_loss_only": false, "remove_unused_columns": true, "report_to": null, "run_name": "output/squad_test3", "save_steps": 5000, "save_strategy": "steps", "save_total_limit": 5, "seed": 17, "sharded_ddp": "", "skip_memory_metrics": false, "tpu_metrics_debug": false, "tpu_num_cores": null, "warmup_ratio": 0.0, "warmup_steps": 5400, "weight_decay": 0.0}, "unopt_eval_metrics": {"exact_match": 77.71996215704824, "f1": 85.77799129804794}}, "f1": 84.83470649534952, "fill_rate": 0.14585141782407407, "speedup": 3.5770330236355736}}
{"fill_rate": 0.13751446759259256, "f1": 84.63605545666391, "meta": {"annotate": "13", "cat_fun_name": "is_new_xp", "checkpoint": {"config": {"_name_or_path": "bert-base-uncased", "architectures": ["BertForQuestionAnswering"], "attention_probs_dropout_prob": 0.1, "gradient_checkpointing": false, "hidden_act": "gelu", "hidden_dropout_prob": 0.1, "hidden_size": 768, "initializer_range": 0.02, "intermediate_size": 3072, "layer_norm_eps": 1e-12, "max_position_embeddings": 512, "model_type": "bert", "num_attention_heads": 12, "num_hidden_layers": 12, "pad_token_id": 0, "position_embedding_type": "absolute", "type_vocab_size": 2, "vocab_size": 30522}, "eval_metrics": {"exact_match": 76.31031220435194, "f1": 84.63605545666391}, "path": "/data_2to/devel_data/nn_pruning/output/squad_test3/hp_od-output__squad_test3_es-steps_nte20_ls250_est5000_rn-output__squad_test3_dpm-sigmoied_threshold:1d_alt_apme-sigmoied_threshold_aowd0_it0_fw10_r-l1_rfl14.9999_al0.05_dtnop-csarron__bert-base-uncased-squad-v1/checkpoint-110000", "sparse_args": {"ampere_pruning_method": "disabled", "attention_block_cols": 768, "attention_block_rows": 64, "attention_lambda": 0.05, "attention_output_with_dense": 0, "attention_pruning_method": "sigmoied_threshold", "dense_block_cols": 1, "dense_block_rows": 1, "dense_lambda": 1.0, "dense_pruning_method": "sigmoied_threshold:1d_alt", "distil_alpha_ce": 0.1, "distil_alpha_teacher": 0.9, "distil_teacher_name_or_path": "csarron/bert-base-uncased-squad-v1", "distil_temperature": 2.0, "final_ampere_temperature": 20.0, "final_threshold": 0.1, "final_warmup": 10, "initial_ampere_temperature": 0.0, "initial_threshold": 0, "initial_warmup": 1, "mask_init": "constant", "mask_scale": 0.0, "mask_scores_learning_rate": 0.01, "regularization": "l1", "regularization_final_lambda": 14.9999}, "speed": {"cuda_eval_elapsed_time": 10.591327346801759, "eval_elapsed_time": 17.679683603346348}, "speedup": 3.6439618700884893, "stats": {"layers": {"0": {"linear_attention_nnz": 1376256, "linear_attention_total": 2359296, "linear_dense_nnz": 210432, "linear_dense_total": 4718592, "linear_nnz": 1586688, "linear_total": 7077888, "nnz": 1596672, "total": 7087872}, "1": {"linear_attention_nnz": 638976, "linear_attention_total": 2359296, "linear_dense_nnz": 248832, "linear_dense_total": 4718592, "linear_nnz": 887808, "linear_total": 7077888, "nnz": 897792, "total": 7087872}, "10": {"linear_attention_nnz": 491520, "linear_attention_total": 2359296, "linear_dense_nnz": 110592, "linear_dense_total": 4718592, "linear_nnz": 602112, "linear_total": 7077888, "nnz": 612096, "total": 7087872}, "11": {"linear_attention_nnz": 196608, "linear_attention_total": 2359296, "linear_dense_nnz": 164352, "linear_dense_total": 4718592, "linear_nnz": 360960, "linear_total": 7077888, "nnz": 370944, "total": 7087872}, "2": {"linear_attention_nnz": 1376256, "linear_attention_total": 2359296, "linear_dense_nnz": 427008, "linear_dense_total": 4718592, "linear_nnz": 1803264, "linear_total": 7077888, "nnz": 1813248, "total": 7087872}, "3": {"linear_attention_nnz": 786432, "linear_attention_total": 2359296, "linear_dense_nnz": 457728, "linear_dense_total": 4718592, "linear_nnz": 1244160, "linear_total": 7077888, "nnz": 1254144, "total": 7087872}, "4": {"linear_attention_nnz": 688128, "linear_attention_total": 2359296, "linear_dense_nnz": 486912, "linear_dense_total": 4718592, "linear_nnz": 1175040, "linear_total": 7077888, "nnz": 1185024, "total": 7087872}, "5": {"linear_attention_nnz": 589824, "linear_attention_total": 2359296, "linear_dense_nnz": 473088, "linear_dense_total": 4718592, "linear_nnz": 1062912, "linear_total": 7077888, "nnz": 1072896, "total": 7087872}, "6": {"linear_attention_nnz": 589824, "linear_attention_total": 2359296, "linear_dense_nnz": 387072, "linear_dense_total": 4718592, "linear_nnz": 976896, "linear_total": 7077888, "nnz": 986880, "total": 7087872}, "7": {"linear_attention_nnz": 393216, "linear_attention_total": 2359296, "linear_dense_nnz": 311808, "linear_dense_total": 4718592, "linear_nnz": 705024, "linear_total": 7077888, "nnz": 715008, "total": 7087872}, "8": {"linear_attention_nnz": 786432, "linear_attention_total": 2359296, "linear_dense_nnz": 198144, "linear_dense_total": 4718592, "linear_nnz": 984576, "linear_total": 7077888, "nnz": 994560, "total": 7087872}, "9": {"linear_attention_nnz": 196608, "linear_attention_total": 2359296, "linear_dense_nnz": 93696, "linear_dense_total": 4718592, "linear_nnz": 290304, "linear_total": 7077888, "nnz": 300288, "total": 7087872}}, "linear_nnz": 11679744, "linear_sparsity": 86.24855324074075, "linear_total": 84934656, "nnz": 35638274, "pruned_heads": {"0": [0, 1, 2, 10, 11], "1": [0, 1, 3, 4, 5, 6, 7, 8, 10], "10": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "11": [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "2": [1, 4, 5, 7, 8], "3": [1, 2, 3, 4, 6, 7, 10, 11], "4": [1, 2, 3, 4, 6, 8, 9, 10, 11], "5": [0, 1, 2, 3, 4, 5, 8, 10, 11], "6": [0, 1, 2, 3, 4, 6, 7, 8, 10], "7": [0, 1, 2, 3, 5, 6, 7, 8, 10, 11], "8": [0, 1, 2, 3, 4, 7, 8, 9], "9": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]}, "total": 108893186, "total_sparsity": 67.27226440045568}, "training_args": {"_n_gpu": -1, "adafactor": false, "adam_beta1": 0.9, "adam_beta2": 0.999, "adam_epsilon": 1e-08, "dataloader_drop_last": false, "dataloader_num_workers": 0, "dataloader_pin_memory": true, "ddp_find_unused_parameters": null, "debug": false, "deepspeed": null, "disable_tqdm": false, "do_eval": 1, "do_predict": false, "do_train": 1, "eval_accumulation_steps": null, "eval_steps": 5000, "evaluation_strategy": "steps", "fp16": false, "fp16_backend": "auto", "fp16_full_eval": false, "fp16_opt_level": "O1", "gradient_accumulation_steps": 1, "greater_is_better": null, "group_by_length": false, "ignore_data_skip": false, "label_names": null, "label_smoothing_factor": 0.0, "learning_rate": 3e-05, "load_best_model_at_end": false, "local_rank": -1, "logging_dir": "output/squad_test3", "logging_first_step": false, "logging_steps": 250, "logging_strategy": "steps", "lr_scheduler_type": "linear", "max_grad_norm": 1.0, "max_steps": -1, "metric_for_best_model": null, "no_cuda": false, "num_train_epochs": 20, "optimize_model_before_eval": "disabled", "output_dir": "output/squad_test3", "overwrite_output_dir": 1, "past_index": -1, "per_device_eval_batch_size": 8, "per_device_train_batch_size": 16, "per_gpu_eval_batch_size": null, "per_gpu_train_batch_size": null, "prediction_loss_only": false, "remove_unused_columns": true, "report_to": null, "run_name": "output/squad_test3", "save_steps": 5000, "save_strategy": "steps", "save_total_limit": 5, "seed": 17, "sharded_ddp": "", "skip_memory_metrics": false, "tpu_metrics_debug": false, "tpu_num_cores": null, "warmup_ratio": 0.0, "warmup_steps": 5400, "weight_decay": 0.0}, "unopt_eval_metrics": {"exact_match": 77.32261116367077, "f1": 85.45260706155949}}, "f1": 84.63605545666391, "fill_rate": 0.13751446759259256, "speedup": 3.6439618700884893}}
