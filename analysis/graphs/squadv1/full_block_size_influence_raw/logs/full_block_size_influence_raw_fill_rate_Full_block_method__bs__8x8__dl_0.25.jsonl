{"fill_rate": 0.5704405984760802, "f1": 88.3744311515211, "meta": {"annotate": "57", "cat_fun_name": "is_full_block", "checkpoint": {"config": {"_name_or_path": "bert-base-uncased", "architectures": ["BertForQuestionAnswering"], "attention_probs_dropout_prob": 0.1, "gradient_checkpointing": false, "hidden_act": "gelu", "hidden_dropout_prob": 0.1, "hidden_size": 768, "initializer_range": 0.02, "intermediate_size": 3072, "layer_norm_eps": 1e-12, "max_position_embeddings": 512, "model_type": "bert", "num_attention_heads": 12, "num_hidden_layers": 12, "pad_token_id": 0, "position_embedding_type": "absolute", "type_vocab_size": 2, "vocab_size": 30522}, "eval_metrics": {"exact_match": 81.10690633869442, "f1": 88.3744311515211}, "path": "/data_2to/devel_data/nn_pruning/output/squad_test_aws/aws_nn-pruning-v9-a8-l10--2021-01-20--18-59-37/checkpoint-110000", "sparse_args": {"ampere_pruning_method": "disabled", "attention_block_cols": 8, "attention_block_rows": 8, "attention_lambda": 1.0, "attention_output_with_dense": 0, "attention_pruning_method": "sigmoied_threshold", "bias_mask": true, "dense_block_cols": 8, "dense_block_rows": 8, "dense_lambda": 0.25, "dense_pruning_method": "sigmoied_threshold", "distil_alpha_ce": 0.1, "distil_alpha_teacher": 0.9, "distil_teacher_name_or_path": "csarron/bert-base-uncased-squad-v1", "distil_temperature": 2.0, "final_ampere_temperature": 20.0, "final_threshold": 0.1, "final_warmup": 10, "initial_ampere_temperature": 0.0, "initial_threshold": 0, "initial_warmup": 1, "mask_init": "constant", "mask_scale": 0.0, "mask_scores_learning_rate": 0.01, "regularization": "l1", "regularization_final_lambda": 10.0}, "speed": {"cuda_eval_elapsed_time": 32.22343955230713, "eval_elapsed_time": 39.62965265568346}, "speedup": 1.1977117757004876, "stats": {"layers": {"0": {"linear_attention_nnz": 446080, "linear_attention_total": 2359296, "linear_dense_nnz": 4004864, "linear_dense_total": 4718592, "linear_nnz": 4450944, "linear_total": 7077888, "nnz": 4459384, "total": 7087872}, "1": {"linear_attention_nnz": 597312, "linear_attention_total": 2359296, "linear_dense_nnz": 4076928, "linear_dense_total": 4718592, "linear_nnz": 4674240, "linear_total": 7077888, "nnz": 4682824, "total": 7087872}, "10": {"linear_attention_nnz": 362048, "linear_attention_total": 2359296, "linear_dense_nnz": 1517376, "linear_dense_total": 4718592, "linear_nnz": 1879424, "linear_total": 7077888, "nnz": 1888000, "total": 7087872}, "11": {"linear_attention_nnz": 217216, "linear_attention_total": 2359296, "linear_dense_nnz": 1063808, "linear_dense_total": 4718592, "linear_nnz": 1281024, "linear_total": 7077888, "nnz": 1288536, "total": 7087872}, "2": {"linear_attention_nnz": 800192, "linear_attention_total": 2359296, "linear_dense_nnz": 4155456, "linear_dense_total": 4718592, "linear_nnz": 4955648, "linear_total": 7077888, "nnz": 4964752, "total": 7087872}, "3": {"linear_attention_nnz": 948864, "linear_attention_total": 2359296, "linear_dense_nnz": 4165760, "linear_dense_total": 4718592, "linear_nnz": 5114624, "linear_total": 7077888, "nnz": 5123824, "total": 7087872}, "4": {"linear_attention_nnz": 1019200, "linear_attention_total": 2359296, "linear_dense_nnz": 4152640, "linear_dense_total": 4718592, "linear_nnz": 5171840, "linear_total": 7077888, "nnz": 5181392, "total": 7087872}, "5": {"linear_attention_nnz": 915392, "linear_attention_total": 2359296, "linear_dense_nnz": 4108416, "linear_dense_total": 4718592, "linear_nnz": 5023808, "linear_total": 7077888, "nnz": 5032920, "total": 7087872}, "6": {"linear_attention_nnz": 916160, "linear_attention_total": 2359296, "linear_dense_nnz": 3960384, "linear_dense_total": 4718592, "linear_nnz": 4876544, "linear_total": 7077888, "nnz": 4885872, "total": 7087872}, "7": {"linear_attention_nnz": 834176, "linear_attention_total": 2359296, "linear_dense_nnz": 3685056, "linear_dense_total": 4718592, "linear_nnz": 4519232, "linear_total": 7077888, "nnz": 4528312, "total": 7087872}, "8": {"linear_attention_nnz": 713856, "linear_attention_total": 2359296, "linear_dense_nnz": 3207936, "linear_dense_total": 4718592, "linear_nnz": 3921792, "linear_total": 7077888, "nnz": 3930904, "total": 7087872}, "9": {"linear_attention_nnz": 465600, "linear_attention_total": 2359296, "linear_dense_nnz": 2115456, "linear_dense_total": 4718592, "linear_nnz": 2581056, "linear_total": 7077888, "nnz": 2589728, "total": 7087872}}, "linear_nnz": 48450176, "linear_sparsity": 42.95594015239198, "linear_total": 84934656, "nnz": 72395170, "pruned_heads": {"0": [9, 2, 4, 5], "1": [0, 2, 3, 5, 6, 8], "10": [1, 4, 5, 6, 7, 8], "11": [0, 5, 6, 7, 8, 10, 11], "2": [8, 4, 7], "3": [2, 4, 6], "4": [], "5": [1, 2, 6, 7], "6": [2, 3, 7], "7": [11, 3, 6, 7], "8": [0, 8, 4], "9": [1, 4, 5, 7, 9, 10]}, "total": 108893186, "total_sparsity": 33.51726342179023}, "training_args": {"_n_gpu": -1, "adafactor": false, "adam_beta1": 0.9, "adam_beta2": 0.999, "adam_epsilon": 1e-08, "dataloader_drop_last": false, "dataloader_num_workers": 0, "dataloader_pin_memory": true, "ddp_find_unused_parameters": null, "debug": false, "deepspeed": null, "disable_tqdm": false, "do_eval": 1, "do_predict": false, "do_train": 1, "eval_accumulation_steps": null, "eval_steps": 5000, "evaluation_strategy": "steps", "fp16": false, "fp16_backend": "auto", "fp16_full_eval": false, "fp16_opt_level": "O1", "gradient_accumulation_steps": 1, "greater_is_better": null, "group_by_length": false, "ignore_data_skip": false, "label_names": null, "label_smoothing_factor": 0.0, "learning_rate": 3e-05, "load_best_model_at_end": false, "local_rank": -1, "logging_dir": "/opt/ml/output", "logging_first_step": false, "logging_steps": 250, "logging_strategy": "steps", "lr_scheduler_type": "linear", "max_grad_norm": 1.0, "max_steps": -1, "metric_for_best_model": null, "no_cuda": false, "num_train_epochs": 20.0, "optimize_model_before_eval": "disabled", "output_dir": "/opt/ml/model", "overwrite_output_dir": 1, "past_index": -1, "per_device_eval_batch_size": 8, "per_device_train_batch_size": 16, "per_gpu_eval_batch_size": null, "per_gpu_train_batch_size": null, "prediction_loss_only": false, "remove_unused_columns": true, "report_to": null, "run_name": "/opt/ml/model", "save_steps": 5000, "save_strategy": "steps", "save_total_limit": 50, "seed": 17, "sharded_ddp": false, "skip_memory_metrics": false, "tpu_metrics_debug": false, "tpu_num_cores": null, "warmup_ratio": 0.0, "warmup_steps": 5400, "weight_decay": 0.0}}, "f1": 88.3744311515211, "fill_rate": 0.5704405984760802, "speedup": 1.1977117757004876}}
{"fill_rate": 0.45844937548225306, "f1": 87.66615713942541, "meta": {"annotate": "45", "cat_fun_name": "is_full_block", "checkpoint": {"config": {"_name_or_path": "bert-base-uncased", "architectures": ["BertForQuestionAnswering"], "attention_probs_dropout_prob": 0.1, "gradient_checkpointing": false, "hidden_act": "gelu", "hidden_dropout_prob": 0.1, "hidden_size": 768, "initializer_range": 0.02, "intermediate_size": 3072, "layer_norm_eps": 1e-12, "max_position_embeddings": 512, "model_type": "bert", "num_attention_heads": 12, "num_hidden_layers": 12, "pad_token_id": 0, "position_embedding_type": "absolute", "type_vocab_size": 2, "vocab_size": 30522}, "eval_metrics": {"exact_match": 80.05676442762535, "f1": 87.66615713942541}, "path": "/data_2to/devel_data/nn_pruning/output/squad_test_aws/aws_nn-pruning-v9-a8-l20--2021-01-20--19-00-06/checkpoint-110660", "sparse_args": {"ampere_pruning_method": "disabled", "attention_block_cols": 8, "attention_block_rows": 8, "attention_lambda": 1.0, "attention_output_with_dense": 0, "attention_pruning_method": "sigmoied_threshold", "bias_mask": true, "dense_block_cols": 8, "dense_block_rows": 8, "dense_lambda": 0.25, "dense_pruning_method": "sigmoied_threshold", "distil_alpha_ce": 0.1, "distil_alpha_teacher": 0.9, "distil_teacher_name_or_path": "csarron/bert-base-uncased-squad-v1", "distil_temperature": 2.0, "final_ampere_temperature": 20.0, "final_threshold": 0.1, "final_warmup": 10, "initial_ampere_temperature": 0.0, "initial_threshold": 0, "initial_warmup": 1, "mask_init": "constant", "mask_scale": 0.0, "mask_scores_learning_rate": 0.01, "regularization": "l1", "regularization_final_lambda": 20.0}, "speed": {"cuda_eval_elapsed_time": 28.86345721435547, "eval_elapsed_time": 36.22357800696045}, "speedup": 1.3371368758339826, "stats": {"layers": {"0": {"linear_attention_nnz": 326336, "linear_attention_total": 2359296, "linear_dense_nnz": 3501120, "linear_dense_total": 4718592, "linear_nnz": 3827456, "linear_total": 7077888, "nnz": 3835760, "total": 7087872}, "1": {"linear_attention_nnz": 487552, "linear_attention_total": 2359296, "linear_dense_nnz": 3653568, "linear_dense_total": 4718592, "linear_nnz": 4141120, "linear_total": 7077888, "nnz": 4149640, "total": 7087872}, "10": {"linear_attention_nnz": 238208, "linear_attention_total": 2359296, "linear_dense_nnz": 756608, "linear_dense_total": 4718592, "linear_nnz": 994816, "linear_total": 7077888, "nnz": 1002184, "total": 7087872}, "11": {"linear_attention_nnz": 141568, "linear_attention_total": 2359296, "linear_dense_nnz": 622848, "linear_dense_total": 4718592, "linear_nnz": 764416, "linear_total": 7077888, "nnz": 771008, "total": 7087872}, "2": {"linear_attention_nnz": 487616, "linear_attention_total": 2359296, "linear_dense_nnz": 3801472, "linear_dense_total": 4718592, "linear_nnz": 4289088, "linear_total": 7077888, "nnz": 4297720, "total": 7087872}, "3": {"linear_attention_nnz": 712832, "linear_attention_total": 2359296, "linear_dense_nnz": 3800064, "linear_dense_total": 4718592, "linear_nnz": 4512896, "linear_total": 7077888, "nnz": 4521776, "total": 7087872}, "4": {"linear_attention_nnz": 646272, "linear_attention_total": 2359296, "linear_dense_nnz": 3743872, "linear_dense_total": 4718592, "linear_nnz": 4390144, "linear_total": 7077888, "nnz": 4398928, "total": 7087872}, "5": {"linear_attention_nnz": 625600, "linear_attention_total": 2359296, "linear_dense_nnz": 3691328, "linear_dense_total": 4718592, "linear_nnz": 4316928, "linear_total": 7077888, "nnz": 4325768, "total": 7087872}, "6": {"linear_attention_nnz": 575808, "linear_attention_total": 2359296, "linear_dense_nnz": 3461056, "linear_dense_total": 4718592, "linear_nnz": 4036864, "linear_total": 7077888, "nnz": 4045744, "total": 7087872}, "7": {"linear_attention_nnz": 579392, "linear_attention_total": 2359296, "linear_dense_nnz": 3012928, "linear_dense_total": 4718592, "linear_nnz": 3592320, "linear_total": 7077888, "nnz": 3601136, "total": 7087872}, "8": {"linear_attention_nnz": 405632, "linear_attention_total": 2359296, "linear_dense_nnz": 2347776, "linear_dense_total": 4718592, "linear_nnz": 2753408, "linear_total": 7077888, "nnz": 2762136, "total": 7087872}, "9": {"linear_attention_nnz": 317440, "linear_attention_total": 2359296, "linear_dense_nnz": 1001344, "linear_dense_total": 4718592, "linear_nnz": 1318784, "linear_total": 7077888, "nnz": 1326816, "total": 7087872}}, "linear_nnz": 38938240, "linear_sparsity": 54.1550624517747, "linear_total": 84934656, "nnz": 62877338, "pruned_heads": {"0": [2, 4, 5, 6, 9, 11], "1": [0, 2, 3, 5, 6, 8, 9], "10": [1, 4, 5, 6, 7, 8, 9], "11": [0, 3, 5, 6, 7, 8, 10, 11], "2": [1, 2, 4, 7, 8], "3": [2, 10, 4, 6], "4": [0, 1, 2, 6, 11], "5": [1, 2, 6, 7, 11], "6": [0, 2, 3, 7], "7": [1, 3, 6, 7, 11], "8": [0, 8, 4, 5], "9": [1, 3, 4, 5, 7, 9, 10]}, "total": 108893186, "total_sparsity": 42.257784614732465}, "training_args": {"_n_gpu": -1, "adafactor": false, "adam_beta1": 0.9, "adam_beta2": 0.999, "adam_epsilon": 1e-08, "dataloader_drop_last": false, "dataloader_num_workers": 0, "dataloader_pin_memory": true, "ddp_find_unused_parameters": null, "debug": false, "deepspeed": null, "disable_tqdm": false, "do_eval": 1, "do_predict": false, "do_train": 1, "eval_accumulation_steps": null, "eval_steps": 5000, "evaluation_strategy": "steps", "fp16": false, "fp16_backend": "auto", "fp16_full_eval": false, "fp16_opt_level": "O1", "gradient_accumulation_steps": 1, "greater_is_better": null, "group_by_length": false, "ignore_data_skip": false, "label_names": null, "label_smoothing_factor": 0.0, "learning_rate": 3e-05, "load_best_model_at_end": false, "local_rank": -1, "logging_dir": "/opt/ml/output", "logging_first_step": false, "logging_steps": 250, "logging_strategy": "steps", "lr_scheduler_type": "linear", "max_grad_norm": 1.0, "max_steps": -1, "metric_for_best_model": null, "no_cuda": false, "num_train_epochs": 20.0, "optimize_model_before_eval": "disabled", "output_dir": "/opt/ml/model", "overwrite_output_dir": 1, "past_index": -1, "per_device_eval_batch_size": 8, "per_device_train_batch_size": 16, "per_gpu_eval_batch_size": null, "per_gpu_train_batch_size": null, "prediction_loss_only": false, "remove_unused_columns": true, "report_to": null, "run_name": "/opt/ml/model", "save_steps": 5000, "save_strategy": "steps", "save_total_limit": 50, "seed": 17, "sharded_ddp": false, "skip_memory_metrics": false, "tpu_metrics_debug": false, "tpu_num_cores": null, "warmup_ratio": 0.0, "warmup_steps": 5400, "weight_decay": 0.0}}, "f1": 87.66615713942541, "fill_rate": 0.45844937548225306, "speedup": 1.3371368758339826}}
{"fill_rate": 0.3447129991319444, "f1": 86.75922108224064, "meta": {"annotate": "34", "cat_fun_name": "is_full_block", "checkpoint": {"config": {"_name_or_path": "bert-base-uncased", "architectures": ["BertForQuestionAnswering"], "attention_probs_dropout_prob": 0.1, "gradient_checkpointing": false, "hidden_act": "gelu", "hidden_dropout_prob": 0.1, "hidden_size": 768, "initializer_range": 0.02, "intermediate_size": 3072, "layer_norm_eps": 1e-12, "max_position_embeddings": 512, "model_type": "bert", "num_attention_heads": 12, "num_hidden_layers": 12, "pad_token_id": 0, "position_embedding_type": "absolute", "type_vocab_size": 2, "vocab_size": 30522}, "eval_metrics": {"exact_match": 78.76064333017976, "f1": 86.75922108224064}, "path": "/data_2to/devel_data/nn_pruning/output/squad_test_aws/aws_nn-pruning-v9-a8-l40--2021-01-20--19-00-35/checkpoint-110660", "sparse_args": {"ampere_pruning_method": "disabled", "attention_block_cols": 8, "attention_block_rows": 8, "attention_lambda": 1.0, "attention_output_with_dense": 0, "attention_pruning_method": "sigmoied_threshold", "bias_mask": true, "dense_block_cols": 8, "dense_block_rows": 8, "dense_lambda": 0.25, "dense_pruning_method": "sigmoied_threshold", "distil_alpha_ce": 0.1, "distil_alpha_teacher": 0.9, "distil_teacher_name_or_path": "csarron/bert-base-uncased-squad-v1", "distil_temperature": 2.0, "final_ampere_temperature": 20.0, "final_threshold": 0.1, "final_warmup": 10, "initial_ampere_temperature": 0.0, "initial_threshold": 0, "initial_warmup": 1, "mask_init": "constant", "mask_scale": 0.0, "mask_scores_learning_rate": 0.01, "regularization": "l1", "regularization_final_lambda": 40.0}, "speed": {"cuda_eval_elapsed_time": 25.933858947753908, "eval_elapsed_time": 33.4375456799753}, "speedup": 1.4881855061802785, "stats": {"layers": {"0": {"linear_attention_nnz": 241280, "linear_attention_total": 2359296, "linear_dense_nnz": 2752704, "linear_dense_total": 4718592, "linear_nnz": 2993984, "linear_total": 7077888, "nnz": 3002184, "total": 7087872}, "1": {"linear_attention_nnz": 379584, "linear_attention_total": 2359296, "linear_dense_nnz": 2951104, "linear_dense_total": 4718592, "linear_nnz": 3330688, "linear_total": 7077888, "nnz": 3338984, "total": 7087872}, "10": {"linear_attention_nnz": 172352, "linear_attention_total": 2359296, "linear_dense_nnz": 419008, "linear_dense_total": 4718592, "linear_nnz": 591360, "linear_total": 7077888, "nnz": 597800, "total": 7087872}, "11": {"linear_attention_nnz": 104768, "linear_attention_total": 2359296, "linear_dense_nnz": 388288, "linear_dense_total": 4718592, "linear_nnz": 493056, "linear_total": 7077888, "nnz": 499016, "total": 7087872}, "2": {"linear_attention_nnz": 322880, "linear_attention_total": 2359296, "linear_dense_nnz": 3194240, "linear_dense_total": 4718592, "linear_nnz": 3517120, "linear_total": 7077888, "nnz": 3525400, "total": 7087872}, "3": {"linear_attention_nnz": 565440, "linear_attention_total": 2359296, "linear_dense_nnz": 3155136, "linear_dense_total": 4718592, "linear_nnz": 3720576, "linear_total": 7077888, "nnz": 3729376, "total": 7087872}, "4": {"linear_attention_nnz": 390400, "linear_attention_total": 2359296, "linear_dense_nnz": 3064768, "linear_dense_total": 4718592, "linear_nnz": 3455168, "linear_total": 7077888, "nnz": 3463576, "total": 7087872}, "5": {"linear_attention_nnz": 406592, "linear_attention_total": 2359296, "linear_dense_nnz": 2993600, "linear_dense_total": 4718592, "linear_nnz": 3400192, "linear_total": 7077888, "nnz": 3408712, "total": 7087872}, "6": {"linear_attention_nnz": 356480, "linear_attention_total": 2359296, "linear_dense_nnz": 2631680, "linear_dense_total": 4718592, "linear_nnz": 2988160, "linear_total": 7077888, "nnz": 2996696, "total": 7087872}, "7": {"linear_attention_nnz": 409920, "linear_attention_total": 2359296, "linear_dense_nnz": 2067776, "linear_dense_total": 4718592, "linear_nnz": 2477696, "linear_total": 7077888, "nnz": 2486200, "total": 7087872}, "8": {"linear_attention_nnz": 242048, "linear_attention_total": 2359296, "linear_dense_nnz": 1370368, "linear_dense_total": 4718592, "linear_nnz": 1612416, "linear_total": 7077888, "nnz": 1620288, "total": 7087872}, "9": {"linear_attention_nnz": 224896, "linear_attention_total": 2359296, "linear_dense_nnz": 472768, "linear_dense_total": 4718592, "linear_nnz": 697664, "linear_total": 7077888, "nnz": 704192, "total": 7087872}}, "linear_nnz": 29278080, "linear_sparsity": 65.52870008680556, "linear_total": 84934656, "nnz": 53211146, "pruned_heads": {"0": [2, 4, 5, 6, 7, 9, 11], "1": [0, 2, 3, 5, 6, 8, 9], "10": [1, 4, 5, 6, 7, 8, 9], "11": [0, 2, 3, 5, 6, 7, 8, 10, 11], "2": [1, 2, 3, 4, 7, 8, 11], "3": [2, 4, 6, 7, 10], "4": [0, 1, 2, 6, 7, 8, 11], "5": [1, 2, 5, 6, 7, 11], "6": [0, 2, 3, 7, 10], "7": [1, 3, 6, 7, 11], "8": [0, 2, 3, 4, 5, 6, 8], "9": [1, 3, 4, 5, 7, 9, 10]}, "total": 108893186, "total_sparsity": 51.13454941064908}, "training_args": {"_n_gpu": -1, "adafactor": false, "adam_beta1": 0.9, "adam_beta2": 0.999, "adam_epsilon": 1e-08, "dataloader_drop_last": false, "dataloader_num_workers": 0, "dataloader_pin_memory": true, "ddp_find_unused_parameters": null, "debug": false, "deepspeed": null, "disable_tqdm": false, "do_eval": 1, "do_predict": false, "do_train": 1, "eval_accumulation_steps": null, "eval_steps": 5000, "evaluation_strategy": "steps", "fp16": false, "fp16_backend": "auto", "fp16_full_eval": false, "fp16_opt_level": "O1", "gradient_accumulation_steps": 1, "greater_is_better": null, "group_by_length": false, "ignore_data_skip": false, "label_names": null, "label_smoothing_factor": 0.0, "learning_rate": 3e-05, "load_best_model_at_end": false, "local_rank": -1, "logging_dir": "/opt/ml/output", "logging_first_step": false, "logging_steps": 250, "logging_strategy": "steps", "lr_scheduler_type": "linear", "max_grad_norm": 1.0, "max_steps": -1, "metric_for_best_model": null, "no_cuda": false, "num_train_epochs": 20.0, "optimize_model_before_eval": "disabled", "output_dir": "/opt/ml/model", "overwrite_output_dir": 1, "past_index": -1, "per_device_eval_batch_size": 8, "per_device_train_batch_size": 16, "per_gpu_eval_batch_size": null, "per_gpu_train_batch_size": null, "prediction_loss_only": false, "remove_unused_columns": true, "report_to": null, "run_name": "/opt/ml/model", "save_steps": 5000, "save_strategy": "steps", "save_total_limit": 50, "seed": 17, "sharded_ddp": false, "skip_memory_metrics": false, "tpu_metrics_debug": false, "tpu_num_cores": null, "warmup_ratio": 0.0, "warmup_steps": 5400, "weight_decay": 0.0}}, "f1": 86.75922108224064, "fill_rate": 0.3447129991319444, "speedup": 1.4881855061802785}}
