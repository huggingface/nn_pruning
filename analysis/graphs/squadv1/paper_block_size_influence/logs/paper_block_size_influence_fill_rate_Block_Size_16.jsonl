{"fill_rate": 0.5761748890817902, "f1": 88.34112193061533, "meta": {"annotate": "57", "cat_fun_name": "is_full_block", "checkpoint": {"config": {"_name_or_path": "bert-base-uncased", "architectures": ["BertForQuestionAnswering"], "attention_probs_dropout_prob": 0.1, "gradient_checkpointing": false, "hidden_act": "gelu", "hidden_dropout_prob": 0.1, "hidden_size": 768, "initializer_range": 0.02, "intermediate_size": 3072, "layer_norm_eps": 1e-12, "max_position_embeddings": 512, "model_type": "bert", "num_attention_heads": 12, "num_hidden_layers": 12, "pad_token_id": 0, "position_embedding_type": "absolute", "type_vocab_size": 2, "vocab_size": 30522}, "eval_metrics": {"exact_match": 80.93661305581836, "f1": 88.34112193061533}, "path": "/data_2to/devel_data/nn_pruning/output/squad_test_aws/aws_nn-pruning-v9-a16-l10--2021-01-20--18-58-11/checkpoint-110660", "sparse_args": {"ampere_pruning_method": "disabled", "attention_block_cols": 16, "attention_block_rows": 16, "attention_lambda": 1.0, "attention_output_with_dense": 0, "attention_pruning_method": "sigmoied_threshold", "bias_mask": true, "dense_block_cols": 16, "dense_block_rows": 16, "dense_lambda": 0.25, "dense_pruning_method": "sigmoied_threshold", "distil_alpha_ce": 0.1, "distil_alpha_teacher": 0.9, "distil_teacher_name_or_path": "csarron/bert-base-uncased-squad-v1", "distil_temperature": 2.0, "final_ampere_temperature": 20.0, "final_threshold": 0.1, "final_warmup": 10, "initial_ampere_temperature": 0.0, "initial_threshold": 0, "initial_warmup": 1, "mask_init": "constant", "mask_scale": 0.0, "mask_scores_learning_rate": 0.01, "regularization": "l1", "regularization_final_lambda": 10.0}, "speed": {"cuda_eval_elapsed_time": 30.13610975646973, "eval_elapsed_time": 37.54532916797325}, "speedup": 1.2806693802635063, "stats": {"layers": {"0": {"linear_attention_nnz": 517888, "linear_attention_total": 2359296, "linear_dense_nnz": 4068608, "linear_dense_total": 4718592, "linear_nnz": 4586496, "linear_total": 7077888, "nnz": 4594896, "total": 7087872}, "1": {"linear_attention_nnz": 641536, "linear_attention_total": 2359296, "linear_dense_nnz": 4202752, "linear_dense_total": 4718592, "linear_nnz": 4844288, "linear_total": 7077888, "nnz": 4852816, "total": 7087872}, "10": {"linear_attention_nnz": 415488, "linear_attention_total": 2359296, "linear_dense_nnz": 1090304, "linear_dense_total": 4718592, "linear_nnz": 1505792, "linear_total": 7077888, "nnz": 1513344, "total": 7087872}, "11": {"linear_attention_nnz": 254720, "linear_attention_total": 2359296, "linear_dense_nnz": 947200, "linear_dense_total": 4718592, "linear_nnz": 1201920, "linear_total": 7077888, "nnz": 1208720, "total": 7087872}, "2": {"linear_attention_nnz": 841472, "linear_attention_total": 2359296, "linear_dense_nnz": 4313856, "linear_dense_total": 4718592, "linear_nnz": 5155328, "linear_total": 7077888, "nnz": 5164240, "total": 7087872}, "3": {"linear_attention_nnz": 1072896, "linear_attention_total": 2359296, "linear_dense_nnz": 4336128, "linear_dense_total": 4718592, "linear_nnz": 5409024, "linear_total": 7077888, "nnz": 5418160, "total": 7087872}, "4": {"linear_attention_nnz": 1068800, "linear_attention_total": 2359296, "linear_dense_nnz": 4317184, "linear_dense_total": 4718592, "linear_nnz": 5385984, "linear_total": 7077888, "nnz": 5395264, "total": 7087872}, "5": {"linear_attention_nnz": 961792, "linear_attention_total": 2359296, "linear_dense_nnz": 4311040, "linear_dense_total": 4718592, "linear_nnz": 5272832, "linear_total": 7077888, "nnz": 5281824, "total": 7087872}, "6": {"linear_attention_nnz": 986880, "linear_attention_total": 2359296, "linear_dense_nnz": 4141568, "linear_dense_total": 4718592, "linear_nnz": 5128448, "linear_total": 7077888, "nnz": 5137632, "total": 7087872}, "7": {"linear_attention_nnz": 905472, "linear_attention_total": 2359296, "linear_dense_nnz": 3820032, "linear_dense_total": 4718592, "linear_nnz": 4725504, "linear_total": 7077888, "nnz": 4734512, "total": 7087872}, "8": {"linear_attention_nnz": 756224, "linear_attention_total": 2359296, "linear_dense_nnz": 3085568, "linear_dense_total": 4718592, "linear_nnz": 3841792, "linear_total": 7077888, "nnz": 3850720, "total": 7087872}, "9": {"linear_attention_nnz": 463360, "linear_attention_total": 2359296, "linear_dense_nnz": 1416448, "linear_dense_total": 4718592, "linear_nnz": 1879808, "linear_total": 7077888, "nnz": 1887632, "total": 7087872}}, "linear_nnz": 48937216, "linear_sparsity": 42.38251109182099, "linear_total": 84934656, "nnz": 72878482, "pruned_heads": {"0": [2, 4, 5, 6, 7, 9, 11], "1": [0, 2, 3, 5, 6, 8, 9], "10": [1, 4, 5, 6, 7, 8], "11": [0, 2, 5, 6, 7, 8, 10, 11], "2": [8, 4, 7], "3": [2, 4, 6], "4": [1, 2], "5": [1, 2, 6, 7, 11], "6": [2, 3, 7], "7": [11, 3, 6, 7], "8": [0, 8, 4], "9": [1, 3, 4, 5, 7, 9, 10]}, "total": 108893186, "total_sparsity": 33.07342297799975}, "training_args": {"_n_gpu": -1, "adafactor": false, "adam_beta1": 0.9, "adam_beta2": 0.999, "adam_epsilon": 1e-08, "dataloader_drop_last": false, "dataloader_num_workers": 0, "dataloader_pin_memory": true, "ddp_find_unused_parameters": null, "debug": false, "deepspeed": null, "disable_tqdm": false, "do_eval": 1, "do_predict": false, "do_train": 1, "eval_accumulation_steps": null, "eval_steps": 5000, "evaluation_strategy": "steps", "fp16": false, "fp16_backend": "auto", "fp16_full_eval": false, "fp16_opt_level": "O1", "gradient_accumulation_steps": 1, "greater_is_better": null, "group_by_length": false, "ignore_data_skip": false, "label_names": null, "label_smoothing_factor": 0.0, "learning_rate": 3e-05, "load_best_model_at_end": false, "local_rank": -1, "logging_dir": "/opt/ml/output", "logging_first_step": false, "logging_steps": 250, "logging_strategy": "steps", "lr_scheduler_type": "linear", "max_grad_norm": 1.0, "max_steps": -1, "metric_for_best_model": null, "no_cuda": false, "num_train_epochs": 20.0, "optimize_model_before_eval": "disabled", "output_dir": "/opt/ml/model", "overwrite_output_dir": 1, "past_index": -1, "per_device_eval_batch_size": 8, "per_device_train_batch_size": 16, "per_gpu_eval_batch_size": null, "per_gpu_train_batch_size": null, "prediction_loss_only": false, "remove_unused_columns": true, "report_to": null, "run_name": "/opt/ml/model", "save_steps": 5000, "save_strategy": "steps", "save_total_limit": 50, "seed": 17, "sharded_ddp": false, "skip_memory_metrics": false, "tpu_metrics_debug": false, "tpu_num_cores": null, "warmup_ratio": 0.0, "warmup_steps": 5400, "weight_decay": 0.0}}, "f1": 88.34112193061533, "fill_rate": 0.5761748890817902, "speedup": 1.2806693802635063}}
{"fill_rate": 0.3578679591049382, "f1": 87.65780769915727, "meta": {"annotate": "35", "cat_fun_name": "is_full_block", "checkpoint": {"config": {"_name_or_path": "bert-base-uncased", "architectures": ["BertForQuestionAnswering"], "attention_probs_dropout_prob": 0.1, "gradient_checkpointing": false, "hidden_act": "gelu", "hidden_dropout_prob": 0.1, "hidden_size": 768, "initializer_range": 0.02, "intermediate_size": 3072, "layer_norm_eps": 1e-12, "max_position_embeddings": 512, "model_type": "bert", "num_attention_heads": 12, "num_hidden_layers": 12, "pad_token_id": 0, "position_embedding_type": "absolute", "type_vocab_size": 2, "vocab_size": 30522}, "eval_metrics": {"exact_match": 80.00946073793756, "f1": 87.65780769915727}, "path": "/data_2to/devel_data/nn_pruning/output/squad_test_aws/aws_nn-pruning-v11-a16-l10-dl1--2021-01-24--15-45-00/checkpoint-110660", "sparse_args": {"ampere_pruning_method": "disabled", "attention_block_cols": 16, "attention_block_rows": 16, "attention_lambda": 1.0, "attention_output_with_dense": 0, "attention_pruning_method": "sigmoied_threshold", "bias_mask": true, "dense_block_cols": 16, "dense_block_rows": 16, "dense_lambda": 1.0, "dense_pruning_method": "sigmoied_threshold", "distil_alpha_ce": 0.1, "distil_alpha_teacher": 0.9, "distil_teacher_name_or_path": "csarron/bert-base-uncased-squad-v1", "distil_temperature": 2.0, "final_ampere_temperature": 20.0, "final_threshold": 0.1, "final_warmup": 10, "initial_ampere_temperature": 0.0, "initial_threshold": 0, "initial_warmup": 1, "mask_init": "constant", "mask_scale": 0.0, "mask_scores_learning_rate": 0.01, "regularization": "l1", "regularization_final_lambda": 10.0}, "speed": {"cuda_eval_elapsed_time": 26.317300163269042, "eval_elapsed_time": 33.56822411296889}, "speedup": 1.4665027478478643, "stats": {"layers": {"0": {"linear_attention_nnz": 720896, "linear_attention_total": 2359296, "linear_dense_nnz": 1657600, "linear_dense_total": 4718592, "linear_nnz": 2378496, "linear_total": 7077888, "nnz": 2386160, "total": 7087872}, "1": {"linear_attention_nnz": 719872, "linear_attention_total": 2359296, "linear_dense_nnz": 2046464, "linear_dense_total": 4718592, "linear_nnz": 2766336, "linear_total": 7077888, "nnz": 2774128, "total": 7087872}, "10": {"linear_attention_nnz": 450560, "linear_attention_total": 2359296, "linear_dense_nnz": 272128, "linear_dense_total": 4718592, "linear_nnz": 722688, "linear_total": 7077888, "nnz": 728816, "total": 7087872}, "11": {"linear_attention_nnz": 307456, "linear_attention_total": 2359296, "linear_dense_nnz": 311808, "linear_dense_total": 4718592, "linear_nnz": 619264, "linear_total": 7077888, "nnz": 625232, "total": 7087872}, "2": {"linear_attention_nnz": 1058304, "linear_attention_total": 2359296, "linear_dense_nnz": 2721792, "linear_dense_total": 4718592, "linear_nnz": 3780096, "linear_total": 7077888, "nnz": 3788768, "total": 7087872}, "3": {"linear_attention_nnz": 1227776, "linear_attention_total": 2359296, "linear_dense_nnz": 2707200, "linear_dense_total": 4718592, "linear_nnz": 3934976, "linear_total": 7077888, "nnz": 3943840, "total": 7087872}, "4": {"linear_attention_nnz": 1367808, "linear_attention_total": 2359296, "linear_dense_nnz": 2789888, "linear_dense_total": 4718592, "linear_nnz": 4157696, "linear_total": 7077888, "nnz": 4166848, "total": 7087872}, "5": {"linear_attention_nnz": 1258240, "linear_attention_total": 2359296, "linear_dense_nnz": 2672384, "linear_dense_total": 4718592, "linear_nnz": 3930624, "linear_total": 7077888, "nnz": 3939824, "total": 7087872}, "6": {"linear_attention_nnz": 1130496, "linear_attention_total": 2359296, "linear_dense_nnz": 2136064, "linear_dense_total": 4718592, "linear_nnz": 3266560, "linear_total": 7077888, "nnz": 3275008, "total": 7087872}, "7": {"linear_attention_nnz": 988928, "linear_attention_total": 2359296, "linear_dense_nnz": 1491200, "linear_dense_total": 4718592, "linear_nnz": 2480128, "linear_total": 7077888, "nnz": 2487824, "total": 7087872}, "8": {"linear_attention_nnz": 888576, "linear_attention_total": 2359296, "linear_dense_nnz": 653568, "linear_dense_total": 4718592, "linear_nnz": 1542144, "linear_total": 7077888, "nnz": 1549312, "total": 7087872}, "9": {"linear_attention_nnz": 567296, "linear_attention_total": 2359296, "linear_dense_nnz": 249088, "linear_dense_total": 4718592, "linear_nnz": 816384, "linear_total": 7077888, "nnz": 822432, "total": 7087872}}, "linear_nnz": 30395392, "linear_sparsity": 64.21320408950618, "linear_total": 84934656, "nnz": 54326914, "pruned_heads": {"0": [2, 4, 5, 6, 7], "1": [0, 2, 3, 5, 6, 8], "10": [1, 4, 5, 6, 7, 8], "11": [0, 5, 6, 8, 11], "2": [8, 4, 7], "3": [2, 4, 6], "4": [2], "5": [1, 2], "6": [2, 3, 7], "7": [11, 3, 6, 7], "8": [0, 8, 4], "9": [1, 4, 5, 7, 9, 10]}, "total": 108893186, "total_sparsity": 50.10990494850615}, "training_args": {"_n_gpu": -1, "adafactor": false, "adam_beta1": 0.9, "adam_beta2": 0.999, "adam_epsilon": 1e-08, "dataloader_drop_last": false, "dataloader_num_workers": 0, "dataloader_pin_memory": true, "ddp_find_unused_parameters": null, "debug": false, "deepspeed": null, "disable_tqdm": false, "do_eval": 1, "do_predict": false, "do_train": 1, "eval_accumulation_steps": null, "eval_steps": 5000, "evaluation_strategy": "steps", "fp16": false, "fp16_backend": "auto", "fp16_full_eval": false, "fp16_opt_level": "O1", "gradient_accumulation_steps": 1, "greater_is_better": null, "group_by_length": false, "ignore_data_skip": false, "label_names": null, "label_smoothing_factor": 0.0, "learning_rate": 3e-05, "load_best_model_at_end": false, "local_rank": -1, "logging_dir": "/opt/ml/output", "logging_first_step": false, "logging_steps": 250, "logging_strategy": "steps", "lr_scheduler_type": "linear", "max_grad_norm": 1.0, "max_steps": -1, "metric_for_best_model": null, "no_cuda": false, "num_train_epochs": 20.0, "optimize_model_before_eval": "disabled", "output_dir": "/opt/ml/model", "overwrite_output_dir": 1, "past_index": -1, "per_device_eval_batch_size": 8, "per_device_train_batch_size": 16, "per_gpu_eval_batch_size": null, "per_gpu_train_batch_size": null, "prediction_loss_only": false, "remove_unused_columns": true, "report_to": null, "run_name": "/opt/ml/model", "save_steps": 5000, "save_strategy": "steps", "save_total_limit": 50, "seed": 17, "sharded_ddp": false, "skip_memory_metrics": false, "tpu_metrics_debug": false, "tpu_num_cores": null, "warmup_ratio": 0.0, "warmup_steps": 5400, "weight_decay": 0.0}}, "f1": 87.65780769915727, "fill_rate": 0.3578679591049382, "speedup": 1.4665027478478643}}
{"fill_rate": 0.23011007426697527, "f1": 86.57822332702295, "meta": {"annotate": "23", "cat_fun_name": "is_full_block", "checkpoint": {"config": {"_name_or_path": "bert-base-uncased", "architectures": ["BertForQuestionAnswering"], "attention_probs_dropout_prob": 0.1, "gradient_checkpointing": false, "hidden_act": "gelu", "hidden_dropout_prob": 0.1, "hidden_size": 768, "initializer_range": 0.02, "intermediate_size": 3072, "layer_norm_eps": 1e-12, "max_position_embeddings": 512, "model_type": "bert", "num_attention_heads": 12, "num_hidden_layers": 12, "pad_token_id": 0, "position_embedding_type": "absolute", "type_vocab_size": 2, "vocab_size": 30522}, "eval_metrics": {"exact_match": 78.62819299905392, "f1": 86.57822332702295}, "path": "/data_2to/devel_data/nn_pruning/output/squad_test_aws/aws_nn-pruning-v11-a16-l20-dl1--2021-01-24--15-45-27/checkpoint-110660", "sparse_args": {"ampere_pruning_method": "disabled", "attention_block_cols": 16, "attention_block_rows": 16, "attention_lambda": 1.0, "attention_output_with_dense": 0, "attention_pruning_method": "sigmoied_threshold", "bias_mask": true, "dense_block_cols": 16, "dense_block_rows": 16, "dense_lambda": 1.0, "dense_pruning_method": "sigmoied_threshold", "distil_alpha_ce": 0.1, "distil_alpha_teacher": 0.9, "distil_teacher_name_or_path": "csarron/bert-base-uncased-squad-v1", "distil_temperature": 2.0, "final_ampere_temperature": 20.0, "final_threshold": 0.1, "final_warmup": 10, "initial_ampere_temperature": 0.0, "initial_threshold": 0, "initial_warmup": 1, "mask_init": "constant", "mask_scale": 0.0, "mask_scores_learning_rate": 0.01, "regularization": "l1", "regularization_final_lambda": 20.0}, "speed": {"cuda_eval_elapsed_time": 21.08596396636963, "eval_elapsed_time": 28.310240568593144}, "speedup": 1.8303357184393354, "stats": {"layers": {"0": {"linear_attention_nnz": 484864, "linear_attention_total": 2359296, "linear_dense_nnz": 821248, "linear_dense_total": 4718592, "linear_nnz": 1306112, "linear_total": 7077888, "nnz": 1312512, "total": 7087872}, "1": {"linear_attention_nnz": 604160, "linear_attention_total": 2359296, "linear_dense_nnz": 1247488, "linear_dense_total": 4718592, "linear_nnz": 1851648, "linear_total": 7077888, "nnz": 1858512, "total": 7087872}, "10": {"linear_attention_nnz": 343296, "linear_attention_total": 2359296, "linear_dense_nnz": 200704, "linear_dense_total": 4718592, "linear_nnz": 544000, "linear_total": 7077888, "nnz": 549840, "total": 7087872}, "11": {"linear_attention_nnz": 215296, "linear_attention_total": 2359296, "linear_dense_nnz": 216320, "linear_dense_total": 4718592, "linear_nnz": 431616, "linear_total": 7077888, "nnz": 437072, "total": 7087872}, "2": {"linear_attention_nnz": 813312, "linear_attention_total": 2359296, "linear_dense_nnz": 1803264, "linear_dense_total": 4718592, "linear_nnz": 2616576, "linear_total": 7077888, "nnz": 2624192, "total": 7087872}, "3": {"linear_attention_nnz": 1050880, "linear_attention_total": 2359296, "linear_dense_nnz": 1707520, "linear_dense_total": 4718592, "linear_nnz": 2758400, "linear_total": 7077888, "nnz": 2766304, "total": 7087872}, "4": {"linear_attention_nnz": 1007104, "linear_attention_total": 2359296, "linear_dense_nnz": 1634816, "linear_dense_total": 4718592, "linear_nnz": 2641920, "linear_total": 7077888, "nnz": 2649840, "total": 7087872}, "5": {"linear_attention_nnz": 769792, "linear_attention_total": 2359296, "linear_dense_nnz": 1574400, "linear_dense_total": 4718592, "linear_nnz": 2344192, "linear_total": 7077888, "nnz": 2351712, "total": 7087872}, "6": {"linear_attention_nnz": 749056, "linear_attention_total": 2359296, "linear_dense_nnz": 1194496, "linear_dense_total": 4718592, "linear_nnz": 1943552, "linear_total": 7077888, "nnz": 1950752, "total": 7087872}, "7": {"linear_attention_nnz": 765440, "linear_attention_total": 2359296, "linear_dense_nnz": 861440, "linear_dense_total": 4718592, "linear_nnz": 1626880, "linear_total": 7077888, "nnz": 1633760, "total": 7087872}, "8": {"linear_attention_nnz": 645888, "linear_attention_total": 2359296, "linear_dense_nnz": 319488, "linear_dense_total": 4718592, "linear_nnz": 965376, "linear_total": 7077888, "nnz": 971712, "total": 7087872}, "9": {"linear_attention_nnz": 368128, "linear_attention_total": 2359296, "linear_dense_nnz": 145920, "linear_dense_total": 4718592, "linear_nnz": 514048, "linear_total": 7077888, "nnz": 519680, "total": 7087872}}, "linear_nnz": 19544320, "linear_sparsity": 76.98899257330247, "linear_total": 84934656, "nnz": 43464610, "pruned_heads": {"0": [0, 2, 4, 5, 6, 7, 9, 11], "1": [0, 2, 3, 5, 6, 8, 9], "10": [1, 4, 5, 6, 7, 8], "11": [0, 2, 5, 6, 8, 10, 11], "2": [8, 11, 4, 7], "3": [2, 4, 6], "4": [0, 2], "5": [1, 2, 6, 7, 11], "6": [0, 2, 3, 7], "7": [1, 3, 6, 7, 11], "8": [0, 8, 4], "9": [1, 3, 4, 5, 7, 9, 10]}, "total": 108893186, "total_sparsity": 60.08509660099393}, "training_args": {"_n_gpu": -1, "adafactor": false, "adam_beta1": 0.9, "adam_beta2": 0.999, "adam_epsilon": 1e-08, "dataloader_drop_last": false, "dataloader_num_workers": 0, "dataloader_pin_memory": true, "ddp_find_unused_parameters": null, "debug": false, "deepspeed": null, "disable_tqdm": false, "do_eval": 1, "do_predict": false, "do_train": 1, "eval_accumulation_steps": null, "eval_steps": 5000, "evaluation_strategy": "steps", "fp16": false, "fp16_backend": "auto", "fp16_full_eval": false, "fp16_opt_level": "O1", "gradient_accumulation_steps": 1, "greater_is_better": null, "group_by_length": false, "ignore_data_skip": false, "label_names": null, "label_smoothing_factor": 0.0, "learning_rate": 3e-05, "load_best_model_at_end": false, "local_rank": -1, "logging_dir": "/opt/ml/output", "logging_first_step": false, "logging_steps": 250, "logging_strategy": "steps", "lr_scheduler_type": "linear", "max_grad_norm": 1.0, "max_steps": -1, "metric_for_best_model": null, "no_cuda": false, "num_train_epochs": 20.0, "optimize_model_before_eval": "disabled", "output_dir": "/opt/ml/model", "overwrite_output_dir": 1, "past_index": -1, "per_device_eval_batch_size": 8, "per_device_train_batch_size": 16, "per_gpu_eval_batch_size": null, "per_gpu_train_batch_size": null, "prediction_loss_only": false, "remove_unused_columns": true, "report_to": null, "run_name": "/opt/ml/model", "save_steps": 5000, "save_strategy": "steps", "save_total_limit": 50, "seed": 17, "sharded_ddp": false, "skip_memory_metrics": false, "tpu_metrics_debug": false, "tpu_num_cores": null, "warmup_ratio": 0.0, "warmup_steps": 5400, "weight_decay": 0.0}, "unopt_eval_metrics": {"exact_match": 78.7511825922422, "f1": 86.70333537174074}}, "f1": 86.57822332702295, "fill_rate": 0.23011007426697527, "speedup": 1.8303357184393354}}
