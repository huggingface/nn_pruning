{"fill_rate": 0.5704405984760802, "f1": 88.3744311515211, "meta": {"annotate": "57", "cat_fun_name": "is_full_block", "checkpoint": {"config": {"_name_or_path": "bert-base-uncased", "architectures": ["BertForQuestionAnswering"], "attention_probs_dropout_prob": 0.1, "gradient_checkpointing": false, "hidden_act": "gelu", "hidden_dropout_prob": 0.1, "hidden_size": 768, "initializer_range": 0.02, "intermediate_size": 3072, "layer_norm_eps": 1e-12, "max_position_embeddings": 512, "model_type": "bert", "num_attention_heads": 12, "num_hidden_layers": 12, "pad_token_id": 0, "position_embedding_type": "absolute", "type_vocab_size": 2, "vocab_size": 30522}, "eval_metrics": {"exact_match": 81.10690633869442, "f1": 88.3744311515211}, "path": "/data_2to/devel_data/nn_pruning/output/squad_test_aws/aws_nn-pruning-v9-a8-l10--2021-01-20--18-59-37/checkpoint-110000", "sparse_args": {"ampere_pruning_method": "disabled", "attention_block_cols": 8, "attention_block_rows": 8, "attention_lambda": 1.0, "attention_output_with_dense": 0, "attention_pruning_method": "sigmoied_threshold", "bias_mask": true, "dense_block_cols": 8, "dense_block_rows": 8, "dense_lambda": 0.25, "dense_pruning_method": "sigmoied_threshold", "distil_alpha_ce": 0.1, "distil_alpha_teacher": 0.9, "distil_teacher_name_or_path": "csarron/bert-base-uncased-squad-v1", "distil_temperature": 2.0, "final_ampere_temperature": 20.0, "final_threshold": 0.1, "final_warmup": 10, "initial_ampere_temperature": 0.0, "initial_threshold": 0, "initial_warmup": 1, "mask_init": "constant", "mask_scale": 0.0, "mask_scores_learning_rate": 0.01, "regularization": "l1", "regularization_final_lambda": 10.0}, "speed": {"cuda_eval_elapsed_time": 32.22343955230713, "eval_elapsed_time": 39.62965265568346}, "speedup": 1.1977117757004876, "stats": {"layers": {"0": {"linear_attention_nnz": 446080, "linear_attention_total": 2359296, "linear_dense_nnz": 4004864, "linear_dense_total": 4718592, "linear_nnz": 4450944, "linear_total": 7077888, "nnz": 4459384, "total": 7087872}, "1": {"linear_attention_nnz": 597312, "linear_attention_total": 2359296, "linear_dense_nnz": 4076928, "linear_dense_total": 4718592, "linear_nnz": 4674240, "linear_total": 7077888, "nnz": 4682824, "total": 7087872}, "10": {"linear_attention_nnz": 362048, "linear_attention_total": 2359296, "linear_dense_nnz": 1517376, "linear_dense_total": 4718592, "linear_nnz": 1879424, "linear_total": 7077888, "nnz": 1888000, "total": 7087872}, "11": {"linear_attention_nnz": 217216, "linear_attention_total": 2359296, "linear_dense_nnz": 1063808, "linear_dense_total": 4718592, "linear_nnz": 1281024, "linear_total": 7077888, "nnz": 1288536, "total": 7087872}, "2": {"linear_attention_nnz": 800192, "linear_attention_total": 2359296, "linear_dense_nnz": 4155456, "linear_dense_total": 4718592, "linear_nnz": 4955648, "linear_total": 7077888, "nnz": 4964752, "total": 7087872}, "3": {"linear_attention_nnz": 948864, "linear_attention_total": 2359296, "linear_dense_nnz": 4165760, "linear_dense_total": 4718592, "linear_nnz": 5114624, "linear_total": 7077888, "nnz": 5123824, "total": 7087872}, "4": {"linear_attention_nnz": 1019200, "linear_attention_total": 2359296, "linear_dense_nnz": 4152640, "linear_dense_total": 4718592, "linear_nnz": 5171840, "linear_total": 7077888, "nnz": 5181392, "total": 7087872}, "5": {"linear_attention_nnz": 915392, "linear_attention_total": 2359296, "linear_dense_nnz": 4108416, "linear_dense_total": 4718592, "linear_nnz": 5023808, "linear_total": 7077888, "nnz": 5032920, "total": 7087872}, "6": {"linear_attention_nnz": 916160, "linear_attention_total": 2359296, "linear_dense_nnz": 3960384, "linear_dense_total": 4718592, "linear_nnz": 4876544, "linear_total": 7077888, "nnz": 4885872, "total": 7087872}, "7": {"linear_attention_nnz": 834176, "linear_attention_total": 2359296, "linear_dense_nnz": 3685056, "linear_dense_total": 4718592, "linear_nnz": 4519232, "linear_total": 7077888, "nnz": 4528312, "total": 7087872}, "8": {"linear_attention_nnz": 713856, "linear_attention_total": 2359296, "linear_dense_nnz": 3207936, "linear_dense_total": 4718592, "linear_nnz": 3921792, "linear_total": 7077888, "nnz": 3930904, "total": 7087872}, "9": {"linear_attention_nnz": 465600, "linear_attention_total": 2359296, "linear_dense_nnz": 2115456, "linear_dense_total": 4718592, "linear_nnz": 2581056, "linear_total": 7077888, "nnz": 2589728, "total": 7087872}}, "linear_nnz": 48450176, "linear_sparsity": 42.95594015239198, "linear_total": 84934656, "nnz": 72395170, "pruned_heads": {"0": [9, 2, 4, 5], "1": [0, 2, 3, 5, 6, 8], "10": [1, 4, 5, 6, 7, 8], "11": [0, 5, 6, 7, 8, 10, 11], "2": [8, 4, 7], "3": [2, 4, 6], "4": [], "5": [1, 2, 6, 7], "6": [2, 3, 7], "7": [11, 3, 6, 7], "8": [0, 8, 4], "9": [1, 4, 5, 7, 9, 10]}, "total": 108893186, "total_sparsity": 33.51726342179023}, "training_args": {"_n_gpu": -1, "adafactor": false, "adam_beta1": 0.9, "adam_beta2": 0.999, "adam_epsilon": 1e-08, "dataloader_drop_last": false, "dataloader_num_workers": 0, "dataloader_pin_memory": true, "ddp_find_unused_parameters": null, "debug": false, "deepspeed": null, "disable_tqdm": false, "do_eval": 1, "do_predict": false, "do_train": 1, "eval_accumulation_steps": null, "eval_steps": 5000, "evaluation_strategy": "steps", "fp16": false, "fp16_backend": "auto", "fp16_full_eval": false, "fp16_opt_level": "O1", "gradient_accumulation_steps": 1, "greater_is_better": null, "group_by_length": false, "ignore_data_skip": false, "label_names": null, "label_smoothing_factor": 0.0, "learning_rate": 3e-05, "load_best_model_at_end": false, "local_rank": -1, "logging_dir": "/opt/ml/output", "logging_first_step": false, "logging_steps": 250, "logging_strategy": "steps", "lr_scheduler_type": "linear", "max_grad_norm": 1.0, "max_steps": -1, "metric_for_best_model": null, "no_cuda": false, "num_train_epochs": 20.0, "optimize_model_before_eval": "disabled", "output_dir": "/opt/ml/model", "overwrite_output_dir": 1, "past_index": -1, "per_device_eval_batch_size": 8, "per_device_train_batch_size": 16, "per_gpu_eval_batch_size": null, "per_gpu_train_batch_size": null, "prediction_loss_only": false, "remove_unused_columns": true, "report_to": null, "run_name": "/opt/ml/model", "save_steps": 5000, "save_strategy": "steps", "save_total_limit": 50, "seed": 17, "sharded_ddp": false, "skip_memory_metrics": false, "tpu_metrics_debug": false, "tpu_num_cores": null, "warmup_ratio": 0.0, "warmup_steps": 5400, "weight_decay": 0.0}}, "f1": 88.3744311515211, "fill_rate": 0.5704405984760802, "speedup": 1.1977117757004876}}
{"fill_rate": 0.353609061535494, "f1": 88.02730364897265, "meta": {"annotate": "35", "cat_fun_name": "is_full_block", "checkpoint": {"config": {"_name_or_path": "bert-base-uncased", "architectures": ["BertForQuestionAnswering"], "attention_probs_dropout_prob": 0.1, "gradient_checkpointing": false, "hidden_act": "gelu", "hidden_dropout_prob": 0.1, "hidden_size": 768, "initializer_range": 0.02, "intermediate_size": 3072, "layer_norm_eps": 1e-12, "max_position_embeddings": 512, "model_type": "bert", "num_attention_heads": 12, "num_hidden_layers": 12, "pad_token_id": 0, "position_embedding_type": "absolute", "type_vocab_size": 2, "vocab_size": 30522}, "eval_metrics": {"exact_match": 80.6244087038789, "f1": 88.02730364897265}, "path": "/data_2to/devel_data/nn_pruning/output/squad_test_aws/aws_nn-pruning-v11-a8-l10-dl1--2021-01-24--15-46-20/checkpoint-110000", "sparse_args": {"ampere_pruning_method": "disabled", "attention_block_cols": 8, "attention_block_rows": 8, "attention_lambda": 1.0, "attention_output_with_dense": 0, "attention_pruning_method": "sigmoied_threshold", "bias_mask": true, "dense_block_cols": 8, "dense_block_rows": 8, "dense_lambda": 1.0, "dense_pruning_method": "sigmoied_threshold", "distil_alpha_ce": 0.1, "distil_alpha_teacher": 0.9, "distil_teacher_name_or_path": "csarron/bert-base-uncased-squad-v1", "distil_temperature": 2.0, "final_ampere_temperature": 20.0, "final_threshold": 0.1, "final_warmup": 10, "initial_ampere_temperature": 0.0, "initial_threshold": 0, "initial_warmup": 1, "mask_init": "constant", "mask_scale": 0.0, "mask_scores_learning_rate": 0.01, "regularization": "l1", "regularization_final_lambda": 10.0}, "speed": {"cuda_eval_elapsed_time": 29.553753234863283, "eval_elapsed_time": 36.97127141384408}, "speedup": 1.3059049623464731, "stats": {"layers": {"0": {"linear_attention_nnz": 633664, "linear_attention_total": 2359296, "linear_dense_nnz": 2102592, "linear_dense_total": 4718592, "linear_nnz": 2736256, "linear_total": 7077888, "nnz": 2744976, "total": 7087872}, "1": {"linear_attention_nnz": 662336, "linear_attention_total": 2359296, "linear_dense_nnz": 2319616, "linear_dense_total": 4718592, "linear_nnz": 2981952, "linear_total": 7077888, "nnz": 2990560, "total": 7087872}, "10": {"linear_attention_nnz": 396032, "linear_attention_total": 2359296, "linear_dense_nnz": 297856, "linear_dense_total": 4718592, "linear_nnz": 693888, "linear_total": 7077888, "nnz": 700408, "total": 7087872}, "11": {"linear_attention_nnz": 262208, "linear_attention_total": 2359296, "linear_dense_nnz": 297792, "linear_dense_total": 4718592, "linear_nnz": 560000, "linear_total": 7077888, "nnz": 566320, "total": 7087872}, "2": {"linear_attention_nnz": 975296, "linear_attention_total": 2359296, "linear_dense_nnz": 2636544, "linear_dense_total": 4718592, "linear_nnz": 3611840, "linear_total": 7077888, "nnz": 3621032, "total": 7087872}, "3": {"linear_attention_nnz": 1107968, "linear_attention_total": 2359296, "linear_dense_nnz": 2680128, "linear_dense_total": 4718592, "linear_nnz": 3788096, "linear_total": 7077888, "nnz": 3797344, "total": 7087872}, "4": {"linear_attention_nnz": 1247936, "linear_attention_total": 2359296, "linear_dense_nnz": 2623936, "linear_dense_total": 4718592, "linear_nnz": 3871872, "linear_total": 7077888, "nnz": 3881544, "total": 7087872}, "5": {"linear_attention_nnz": 1181888, "linear_attention_total": 2359296, "linear_dense_nnz": 2558208, "linear_dense_total": 4718592, "linear_nnz": 3740096, "linear_total": 7077888, "nnz": 3749616, "total": 7087872}, "6": {"linear_attention_nnz": 1015040, "linear_attention_total": 2359296, "linear_dense_nnz": 2132480, "linear_dense_total": 4718592, "linear_nnz": 3147520, "linear_total": 7077888, "nnz": 3156728, "total": 7087872}, "7": {"linear_attention_nnz": 913792, "linear_attention_total": 2359296, "linear_dense_nnz": 1523328, "linear_dense_total": 4718592, "linear_nnz": 2437120, "linear_total": 7077888, "nnz": 2445696, "total": 7087872}, "8": {"linear_attention_nnz": 818752, "linear_attention_total": 2359296, "linear_dense_nnz": 827264, "linear_dense_total": 4718592, "linear_nnz": 1646016, "linear_total": 7077888, "nnz": 1654216, "total": 7087872}, "9": {"linear_attention_nnz": 514368, "linear_attention_total": 2359296, "linear_dense_nnz": 304640, "linear_dense_total": 4718592, "linear_nnz": 819008, "linear_total": 7077888, "nnz": 825488, "total": 7087872}}, "linear_nnz": 30033664, "linear_sparsity": 64.6390938464506, "linear_total": 84934656, "nnz": 53972650, "pruned_heads": {"0": [9, 4, 5], "1": [0, 2, 3, 5, 6, 8], "10": [1, 4, 5, 6, 7, 8], "11": [0, 5, 7, 8, 10, 11], "2": [8, 4, 7], "3": [2, 4, 6], "4": [], "5": [1, 2], "6": [2, 3, 7], "7": [11, 3, 6, 7], "8": [0, 8, 4], "9": [1, 4, 5, 7, 9, 10]}, "total": 108893186, "total_sparsity": 50.4352365996528}, "training_args": {"_n_gpu": -1, "adafactor": false, "adam_beta1": 0.9, "adam_beta2": 0.999, "adam_epsilon": 1e-08, "dataloader_drop_last": false, "dataloader_num_workers": 0, "dataloader_pin_memory": true, "ddp_find_unused_parameters": null, "debug": false, "deepspeed": null, "disable_tqdm": false, "do_eval": 1, "do_predict": false, "do_train": 1, "eval_accumulation_steps": null, "eval_steps": 5000, "evaluation_strategy": "steps", "fp16": false, "fp16_backend": "auto", "fp16_full_eval": false, "fp16_opt_level": "O1", "gradient_accumulation_steps": 1, "greater_is_better": null, "group_by_length": false, "ignore_data_skip": false, "label_names": null, "label_smoothing_factor": 0.0, "learning_rate": 3e-05, "load_best_model_at_end": false, "local_rank": -1, "logging_dir": "/opt/ml/output", "logging_first_step": false, "logging_steps": 250, "logging_strategy": "steps", "lr_scheduler_type": "linear", "max_grad_norm": 1.0, "max_steps": -1, "metric_for_best_model": null, "no_cuda": false, "num_train_epochs": 20.0, "optimize_model_before_eval": "disabled", "output_dir": "/opt/ml/model", "overwrite_output_dir": 1, "past_index": -1, "per_device_eval_batch_size": 8, "per_device_train_batch_size": 16, "per_gpu_eval_batch_size": null, "per_gpu_train_batch_size": null, "prediction_loss_only": false, "remove_unused_columns": true, "report_to": null, "run_name": "/opt/ml/model", "save_steps": 5000, "save_strategy": "steps", "save_total_limit": 50, "seed": 17, "sharded_ddp": false, "skip_memory_metrics": false, "tpu_metrics_debug": false, "tpu_num_cores": null, "warmup_ratio": 0.0, "warmup_steps": 5400, "weight_decay": 0.0}}, "f1": 88.02730364897265, "fill_rate": 0.353609061535494, "speedup": 1.3059049623464731}}
{"fill_rate": 0.22401861496913578, "f1": 86.84949475139184, "meta": {"annotate": "22", "cat_fun_name": "is_full_block", "checkpoint": {"config": {"_name_or_path": "bert-base-uncased", "architectures": ["BertForQuestionAnswering"], "attention_probs_dropout_prob": 0.1, "gradient_checkpointing": false, "hidden_act": "gelu", "hidden_dropout_prob": 0.1, "hidden_size": 768, "initializer_range": 0.02, "intermediate_size": 3072, "layer_norm_eps": 1e-12, "max_position_embeddings": 512, "model_type": "bert", "num_attention_heads": 12, "num_hidden_layers": 12, "pad_token_id": 0, "position_embedding_type": "absolute", "type_vocab_size": 2, "vocab_size": 30522}, "eval_metrics": {"exact_match": 79.05392620624409, "f1": 86.84949475139184}, "path": "/data_2to/devel_data/nn_pruning/output/squad_test_aws/aws_nn-pruning-v11-a8-l20-dl1--2021-01-24--15-46-47/checkpoint-110660", "sparse_args": {"ampere_pruning_method": "disabled", "attention_block_cols": 8, "attention_block_rows": 8, "attention_lambda": 1.0, "attention_output_with_dense": 0, "attention_pruning_method": "sigmoied_threshold", "bias_mask": true, "dense_block_cols": 8, "dense_block_rows": 8, "dense_lambda": 1.0, "dense_pruning_method": "sigmoied_threshold", "distil_alpha_ce": 0.1, "distil_alpha_teacher": 0.9, "distil_teacher_name_or_path": "csarron/bert-base-uncased-squad-v1", "distil_temperature": 2.0, "final_ampere_temperature": 20.0, "final_threshold": 0.1, "final_warmup": 10, "initial_ampere_temperature": 0.0, "initial_threshold": 0, "initial_warmup": 1, "mask_init": "constant", "mask_scale": 0.0, "mask_scores_learning_rate": 0.01, "regularization": "l1", "regularization_final_lambda": 20.0}, "speed": {"cuda_eval_elapsed_time": 24.667898628234862, "eval_elapsed_time": 32.10200677579269}, "speedup": 1.5645594133095706, "stats": {"layers": {"0": {"linear_attention_nnz": 407936, "linear_attention_total": 2359296, "linear_dense_nnz": 1088064, "linear_dense_total": 4718592, "linear_nnz": 1496000, "linear_total": 7077888, "nnz": 1503608, "total": 7087872}, "1": {"linear_attention_nnz": 569088, "linear_attention_total": 2359296, "linear_dense_nnz": 1378944, "linear_dense_total": 4718592, "linear_nnz": 1948032, "linear_total": 7077888, "nnz": 1955776, "total": 7087872}, "10": {"linear_attention_nnz": 298112, "linear_attention_total": 2359296, "linear_dense_nnz": 181568, "linear_dense_total": 4718592, "linear_nnz": 479680, "linear_total": 7077888, "nnz": 485744, "total": 7087872}, "11": {"linear_attention_nnz": 185728, "linear_attention_total": 2359296, "linear_dense_nnz": 199488, "linear_dense_total": 4718592, "linear_nnz": 385216, "linear_total": 7077888, "nnz": 390952, "total": 7087872}, "2": {"linear_attention_nnz": 770560, "linear_attention_total": 2359296, "linear_dense_nnz": 1695552, "linear_dense_total": 4718592, "linear_nnz": 2466112, "linear_total": 7077888, "nnz": 2474536, "total": 7087872}, "3": {"linear_attention_nnz": 902848, "linear_attention_total": 2359296, "linear_dense_nnz": 1680512, "linear_dense_total": 4718592, "linear_nnz": 2583360, "linear_total": 7077888, "nnz": 2591904, "total": 7087872}, "4": {"linear_attention_nnz": 913216, "linear_attention_total": 2359296, "linear_dense_nnz": 1624640, "linear_dense_total": 4718592, "linear_nnz": 2537856, "linear_total": 7077888, "nnz": 2546584, "total": 7087872}, "5": {"linear_attention_nnz": 749440, "linear_attention_total": 2359296, "linear_dense_nnz": 1534912, "linear_dense_total": 4718592, "linear_nnz": 2284352, "linear_total": 7077888, "nnz": 2292792, "total": 7087872}, "6": {"linear_attention_nnz": 684480, "linear_attention_total": 2359296, "linear_dense_nnz": 1190976, "linear_dense_total": 4718592, "linear_nnz": 1875456, "linear_total": 7077888, "nnz": 1883488, "total": 7087872}, "7": {"linear_attention_nnz": 672320, "linear_attention_total": 2359296, "linear_dense_nnz": 815872, "linear_dense_total": 4718592, "linear_nnz": 1488192, "linear_total": 7077888, "nnz": 1495544, "total": 7087872}, "8": {"linear_attention_nnz": 570176, "linear_attention_total": 2359296, "linear_dense_nnz": 399104, "linear_dense_total": 4718592, "linear_nnz": 969280, "linear_total": 7077888, "nnz": 976272, "total": 7087872}, "9": {"linear_attention_nnz": 345664, "linear_attention_total": 2359296, "linear_dense_nnz": 167744, "linear_dense_total": 4718592, "linear_nnz": 513408, "linear_total": 7077888, "nnz": 519352, "total": 7087872}}, "linear_nnz": 19026944, "linear_sparsity": 77.59813850308642, "linear_total": 84934656, "nnz": 42955274, "pruned_heads": {"0": [2, 4, 5, 6, 9], "1": [0, 2, 3, 5, 6, 8], "10": [1, 4, 5, 6, 7, 8], "11": [0, 5, 6, 7, 8, 10, 11], "2": [8, 4, 7], "3": [2, 4, 6], "4": [2], "5": [1, 2, 6, 7], "6": [0, 2, 3, 7], "7": [1, 3, 6, 7, 11], "8": [0, 8, 4], "9": [1, 3, 4, 5, 7, 9, 10]}, "total": 108893186, "total_sparsity": 60.55283569350244}, "training_args": {"_n_gpu": -1, "adafactor": false, "adam_beta1": 0.9, "adam_beta2": 0.999, "adam_epsilon": 1e-08, "dataloader_drop_last": false, "dataloader_num_workers": 0, "dataloader_pin_memory": true, "ddp_find_unused_parameters": null, "debug": false, "deepspeed": null, "disable_tqdm": false, "do_eval": 1, "do_predict": false, "do_train": 1, "eval_accumulation_steps": null, "eval_steps": 5000, "evaluation_strategy": "steps", "fp16": false, "fp16_backend": "auto", "fp16_full_eval": false, "fp16_opt_level": "O1", "gradient_accumulation_steps": 1, "greater_is_better": null, "group_by_length": false, "ignore_data_skip": false, "label_names": null, "label_smoothing_factor": 0.0, "learning_rate": 3e-05, "load_best_model_at_end": false, "local_rank": -1, "logging_dir": "/opt/ml/output", "logging_first_step": false, "logging_steps": 250, "logging_strategy": "steps", "lr_scheduler_type": "linear", "max_grad_norm": 1.0, "max_steps": -1, "metric_for_best_model": null, "no_cuda": false, "num_train_epochs": 20.0, "optimize_model_before_eval": "disabled", "output_dir": "/opt/ml/model", "overwrite_output_dir": 1, "past_index": -1, "per_device_eval_batch_size": 8, "per_device_train_batch_size": 16, "per_gpu_eval_batch_size": null, "per_gpu_train_batch_size": null, "prediction_loss_only": false, "remove_unused_columns": true, "report_to": null, "run_name": "/opt/ml/model", "save_steps": 5000, "save_strategy": "steps", "save_total_limit": 50, "seed": 17, "sharded_ddp": false, "skip_memory_metrics": false, "tpu_metrics_debug": false, "tpu_num_cores": null, "warmup_ratio": 0.0, "warmup_steps": 5400, "weight_decay": 0.0}}, "f1": 86.84949475139184, "fill_rate": 0.22401861496913578, "speedup": 1.5645594133095706}}
{"fill_rate": 0.13401210455246915, "f1": 85.16652519097626, "meta": {"annotate": "13", "cat_fun_name": "is_full_block", "checkpoint": {"config": {"_name_or_path": "bert-base-uncased", "architectures": ["BertForQuestionAnswering"], "attention_probs_dropout_prob": 0.1, "gradient_checkpointing": false, "hidden_act": "gelu", "hidden_dropout_prob": 0.1, "hidden_size": 768, "initializer_range": 0.02, "intermediate_size": 3072, "layer_norm_eps": 1e-12, "max_position_embeddings": 512, "model_type": "bert", "num_attention_heads": 12, "num_hidden_layers": 12, "pad_token_id": 0, "position_embedding_type": "absolute", "type_vocab_size": 2, "vocab_size": 30522}, "eval_metrics": {"exact_match": 76.87795648060549, "f1": 85.16652519097626}, "path": "/data_2to/devel_data/nn_pruning/output/squad_test_aws/aws_nn-pruning-v11-a8-l40-dl1--2021-01-24--15-47-15/checkpoint-110660", "sparse_args": {"ampere_pruning_method": "disabled", "attention_block_cols": 8, "attention_block_rows": 8, "attention_lambda": 1.0, "attention_output_with_dense": 0, "attention_pruning_method": "sigmoied_threshold", "bias_mask": true, "dense_block_cols": 8, "dense_block_rows": 8, "dense_lambda": 1.0, "dense_pruning_method": "sigmoied_threshold", "distil_alpha_ce": 0.1, "distil_alpha_teacher": 0.9, "distil_teacher_name_or_path": "csarron/bert-base-uncased-squad-v1", "distil_temperature": 2.0, "final_ampere_temperature": 20.0, "final_threshold": 0.1, "final_warmup": 10, "initial_ampere_temperature": 0.0, "initial_threshold": 0, "initial_warmup": 1, "mask_init": "constant", "mask_scale": 0.0, "mask_scores_learning_rate": 0.01, "regularization": "l1", "regularization_final_lambda": 40.0}, "speed": {"cuda_eval_elapsed_time": 19.238733966827393, "eval_elapsed_time": 26.43846725206822}, "speedup": 2.0060775865978457, "stats": {"layers": {"0": {"linear_attention_nnz": 330432, "linear_attention_total": 2359296, "linear_dense_nnz": 520000, "linear_dense_total": 4718592, "linear_nnz": 850432, "linear_total": 7077888, "nnz": 856864, "total": 7087872}, "1": {"linear_attention_nnz": 468224, "linear_attention_total": 2359296, "linear_dense_nnz": 724864, "linear_dense_total": 4718592, "linear_nnz": 1193088, "linear_total": 7077888, "nnz": 1199800, "total": 7087872}, "10": {"linear_attention_nnz": 206912, "linear_attention_total": 2359296, "linear_dense_nnz": 137088, "linear_dense_total": 4718592, "linear_nnz": 344000, "linear_total": 7077888, "nnz": 349744, "total": 7087872}, "11": {"linear_attention_nnz": 127744, "linear_attention_total": 2359296, "linear_dense_nnz": 128064, "linear_dense_total": 4718592, "linear_nnz": 255808, "linear_total": 7077888, "nnz": 261080, "total": 7087872}, "2": {"linear_attention_nnz": 511104, "linear_attention_total": 2359296, "linear_dense_nnz": 975680, "linear_dense_total": 4718592, "linear_nnz": 1486784, "linear_total": 7077888, "nnz": 1493920, "total": 7087872}, "3": {"linear_attention_nnz": 688192, "linear_attention_total": 2359296, "linear_dense_nnz": 908032, "linear_dense_total": 4718592, "linear_nnz": 1596224, "linear_total": 7077888, "nnz": 1603528, "total": 7087872}, "4": {"linear_attention_nnz": 551360, "linear_attention_total": 2359296, "linear_dense_nnz": 863296, "linear_dense_total": 4718592, "linear_nnz": 1414656, "linear_total": 7077888, "nnz": 1421800, "total": 7087872}, "5": {"linear_attention_nnz": 466304, "linear_attention_total": 2359296, "linear_dense_nnz": 787328, "linear_dense_total": 4718592, "linear_nnz": 1253632, "linear_total": 7077888, "nnz": 1260664, "total": 7087872}, "6": {"linear_attention_nnz": 451840, "linear_attention_total": 2359296, "linear_dense_nnz": 695488, "linear_dense_total": 4718592, "linear_nnz": 1147328, "linear_total": 7077888, "nnz": 1154120, "total": 7087872}, "7": {"linear_attention_nnz": 497920, "linear_attention_total": 2359296, "linear_dense_nnz": 475840, "linear_dense_total": 4718592, "linear_nnz": 973760, "linear_total": 7077888, "nnz": 980328, "total": 7087872}, "8": {"linear_attention_nnz": 302528, "linear_attention_total": 2359296, "linear_dense_nnz": 217600, "linear_dense_total": 4718592, "linear_nnz": 520128, "linear_total": 7077888, "nnz": 526056, "total": 7087872}, "9": {"linear_attention_nnz": 255168, "linear_attention_total": 2359296, "linear_dense_nnz": 91264, "linear_dense_total": 4718592, "linear_nnz": 346432, "linear_total": 7077888, "nnz": 352056, "total": 7087872}}, "linear_nnz": 11382272, "linear_sparsity": 86.59878954475309, "linear_total": 84934656, "nnz": 35298682, "pruned_heads": {"0": [2, 4, 5, 6, 7, 9], "1": [0, 2, 3, 5, 6, 8, 9], "10": [1, 4, 5, 6, 7, 8, 9], "11": [0, 2, 3, 5, 6, 7, 8, 10, 11], "2": [8, 1, 4, 7], "3": [2, 4, 6, 7, 10], "4": [0, 2, 11, 6], "5": [1, 2, 6, 7, 11], "6": [0, 2, 3, 7], "7": [1, 3, 6, 7, 11], "8": [0, 3, 4, 5, 6, 8], "9": [1, 3, 4, 5, 7, 9, 10]}, "total": 108893186, "total_sparsity": 67.5841222976064}, "training_args": {"_n_gpu": -1, "adafactor": false, "adam_beta1": 0.9, "adam_beta2": 0.999, "adam_epsilon": 1e-08, "dataloader_drop_last": false, "dataloader_num_workers": 0, "dataloader_pin_memory": true, "ddp_find_unused_parameters": null, "debug": false, "deepspeed": null, "disable_tqdm": false, "do_eval": 1, "do_predict": false, "do_train": 1, "eval_accumulation_steps": null, "eval_steps": 5000, "evaluation_strategy": "steps", "fp16": false, "fp16_backend": "auto", "fp16_full_eval": false, "fp16_opt_level": "O1", "gradient_accumulation_steps": 1, "greater_is_better": null, "group_by_length": false, "ignore_data_skip": false, "label_names": null, "label_smoothing_factor": 0.0, "learning_rate": 3e-05, "load_best_model_at_end": false, "local_rank": -1, "logging_dir": "/opt/ml/output", "logging_first_step": false, "logging_steps": 250, "logging_strategy": "steps", "lr_scheduler_type": "linear", "max_grad_norm": 1.0, "max_steps": -1, "metric_for_best_model": null, "no_cuda": false, "num_train_epochs": 20.0, "optimize_model_before_eval": "disabled", "output_dir": "/opt/ml/model", "overwrite_output_dir": 1, "past_index": -1, "per_device_eval_batch_size": 8, "per_device_train_batch_size": 16, "per_gpu_eval_batch_size": null, "per_gpu_train_batch_size": null, "prediction_loss_only": false, "remove_unused_columns": true, "report_to": null, "run_name": "/opt/ml/model", "save_steps": 5000, "save_strategy": "steps", "save_total_limit": 50, "seed": 17, "sharded_ddp": false, "skip_memory_metrics": false, "tpu_metrics_debug": false, "tpu_num_cores": null, "warmup_ratio": 0.0, "warmup_steps": 5400, "weight_decay": 0.0}}, "f1": 85.16652519097626, "fill_rate": 0.13401210455246915, "speedup": 2.0060775865978457}}
