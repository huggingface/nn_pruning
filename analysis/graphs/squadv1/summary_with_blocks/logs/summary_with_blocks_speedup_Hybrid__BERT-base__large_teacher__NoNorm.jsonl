{"speedup": 1.655750645813363, "f1": 89.04891748061114, "meta": {"annotate": "38", "cat_fun_name": "is_new_xp", "checkpoint": {"config": {"_name_or_path": "bert-base-uncased", "architectures": ["BertForQuestionAnswering"], "attention_probs_dropout_prob": 0.1, "gradient_checkpointing": false, "hidden_act": "gelu", "hidden_dropout_prob": 0.1, "hidden_size": 768, "initializer_range": 0.02, "intermediate_size": 3072, "layer_norm_eps": 1e-12, "max_position_embeddings": 512, "model_type": "bert", "num_attention_heads": 12, "num_hidden_layers": 12, "pad_token_id": 0, "position_embedding_type": "absolute", "type_vocab_size": 2, "vocab_size": 30522}, "eval_metrics": {"exact_match": 82.55439924314096, "f1": 89.04891748061114}, "path": "/data_2to/devel_data/nn_pruning/output/squad_test4/hp_od-__data_2to__devel_data__nn_pruning__output__squad_test4___es-steps_nte20_ls250_stl50_est5000_rn-__data_2to__devel_data__nn_pruning__output__squad_test4___dpm-sigmoied_threshold--5fcfb7ff678f0d71/checkpoint-110000", "sparse_args": {"ampere_pruning_method": "disabled", "attention_block_cols": 32, "attention_block_rows": 32, "attention_lambda": 1.0, "attention_output_with_dense": 0, "attention_pruning_method": "sigmoied_threshold", "bias_mask": true, "dense_block_cols": 1, "dense_block_rows": 1, "dense_lambda": 1.0, "dense_pruning_method": "sigmoied_threshold:1d_alt", "distil_alpha_ce": 0.1, "distil_alpha_teacher": 0.9, "distil_teacher_name_or_path": "bert-large-uncased-whole-word-masking-finetuned-squad", "distil_temperature": 2.0, "final_ampere_temperature": 20.0, "final_finetune": false, "final_threshold": 0.1, "final_warmup": 10, "gelu_patch": 0, "initial_ampere_temperature": 0.0, "initial_threshold": 0, "initial_warmup": 1, "layer_norm_patch": 1, "layer_norm_patch_start_delta": 0.99, "layer_norm_patch_steps": 20000, "mask_init": "constant", "mask_scale": 0.0, "mask_scores_learning_rate": 0.01, "regularization": "l1", "regularization_final_lambda": 5}, "speed": {"cuda_eval_elapsed_time": 23.309302703857423, "eval_elapsed_time": 30.37249969970435}, "speedup": 1.655750645813363, "stats": {"layers": {"0": {"linear_attention_nnz": 1222656, "linear_attention_total": 2359296, "linear_dense_nnz": 2322432, "linear_dense_total": 4718592, "linear_nnz": 3545088, "linear_total": 7077888, "nnz": 3552648, "total": 7087872}, "1": {"linear_attention_nnz": 802816, "linear_attention_total": 2359296, "linear_dense_nnz": 2038272, "linear_dense_total": 4718592, "linear_nnz": 2841088, "linear_total": 7077888, "nnz": 2847919, "total": 7087872}, "10": {"linear_attention_nnz": 838656, "linear_attention_total": 2359296, "linear_dense_nnz": 935424, "linear_dense_total": 4718592, "linear_nnz": 1774080, "linear_total": 7077888, "nnz": 1780609, "total": 7087872}, "11": {"linear_attention_nnz": 446464, "linear_attention_total": 2359296, "linear_dense_nnz": 1503744, "linear_dense_total": 4718592, "linear_nnz": 1950208, "linear_total": 7077888, "nnz": 1956755, "total": 7087872}, "2": {"linear_attention_nnz": 1433600, "linear_attention_total": 2359296, "linear_dense_nnz": 2096640, "linear_dense_total": 4718592, "linear_nnz": 3530240, "linear_total": 7077888, "nnz": 3537877, "total": 7087872}, "3": {"linear_attention_nnz": 1512448, "linear_attention_total": 2359296, "linear_dense_nnz": 1915392, "linear_dense_total": 4718592, "linear_nnz": 3427840, "linear_total": 7077888, "nnz": 3435327, "total": 7087872}, "4": {"linear_attention_nnz": 1702912, "linear_attention_total": 2359296, "linear_dense_nnz": 1684992, "linear_dense_total": 4718592, "linear_nnz": 3387904, "linear_total": 7077888, "nnz": 3395497, "total": 7087872}, "5": {"linear_attention_nnz": 1391616, "linear_attention_total": 2359296, "linear_dense_nnz": 1589760, "linear_dense_total": 4718592, "linear_nnz": 2981376, "linear_total": 7077888, "nnz": 2988715, "total": 7087872}, "6": {"linear_attention_nnz": 1476608, "linear_attention_total": 2359296, "linear_dense_nnz": 1399296, "linear_dense_total": 4718592, "linear_nnz": 2875904, "linear_total": 7077888, "nnz": 2883279, "total": 7087872}, "7": {"linear_attention_nnz": 1180672, "linear_attention_total": 2359296, "linear_dense_nnz": 1108992, "linear_dense_total": 4718592, "linear_nnz": 2289664, "linear_total": 7077888, "nnz": 2296338, "total": 7087872}, "8": {"linear_attention_nnz": 1488896, "linear_attention_total": 2359296, "linear_dense_nnz": 830976, "linear_dense_total": 4718592, "linear_nnz": 2319872, "linear_total": 7077888, "nnz": 2326845, "total": 7087872}, "9": {"linear_attention_nnz": 1105920, "linear_attention_total": 2359296, "linear_dense_nnz": 941568, "linear_dense_total": 4718592, "linear_nnz": 2047488, "linear_total": 7077888, "nnz": 2054149, "total": 7087872}}, "linear_nnz": 32970752, "linear_sparsity": 61.18103780864197, "linear_total": 84934656, "nnz": 56894680, "pruned_heads": {"0": [0, 2, 6], "1": [0, 2, 3, 5, 6, 7, 8], "10": [1, 4, 5, 7], "11": [0, 5, 7, 8, 10, 11], "2": [8, 4, 7], "3": [2, 4, 6], "4": [1, 2], "5": [1, 2, 6], "6": [2, 3], "7": [1, 3, 6, 7, 11], "8": [0], "9": [1, 4, 5, 7]}, "total": 108893186, "total_sparsity": 47.75184555624996}, "training_args": {"adam_beta1": 0.9, "adam_beta2": 0.999, "adam_epsilon": 1e-08, "dataloader_drop_last": false, "dataloader_num_workers": 0, "debug": false, "disable_tqdm": false, "do_eval": 1, "do_predict": false, "do_train": 1, "eval_accumulation_steps": null, "eval_steps": 5000, "evaluation_strategy": "steps", "fp16": false, "fp16_opt_level": "O1", "gradient_accumulation_steps": 1, "greater_is_better": null, "ignore_data_skip": false, "label_names": null, "learning_rate": 3e-05, "load_best_model_at_end": false, "local_rank": -1, "logging_dir": "/data_2to/devel_data/nn_pruning/output/squad_test4/", "logging_first_step": false, "logging_steps": 250, "max_grad_norm": 1.0, "max_steps": -1, "metric_for_best_model": null, "model_parallel": false, "no_cuda": false, "num_train_epochs": 20, "optimize_model_before_eval": "disabled", "output_dir": "/data_2to/devel_data/nn_pruning/output/squad_test4/", "overwrite_output_dir": 1, "past_index": -1, "per_device_eval_batch_size": 8, "per_device_train_batch_size": 16, "per_gpu_eval_batch_size": null, "per_gpu_train_batch_size": null, "prediction_loss_only": false, "remove_unused_columns": true, "run_name": "/data_2to/devel_data/nn_pruning/output/squad_test4/", "save_steps": 5000, "save_total_limit": 50, "seed": 17, "tpu_metrics_debug": false, "tpu_num_cores": null, "warmup_steps": 5400, "weight_decay": 0.0}}, "f1": 89.04891748061114, "fill_rate": 0.3881896219135803, "speedup": 1.655750645813363}}
{"speedup": 2.0687203310282287, "f1": 88.04977607167375, "meta": {"annotate": "25", "cat_fun_name": "is_new_xp", "checkpoint": {"config": {"_name_or_path": "bert-base-uncased", "architectures": ["BertForQuestionAnswering"], "attention_probs_dropout_prob": 0.1, "gradient_checkpointing": false, "hidden_act": "gelu", "hidden_dropout_prob": 0.1, "hidden_size": 768, "initializer_range": 0.02, "intermediate_size": 3072, "layer_norm_eps": 1e-12, "max_position_embeddings": 512, "model_type": "bert", "num_attention_heads": 12, "num_hidden_layers": 12, "pad_token_id": 0, "position_embedding_type": "absolute", "type_vocab_size": 2, "vocab_size": 30522}, "eval_metrics": {"exact_match": 81.10690633869442, "f1": 88.04977607167375}, "path": "/data_2to/devel_data/nn_pruning/output/squad_test5/hp_od-__data_2to__devel_data__nn_pruning__output__squad_test5___es-steps_nte20_ls250_stl50_est5000_rn-__data_2to__devel_data__nn_pruning__output__squad_test5___dpm-sigmoied_threshold--35f0c1d86d528754/checkpoint-105000", "sparse_args": {"ampere_pruning_method": "disabled", "attention_block_cols": 32, "attention_block_rows": 32, "attention_lambda": 1.0, "attention_output_with_dense": 0, "attention_pruning_method": "sigmoied_threshold", "bias_mask": true, "dense_block_cols": 1, "dense_block_rows": 1, "dense_lambda": 1.0, "dense_pruning_method": "sigmoied_threshold:1d_alt", "distil_alpha_ce": 0.1, "distil_alpha_teacher": 0.9, "distil_teacher_name_or_path": "bert-large-uncased-whole-word-masking-finetuned-squad", "distil_temperature": 2.0, "final_ampere_temperature": 20.0, "final_finetune": false, "final_threshold": 0.1, "final_warmup": 10, "gelu_patch": 0, "initial_ampere_temperature": 0.0, "initial_threshold": 0, "initial_warmup": 1, "layer_norm_patch": 1, "layer_norm_patch_start_delta": 0.99, "layer_norm_patch_steps": 50000, "mask_init": "constant", "mask_scale": 0.0, "mask_scores_learning_rate": 0.01, "regularization": "l1", "regularization_final_lambda": 10}, "speed": {"cuda_eval_elapsed_time": 18.656167499542235, "eval_elapsed_time": 25.615012356080115}, "speedup": 2.0687203310282287, "stats": {"layers": {"0": {"linear_attention_nnz": 847872, "linear_attention_total": 2359296, "linear_dense_nnz": 771072, "linear_dense_total": 4718592, "linear_nnz": 1618944, "linear_total": 7077888, "nnz": 1625078, "total": 7087872}, "1": {"linear_attention_nnz": 686080, "linear_attention_total": 2359296, "linear_dense_nnz": 1009152, "linear_dense_total": 4718592, "linear_nnz": 1695232, "linear_total": 7077888, "nnz": 1701361, "total": 7087872}, "10": {"linear_attention_nnz": 615424, "linear_attention_total": 2359296, "linear_dense_nnz": 539136, "linear_dense_total": 4718592, "linear_nnz": 1154560, "linear_total": 7077888, "nnz": 1160319, "total": 7087872}, "11": {"linear_attention_nnz": 369664, "linear_attention_total": 2359296, "linear_dense_nnz": 769536, "linear_dense_total": 4718592, "linear_nnz": 1139200, "linear_total": 7077888, "nnz": 1144885, "total": 7087872}, "2": {"linear_attention_nnz": 1100800, "linear_attention_total": 2359296, "linear_dense_nnz": 1207296, "linear_dense_total": 4718592, "linear_nnz": 2308096, "linear_total": 7077888, "nnz": 2314866, "total": 7087872}, "3": {"linear_attention_nnz": 1414144, "linear_attention_total": 2359296, "linear_dense_nnz": 1201152, "linear_dense_total": 4718592, "linear_nnz": 2615296, "linear_total": 7077888, "nnz": 2622318, "total": 7087872}, "4": {"linear_attention_nnz": 1507328, "linear_attention_total": 2359296, "linear_dense_nnz": 1156608, "linear_dense_total": 4718592, "linear_nnz": 2663936, "linear_total": 7077888, "nnz": 2671121, "total": 7087872}, "5": {"linear_attention_nnz": 1105920, "linear_attention_total": 2359296, "linear_dense_nnz": 1056768, "linear_dense_total": 4718592, "linear_nnz": 2162688, "linear_total": 7077888, "nnz": 2169328, "total": 7087872}, "6": {"linear_attention_nnz": 1052672, "linear_attention_total": 2359296, "linear_dense_nnz": 960000, "linear_dense_total": 4718592, "linear_nnz": 2012672, "linear_total": 7077888, "nnz": 2019345, "total": 7087872}, "7": {"linear_attention_nnz": 1116160, "linear_attention_total": 2359296, "linear_dense_nnz": 718848, "linear_dense_total": 4718592, "linear_nnz": 1835008, "linear_total": 7077888, "nnz": 1841396, "total": 7087872}, "8": {"linear_attention_nnz": 1076224, "linear_attention_total": 2359296, "linear_dense_nnz": 390144, "linear_dense_total": 4718592, "linear_nnz": 1466368, "linear_total": 7077888, "nnz": 1472606, "total": 7087872}, "9": {"linear_attention_nnz": 655360, "linear_attention_total": 2359296, "linear_dense_nnz": 279552, "linear_dense_total": 4718592, "linear_nnz": 934912, "linear_total": 7077888, "nnz": 940630, "total": 7087872}}, "linear_nnz": 21606912, "linear_sparsity": 74.560546875, "linear_total": 84934656, "nnz": 45521975, "pruned_heads": {"0": [0, 2, 4, 5, 6, 11], "1": [0, 2, 3, 5, 6, 7, 8], "10": [1, 2, 4, 5, 6, 7, 8], "11": [0, 2, 5, 7, 8, 10, 11], "2": [8, 4, 5, 7], "3": [2, 4, 6], "4": [1, 2], "5": [1, 2, 6, 7, 11], "6": [10, 2, 3, 7], "7": [1, 3, 6, 7, 11], "8": [0, 3, 4], "9": [1, 4, 5, 7, 9, 10]}, "total": 108893186, "total_sparsity": 58.19575432387478}, "training_args": {"adam_beta1": 0.9, "adam_beta2": 0.999, "adam_epsilon": 1e-08, "dataloader_drop_last": false, "dataloader_num_workers": 0, "debug": false, "disable_tqdm": false, "do_eval": 1, "do_predict": false, "do_train": 1, "eval_accumulation_steps": null, "eval_steps": 5000, "evaluation_strategy": "steps", "fp16": false, "fp16_opt_level": "O1", "gradient_accumulation_steps": 1, "greater_is_better": null, "ignore_data_skip": false, "label_names": null, "learning_rate": 3e-05, "load_best_model_at_end": false, "local_rank": -1, "logging_dir": "/data_2to/devel_data/nn_pruning/output/squad_test5/", "logging_first_step": false, "logging_steps": 250, "max_grad_norm": 1.0, "max_steps": -1, "metric_for_best_model": null, "model_parallel": false, "no_cuda": false, "num_train_epochs": 20, "optimize_model_before_eval": "disabled", "output_dir": "/data_2to/devel_data/nn_pruning/output/squad_test5/", "overwrite_output_dir": 1, "past_index": -1, "per_device_eval_batch_size": 8, "per_device_train_batch_size": 16, "per_gpu_eval_batch_size": null, "per_gpu_train_batch_size": null, "prediction_loss_only": false, "remove_unused_columns": true, "run_name": "/data_2to/devel_data/nn_pruning/output/squad_test5/", "save_steps": 5000, "save_total_limit": 50, "seed": 17, "tpu_metrics_debug": false, "tpu_num_cores": null, "warmup_steps": 5400, "weight_decay": 0.0}}, "f1": 88.04977607167375, "fill_rate": 0.25439453125, "speedup": 2.0687203310282287}}
{"speedup": 2.151592015203899, "f1": 87.45888007303566, "meta": {"annotate": "21", "cat_fun_name": "is_new_xp", "checkpoint": {"config": {"_name_or_path": "bert-base-uncased", "architectures": ["BertForQuestionAnswering"], "attention_probs_dropout_prob": 0.1, "gradient_checkpointing": false, "hidden_act": "gelu", "hidden_dropout_prob": 0.1, "hidden_size": 768, "initializer_range": 0.02, "intermediate_size": 3072, "layer_norm_eps": 1e-12, "max_position_embeddings": 512, "model_type": "bert", "num_attention_heads": 12, "num_hidden_layers": 12, "pad_token_id": 0, "position_embedding_type": "absolute", "type_vocab_size": 2, "vocab_size": 30522}, "eval_metrics": {"exact_match": 80.1608325449385, "f1": 87.45888007303566}, "path": "/data_2to/devel_data/nn_pruning/output/squad_test5/hp_od-__data_2to__devel_data__nn_pruning__output__squad_test5___es-steps_nte20_ls250_stl50_est5000_rn-__data_2to__devel_data__nn_pruning__output__squad_test5___dpm-sigmoied_threshold--3006fe9afa215f73/checkpoint-110000", "sparse_args": {"ampere_pruning_method": "disabled", "attention_block_cols": 32, "attention_block_rows": 32, "attention_lambda": 1.0, "attention_output_with_dense": 0, "attention_pruning_method": "sigmoied_threshold", "bias_mask": true, "dense_block_cols": 1, "dense_block_rows": 1, "dense_lambda": 2.0, "dense_pruning_method": "sigmoied_threshold:1d_alt", "distil_alpha_ce": 0.1, "distil_alpha_teacher": 0.9, "distil_teacher_name_or_path": "bert-large-uncased-whole-word-masking-finetuned-squad", "distil_temperature": 2.0, "final_ampere_temperature": 20.0, "final_finetune": false, "final_threshold": 0.1, "final_warmup": 10, "gelu_patch": 0, "initial_ampere_temperature": 0.0, "initial_threshold": 0, "initial_warmup": 1, "layer_norm_patch": 1, "layer_norm_patch_start_delta": 0.99, "layer_norm_patch_steps": 50000, "mask_init": "constant", "mask_scale": 0.0, "mask_scores_learning_rate": 0.01, "regularization": "l1", "regularization_final_lambda": 10}, "speed": {"cuda_eval_elapsed_time": 17.93759817504883, "eval_elapsed_time": 24.918185566551983}, "speedup": 2.151592015203899, "stats": {"layers": {"0": {"linear_attention_nnz": 1049600, "linear_attention_total": 2359296, "linear_dense_nnz": 405504, "linear_dense_total": 4718592, "linear_nnz": 1455104, "linear_total": 7077888, "nnz": 1461256, "total": 7087872}, "1": {"linear_attention_nnz": 737280, "linear_attention_total": 2359296, "linear_dense_nnz": 536064, "linear_dense_total": 4718592, "linear_nnz": 1273344, "linear_total": 7077888, "nnz": 1279165, "total": 7087872}, "10": {"linear_attention_nnz": 622592, "linear_attention_total": 2359296, "linear_dense_nnz": 290304, "linear_dense_total": 4718592, "linear_nnz": 912896, "linear_total": 7077888, "nnz": 918493, "total": 7087872}, "11": {"linear_attention_nnz": 404480, "linear_attention_total": 2359296, "linear_dense_nnz": 423936, "linear_dense_total": 4718592, "linear_nnz": 828416, "linear_total": 7077888, "nnz": 834036, "total": 7087872}, "2": {"linear_attention_nnz": 1270784, "linear_attention_total": 2359296, "linear_dense_nnz": 744960, "linear_dense_total": 4718592, "linear_nnz": 2015744, "linear_total": 7077888, "nnz": 2022405, "total": 7087872}, "3": {"linear_attention_nnz": 1457152, "linear_attention_total": 2359296, "linear_dense_nnz": 726528, "linear_dense_total": 4718592, "linear_nnz": 2183680, "linear_total": 7077888, "nnz": 2190393, "total": 7087872}, "4": {"linear_attention_nnz": 1575936, "linear_attention_total": 2359296, "linear_dense_nnz": 705024, "linear_dense_total": 4718592, "linear_nnz": 2280960, "linear_total": 7077888, "nnz": 2287883, "total": 7087872}, "5": {"linear_attention_nnz": 1094656, "linear_attention_total": 2359296, "linear_dense_nnz": 635904, "linear_dense_total": 4718592, "linear_nnz": 1730560, "linear_total": 7077888, "nnz": 1736926, "total": 7087872}, "6": {"linear_attention_nnz": 1110016, "linear_attention_total": 2359296, "linear_dense_nnz": 539136, "linear_dense_total": 4718592, "linear_nnz": 1649152, "linear_total": 7077888, "nnz": 1655551, "total": 7087872}, "7": {"linear_attention_nnz": 1128448, "linear_attention_total": 2359296, "linear_dense_nnz": 423936, "linear_dense_total": 4718592, "linear_nnz": 1552384, "linear_total": 7077888, "nnz": 1558580, "total": 7087872}, "8": {"linear_attention_nnz": 1105920, "linear_attention_total": 2359296, "linear_dense_nnz": 213504, "linear_dense_total": 4718592, "linear_nnz": 1319424, "linear_total": 7077888, "nnz": 1325707, "total": 7087872}, "9": {"linear_attention_nnz": 644096, "linear_attention_total": 2359296, "linear_dense_nnz": 147456, "linear_dense_total": 4718592, "linear_nnz": 791552, "linear_total": 7077888, "nnz": 797152, "total": 7087872}}, "linear_nnz": 17993216, "linear_sparsity": 78.81522472993827, "linear_total": 84934656, "nnz": 41906269, "pruned_heads": {"0": [0, 2, 5, 6], "1": [0, 2, 3, 5, 6, 7, 8], "10": [1, 2, 4, 5, 6, 7, 8], "11": [0, 2, 5, 7, 8, 10, 11], "2": [8, 4, 7], "3": [2, 4, 6], "4": [1, 2], "5": [1, 2, 6, 7, 11], "6": [0, 2, 3, 7], "7": [1, 3, 6, 7, 11], "8": [0, 4], "9": [1, 4, 5, 7, 9, 10]}, "total": 108893186, "total_sparsity": 61.51616961597579}, "training_args": {"adam_beta1": 0.9, "adam_beta2": 0.999, "adam_epsilon": 1e-08, "dataloader_drop_last": false, "dataloader_num_workers": 0, "debug": false, "disable_tqdm": false, "do_eval": 1, "do_predict": false, "do_train": 1, "eval_accumulation_steps": null, "eval_steps": 5000, "evaluation_strategy": "steps", "fp16": false, "fp16_opt_level": "O1", "gradient_accumulation_steps": 1, "greater_is_better": null, "ignore_data_skip": false, "label_names": null, "learning_rate": 3e-05, "load_best_model_at_end": false, "local_rank": -1, "logging_dir": "/data_2to/devel_data/nn_pruning/output/squad_test5/", "logging_first_step": false, "logging_steps": 250, "max_grad_norm": 1.0, "max_steps": -1, "metric_for_best_model": null, "model_parallel": false, "no_cuda": false, "num_train_epochs": 20, "optimize_model_before_eval": "disabled", "output_dir": "/data_2to/devel_data/nn_pruning/output/squad_test5/", "overwrite_output_dir": 1, "past_index": -1, "per_device_eval_batch_size": 8, "per_device_train_batch_size": 16, "per_gpu_eval_batch_size": null, "per_gpu_train_batch_size": null, "prediction_loss_only": false, "remove_unused_columns": true, "run_name": "/data_2to/devel_data/nn_pruning/output/squad_test5/", "save_steps": 5000, "save_total_limit": 50, "seed": 17, "tpu_metrics_debug": false, "tpu_num_cores": null, "warmup_steps": 5400, "weight_decay": 0.0}}, "f1": 87.45888007303566, "fill_rate": 0.2118477527006174, "speedup": 2.151592015203899}}
{"speedup": 2.2265480935180695, "f1": 86.81165607636312, "meta": {"annotate": "21", "cat_fun_name": "is_new_xp", "checkpoint": {"config": {"_name_or_path": "bert-base-uncased", "architectures": ["BertForQuestionAnswering"], "attention_probs_dropout_prob": 0.1, "gradient_checkpointing": false, "hidden_act": "gelu", "hidden_dropout_prob": 0.1, "hidden_size": 768, "initializer_range": 0.02, "intermediate_size": 3072, "layer_norm_eps": 1e-12, "max_position_embeddings": 512, "model_type": "bert", "num_attention_heads": 12, "num_hidden_layers": 12, "pad_token_id": 0, "position_embedding_type": "absolute", "type_vocab_size": 2, "vocab_size": 30522}, "eval_metrics": {"exact_match": 79.4228949858089, "f1": 86.81165607636312}, "path": "/data_2to/devel_data/nn_pruning/output/squad_test4/hp_od-__data_2to__devel_data__nn_pruning__output__squad_test4___es-steps_nte20_ls250_stl50_est5000_rn-__data_2to__devel_data__nn_pruning__output__squad_test4___dpm-sigmoied_threshold:--63d7a49c946fed3/checkpoint-110000", "sparse_args": {"ampere_pruning_method": "disabled", "attention_block_cols": 32, "attention_block_rows": 32, "attention_lambda": 1.0, "attention_output_with_dense": 0, "attention_pruning_method": "sigmoied_threshold", "bias_mask": true, "dense_block_cols": 1, "dense_block_rows": 1, "dense_lambda": 1.0, "dense_pruning_method": "sigmoied_threshold:1d_alt", "distil_alpha_ce": 0.1, "distil_alpha_teacher": 0.9, "distil_teacher_name_or_path": "bert-large-uncased-whole-word-masking-finetuned-squad", "distil_temperature": 2.0, "final_ampere_temperature": 20.0, "final_finetune": false, "final_threshold": 0.1, "final_warmup": 10, "gelu_patch": 0, "initial_ampere_temperature": 0.0, "initial_threshold": 0, "initial_warmup": 1, "layer_norm_patch": 1, "layer_norm_patch_start_delta": 0.99, "layer_norm_patch_steps": 20000, "mask_init": "constant", "mask_scale": 0.0, "mask_scores_learning_rate": 0.01, "regularization": "l1", "regularization_final_lambda": 20}, "speed": {"cuda_eval_elapsed_time": 17.33373427581787, "eval_elapsed_time": 24.38529558479786}, "speedup": 2.2265480935180695, "stats": {"layers": {"0": {"linear_attention_nnz": 704512, "linear_attention_total": 2359296, "linear_dense_nnz": 1208832, "linear_dense_total": 4718592, "linear_nnz": 1913344, "linear_total": 7077888, "nnz": 1919603, "total": 7087872}, "1": {"linear_attention_nnz": 611328, "linear_attention_total": 2359296, "linear_dense_nnz": 992256, "linear_dense_total": 4718592, "linear_nnz": 1603584, "linear_total": 7077888, "nnz": 1609638, "total": 7087872}, "10": {"linear_attention_nnz": 434176, "linear_attention_total": 2359296, "linear_dense_nnz": 442368, "linear_dense_total": 4718592, "linear_nnz": 876544, "linear_total": 7077888, "nnz": 882208, "total": 7087872}, "11": {"linear_attention_nnz": 262144, "linear_attention_total": 2359296, "linear_dense_nnz": 649728, "linear_dense_total": 4718592, "linear_nnz": 911872, "linear_total": 7077888, "nnz": 917479, "total": 7087872}, "2": {"linear_attention_nnz": 1036288, "linear_attention_total": 2359296, "linear_dense_nnz": 1001472, "linear_dense_total": 4718592, "linear_nnz": 2037760, "linear_total": 7077888, "nnz": 2044492, "total": 7087872}, "3": {"linear_attention_nnz": 1167360, "linear_attention_total": 2359296, "linear_dense_nnz": 889344, "linear_dense_total": 4718592, "linear_nnz": 2056704, "linear_total": 7077888, "nnz": 2063395, "total": 7087872}, "4": {"linear_attention_nnz": 885760, "linear_attention_total": 2359296, "linear_dense_nnz": 832512, "linear_dense_total": 4718592, "linear_nnz": 1718272, "linear_total": 7077888, "nnz": 1724606, "total": 7087872}, "5": {"linear_attention_nnz": 773120, "linear_attention_total": 2359296, "linear_dense_nnz": 787968, "linear_dense_total": 4718592, "linear_nnz": 1561088, "linear_total": 7077888, "nnz": 1567265, "total": 7087872}, "6": {"linear_attention_nnz": 815104, "linear_attention_total": 2359296, "linear_dense_nnz": 663552, "linear_dense_total": 4718592, "linear_nnz": 1478656, "linear_total": 7077888, "nnz": 1484976, "total": 7087872}, "7": {"linear_attention_nnz": 885760, "linear_attention_total": 2359296, "linear_dense_nnz": 576000, "linear_dense_total": 4718592, "linear_nnz": 1461760, "linear_total": 7077888, "nnz": 1467927, "total": 7087872}, "8": {"linear_attention_nnz": 769024, "linear_attention_total": 2359296, "linear_dense_nnz": 436224, "linear_dense_total": 4718592, "linear_nnz": 1205248, "linear_total": 7077888, "nnz": 1211356, "total": 7087872}, "9": {"linear_attention_nnz": 564224, "linear_attention_total": 2359296, "linear_dense_nnz": 463872, "linear_dense_total": 4718592, "linear_nnz": 1028096, "linear_total": 7077888, "nnz": 1033934, "total": 7087872}}, "linear_nnz": 17852928, "linear_sparsity": 78.98039641203704, "linear_total": 84934656, "nnz": 41765601, "pruned_heads": {"0": [0, 2, 4, 5, 6, 7, 11], "1": [0, 2, 3, 5, 6, 7, 8, 9], "10": [1, 2, 4, 5, 6, 7, 8], "11": [2, 3, 5, 7, 8, 10, 11], "2": [8, 4, 7], "3": [2, 4, 6], "4": [1, 2, 6, 7, 8, 11], "5": [1, 2, 5, 6, 7, 11], "6": [0, 2, 3, 7, 10], "7": [1, 3, 6, 7, 11], "8": [0, 8, 3, 4], "9": [1, 4, 5, 7, 9, 10]}, "total": 108893186, "total_sparsity": 61.64534941607825}, "training_args": {"adam_beta1": 0.9, "adam_beta2": 0.999, "adam_epsilon": 1e-08, "dataloader_drop_last": false, "dataloader_num_workers": 0, "debug": false, "disable_tqdm": false, "do_eval": 1, "do_predict": false, "do_train": 1, "eval_accumulation_steps": null, "eval_steps": 5000, "evaluation_strategy": "steps", "fp16": false, "fp16_opt_level": "O1", "gradient_accumulation_steps": 1, "greater_is_better": null, "ignore_data_skip": false, "label_names": null, "learning_rate": 3e-05, "load_best_model_at_end": false, "local_rank": -1, "logging_dir": "/data_2to/devel_data/nn_pruning/output/squad_test4/", "logging_first_step": false, "logging_steps": 250, "max_grad_norm": 1.0, "max_steps": -1, "metric_for_best_model": null, "model_parallel": false, "no_cuda": false, "num_train_epochs": 20, "optimize_model_before_eval": "disabled", "output_dir": "/data_2to/devel_data/nn_pruning/output/squad_test4/", "overwrite_output_dir": 1, "past_index": -1, "per_device_eval_batch_size": 8, "per_device_train_batch_size": 16, "per_gpu_eval_batch_size": null, "per_gpu_train_batch_size": null, "prediction_loss_only": false, "remove_unused_columns": true, "run_name": "/data_2to/devel_data/nn_pruning/output/squad_test4/", "save_steps": 5000, "save_total_limit": 50, "seed": 17, "tpu_metrics_debug": false, "tpu_num_cores": null, "warmup_steps": 5400, "weight_decay": 0.0}}, "f1": 86.81165607636312, "fill_rate": 0.21019603587962965, "speedup": 2.2265480935180695}}
