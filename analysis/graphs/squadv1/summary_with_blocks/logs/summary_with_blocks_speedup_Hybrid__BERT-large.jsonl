{"speedup": 0.9300676995438012, "f1": 90.32458147221426, "meta": {"annotate": "18", "cat_fun_name": "is_new_xp", "checkpoint": {"config": {"_name_or_path": "bert-large-uncased", "architectures": ["BertForQuestionAnswering"], "attention_probs_dropout_prob": 0.1, "gradient_checkpointing": false, "hidden_act": "gelu", "hidden_dropout_prob": 0.1, "hidden_size": 1024, "initializer_range": 0.02, "intermediate_size": 4096, "layer_norm_eps": 1e-12, "max_position_embeddings": 512, "model_type": "bert", "num_attention_heads": 16, "num_hidden_layers": 24, "pad_token_id": 0, "position_embedding_type": "absolute", "type_vocab_size": 2, "vocab_size": 30522}, "eval_metrics": {"exact_match": 83.78429517502366, "f1": 90.32458147221426}, "path": "/data_2to/devel_data/nn_pruning/output/squad_test_large/large_regu_10_d0.25/checkpoint-210000", "sparse_args": {"ampere_pruning_method": "disabled", "attention_block_cols": 32, "attention_block_rows": 32, "attention_lambda": 1.0, "attention_output_with_dense": 0, "attention_pruning_method": "sigmoied_threshold", "bias_mask": true, "dense_block_cols": 1, "dense_block_rows": 1, "dense_lambda": 0.25, "dense_pruning_method": "sigmoied_threshold:1d_alt", "distil_alpha_ce": 0.1, "distil_alpha_teacher": 0.9, "distil_teacher_name_or_path": "bert-large-uncased-whole-word-masking-finetuned-squad", "distil_temperature": 2.0, "final_ampere_temperature": 20.0, "final_finetune": false, "final_threshold": 0.1, "final_warmup": 10, "initial_ampere_temperature": 0.0, "initial_threshold": 0, "initial_warmup": 1, "mask_init": "constant", "mask_scale": 0.0, "mask_scores_learning_rate": 0.01, "regularization": "l1", "regularization_final_lambda": 10}, "speed": {"cuda_eval_elapsed_time": 41.496326583862306, "eval_elapsed_time": 49.08256564009935}, "speedup": 0.9300676995438012, "stats": {"layers": {"0": {"linear_attention_nnz": 783360, "linear_attention_total": 4194304, "linear_dense_nnz": 835584, "linear_dense_total": 8388608, "linear_nnz": 1618944, "linear_total": 12582912, "nnz": 1626424, "total": 12596224}, "1": {"linear_attention_nnz": 326656, "linear_attention_total": 4194304, "linear_dense_nnz": 1275904, "linear_dense_total": 8388608, "linear_nnz": 1602560, "linear_total": 12582912, "nnz": 1609647, "total": 12596224}, "10": {"linear_attention_nnz": 1636352, "linear_attention_total": 4194304, "linear_dense_nnz": 2410496, "linear_dense_total": 8388608, "linear_nnz": 4046848, "linear_total": 12582912, "nnz": 4056121, "total": 12596224}, "11": {"linear_attention_nnz": 1575936, "linear_attention_total": 4194304, "linear_dense_nnz": 2510848, "linear_dense_total": 8388608, "linear_nnz": 4086784, "linear_total": 12582912, "nnz": 4095818, "total": 12596224}, "12": {"linear_attention_nnz": 1203200, "linear_attention_total": 4194304, "linear_dense_nnz": 2660352, "linear_dense_total": 8388608, "linear_nnz": 3863552, "linear_total": 12582912, "nnz": 3872307, "total": 12596224}, "13": {"linear_attention_nnz": 2030592, "linear_attention_total": 4194304, "linear_dense_nnz": 2605056, "linear_dense_total": 8388608, "linear_nnz": 4635648, "linear_total": 12582912, "nnz": 4645176, "total": 12596224}, "14": {"linear_attention_nnz": 1785856, "linear_attention_total": 4194304, "linear_dense_nnz": 2299904, "linear_dense_total": 8388608, "linear_nnz": 4085760, "linear_total": 12582912, "nnz": 4094851, "total": 12596224}, "15": {"linear_attention_nnz": 1946624, "linear_attention_total": 4194304, "linear_dense_nnz": 1699840, "linear_dense_total": 8388608, "linear_nnz": 3646464, "linear_total": 12582912, "nnz": 3655358, "total": 12596224}, "16": {"linear_attention_nnz": 1647616, "linear_attention_total": 4194304, "linear_dense_nnz": 1402880, "linear_dense_total": 8388608, "linear_nnz": 3050496, "linear_total": 12582912, "nnz": 3059149, "total": 12596224}, "17": {"linear_attention_nnz": 1538048, "linear_attention_total": 4194304, "linear_dense_nnz": 1097728, "linear_dense_total": 8388608, "linear_nnz": 2635776, "linear_total": 12582912, "nnz": 2644472, "total": 12596224}, "18": {"linear_attention_nnz": 1169408, "linear_attention_total": 4194304, "linear_dense_nnz": 901120, "linear_dense_total": 8388608, "linear_nnz": 2070528, "linear_total": 12582912, "nnz": 2078488, "total": 12596224}, "19": {"linear_attention_nnz": 607232, "linear_attention_total": 4194304, "linear_dense_nnz": 739328, "linear_dense_total": 8388608, "linear_nnz": 1346560, "linear_total": 12582912, "nnz": 1353929, "total": 12596224}, "2": {"linear_attention_nnz": 305152, "linear_attention_total": 4194304, "linear_dense_nnz": 1359872, "linear_dense_total": 8388608, "linear_nnz": 1665024, "linear_total": 12582912, "nnz": 1672152, "total": 12596224}, "20": {"linear_attention_nnz": 396288, "linear_attention_total": 4194304, "linear_dense_nnz": 358400, "linear_dense_total": 8388608, "linear_nnz": 754688, "linear_total": 12582912, "nnz": 761551, "total": 12596224}, "21": {"linear_attention_nnz": 284672, "linear_attention_total": 4194304, "linear_dense_nnz": 194560, "linear_dense_total": 8388608, "linear_nnz": 479232, "linear_total": 12582912, "nnz": 485695, "total": 12596224}, "22": {"linear_attention_nnz": 70656, "linear_attention_total": 4194304, "linear_dense_nnz": 180224, "linear_dense_total": 8388608, "linear_nnz": 250880, "linear_total": 12582912, "nnz": 256728, "total": 12596224}, "23": {"linear_attention_nnz": 111616, "linear_attention_total": 4194304, "linear_dense_nnz": 323584, "linear_dense_total": 8388608, "linear_nnz": 435200, "linear_total": 12582912, "nnz": 441598, "total": 12596224}, "3": {"linear_attention_nnz": 626688, "linear_attention_total": 4194304, "linear_dense_nnz": 1685504, "linear_dense_total": 8388608, "linear_nnz": 2312192, "linear_total": 12582912, "nnz": 2319831, "total": 12596224}, "4": {"linear_attention_nnz": 369664, "linear_attention_total": 4194304, "linear_dense_nnz": 1767424, "linear_dense_total": 8388608, "linear_nnz": 2137088, "linear_total": 12582912, "nnz": 2144479, "total": 12596224}, "5": {"linear_attention_nnz": 463872, "linear_attention_total": 4194304, "linear_dense_nnz": 1873920, "linear_dense_total": 8388608, "linear_nnz": 2337792, "linear_total": 12582912, "nnz": 2345331, "total": 12596224}, "6": {"linear_attention_nnz": 294912, "linear_attention_total": 4194304, "linear_dense_nnz": 2054144, "linear_dense_total": 8388608, "linear_nnz": 2349056, "linear_total": 12582912, "nnz": 2356491, "total": 12596224}, "7": {"linear_attention_nnz": 613376, "linear_attention_total": 4194304, "linear_dense_nnz": 1773568, "linear_dense_total": 8388608, "linear_nnz": 2386944, "linear_total": 12582912, "nnz": 2394690, "total": 12596224}, "8": {"linear_attention_nnz": 208896, "linear_attention_total": 4194304, "linear_dense_nnz": 1968128, "linear_dense_total": 8388608, "linear_nnz": 2177024, "linear_total": 12582912, "nnz": 2184321, "total": 12596224}, "9": {"linear_attention_nnz": 923648, "linear_attention_total": 4194304, "linear_dense_nnz": 1986560, "linear_dense_total": 8388608, "linear_nnz": 2910208, "linear_total": 12582912, "nnz": 2918282, "total": 12596224}}, "linear_nnz": 56885248, "linear_sparsity": 81.16319444444444, "linear_total": 301989888, "nnz": 88857851, "pruned_heads": {"0": [4, 5, 7, 8, 9, 10, 11, 13, 14, 15], "1": [0, 1, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], "10": [0, 7, 8, 10, 12, 13], "11": [0, 1, 2, 4, 5, 8, 10], "12": [2, 3, 5, 6, 7, 8, 10, 13], "13": [10, 2, 3, 12], "14": [1, 2, 3, 4, 8, 11], "15": [0, 5, 6, 7, 11, 12], "16": [3, 6, 8, 10, 13, 15], "17": [0, 2, 11, 15], "18": [2, 3, 5, 9, 11, 12, 13], "19": [0, 2, 3, 4, 9, 10, 11, 13, 15], "2": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 15], "20": [1, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 15], "21": [2, 3, 4, 5, 6, 8, 10, 11, 12, 13, 14, 15], "22": [0, 1, 2, 3, 4, 5, 8, 9, 10, 11, 12, 13, 14, 15], "23": [1, 2, 4, 5, 6, 7, 9, 10, 12, 13, 14], "3": [0, 2, 3, 4, 5, 6, 7, 8, 10, 13, 14, 15], "4": [0, 1, 2, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], "5": [0, 1, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13, 14], "6": [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15], "7": [0, 1, 2, 4, 5, 6, 8, 10, 11, 13, 14, 15], "8": [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 12, 13, 14, 15], "9": [1, 2, 3, 4, 5, 6, 8, 9, 12, 13, 15]}, "total": 334094338, "total_sparsity": 73.40336518962498}, "training_args": {"_n_gpu": -1, "adafactor": false, "adam_beta1": 0.9, "adam_beta2": 0.999, "adam_epsilon": 1e-08, "dataloader_drop_last": false, "dataloader_num_workers": 0, "dataloader_pin_memory": true, "ddp_find_unused_parameters": null, "debug": false, "deepspeed": null, "disable_tqdm": false, "do_eval": 1, "do_predict": false, "do_train": 1, "eval_accumulation_steps": null, "eval_steps": 10000, "evaluation_strategy": "steps", "fp16": false, "fp16_backend": "auto", "fp16_full_eval": false, "fp16_opt_level": "O1", "gradient_accumulation_steps": 1, "greater_is_better": null, "group_by_length": false, "ignore_data_skip": false, "label_names": null, "label_smoothing_factor": 0.0, "learning_rate": 3e-05, "load_best_model_at_end": false, "local_rank": -1, "logging_dir": "output/squad_test_large/squad_test_large_regu_10_d0.25", "logging_first_step": false, "logging_steps": 250, "logging_strategy": "steps", "lr_scheduler_type": "linear", "max_grad_norm": 1.0, "max_steps": -1, "metric_for_best_model": null, "no_cuda": false, "num_train_epochs": 20, "optimize_model_before_eval": "disabled", "output_dir": "output/squad_test_large/squad_test_large_regu_10_d0.25", "overwrite_output_dir": 1, "past_index": -1, "per_device_eval_batch_size": 8, "per_device_train_batch_size": 8, "per_gpu_eval_batch_size": null, "per_gpu_train_batch_size": null, "prediction_loss_only": false, "remove_unused_columns": true, "report_to": null, "run_name": "output/squad_test_large/squad_test_large_regu_10_d0.25", "save_steps": 10000, "save_strategy": "steps", "save_total_limit": 50, "seed": 17, "sharded_ddp": "", "skip_memory_metrics": false, "tpu_metrics_debug": false, "tpu_num_cores": null, "warmup_ratio": 0.0, "warmup_steps": 5400, "weight_decay": 0.0}}, "f1": 90.32458147221426, "fill_rate": 0.5023148148148149, "speedup": 0.9300676995438012}}
{"speedup": 0.9350465325310627, "f1": 90.22195941338013, "meta": {"annotate": "18", "cat_fun_name": "is_new_xp", "checkpoint": {"config": {"_name_or_path": "bert-large-uncased", "architectures": ["BertForQuestionAnswering"], "attention_probs_dropout_prob": 0.1, "gradient_checkpointing": false, "hidden_act": "gelu", "hidden_dropout_prob": 0.1, "hidden_size": 1024, "initializer_range": 0.02, "intermediate_size": 4096, "layer_norm_eps": 1e-12, "max_position_embeddings": 512, "model_type": "bert", "num_attention_heads": 16, "num_hidden_layers": 24, "pad_token_id": 0, "position_embedding_type": "absolute", "type_vocab_size": 2, "vocab_size": 30522}, "eval_metrics": {"exact_match": 83.66130558183538, "f1": 90.22195941338013}, "path": "/data_2to/devel_data/nn_pruning/output/squad_test_large/large_regu_10_d0.25/checkpoint-221320", "sparse_args": {"ampere_pruning_method": "disabled", "attention_block_cols": 32, "attention_block_rows": 32, "attention_lambda": 1.0, "attention_output_with_dense": 0, "attention_pruning_method": "sigmoied_threshold", "bias_mask": true, "dense_block_cols": 1, "dense_block_rows": 1, "dense_lambda": 0.25, "dense_pruning_method": "sigmoied_threshold:1d_alt", "distil_alpha_ce": 0.1, "distil_alpha_teacher": 0.9, "distil_teacher_name_or_path": "bert-large-uncased-whole-word-masking-finetuned-squad", "distil_temperature": 2.0, "final_ampere_temperature": 20.0, "final_finetune": false, "final_threshold": 0.1, "final_warmup": 10, "initial_ampere_temperature": 0.0, "initial_threshold": 0, "initial_warmup": 1, "mask_init": "constant", "mask_scale": 0.0, "mask_scores_learning_rate": 0.01, "regularization": "l1", "regularization_final_lambda": 10}, "speed": {"cuda_eval_elapsed_time": 41.275371505737304, "eval_elapsed_time": 48.98561626393348}, "speedup": 0.9350465325310627, "stats": {"layers": {"0": {"linear_attention_nnz": 766976, "linear_attention_total": 4194304, "linear_dense_nnz": 831488, "linear_dense_total": 8388608, "linear_nnz": 1598464, "linear_total": 12582912, "nnz": 1605910, "total": 12596224}, "1": {"linear_attention_nnz": 338944, "linear_attention_total": 4194304, "linear_dense_nnz": 1273856, "linear_dense_total": 8388608, "linear_nnz": 1612800, "linear_total": 12582912, "nnz": 1619886, "total": 12596224}, "10": {"linear_attention_nnz": 1596416, "linear_attention_total": 4194304, "linear_dense_nnz": 2408448, "linear_dense_total": 8388608, "linear_nnz": 4004864, "linear_total": 12582912, "nnz": 4014136, "total": 12596224}, "11": {"linear_attention_nnz": 1615872, "linear_attention_total": 4194304, "linear_dense_nnz": 2508800, "linear_dense_total": 8388608, "linear_nnz": 4124672, "linear_total": 12582912, "nnz": 4133705, "total": 12596224}, "12": {"linear_attention_nnz": 1205248, "linear_attention_total": 4194304, "linear_dense_nnz": 2658304, "linear_dense_total": 8388608, "linear_nnz": 3863552, "linear_total": 12582912, "nnz": 3872306, "total": 12596224}, "13": {"linear_attention_nnz": 2006016, "linear_attention_total": 4194304, "linear_dense_nnz": 2603008, "linear_dense_total": 8388608, "linear_nnz": 4609024, "linear_total": 12582912, "nnz": 4618551, "total": 12596224}, "14": {"linear_attention_nnz": 1718272, "linear_attention_total": 4194304, "linear_dense_nnz": 2299904, "linear_dense_total": 8388608, "linear_nnz": 4018176, "linear_total": 12582912, "nnz": 4027267, "total": 12596224}, "15": {"linear_attention_nnz": 1935360, "linear_attention_total": 4194304, "linear_dense_nnz": 1699840, "linear_dense_total": 8388608, "linear_nnz": 3635200, "linear_total": 12582912, "nnz": 3644094, "total": 12596224}, "16": {"linear_attention_nnz": 1612800, "linear_attention_total": 4194304, "linear_dense_nnz": 1402880, "linear_dense_total": 8388608, "linear_nnz": 3015680, "linear_total": 12582912, "nnz": 3024333, "total": 12596224}, "17": {"linear_attention_nnz": 1502208, "linear_attention_total": 4194304, "linear_dense_nnz": 1097728, "linear_dense_total": 8388608, "linear_nnz": 2599936, "linear_total": 12582912, "nnz": 2608632, "total": 12596224}, "18": {"linear_attention_nnz": 1167360, "linear_attention_total": 4194304, "linear_dense_nnz": 901120, "linear_dense_total": 8388608, "linear_nnz": 2068480, "linear_total": 12582912, "nnz": 2076440, "total": 12596224}, "19": {"linear_attention_nnz": 601088, "linear_attention_total": 4194304, "linear_dense_nnz": 739328, "linear_dense_total": 8388608, "linear_nnz": 1340416, "linear_total": 12582912, "nnz": 1347785, "total": 12596224}, "2": {"linear_attention_nnz": 305152, "linear_attention_total": 4194304, "linear_dense_nnz": 1357824, "linear_dense_total": 8388608, "linear_nnz": 1662976, "linear_total": 12582912, "nnz": 1670103, "total": 12596224}, "20": {"linear_attention_nnz": 364544, "linear_attention_total": 4194304, "linear_dense_nnz": 356352, "linear_dense_total": 8388608, "linear_nnz": 720896, "linear_total": 12582912, "nnz": 727758, "total": 12596224}, "21": {"linear_attention_nnz": 274432, "linear_attention_total": 4194304, "linear_dense_nnz": 194560, "linear_dense_total": 8388608, "linear_nnz": 468992, "linear_total": 12582912, "nnz": 475519, "total": 12596224}, "22": {"linear_attention_nnz": 70656, "linear_attention_total": 4194304, "linear_dense_nnz": 180224, "linear_dense_total": 8388608, "linear_nnz": 250880, "linear_total": 12582912, "nnz": 256728, "total": 12596224}, "23": {"linear_attention_nnz": 102400, "linear_attention_total": 4194304, "linear_dense_nnz": 321536, "linear_dense_total": 8388608, "linear_nnz": 423936, "linear_total": 12582912, "nnz": 430301, "total": 12596224}, "3": {"linear_attention_nnz": 621568, "linear_attention_total": 4194304, "linear_dense_nnz": 1685504, "linear_dense_total": 8388608, "linear_nnz": 2307072, "linear_total": 12582912, "nnz": 2314711, "total": 12596224}, "4": {"linear_attention_nnz": 377856, "linear_attention_total": 4194304, "linear_dense_nnz": 1767424, "linear_dense_total": 8388608, "linear_nnz": 2145280, "linear_total": 12582912, "nnz": 2152671, "total": 12596224}, "5": {"linear_attention_nnz": 460800, "linear_attention_total": 4194304, "linear_dense_nnz": 1871872, "linear_dense_total": 8388608, "linear_nnz": 2332672, "linear_total": 12582912, "nnz": 2340210, "total": 12596224}, "6": {"linear_attention_nnz": 309248, "linear_attention_total": 4194304, "linear_dense_nnz": 2054144, "linear_dense_total": 8388608, "linear_nnz": 2363392, "linear_total": 12582912, "nnz": 2370827, "total": 12596224}, "7": {"linear_attention_nnz": 583680, "linear_attention_total": 4194304, "linear_dense_nnz": 1773568, "linear_dense_total": 8388608, "linear_nnz": 2357248, "linear_total": 12582912, "nnz": 2364994, "total": 12596224}, "8": {"linear_attention_nnz": 215040, "linear_attention_total": 4194304, "linear_dense_nnz": 1966080, "linear_dense_total": 8388608, "linear_nnz": 2181120, "linear_total": 12582912, "nnz": 2188448, "total": 12596224}, "9": {"linear_attention_nnz": 916480, "linear_attention_total": 4194304, "linear_dense_nnz": 1986560, "linear_dense_total": 8388608, "linear_nnz": 2903040, "linear_total": 12582912, "nnz": 2911082, "total": 12596224}}, "linear_nnz": 56608768, "linear_sparsity": 81.25474717881944, "linear_total": 301989888, "nnz": 88581359, "pruned_heads": {"0": [4, 5, 7, 8, 9, 10, 11, 13, 14, 15], "1": [0, 1, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], "10": [0, 7, 8, 10, 12, 13], "11": [0, 1, 2, 4, 5, 8, 10], "12": [2, 3, 5, 6, 7, 8, 10, 13], "13": [10, 2, 3, 12], "14": [1, 2, 3, 4, 8, 11], "15": [0, 5, 6, 7, 11, 12], "16": [3, 6, 8, 10, 13, 15], "17": [0, 2, 11, 15], "18": [2, 3, 5, 9, 11, 12, 13], "19": [0, 2, 3, 4, 9, 10, 11, 13, 15], "2": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 15], "20": [1, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 15], "21": [2, 3, 4, 5, 6, 8, 10, 11, 12, 13, 14, 15], "22": [0, 1, 2, 3, 4, 5, 8, 9, 10, 11, 12, 13, 14, 15], "23": [1, 2, 4, 5, 6, 7, 9, 10, 12, 13, 14], "3": [0, 2, 3, 4, 5, 6, 7, 8, 10, 13, 14, 15], "4": [0, 1, 2, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], "5": [0, 1, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13, 14], "6": [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15], "7": [0, 1, 2, 4, 5, 6, 8, 10, 11, 13, 14, 15], "8": [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 12, 13, 14, 15], "9": [1, 2, 3, 4, 5, 6, 8, 9, 12, 13, 15]}, "total": 334094338, "total_sparsity": 73.4861238504437}, "training_args": {"_n_gpu": -1, "adafactor": false, "adam_beta1": 0.9, "adam_beta2": 0.999, "adam_epsilon": 1e-08, "dataloader_drop_last": false, "dataloader_num_workers": 0, "dataloader_pin_memory": true, "ddp_find_unused_parameters": null, "debug": false, "deepspeed": null, "disable_tqdm": false, "do_eval": 1, "do_predict": false, "do_train": 1, "eval_accumulation_steps": null, "eval_steps": 10000, "evaluation_strategy": "steps", "fp16": false, "fp16_backend": "auto", "fp16_full_eval": false, "fp16_opt_level": "O1", "gradient_accumulation_steps": 1, "greater_is_better": null, "group_by_length": false, "ignore_data_skip": false, "label_names": null, "label_smoothing_factor": 0.0, "learning_rate": 3e-05, "load_best_model_at_end": false, "local_rank": -1, "logging_dir": "output/squad_test_large/squad_test_large_regu_10_d0.25", "logging_first_step": false, "logging_steps": 250, "logging_strategy": "steps", "lr_scheduler_type": "linear", "max_grad_norm": 1.0, "max_steps": -1, "metric_for_best_model": null, "no_cuda": false, "num_train_epochs": 20, "optimize_model_before_eval": "disabled", "output_dir": "output/squad_test_large/squad_test_large_regu_10_d0.25", "overwrite_output_dir": 1, "past_index": -1, "per_device_eval_batch_size": 8, "per_device_train_batch_size": 8, "per_gpu_eval_batch_size": null, "per_gpu_train_batch_size": null, "prediction_loss_only": false, "remove_unused_columns": true, "report_to": null, "run_name": "output/squad_test_large/squad_test_large_regu_10_d0.25", "save_steps": 10000, "save_strategy": "steps", "save_total_limit": 50, "seed": 17, "sharded_ddp": "", "skip_memory_metrics": false, "tpu_metrics_debug": false, "tpu_num_cores": null, "warmup_ratio": 0.0, "warmup_steps": 5400, "weight_decay": 0.0}}, "f1": 90.22195941338013, "fill_rate": 0.4998734085648149, "speedup": 0.9350465325310627}}
{"speedup": 1.0289741034797428, "f1": 89.04761607630476, "meta": {"annotate": "12", "cat_fun_name": "is_new_xp", "checkpoint": {"config": {"_name_or_path": "bert-large-uncased", "architectures": ["BertForQuestionAnswering"], "attention_probs_dropout_prob": 0.1, "gradient_checkpointing": false, "hidden_act": "gelu", "hidden_dropout_prob": 0.1, "hidden_size": 1024, "initializer_range": 0.02, "intermediate_size": 4096, "layer_norm_eps": 1e-12, "max_position_embeddings": 512, "model_type": "bert", "num_attention_heads": 16, "num_hidden_layers": 24, "pad_token_id": 0, "position_embedding_type": "absolute", "type_vocab_size": 2, "vocab_size": 30522}, "eval_metrics": {"exact_match": 82.33680227057711, "f1": 89.04761607630476}, "path": "/data_2to/devel_data/nn_pruning/output/squad_test_large/large_regu_10/checkpoint-215000", "sparse_args": {"ampere_pruning_method": "disabled", "attention_block_cols": 32, "attention_block_rows": 32, "attention_lambda": 1.0, "attention_output_with_dense": 0, "attention_pruning_method": "sigmoied_threshold", "bias_mask": true, "dense_block_cols": 1, "dense_block_rows": 1, "dense_lambda": 1.0, "dense_pruning_method": "sigmoied_threshold:1d_alt", "distil_alpha_ce": 0.1, "distil_alpha_teacher": 0.9, "distil_teacher_name_or_path": "bert-large-uncased-whole-word-masking-finetuned-squad", "distil_temperature": 2.0, "final_ampere_temperature": 20.0, "final_finetune": false, "final_threshold": 0.1, "final_warmup": 10, "initial_ampere_temperature": 0.0, "initial_threshold": 0, "initial_warmup": 1, "mask_init": "constant", "mask_scale": 0.0, "mask_scores_learning_rate": 0.01, "regularization": "l1", "regularization_final_lambda": 10}, "speed": {"cuda_eval_elapsed_time": 37.50764268493653, "eval_elapsed_time": 44.93039320781827}, "speedup": 1.0289741034797428, "stats": {"layers": {"0": {"linear_attention_nnz": 974848, "linear_attention_total": 4194304, "linear_dense_nnz": 192512, "linear_dense_total": 8388608, "linear_nnz": 1167360, "linear_total": 12582912, "nnz": 1174526, "total": 12596224}, "1": {"linear_attention_nnz": 306176, "linear_attention_total": 4194304, "linear_dense_nnz": 270336, "linear_dense_total": 8388608, "linear_nnz": 576512, "linear_total": 12582912, "nnz": 583204, "total": 12596224}, "10": {"linear_attention_nnz": 1714176, "linear_attention_total": 4194304, "linear_dense_nnz": 995328, "linear_dense_total": 8388608, "linear_nnz": 2709504, "linear_total": 12582912, "nnz": 2717926, "total": 12596224}, "11": {"linear_attention_nnz": 1875968, "linear_attention_total": 4194304, "linear_dense_nnz": 1032192, "linear_dense_total": 8388608, "linear_nnz": 2908160, "linear_total": 12582912, "nnz": 2916760, "total": 12596224}, "12": {"linear_attention_nnz": 1832960, "linear_attention_total": 4194304, "linear_dense_nnz": 1241088, "linear_dense_total": 8388608, "linear_nnz": 3074048, "linear_total": 12582912, "nnz": 3082878, "total": 12596224}, "13": {"linear_attention_nnz": 2155520, "linear_attention_total": 4194304, "linear_dense_nnz": 1179648, "linear_dense_total": 8388608, "linear_nnz": 3335168, "linear_total": 12582912, "nnz": 3344128, "total": 12596224}, "14": {"linear_attention_nnz": 1942528, "linear_attention_total": 4194304, "linear_dense_nnz": 909312, "linear_dense_total": 8388608, "linear_nnz": 2851840, "linear_total": 12582912, "nnz": 2860412, "total": 12596224}, "15": {"linear_attention_nnz": 2079744, "linear_attention_total": 4194304, "linear_dense_nnz": 681984, "linear_dense_total": 8388608, "linear_nnz": 2761728, "linear_total": 12582912, "nnz": 2770125, "total": 12596224}, "16": {"linear_attention_nnz": 1843200, "linear_attention_total": 4194304, "linear_dense_nnz": 473088, "linear_dense_total": 8388608, "linear_nnz": 2316288, "linear_total": 12582912, "nnz": 2324615, "total": 12596224}, "17": {"linear_attention_nnz": 1582080, "linear_attention_total": 4194304, "linear_dense_nnz": 368640, "linear_dense_total": 8388608, "linear_nnz": 1950720, "linear_total": 12582912, "nnz": 1958964, "total": 12596224}, "18": {"linear_attention_nnz": 1435648, "linear_attention_total": 4194304, "linear_dense_nnz": 321536, "linear_dense_total": 8388608, "linear_nnz": 1757184, "linear_total": 12582912, "nnz": 1765277, "total": 12596224}, "19": {"linear_attention_nnz": 717824, "linear_attention_total": 4194304, "linear_dense_nnz": 270336, "linear_dense_total": 8388608, "linear_nnz": 988160, "linear_total": 12582912, "nnz": 995428, "total": 12596224}, "2": {"linear_attention_nnz": 297984, "linear_attention_total": 4194304, "linear_dense_nnz": 286720, "linear_dense_total": 8388608, "linear_nnz": 584704, "linear_total": 12582912, "nnz": 591308, "total": 12596224}, "20": {"linear_attention_nnz": 334848, "linear_attention_total": 4194304, "linear_dense_nnz": 112640, "linear_dense_total": 8388608, "linear_nnz": 447488, "linear_total": 12582912, "nnz": 454135, "total": 12596224}, "21": {"linear_attention_nnz": 358400, "linear_attention_total": 4194304, "linear_dense_nnz": 77824, "linear_dense_total": 8388608, "linear_nnz": 436224, "linear_total": 12582912, "nnz": 443014, "total": 12596224}, "22": {"linear_attention_nnz": 134144, "linear_attention_total": 4194304, "linear_dense_nnz": 79872, "linear_dense_total": 8388608, "linear_nnz": 214016, "linear_total": 12582912, "nnz": 220231, "total": 12596224}, "23": {"linear_attention_nnz": 111616, "linear_attention_total": 4194304, "linear_dense_nnz": 182272, "linear_dense_total": 8388608, "linear_nnz": 293888, "linear_total": 12582912, "nnz": 300185, "total": 12596224}, "3": {"linear_attention_nnz": 834560, "linear_attention_total": 4194304, "linear_dense_nnz": 413696, "linear_dense_total": 8388608, "linear_nnz": 1248256, "linear_total": 12582912, "nnz": 1255434, "total": 12596224}, "4": {"linear_attention_nnz": 381952, "linear_attention_total": 4194304, "linear_dense_nnz": 466944, "linear_dense_total": 8388608, "linear_nnz": 848896, "linear_total": 12582912, "nnz": 855652, "total": 12596224}, "5": {"linear_attention_nnz": 406528, "linear_attention_total": 4194304, "linear_dense_nnz": 552960, "linear_dense_total": 8388608, "linear_nnz": 959488, "linear_total": 12582912, "nnz": 966318, "total": 12596224}, "6": {"linear_attention_nnz": 522240, "linear_attention_total": 4194304, "linear_dense_nnz": 608256, "linear_dense_total": 8388608, "linear_nnz": 1130496, "linear_total": 12582912, "nnz": 1137481, "total": 12596224}, "7": {"linear_attention_nnz": 771072, "linear_attention_total": 4194304, "linear_dense_nnz": 438272, "linear_dense_total": 8388608, "linear_nnz": 1209344, "linear_total": 12582912, "nnz": 1216534, "total": 12596224}, "8": {"linear_attention_nnz": 414720, "linear_attention_total": 4194304, "linear_dense_nnz": 661504, "linear_dense_total": 8388608, "linear_nnz": 1076224, "linear_total": 12582912, "nnz": 1083267, "total": 12596224}, "9": {"linear_attention_nnz": 1091584, "linear_attention_total": 4194304, "linear_dense_nnz": 747520, "linear_dense_total": 8388608, "linear_nnz": 1839104, "linear_total": 12582912, "nnz": 1846669, "total": 12596224}}, "linear_nnz": 36684800, "linear_sparsity": 87.85230848524306, "linear_total": 301989888, "nnz": 68649433, "pruned_heads": {"0": [2, 3, 4, 7, 8, 9, 10, 13, 14, 15], "1": [0, 1, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], "10": [7, 8, 10, 12, 13, 14], "11": [0, 2, 4, 5, 8, 10], "12": [10, 3, 13, 6], "13": [2, 10, 4, 12], "14": [2, 3, 4, 8, 11], "15": [0, 5, 6, 7, 11, 12], "16": [3, 6, 8, 13, 15], "17": [0, 2, 4, 11, 15], "18": [2, 3, 5, 11, 13], "19": [0, 2, 3, 4, 9, 10, 11, 15], "2": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 15], "20": [0, 1, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 15], "21": [2, 4, 5, 6, 8, 10, 11, 12, 13, 14, 15], "22": [0, 1, 2, 3, 4, 7, 8, 9, 10, 11, 12, 13, 14], "23": [1, 2, 3, 4, 5, 6, 7, 9, 10, 12, 13, 14], "3": [0, 2, 3, 4, 5, 6, 7, 8, 10, 14, 15], "4": [0, 1, 2, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], "5": [0, 1, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15], "6": [0, 1, 2, 3, 5, 6, 8, 9, 10, 11, 13, 14, 15], "7": [0, 1, 2, 4, 5, 6, 8, 10, 11, 13, 14], "8": [0, 1, 2, 3, 4, 5, 6, 8, 12, 13, 14, 15], "9": [1, 2, 3, 4, 5, 6, 8, 12, 13, 15]}, "total": 334094338, "total_sparsity": 79.45208128609471}, "training_args": {"_n_gpu": -1, "adafactor": false, "adam_beta1": 0.9, "adam_beta2": 0.999, "adam_epsilon": 1e-08, "dataloader_drop_last": false, "dataloader_num_workers": 0, "dataloader_pin_memory": true, "ddp_find_unused_parameters": null, "debug": false, "deepspeed": null, "disable_tqdm": false, "do_eval": 1, "do_predict": false, "do_train": 1, "eval_accumulation_steps": null, "eval_steps": 5000, "evaluation_strategy": "steps", "fp16": false, "fp16_backend": "auto", "fp16_full_eval": false, "fp16_opt_level": "O1", "gradient_accumulation_steps": 1, "greater_is_better": null, "group_by_length": false, "ignore_data_skip": false, "label_names": null, "label_smoothing_factor": 0.0, "learning_rate": 3e-05, "load_best_model_at_end": false, "local_rank": -1, "logging_dir": "output/squad_test_large/squad_test_large_regu-10", "logging_first_step": false, "logging_steps": 250, "logging_strategy": "steps", "lr_scheduler_type": "linear", "max_grad_norm": 1.0, "max_steps": -1, "metric_for_best_model": null, "no_cuda": false, "num_train_epochs": 20, "optimize_model_before_eval": "disabled", "output_dir": "output/squad_test_large/squad_test_large_regu-10", "overwrite_output_dir": 1, "past_index": -1, "per_device_eval_batch_size": 8, "per_device_train_batch_size": 8, "per_gpu_eval_batch_size": null, "per_gpu_train_batch_size": null, "prediction_loss_only": false, "remove_unused_columns": true, "report_to": null, "run_name": "output/squad_test_large/squad_test_large_regu-10", "save_steps": 5000, "save_strategy": "steps", "save_total_limit": 50, "seed": 17, "sharded_ddp": "", "skip_memory_metrics": false, "tpu_metrics_debug": false, "tpu_num_cores": null, "warmup_ratio": 0.0, "warmup_steps": 5400, "weight_decay": 0.0}}, "f1": 89.04761607630476, "fill_rate": 0.32393844039351843, "speedup": 1.0289741034797428}}
{"speedup": 1.2936473074353696, "f1": 87.8561484925226, "meta": {"annotate": "8", "cat_fun_name": "is_new_xp", "checkpoint": {"config": {"_name_or_path": "bert-large-uncased", "architectures": ["BertForQuestionAnswering"], "attention_probs_dropout_prob": 0.1, "gradient_checkpointing": false, "hidden_act": "gelu", "hidden_dropout_prob": 0.1, "hidden_size": 1024, "initializer_range": 0.02, "intermediate_size": 4096, "layer_norm_eps": 1e-12, "max_position_embeddings": 512, "model_type": "bert", "num_attention_heads": 16, "num_hidden_layers": 24, "pad_token_id": 0, "position_embedding_type": "absolute", "type_vocab_size": 2, "vocab_size": 30522}, "eval_metrics": {"exact_match": 80.59602649006622, "f1": 87.8561484925226}, "path": "/data_2to/devel_data/nn_pruning/output/squad_test_large/large_regu_40_d0.25/checkpoint-220000", "sparse_args": {"ampere_pruning_method": "disabled", "attention_block_cols": 32, "attention_block_rows": 32, "attention_lambda": 1.0, "attention_output_with_dense": 0, "attention_pruning_method": "sigmoied_threshold", "bias_mask": true, "dense_block_cols": 1, "dense_block_rows": 1, "dense_lambda": 0.25, "dense_pruning_method": "sigmoied_threshold:1d_alt", "distil_alpha_ce": 0.1, "distil_alpha_teacher": 0.9, "distil_teacher_name_or_path": "bert-large-uncased-whole-word-masking-finetuned-squad", "distil_temperature": 2.0, "final_ampere_temperature": 20.0, "final_finetune": false, "final_threshold": 0.1, "final_warmup": 10, "initial_ampere_temperature": 0.0, "initial_threshold": 0, "initial_warmup": 1, "mask_init": "constant", "mask_scale": 0.0, "mask_scores_learning_rate": 0.01, "regularization": "l1", "regularization_final_lambda": 40}, "speed": {"cuda_eval_elapsed_time": 29.83378296661377, "eval_elapsed_time": 37.31617963500321}, "speedup": 1.2936473074353696, "stats": {"layers": {"0": {"linear_attention_nnz": 340992, "linear_attention_total": 4194304, "linear_dense_nnz": 253952, "linear_dense_total": 8388608, "linear_nnz": 594944, "linear_total": 12582912, "nnz": 601564, "total": 12596224}, "1": {"linear_attention_nnz": 141312, "linear_attention_total": 4194304, "linear_dense_nnz": 432128, "linear_dense_total": 8388608, "linear_nnz": 573440, "linear_total": 12582912, "nnz": 579955, "total": 12596224}, "10": {"linear_attention_nnz": 832512, "linear_attention_total": 4194304, "linear_dense_nnz": 1210368, "linear_dense_total": 8388608, "linear_nnz": 2042880, "linear_total": 12582912, "nnz": 2050735, "total": 12596224}, "11": {"linear_attention_nnz": 765952, "linear_attention_total": 4194304, "linear_dense_nnz": 1277952, "linear_dense_total": 8388608, "linear_nnz": 2043904, "linear_total": 12582912, "nnz": 2051536, "total": 12596224}, "12": {"linear_attention_nnz": 720896, "linear_attention_total": 4194304, "linear_dense_nnz": 1400832, "linear_dense_total": 8388608, "linear_nnz": 2121728, "linear_total": 12582912, "nnz": 2129420, "total": 12596224}, "13": {"linear_attention_nnz": 1234944, "linear_attention_total": 4194304, "linear_dense_nnz": 1464320, "linear_dense_total": 8388608, "linear_nnz": 2699264, "linear_total": 12582912, "nnz": 2707787, "total": 12596224}, "14": {"linear_attention_nnz": 879616, "linear_attention_total": 4194304, "linear_dense_nnz": 1122304, "linear_dense_total": 8388608, "linear_nnz": 2001920, "linear_total": 12582912, "nnz": 2009956, "total": 12596224}, "15": {"linear_attention_nnz": 917504, "linear_attention_total": 4194304, "linear_dense_nnz": 778240, "linear_dense_total": 8388608, "linear_nnz": 1695744, "linear_total": 12582912, "nnz": 1703324, "total": 12596224}, "16": {"linear_attention_nnz": 793600, "linear_attention_total": 4194304, "linear_dense_nnz": 532480, "linear_dense_total": 8388608, "linear_nnz": 1326080, "linear_total": 12582912, "nnz": 1333572, "total": 12596224}, "17": {"linear_attention_nnz": 726016, "linear_attention_total": 4194304, "linear_dense_nnz": 456704, "linear_dense_total": 8388608, "linear_nnz": 1182720, "linear_total": 12582912, "nnz": 1190495, "total": 12596224}, "18": {"linear_attention_nnz": 656384, "linear_attention_total": 4194304, "linear_dense_nnz": 440320, "linear_dense_total": 8388608, "linear_nnz": 1096704, "linear_total": 12582912, "nnz": 1104087, "total": 12596224}, "19": {"linear_attention_nnz": 281600, "linear_attention_total": 4194304, "linear_dense_nnz": 362496, "linear_dense_total": 8388608, "linear_nnz": 644096, "linear_total": 12582912, "nnz": 650801, "total": 12596224}, "2": {"linear_attention_nnz": 238592, "linear_attention_total": 4194304, "linear_dense_nnz": 450560, "linear_dense_total": 8388608, "linear_nnz": 689152, "linear_total": 12582912, "nnz": 695836, "total": 12596224}, "20": {"linear_attention_nnz": 137216, "linear_attention_total": 4194304, "linear_dense_nnz": 184320, "linear_dense_total": 8388608, "linear_nnz": 321536, "linear_total": 12582912, "nnz": 327738, "total": 12596224}, "21": {"linear_attention_nnz": 175104, "linear_attention_total": 4194304, "linear_dense_nnz": 112640, "linear_dense_total": 8388608, "linear_nnz": 287744, "linear_total": 12582912, "nnz": 293879, "total": 12596224}, "22": {"linear_attention_nnz": 54272, "linear_attention_total": 4194304, "linear_dense_nnz": 114688, "linear_dense_total": 8388608, "linear_nnz": 168960, "linear_total": 12582912, "nnz": 174872, "total": 12596224}, "23": {"linear_attention_nnz": 24576, "linear_attention_total": 4194304, "linear_dense_nnz": 184320, "linear_dense_total": 8388608, "linear_nnz": 208896, "linear_total": 12582912, "nnz": 214458, "total": 12596224}, "3": {"linear_attention_nnz": 320512, "linear_attention_total": 4194304, "linear_dense_nnz": 548864, "linear_dense_total": 8388608, "linear_nnz": 869376, "linear_total": 12582912, "nnz": 876172, "total": 12596224}, "4": {"linear_attention_nnz": 332800, "linear_attention_total": 4194304, "linear_dense_nnz": 614400, "linear_dense_total": 8388608, "linear_nnz": 947200, "linear_total": 12582912, "nnz": 954028, "total": 12596224}, "5": {"linear_attention_nnz": 147456, "linear_attention_total": 4194304, "linear_dense_nnz": 839680, "linear_dense_total": 8388608, "linear_nnz": 987136, "linear_total": 12582912, "nnz": 993786, "total": 12596224}, "6": {"linear_attention_nnz": 166912, "linear_attention_total": 4194304, "linear_dense_nnz": 858112, "linear_dense_total": 8388608, "linear_nnz": 1025024, "linear_total": 12582912, "nnz": 1031555, "total": 12596224}, "7": {"linear_attention_nnz": 376832, "linear_attention_total": 4194304, "linear_dense_nnz": 636928, "linear_dense_total": 8388608, "linear_nnz": 1013760, "linear_total": 12582912, "nnz": 1020759, "total": 12596224}, "8": {"linear_attention_nnz": 145408, "linear_attention_total": 4194304, "linear_dense_nnz": 847872, "linear_dense_total": 8388608, "linear_nnz": 993280, "linear_total": 12582912, "nnz": 999934, "total": 12596224}, "9": {"linear_attention_nnz": 466944, "linear_attention_total": 4194304, "linear_dense_nnz": 901120, "linear_dense_total": 8388608, "linear_nnz": 1368064, "linear_total": 12582912, "nnz": 1375160, "total": 12596224}}, "linear_nnz": 26903552, "linear_sparsity": 91.09124077690971, "linear_total": 301989888, "nnz": 58856371, "pruned_heads": {"0": [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 13, 14, 15], "1": [0, 1, 2, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], "10": [0, 3, 6, 7, 8, 10, 12, 13, 14], "11": [0, 1, 2, 4, 5, 6, 7, 8, 10, 12, 15], "12": [2, 3, 5, 6, 7, 8, 9, 10, 12, 13, 14], "13": [2, 3, 4, 10, 11, 12], "14": [1, 2, 3, 4, 8, 9, 11, 13], "15": [0, 1, 2, 5, 6, 7, 8, 9, 11, 12], "16": [3, 6, 7, 8, 10, 12, 13, 15], "17": [0, 2, 4, 11, 12, 15], "18": [2, 3, 5, 9, 11, 12, 13], "19": [0, 1, 2, 3, 4, 5, 9, 10, 11, 13, 15], "2": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 15], "20": [0, 1, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15], "21": [0, 2, 3, 4, 5, 6, 8, 10, 11, 12, 13, 14, 15], "22": [0, 1, 2, 3, 4, 7, 8, 9, 10, 11, 12, 13, 14], "23": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14], "3": [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14, 15], "4": [0, 1, 2, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], "5": [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], "6": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15], "7": [0, 1, 2, 4, 5, 6, 8, 10, 11, 12, 13, 14, 15], "8": [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 12, 13, 14, 15], "9": [1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 15]}, "total": 334094338, "total_sparsity": 82.38330785480117}, "training_args": {"_n_gpu": -1, "adafactor": false, "adam_beta1": 0.9, "adam_beta2": 0.999, "adam_epsilon": 1e-08, "dataloader_drop_last": false, "dataloader_num_workers": 0, "dataloader_pin_memory": true, "ddp_find_unused_parameters": null, "debug": false, "deepspeed": null, "disable_tqdm": false, "do_eval": 1, "do_predict": false, "do_train": 1, "eval_accumulation_steps": null, "eval_steps": 10000, "evaluation_strategy": "steps", "fp16": false, "fp16_backend": "auto", "fp16_full_eval": false, "fp16_opt_level": "O1", "gradient_accumulation_steps": 1, "greater_is_better": null, "group_by_length": false, "ignore_data_skip": false, "label_names": null, "label_smoothing_factor": 0.0, "learning_rate": 3e-05, "load_best_model_at_end": false, "local_rank": -1, "logging_dir": "output/squad_test_large/squad_test_large_regu_40_d0.25", "logging_first_step": false, "logging_steps": 250, "logging_strategy": "steps", "lr_scheduler_type": "linear", "max_grad_norm": 1.0, "max_steps": -1, "metric_for_best_model": null, "no_cuda": false, "num_train_epochs": 20, "optimize_model_before_eval": "disabled", "output_dir": "output/squad_test_large/squad_test_large_regu_40_d0.25", "overwrite_output_dir": 1, "past_index": -1, "per_device_eval_batch_size": 8, "per_device_train_batch_size": 8, "per_gpu_eval_batch_size": null, "per_gpu_train_batch_size": null, "prediction_loss_only": false, "remove_unused_columns": true, "report_to": null, "run_name": "output/squad_test_large/squad_test_large_regu_40_d0.25", "save_steps": 10000, "save_strategy": "steps", "save_total_limit": 50, "seed": 17, "sharded_ddp": "", "skip_memory_metrics": false, "tpu_metrics_debug": false, "tpu_num_cores": null, "warmup_ratio": 0.0, "warmup_steps": 5400, "weight_decay": 0.0}}, "f1": 87.8561484925226, "fill_rate": 0.23756691261574106, "speedup": 1.2936473074353696}}
{"speedup": 1.3610235261481995, "f1": 86.9851273164745, "meta": {"annotate": "7", "cat_fun_name": "is_new_xp", "checkpoint": {"config": {"_name_or_path": "bert-large-uncased", "architectures": ["BertForQuestionAnswering"], "attention_probs_dropout_prob": 0.1, "gradient_checkpointing": false, "hidden_act": "gelu", "hidden_dropout_prob": 0.1, "hidden_size": 1024, "initializer_range": 0.02, "intermediate_size": 4096, "layer_norm_eps": 1e-12, "max_position_embeddings": 512, "model_type": "bert", "num_attention_heads": 16, "num_hidden_layers": 24, "pad_token_id": 0, "position_embedding_type": "absolute", "type_vocab_size": 2, "vocab_size": 30522}, "eval_metrics": {"exact_match": 79.50804162724693, "f1": 86.9851273164745}, "path": "/data_2to/devel_data/nn_pruning/output/squad_test_large/large_regu_60_d0.25/checkpoint-221320", "sparse_args": {"ampere_pruning_method": "disabled", "attention_block_cols": 32, "attention_block_rows": 32, "attention_lambda": 1.0, "attention_output_with_dense": 0, "attention_pruning_method": "sigmoied_threshold", "bias_mask": true, "dense_block_cols": 1, "dense_block_rows": 1, "dense_lambda": 0.25, "dense_pruning_method": "sigmoied_threshold:1d_alt", "distil_alpha_ce": 0.1, "distil_alpha_teacher": 0.9, "distil_teacher_name_or_path": "bert-large-uncased-whole-word-masking-finetuned-squad", "distil_temperature": 2.0, "final_ampere_temperature": 20.0, "final_finetune": false, "final_threshold": 0.1, "final_warmup": 10, "initial_ampere_temperature": 0.0, "initial_threshold": 0, "initial_warmup": 1, "mask_init": "constant", "mask_scale": 0.0, "mask_scores_learning_rate": 0.01, "regularization": "l1", "regularization_final_lambda": 60}, "speed": {"cuda_eval_elapsed_time": 28.35688896179199, "eval_elapsed_time": 35.278680617921054}, "speedup": 1.3610235261481995, "stats": {"layers": {"0": {"linear_attention_nnz": 388096, "linear_attention_total": 4194304, "linear_dense_nnz": 231424, "linear_dense_total": 8388608, "linear_nnz": 619520, "linear_total": 12582912, "nnz": 626257, "total": 12596224}, "1": {"linear_attention_nnz": 78848, "linear_attention_total": 4194304, "linear_dense_nnz": 290816, "linear_dense_total": 8388608, "linear_nnz": 369664, "linear_total": 12582912, "nnz": 375982, "total": 12596224}, "10": {"linear_attention_nnz": 696320, "linear_attention_total": 4194304, "linear_dense_nnz": 923648, "linear_dense_total": 8388608, "linear_nnz": 1619968, "linear_total": 12582912, "nnz": 1627427, "total": 12596224}, "11": {"linear_attention_nnz": 627712, "linear_attention_total": 4194304, "linear_dense_nnz": 1075200, "linear_dense_total": 8388608, "linear_nnz": 1702912, "linear_total": 12582912, "nnz": 1710349, "total": 12596224}, "12": {"linear_attention_nnz": 573440, "linear_attention_total": 4194304, "linear_dense_nnz": 1126400, "linear_dense_total": 8388608, "linear_nnz": 1699840, "linear_total": 12582912, "nnz": 1707206, "total": 12596224}, "13": {"linear_attention_nnz": 932864, "linear_attention_total": 4194304, "linear_dense_nnz": 1179648, "linear_dense_total": 8388608, "linear_nnz": 2112512, "linear_total": 12582912, "nnz": 2120576, "total": 12596224}, "14": {"linear_attention_nnz": 676864, "linear_attention_total": 4194304, "linear_dense_nnz": 929792, "linear_dense_total": 8388608, "linear_nnz": 1606656, "linear_total": 12582912, "nnz": 1614374, "total": 12596224}, "15": {"linear_attention_nnz": 807936, "linear_attention_total": 4194304, "linear_dense_nnz": 622592, "linear_dense_total": 8388608, "linear_nnz": 1430528, "linear_total": 12582912, "nnz": 1438000, "total": 12596224}, "16": {"linear_attention_nnz": 628736, "linear_attention_total": 4194304, "linear_dense_nnz": 403456, "linear_dense_total": 8388608, "linear_nnz": 1032192, "linear_total": 12582912, "nnz": 1039525, "total": 12596224}, "17": {"linear_attention_nnz": 567296, "linear_attention_total": 4194304, "linear_dense_nnz": 360448, "linear_dense_total": 8388608, "linear_nnz": 927744, "linear_total": 12582912, "nnz": 935024, "total": 12596224}, "18": {"linear_attention_nnz": 482304, "linear_attention_total": 4194304, "linear_dense_nnz": 335872, "linear_dense_total": 8388608, "linear_nnz": 818176, "linear_total": 12582912, "nnz": 825348, "total": 12596224}, "19": {"linear_attention_nnz": 198656, "linear_attention_total": 4194304, "linear_dense_nnz": 307200, "linear_dense_total": 8388608, "linear_nnz": 505856, "linear_total": 12582912, "nnz": 512118, "total": 12596224}, "2": {"linear_attention_nnz": 220160, "linear_attention_total": 4194304, "linear_dense_nnz": 331776, "linear_dense_total": 8388608, "linear_nnz": 551936, "linear_total": 12582912, "nnz": 558530, "total": 12596224}, "20": {"linear_attention_nnz": 115712, "linear_attention_total": 4194304, "linear_dense_nnz": 165888, "linear_dense_total": 8388608, "linear_nnz": 281600, "linear_total": 12582912, "nnz": 287633, "total": 12596224}, "21": {"linear_attention_nnz": 151552, "linear_attention_total": 4194304, "linear_dense_nnz": 75776, "linear_dense_total": 8388608, "linear_nnz": 227328, "linear_total": 12582912, "nnz": 233509, "total": 12596224}, "22": {"linear_attention_nnz": 46080, "linear_attention_total": 4194304, "linear_dense_nnz": 100352, "linear_dense_total": 8388608, "linear_nnz": 146432, "linear_total": 12582912, "nnz": 152209, "total": 12596224}, "23": {"linear_attention_nnz": 24576, "linear_attention_total": 4194304, "linear_dense_nnz": 184320, "linear_dense_total": 8388608, "linear_nnz": 208896, "linear_total": 12582912, "nnz": 214394, "total": 12596224}, "3": {"linear_attention_nnz": 301056, "linear_attention_total": 4194304, "linear_dense_nnz": 432128, "linear_dense_total": 8388608, "linear_nnz": 733184, "linear_total": 12582912, "nnz": 739891, "total": 12596224}, "4": {"linear_attention_nnz": 313344, "linear_attention_total": 4194304, "linear_dense_nnz": 452608, "linear_dense_total": 8388608, "linear_nnz": 765952, "linear_total": 12582912, "nnz": 772669, "total": 12596224}, "5": {"linear_attention_nnz": 24576, "linear_attention_total": 4194304, "linear_dense_nnz": 614400, "linear_dense_total": 8388608, "linear_nnz": 638976, "linear_total": 12582912, "nnz": 644684, "total": 12596224}, "6": {"linear_attention_nnz": 155648, "linear_attention_total": 4194304, "linear_dense_nnz": 598016, "linear_dense_total": 8388608, "linear_nnz": 753664, "linear_total": 12582912, "nnz": 760036, "total": 12596224}, "7": {"linear_attention_nnz": 324608, "linear_attention_total": 4194304, "linear_dense_nnz": 466944, "linear_dense_total": 8388608, "linear_nnz": 791552, "linear_total": 12582912, "nnz": 798276, "total": 12596224}, "8": {"linear_attention_nnz": 97280, "linear_attention_total": 4194304, "linear_dense_nnz": 673792, "linear_dense_total": 8388608, "linear_nnz": 771072, "linear_total": 12582912, "nnz": 777449, "total": 12596224}, "9": {"linear_attention_nnz": 473088, "linear_attention_total": 4194304, "linear_dense_nnz": 692224, "linear_dense_total": 8388608, "linear_nnz": 1165312, "linear_total": 12582912, "nnz": 1172306, "total": 12596224}}, "linear_nnz": 21481472, "linear_sparsity": 92.88669162326389, "linear_total": 301989888, "nnz": 53428734, "pruned_heads": {"0": [0, 1, 2, 3, 4, 7, 8, 9, 10, 11, 13, 14, 15], "1": [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], "10": [0, 3, 6, 7, 8, 10, 12, 13, 14, 15], "11": [0, 1, 2, 4, 5, 6, 7, 8, 10, 12, 15], "12": [1, 2, 3, 5, 6, 7, 8, 9, 10, 12, 13, 14], "13": [2, 3, 4, 9, 10, 11, 12, 13], "14": [1, 2, 3, 4, 8, 9, 11, 12], "15": [0, 1, 2, 5, 6, 7, 8, 9, 11, 12], "16": [3, 6, 7, 8, 10, 12, 13, 15], "17": [0, 2, 4, 8, 11, 12, 15], "18": [2, 3, 5, 9, 10, 11, 12, 13, 15], "19": [0, 1, 2, 3, 4, 5, 8, 9, 10, 11, 13, 14, 15], "2": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 15], "20": [0, 1, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15], "21": [0, 2, 3, 4, 5, 6, 8, 10, 11, 12, 13, 14, 15], "22": [0, 1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15], "23": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14], "3": [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14, 15], "4": [0, 1, 2, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], "5": [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], "6": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15], "7": [0, 1, 2, 4, 5, 6, 8, 10, 11, 12, 13, 14, 15], "8": [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15], "9": [1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 15]}, "total": 334094338, "total_sparsity": 84.00789001099444}, "training_args": {"_n_gpu": -1, "adafactor": false, "adam_beta1": 0.9, "adam_beta2": 0.999, "adam_epsilon": 1e-08, "dataloader_drop_last": false, "dataloader_num_workers": 0, "dataloader_pin_memory": true, "ddp_find_unused_parameters": null, "debug": false, "deepspeed": null, "disable_tqdm": false, "do_eval": 1, "do_predict": false, "do_train": 1, "eval_accumulation_steps": null, "eval_steps": 10000, "evaluation_strategy": "steps", "fp16": false, "fp16_backend": "auto", "fp16_full_eval": false, "fp16_opt_level": "O1", "gradient_accumulation_steps": 1, "greater_is_better": null, "group_by_length": false, "ignore_data_skip": false, "label_names": null, "label_smoothing_factor": 0.0, "learning_rate": 3e-05, "load_best_model_at_end": false, "local_rank": -1, "logging_dir": "output/squad_test_large/large_regu_60_d0.25", "logging_first_step": false, "logging_steps": 250, "logging_strategy": "steps", "lr_scheduler_type": "linear", "max_grad_norm": 1.0, "max_steps": -1, "metric_for_best_model": null, "no_cuda": false, "num_train_epochs": 20, "optimize_model_before_eval": "disabled", "output_dir": "output/squad_test_large/large_regu_60_d0.25", "overwrite_output_dir": 1, "past_index": -1, "per_device_eval_batch_size": 8, "per_device_train_batch_size": 8, "per_gpu_eval_batch_size": null, "per_gpu_train_batch_size": null, "prediction_loss_only": false, "remove_unused_columns": true, "report_to": null, "run_name": "output/squad_test_large/large_regu_60_d0.25", "save_steps": 10000, "save_strategy": "steps", "save_total_limit": 50, "seed": 17, "sharded_ddp": "", "skip_memory_metrics": false, "tpu_metrics_debug": false, "tpu_num_cores": null, "warmup_ratio": 0.0, "warmup_steps": 5400, "weight_decay": 0.0}}, "f1": 86.9851273164745, "fill_rate": 0.18968822337962976, "speedup": 1.3610235261481995}}
{"speedup": 1.4072439764136124, "f1": 86.51897974152047, "meta": {"annotate": "7", "cat_fun_name": "is_new_xp", "checkpoint": {"config": {"_name_or_path": "bert-large-uncased", "architectures": ["BertForQuestionAnswering"], "attention_probs_dropout_prob": 0.1, "gradient_checkpointing": false, "hidden_act": "gelu", "hidden_dropout_prob": 0.1, "hidden_size": 1024, "initializer_range": 0.02, "intermediate_size": 4096, "layer_norm_eps": 1e-12, "max_position_embeddings": 512, "model_type": "bert", "num_attention_heads": 16, "num_hidden_layers": 24, "pad_token_id": 0, "position_embedding_type": "absolute", "type_vocab_size": 2, "vocab_size": 30522}, "eval_metrics": {"exact_match": 79.120151371807, "f1": 86.51897974152047}, "path": "/data_2to/devel_data/nn_pruning/output/squad_test_large/large_regu_60_d0.25_partial/checkpoint-160000", "sparse_args": {"ampere_pruning_method": "disabled", "attention_block_cols": 32, "attention_block_rows": 32, "attention_lambda": 1.0, "attention_output_with_dense": 0, "attention_pruning_method": "sigmoied_threshold", "bias_mask": true, "dense_block_cols": 1, "dense_block_rows": 1, "dense_lambda": 0.25, "dense_pruning_method": "sigmoied_threshold:1d_alt", "distil_alpha_ce": 0.1, "distil_alpha_teacher": 0.9, "distil_teacher_name_or_path": "bert-large-uncased-whole-word-masking-finetuned-squad", "distil_temperature": 2.0, "final_ampere_temperature": 20.0, "final_finetune": false, "final_threshold": 0.1, "final_warmup": 10, "initial_ampere_temperature": 0.0, "initial_threshold": 0, "initial_warmup": 1, "mask_init": "constant", "mask_scale": 0.0, "mask_scores_learning_rate": 0.01, "regularization": "l1", "regularization_final_lambda": 60}, "speed": {"cuda_eval_elapsed_time": 27.425516578674316, "eval_elapsed_time": 34.279891720972955}, "speedup": 1.4072439764136124, "stats": {"layers": {"0": {"linear_attention_nnz": 336896, "linear_attention_total": 4194304, "linear_dense_nnz": 239616, "linear_dense_total": 8388608, "linear_nnz": 576512, "linear_total": 12582912, "nnz": 583093, "total": 12596224}, "1": {"linear_attention_nnz": 104448, "linear_attention_total": 4194304, "linear_dense_nnz": 264192, "linear_dense_total": 8388608, "linear_nnz": 368640, "linear_total": 12582912, "nnz": 374913, "total": 12596224}, "10": {"linear_attention_nnz": 692224, "linear_attention_total": 4194304, "linear_dense_nnz": 954368, "linear_dense_total": 8388608, "linear_nnz": 1646592, "linear_total": 12582912, "nnz": 1654034, "total": 12596224}, "11": {"linear_attention_nnz": 736256, "linear_attention_total": 4194304, "linear_dense_nnz": 1071104, "linear_dense_total": 8388608, "linear_nnz": 1807360, "linear_total": 12582912, "nnz": 1814891, "total": 12596224}, "12": {"linear_attention_nnz": 663552, "linear_attention_total": 4194304, "linear_dense_nnz": 1212416, "linear_dense_total": 8388608, "linear_nnz": 1875968, "linear_total": 12582912, "nnz": 1883472, "total": 12596224}, "13": {"linear_attention_nnz": 1081344, "linear_attention_total": 4194304, "linear_dense_nnz": 1165312, "linear_dense_total": 8388608, "linear_nnz": 2246656, "linear_total": 12582912, "nnz": 2254745, "total": 12596224}, "14": {"linear_attention_nnz": 798720, "linear_attention_total": 4194304, "linear_dense_nnz": 978944, "linear_dense_total": 8388608, "linear_nnz": 1777664, "linear_total": 12582912, "nnz": 1785502, "total": 12596224}, "15": {"linear_attention_nnz": 826368, "linear_attention_total": 4194304, "linear_dense_nnz": 749568, "linear_dense_total": 8388608, "linear_nnz": 1575936, "linear_total": 12582912, "nnz": 1583406, "total": 12596224}, "16": {"linear_attention_nnz": 796672, "linear_attention_total": 4194304, "linear_dense_nnz": 425984, "linear_dense_total": 8388608, "linear_nnz": 1222656, "linear_total": 12582912, "nnz": 1230192, "total": 12596224}, "17": {"linear_attention_nnz": 643072, "linear_attention_total": 4194304, "linear_dense_nnz": 374784, "linear_dense_total": 8388608, "linear_nnz": 1017856, "linear_total": 12582912, "nnz": 1025399, "total": 12596224}, "18": {"linear_attention_nnz": 565248, "linear_attention_total": 4194304, "linear_dense_nnz": 350208, "linear_dense_total": 8388608, "linear_nnz": 915456, "linear_total": 12582912, "nnz": 922667, "total": 12596224}, "19": {"linear_attention_nnz": 237568, "linear_attention_total": 4194304, "linear_dense_nnz": 307200, "linear_dense_total": 8388608, "linear_nnz": 544768, "linear_total": 12582912, "nnz": 551094, "total": 12596224}, "2": {"linear_attention_nnz": 246784, "linear_attention_total": 4194304, "linear_dense_nnz": 405504, "linear_dense_total": 8388608, "linear_nnz": 652288, "linear_total": 12582912, "nnz": 658918, "total": 12596224}, "20": {"linear_attention_nnz": 164864, "linear_attention_total": 4194304, "linear_dense_nnz": 172032, "linear_dense_total": 8388608, "linear_nnz": 336896, "linear_total": 12582912, "nnz": 343124, "total": 12596224}, "21": {"linear_attention_nnz": 164864, "linear_attention_total": 4194304, "linear_dense_nnz": 106496, "linear_dense_total": 8388608, "linear_nnz": 271360, "linear_total": 12582912, "nnz": 277460, "total": 12596224}, "22": {"linear_attention_nnz": 32768, "linear_attention_total": 4194304, "linear_dense_nnz": 112640, "linear_dense_total": 8388608, "linear_nnz": 145408, "linear_total": 12582912, "nnz": 150967, "total": 12596224}, "23": {"linear_attention_nnz": 33792, "linear_attention_total": 4194304, "linear_dense_nnz": 186368, "linear_dense_total": 8388608, "linear_nnz": 220160, "linear_total": 12582912, "nnz": 225755, "total": 12596224}, "3": {"linear_attention_nnz": 311296, "linear_attention_total": 4194304, "linear_dense_nnz": 514048, "linear_dense_total": 8388608, "linear_nnz": 825344, "linear_total": 12582912, "nnz": 832123, "total": 12596224}, "4": {"linear_attention_nnz": 349184, "linear_attention_total": 4194304, "linear_dense_nnz": 530432, "linear_dense_total": 8388608, "linear_nnz": 879616, "linear_total": 12582912, "nnz": 886371, "total": 12596224}, "5": {"linear_attention_nnz": 24576, "linear_attention_total": 4194304, "linear_dense_nnz": 628736, "linear_dense_total": 8388608, "linear_nnz": 653312, "linear_total": 12582912, "nnz": 659027, "total": 12596224}, "6": {"linear_attention_nnz": 171008, "linear_attention_total": 4194304, "linear_dense_nnz": 659456, "linear_dense_total": 8388608, "linear_nnz": 830464, "linear_total": 12582912, "nnz": 836994, "total": 12596224}, "7": {"linear_attention_nnz": 315392, "linear_attention_total": 4194304, "linear_dense_nnz": 495616, "linear_dense_total": 8388608, "linear_nnz": 811008, "linear_total": 12582912, "nnz": 817778, "total": 12596224}, "8": {"linear_attention_nnz": 120832, "linear_attention_total": 4194304, "linear_dense_nnz": 712704, "linear_dense_total": 8388608, "linear_nnz": 833536, "linear_total": 12582912, "nnz": 839900, "total": 12596224}, "9": {"linear_attention_nnz": 504832, "linear_attention_total": 4194304, "linear_dense_nnz": 776192, "linear_dense_total": 8388608, "linear_nnz": 1281024, "linear_total": 12582912, "nnz": 1288059, "total": 12596224}}, "linear_nnz": 23316480, "linear_sparsity": 92.279052734375, "linear_total": 301989888, "nnz": 55264846, "pruned_heads": {"0": [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 13, 14, 15], "1": [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], "10": [0, 1, 3, 6, 7, 8, 10, 12, 13, 14, 15], "11": [0, 1, 2, 4, 5, 6, 7, 8, 10, 12, 15], "12": [1, 2, 3, 5, 6, 7, 8, 9, 10, 12, 13, 14], "13": [2, 3, 4, 6, 10, 11, 12, 13], "14": [1, 2, 3, 4, 8, 9, 11, 14], "15": [0, 1, 2, 4, 5, 6, 7, 8, 9, 11, 12], "16": [3, 6, 7, 8, 10, 12, 13, 15], "17": [0, 2, 4, 8, 11, 12, 15], "18": [2, 3, 5, 8, 9, 10, 11, 12, 13, 15], "19": [0, 1, 2, 3, 4, 5, 8, 9, 10, 11, 13, 14, 15], "2": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 15], "20": [0, 1, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 15], "21": [2, 3, 4, 5, 6, 8, 10, 11, 12, 13, 14, 15], "22": [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15], "23": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14], "3": [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14, 15], "4": [0, 1, 2, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], "5": [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], "6": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15], "7": [0, 1, 2, 4, 5, 6, 8, 10, 11, 12, 13, 14, 15], "8": [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15], "9": [1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 15]}, "total": 334094338, "total_sparsity": 83.45831110732563}, "training_args": {"_n_gpu": -1, "adafactor": false, "adam_beta1": 0.9, "adam_beta2": 0.999, "adam_epsilon": 1e-08, "dataloader_drop_last": false, "dataloader_num_workers": 0, "dataloader_pin_memory": true, "ddp_find_unused_parameters": null, "debug": false, "deepspeed": null, "disable_tqdm": false, "do_eval": 1, "do_predict": false, "do_train": 1, "eval_accumulation_steps": null, "eval_steps": 10000, "evaluation_strategy": "steps", "fp16": false, "fp16_backend": "auto", "fp16_full_eval": false, "fp16_opt_level": "O1", "gradient_accumulation_steps": 1, "greater_is_better": null, "group_by_length": false, "ignore_data_skip": false, "label_names": null, "label_smoothing_factor": 0.0, "learning_rate": 3e-05, "load_best_model_at_end": false, "local_rank": -1, "logging_dir": "output/squad_test_large/large_regu_60_d0.25", "logging_first_step": false, "logging_steps": 250, "logging_strategy": "steps", "lr_scheduler_type": "linear", "max_grad_norm": 1.0, "max_steps": -1, "metric_for_best_model": null, "no_cuda": false, "num_train_epochs": 20, "optimize_model_before_eval": "disabled", "output_dir": "output/squad_test_large/large_regu_60_d0.25", "overwrite_output_dir": 1, "past_index": -1, "per_device_eval_batch_size": 8, "per_device_train_batch_size": 8, "per_gpu_eval_batch_size": null, "per_gpu_train_batch_size": null, "prediction_loss_only": false, "remove_unused_columns": true, "report_to": null, "run_name": "output/squad_test_large/large_regu_60_d0.25", "save_steps": 10000, "save_strategy": "steps", "save_total_limit": 50, "seed": 17, "sharded_ddp": "", "skip_memory_metrics": false, "tpu_metrics_debug": false, "tpu_num_cores": null, "warmup_ratio": 0.0, "warmup_steps": 5400, "weight_decay": 0.0}}, "f1": 86.51897974152047, "fill_rate": 0.20589192708333331, "speedup": 1.4072439764136124}}
{"speedup": 1.4315993728861762, "f1": 86.42554404823127, "meta": {"annotate": "7", "cat_fun_name": "is_new_xp", "checkpoint": {"config": {"_name_or_path": "bert-large-uncased", "architectures": ["BertForQuestionAnswering"], "attention_probs_dropout_prob": 0.1, "gradient_checkpointing": false, "hidden_act": "gelu", "hidden_dropout_prob": 0.1, "hidden_size": 1024, "initializer_range": 0.02, "intermediate_size": 4096, "layer_norm_eps": 1e-12, "max_position_embeddings": 512, "model_type": "bert", "num_attention_heads": 16, "num_hidden_layers": 24, "pad_token_id": 0, "position_embedding_type": "absolute", "type_vocab_size": 2, "vocab_size": 30522}, "eval_metrics": {"exact_match": 78.72280037842951, "f1": 86.42554404823127}, "path": "/data_2to/devel_data/nn_pruning/output/squad_test_large/large_regu_60_d0.25_partial/checkpoint-170000", "sparse_args": {"ampere_pruning_method": "disabled", "attention_block_cols": 32, "attention_block_rows": 32, "attention_lambda": 1.0, "attention_output_with_dense": 0, "attention_pruning_method": "sigmoied_threshold", "bias_mask": true, "dense_block_cols": 1, "dense_block_rows": 1, "dense_lambda": 0.25, "dense_pruning_method": "sigmoied_threshold:1d_alt", "distil_alpha_ce": 0.1, "distil_alpha_teacher": 0.9, "distil_teacher_name_or_path": "bert-large-uncased-whole-word-masking-finetuned-squad", "distil_temperature": 2.0, "final_ampere_temperature": 20.0, "final_finetune": false, "final_threshold": 0.1, "final_warmup": 10, "initial_ampere_temperature": 0.0, "initial_threshold": 0, "initial_warmup": 1, "mask_init": "constant", "mask_scale": 0.0, "mask_scores_learning_rate": 0.01, "regularization": "l1", "regularization_final_lambda": 60}, "speed": {"cuda_eval_elapsed_time": 26.95893399810791, "eval_elapsed_time": 34.00091099366546}, "speedup": 1.4315993728861762, "stats": {"layers": {"0": {"linear_attention_nnz": 328704, "linear_attention_total": 4194304, "linear_dense_nnz": 233472, "linear_dense_total": 8388608, "linear_nnz": 562176, "linear_total": 12582912, "nnz": 568786, "total": 12596224}, "1": {"linear_attention_nnz": 106496, "linear_attention_total": 4194304, "linear_dense_nnz": 256000, "linear_dense_total": 8388608, "linear_nnz": 362496, "linear_total": 12582912, "nnz": 368861, "total": 12596224}, "10": {"linear_attention_nnz": 734208, "linear_attention_total": 4194304, "linear_dense_nnz": 937984, "linear_dense_total": 8388608, "linear_nnz": 1672192, "linear_total": 12582912, "nnz": 1679626, "total": 12596224}, "11": {"linear_attention_nnz": 739328, "linear_attention_total": 4194304, "linear_dense_nnz": 1062912, "linear_dense_total": 8388608, "linear_nnz": 1802240, "linear_total": 12582912, "nnz": 1809767, "total": 12596224}, "12": {"linear_attention_nnz": 655360, "linear_attention_total": 4194304, "linear_dense_nnz": 1189888, "linear_dense_total": 8388608, "linear_nnz": 1845248, "linear_total": 12582912, "nnz": 1852741, "total": 12596224}, "13": {"linear_attention_nnz": 1070080, "linear_attention_total": 4194304, "linear_dense_nnz": 1142784, "linear_dense_total": 8388608, "linear_nnz": 2212864, "linear_total": 12582912, "nnz": 2220942, "total": 12596224}, "14": {"linear_attention_nnz": 719872, "linear_attention_total": 4194304, "linear_dense_nnz": 950272, "linear_dense_total": 8388608, "linear_nnz": 1670144, "linear_total": 12582912, "nnz": 1677744, "total": 12596224}, "15": {"linear_attention_nnz": 798720, "linear_attention_total": 4194304, "linear_dense_nnz": 733184, "linear_dense_total": 8388608, "linear_nnz": 1531904, "linear_total": 12582912, "nnz": 1539366, "total": 12596224}, "16": {"linear_attention_nnz": 747520, "linear_attention_total": 4194304, "linear_dense_nnz": 419840, "linear_dense_total": 8388608, "linear_nnz": 1167360, "linear_total": 12582912, "nnz": 1174829, "total": 12596224}, "17": {"linear_attention_nnz": 615424, "linear_attention_total": 4194304, "linear_dense_nnz": 370688, "linear_dense_total": 8388608, "linear_nnz": 986112, "linear_total": 12582912, "nnz": 993589, "total": 12596224}, "18": {"linear_attention_nnz": 537600, "linear_attention_total": 4194304, "linear_dense_nnz": 348160, "linear_dense_total": 8388608, "linear_nnz": 885760, "linear_total": 12582912, "nnz": 892842, "total": 12596224}, "19": {"linear_attention_nnz": 211968, "linear_attention_total": 4194304, "linear_dense_nnz": 305152, "linear_dense_total": 8388608, "linear_nnz": 517120, "linear_total": 12582912, "nnz": 523477, "total": 12596224}, "2": {"linear_attention_nnz": 240640, "linear_attention_total": 4194304, "linear_dense_nnz": 397312, "linear_dense_total": 8388608, "linear_nnz": 637952, "linear_total": 12582912, "nnz": 644578, "total": 12596224}, "20": {"linear_attention_nnz": 158720, "linear_attention_total": 4194304, "linear_dense_nnz": 169984, "linear_dense_total": 8388608, "linear_nnz": 328704, "linear_total": 12582912, "nnz": 334931, "total": 12596224}, "21": {"linear_attention_nnz": 132096, "linear_attention_total": 4194304, "linear_dense_nnz": 104448, "linear_dense_total": 8388608, "linear_nnz": 236544, "linear_total": 12582912, "nnz": 242675, "total": 12596224}, "22": {"linear_attention_nnz": 35840, "linear_attention_total": 4194304, "linear_dense_nnz": 110592, "linear_dense_total": 8388608, "linear_nnz": 146432, "linear_total": 12582912, "nnz": 152022, "total": 12596224}, "23": {"linear_attention_nnz": 27648, "linear_attention_total": 4194304, "linear_dense_nnz": 178176, "linear_dense_total": 8388608, "linear_nnz": 205824, "linear_total": 12582912, "nnz": 211415, "total": 12596224}, "3": {"linear_attention_nnz": 314368, "linear_attention_total": 4194304, "linear_dense_nnz": 499712, "linear_dense_total": 8388608, "linear_nnz": 814080, "linear_total": 12582912, "nnz": 820820, "total": 12596224}, "4": {"linear_attention_nnz": 347136, "linear_attention_total": 4194304, "linear_dense_nnz": 507904, "linear_dense_total": 8388608, "linear_nnz": 855040, "linear_total": 12582912, "nnz": 861816, "total": 12596224}, "5": {"linear_attention_nnz": 24576, "linear_attention_total": 4194304, "linear_dense_nnz": 614400, "linear_dense_total": 8388608, "linear_nnz": 638976, "linear_total": 12582912, "nnz": 644684, "total": 12596224}, "6": {"linear_attention_nnz": 161792, "linear_attention_total": 4194304, "linear_dense_nnz": 645120, "linear_dense_total": 8388608, "linear_nnz": 806912, "linear_total": 12582912, "nnz": 813435, "total": 12596224}, "7": {"linear_attention_nnz": 325632, "linear_attention_total": 4194304, "linear_dense_nnz": 481280, "linear_dense_total": 8388608, "linear_nnz": 806912, "linear_total": 12582912, "nnz": 813707, "total": 12596224}, "8": {"linear_attention_nnz": 101376, "linear_attention_total": 4194304, "linear_dense_nnz": 692224, "linear_dense_total": 8388608, "linear_nnz": 793600, "linear_total": 12582912, "nnz": 799858, "total": 12596224}, "9": {"linear_attention_nnz": 475136, "linear_attention_total": 4194304, "linear_dense_nnz": 765952, "linear_dense_total": 8388608, "linear_nnz": 1241088, "linear_total": 12582912, "nnz": 1248118, "total": 12596224}}, "linear_nnz": 22727680, "linear_sparsity": 92.47402615017361, "linear_total": 301989888, "nnz": 54675591, "pruned_heads": {"0": [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 13, 14, 15], "1": [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], "10": [0, 1, 3, 6, 7, 8, 10, 12, 13, 14, 15], "11": [0, 1, 2, 4, 5, 6, 7, 8, 10, 12, 15], "12": [1, 2, 3, 5, 6, 7, 8, 9, 10, 12, 13, 14], "13": [2, 3, 4, 6, 10, 11, 12, 13], "14": [1, 2, 3, 4, 8, 9, 10, 11, 14], "15": [0, 1, 2, 4, 5, 6, 7, 8, 9, 11, 12], "16": [3, 6, 7, 8, 10, 12, 13, 15], "17": [0, 2, 4, 8, 11, 12, 15], "18": [2, 3, 5, 8, 9, 10, 11, 12, 13, 15], "19": [0, 1, 2, 3, 4, 5, 8, 9, 10, 11, 13, 14, 15], "2": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 15], "20": [0, 1, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 15], "21": [2, 3, 4, 5, 6, 8, 10, 11, 12, 13, 14, 15], "22": [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15], "23": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14], "3": [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14, 15], "4": [0, 1, 2, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], "5": [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], "6": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15], "7": [0, 1, 2, 4, 5, 6, 8, 10, 11, 12, 13, 14, 15], "8": [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15], "9": [1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 15]}, "total": 334094338, "total_sparsity": 83.63468494338866}, "training_args": {"_n_gpu": -1, "adafactor": false, "adam_beta1": 0.9, "adam_beta2": 0.999, "adam_epsilon": 1e-08, "dataloader_drop_last": false, "dataloader_num_workers": 0, "dataloader_pin_memory": true, "ddp_find_unused_parameters": null, "debug": false, "deepspeed": null, "disable_tqdm": false, "do_eval": 1, "do_predict": false, "do_train": 1, "eval_accumulation_steps": null, "eval_steps": 10000, "evaluation_strategy": "steps", "fp16": false, "fp16_backend": "auto", "fp16_full_eval": false, "fp16_opt_level": "O1", "gradient_accumulation_steps": 1, "greater_is_better": null, "group_by_length": false, "ignore_data_skip": false, "label_names": null, "label_smoothing_factor": 0.0, "learning_rate": 3e-05, "load_best_model_at_end": false, "local_rank": -1, "logging_dir": "output/squad_test_large/large_regu_60_d0.25", "logging_first_step": false, "logging_steps": 250, "logging_strategy": "steps", "lr_scheduler_type": "linear", "max_grad_norm": 1.0, "max_steps": -1, "metric_for_best_model": null, "no_cuda": false, "num_train_epochs": 20, "optimize_model_before_eval": "disabled", "output_dir": "output/squad_test_large/large_regu_60_d0.25", "overwrite_output_dir": 1, "past_index": -1, "per_device_eval_batch_size": 8, "per_device_train_batch_size": 8, "per_gpu_eval_batch_size": null, "per_gpu_train_batch_size": null, "prediction_loss_only": false, "remove_unused_columns": true, "report_to": null, "run_name": "output/squad_test_large/large_regu_60_d0.25", "save_steps": 10000, "save_strategy": "steps", "save_total_limit": 50, "seed": 17, "sharded_ddp": "", "skip_memory_metrics": false, "tpu_metrics_debug": false, "tpu_num_cores": null, "warmup_ratio": 0.0, "warmup_steps": 5400, "weight_decay": 0.0}}, "f1": 86.42554404823127, "fill_rate": 0.20069263599537024, "speedup": 1.4315993728861762}}
{"speedup": 1.4324102529903697, "f1": 86.34346487920875, "meta": {"annotate": "7", "cat_fun_name": "is_new_xp", "checkpoint": {"config": {"_name_or_path": "bert-large-uncased", "architectures": ["BertForQuestionAnswering"], "attention_probs_dropout_prob": 0.1, "gradient_checkpointing": false, "hidden_act": "gelu", "hidden_dropout_prob": 0.1, "hidden_size": 1024, "initializer_range": 0.02, "intermediate_size": 4096, "layer_norm_eps": 1e-12, "max_position_embeddings": 512, "model_type": "bert", "num_attention_heads": 16, "num_hidden_layers": 24, "pad_token_id": 0, "position_embedding_type": "absolute", "type_vocab_size": 2, "vocab_size": 30522}, "eval_metrics": {"exact_match": 78.62819299905392, "f1": 86.34346487920875}, "path": "/data_2to/devel_data/nn_pruning/output/squad_test_large/large_regu_60_d0.25_partial/checkpoint-180000", "sparse_args": {"ampere_pruning_method": "disabled", "attention_block_cols": 32, "attention_block_rows": 32, "attention_lambda": 1.0, "attention_output_with_dense": 0, "attention_pruning_method": "sigmoied_threshold", "bias_mask": true, "dense_block_cols": 1, "dense_block_rows": 1, "dense_lambda": 0.25, "dense_pruning_method": "sigmoied_threshold:1d_alt", "distil_alpha_ce": 0.1, "distil_alpha_teacher": 0.9, "distil_teacher_name_or_path": "bert-large-uncased-whole-word-masking-finetuned-squad", "distil_temperature": 2.0, "final_ampere_temperature": 20.0, "final_finetune": false, "final_threshold": 0.1, "final_warmup": 10, "initial_ampere_temperature": 0.0, "initial_threshold": 0, "initial_warmup": 1, "mask_init": "constant", "mask_scale": 0.0, "mask_scores_learning_rate": 0.01, "regularization": "l1", "regularization_final_lambda": 60}, "speed": {"cuda_eval_elapsed_time": 26.94367268371582, "eval_elapsed_time": 34.14706540107727}, "speedup": 1.4324102529903697, "stats": {"layers": {"0": {"linear_attention_nnz": 332800, "linear_attention_total": 4194304, "linear_dense_nnz": 225280, "linear_dense_total": 8388608, "linear_nnz": 558080, "linear_total": 12582912, "nnz": 564654, "total": 12596224}, "1": {"linear_attention_nnz": 95232, "linear_attention_total": 4194304, "linear_dense_nnz": 247808, "linear_dense_total": 8388608, "linear_nnz": 343040, "linear_total": 12582912, "nnz": 349401, "total": 12596224}, "10": {"linear_attention_nnz": 688128, "linear_attention_total": 4194304, "linear_dense_nnz": 921600, "linear_dense_total": 8388608, "linear_nnz": 1609728, "linear_total": 12582912, "nnz": 1617154, "total": 12596224}, "11": {"linear_attention_nnz": 708608, "linear_attention_total": 4194304, "linear_dense_nnz": 1050624, "linear_dense_total": 8388608, "linear_nnz": 1759232, "linear_total": 12582912, "nnz": 1766753, "total": 12596224}, "12": {"linear_attention_nnz": 659456, "linear_attention_total": 4194304, "linear_dense_nnz": 1167360, "linear_dense_total": 8388608, "linear_nnz": 1826816, "linear_total": 12582912, "nnz": 1834298, "total": 12596224}, "13": {"linear_attention_nnz": 984064, "linear_attention_total": 4194304, "linear_dense_nnz": 1122304, "linear_dense_total": 8388608, "linear_nnz": 2106368, "linear_total": 12582912, "nnz": 2114436, "total": 12596224}, "14": {"linear_attention_nnz": 730112, "linear_attention_total": 4194304, "linear_dense_nnz": 927744, "linear_dense_total": 8388608, "linear_nnz": 1657856, "linear_total": 12582912, "nnz": 1665413, "total": 12596224}, "15": {"linear_attention_nnz": 799744, "linear_attention_total": 4194304, "linear_dense_nnz": 720896, "linear_dense_total": 8388608, "linear_nnz": 1520640, "linear_total": 12582912, "nnz": 1528064, "total": 12596224}, "16": {"linear_attention_nnz": 738304, "linear_attention_total": 4194304, "linear_dense_nnz": 413696, "linear_dense_total": 8388608, "linear_nnz": 1152000, "linear_total": 12582912, "nnz": 1159530, "total": 12596224}, "17": {"linear_attention_nnz": 640000, "linear_attention_total": 4194304, "linear_dense_nnz": 370688, "linear_dense_total": 8388608, "linear_nnz": 1010688, "linear_total": 12582912, "nnz": 1018229, "total": 12596224}, "18": {"linear_attention_nnz": 534528, "linear_attention_total": 4194304, "linear_dense_nnz": 346112, "linear_dense_total": 8388608, "linear_nnz": 880640, "linear_total": 12582912, "nnz": 887785, "total": 12596224}, "19": {"linear_attention_nnz": 217088, "linear_attention_total": 4194304, "linear_dense_nnz": 305152, "linear_dense_total": 8388608, "linear_nnz": 522240, "linear_total": 12582912, "nnz": 528501, "total": 12596224}, "2": {"linear_attention_nnz": 251904, "linear_attention_total": 4194304, "linear_dense_nnz": 391168, "linear_dense_total": 8388608, "linear_nnz": 643072, "linear_total": 12582912, "nnz": 649695, "total": 12596224}, "20": {"linear_attention_nnz": 161792, "linear_attention_total": 4194304, "linear_dense_nnz": 169984, "linear_dense_total": 8388608, "linear_nnz": 331776, "linear_total": 12582912, "nnz": 337939, "total": 12596224}, "21": {"linear_attention_nnz": 153600, "linear_attention_total": 4194304, "linear_dense_nnz": 100352, "linear_dense_total": 8388608, "linear_nnz": 253952, "linear_total": 12582912, "nnz": 260049, "total": 12596224}, "22": {"linear_attention_nnz": 30720, "linear_attention_total": 4194304, "linear_dense_nnz": 108544, "linear_dense_total": 8388608, "linear_nnz": 139264, "linear_total": 12582912, "nnz": 144821, "total": 12596224}, "23": {"linear_attention_nnz": 29696, "linear_attention_total": 4194304, "linear_dense_nnz": 172032, "linear_dense_total": 8388608, "linear_nnz": 201728, "linear_total": 12582912, "nnz": 207316, "total": 12596224}, "3": {"linear_attention_nnz": 287744, "linear_attention_total": 4194304, "linear_dense_nnz": 493568, "linear_dense_total": 8388608, "linear_nnz": 781312, "linear_total": 12582912, "nnz": 788017, "total": 12596224}, "4": {"linear_attention_nnz": 305152, "linear_attention_total": 4194304, "linear_dense_nnz": 491520, "linear_dense_total": 8388608, "linear_nnz": 796672, "linear_total": 12582912, "nnz": 803440, "total": 12596224}, "5": {"linear_attention_nnz": 24576, "linear_attention_total": 4194304, "linear_dense_nnz": 602112, "linear_dense_total": 8388608, "linear_nnz": 626688, "linear_total": 12582912, "nnz": 632390, "total": 12596224}, "6": {"linear_attention_nnz": 163840, "linear_attention_total": 4194304, "linear_dense_nnz": 620544, "linear_dense_total": 8388608, "linear_nnz": 784384, "linear_total": 12582912, "nnz": 790895, "total": 12596224}, "7": {"linear_attention_nnz": 301056, "linear_attention_total": 4194304, "linear_dense_nnz": 471040, "linear_dense_total": 8388608, "linear_nnz": 772096, "linear_total": 12582912, "nnz": 778694, "total": 12596224}, "8": {"linear_attention_nnz": 112640, "linear_attention_total": 4194304, "linear_dense_nnz": 684032, "linear_dense_total": 8388608, "linear_nnz": 796672, "linear_total": 12582912, "nnz": 803150, "total": 12596224}, "9": {"linear_attention_nnz": 484352, "linear_attention_total": 4194304, "linear_dense_nnz": 747520, "linear_dense_total": 8388608, "linear_nnz": 1231872, "linear_total": 12582912, "nnz": 1238893, "total": 12596224}}, "linear_nnz": 22306816, "linear_sparsity": 92.61338975694444, "linear_total": 301989888, "nnz": 54254479, "pruned_heads": {"0": [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 13, 14, 15], "1": [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], "10": [0, 1, 3, 6, 7, 8, 10, 12, 13, 14, 15], "11": [0, 1, 2, 4, 5, 6, 7, 8, 10, 12, 15], "12": [1, 2, 3, 5, 6, 7, 8, 9, 10, 12, 13, 14], "13": [2, 3, 4, 6, 10, 11, 12, 13], "14": [1, 2, 3, 4, 8, 9, 10, 11, 14], "15": [0, 1, 2, 4, 5, 6, 7, 8, 9, 11, 12], "16": [3, 6, 7, 8, 10, 12, 13, 15], "17": [0, 2, 4, 8, 11, 12, 15], "18": [2, 3, 5, 8, 9, 10, 11, 12, 13, 15], "19": [0, 1, 2, 3, 4, 5, 8, 9, 10, 11, 13, 14, 15], "2": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 15], "20": [0, 1, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 15], "21": [2, 3, 4, 5, 6, 8, 10, 11, 12, 13, 14, 15], "22": [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15], "23": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14], "3": [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14, 15], "4": [0, 1, 2, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], "5": [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], "6": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15], "7": [0, 1, 2, 4, 5, 6, 8, 10, 11, 12, 13, 14, 15], "8": [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15], "9": [1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 15]}, "total": 334094338, "total_sparsity": 83.76073077898135}, "training_args": {"_n_gpu": -1, "adafactor": false, "adam_beta1": 0.9, "adam_beta2": 0.999, "adam_epsilon": 1e-08, "dataloader_drop_last": false, "dataloader_num_workers": 0, "dataloader_pin_memory": true, "ddp_find_unused_parameters": null, "debug": false, "deepspeed": null, "disable_tqdm": false, "do_eval": 1, "do_predict": false, "do_train": 1, "eval_accumulation_steps": null, "eval_steps": 10000, "evaluation_strategy": "steps", "fp16": false, "fp16_backend": "auto", "fp16_full_eval": false, "fp16_opt_level": "O1", "gradient_accumulation_steps": 1, "greater_is_better": null, "group_by_length": false, "ignore_data_skip": false, "label_names": null, "label_smoothing_factor": 0.0, "learning_rate": 3e-05, "load_best_model_at_end": false, "local_rank": -1, "logging_dir": "output/squad_test_large/large_regu_60_d0.25", "logging_first_step": false, "logging_steps": 250, "logging_strategy": "steps", "lr_scheduler_type": "linear", "max_grad_norm": 1.0, "max_steps": -1, "metric_for_best_model": null, "no_cuda": false, "num_train_epochs": 20, "optimize_model_before_eval": "disabled", "output_dir": "output/squad_test_large/large_regu_60_d0.25", "overwrite_output_dir": 1, "past_index": -1, "per_device_eval_batch_size": 8, "per_device_train_batch_size": 8, "per_gpu_eval_batch_size": null, "per_gpu_train_batch_size": null, "prediction_loss_only": false, "remove_unused_columns": true, "report_to": null, "run_name": "output/squad_test_large/large_regu_60_d0.25", "save_steps": 10000, "save_strategy": "steps", "save_total_limit": 50, "seed": 17, "sharded_ddp": "", "skip_memory_metrics": false, "tpu_metrics_debug": false, "tpu_num_cores": null, "warmup_ratio": 0.0, "warmup_steps": 5400, "weight_decay": 0.0}}, "f1": 86.34346487920875, "fill_rate": 0.1969762731481482, "speedup": 1.4324102529903697}}
{"speedup": 1.4331301499255447, "f1": 86.23578242662717, "meta": {"annotate": "4", "cat_fun_name": "is_new_xp", "checkpoint": {"config": {"_name_or_path": "bert-large-uncased", "architectures": ["BertForQuestionAnswering"], "attention_probs_dropout_prob": 0.1, "gradient_checkpointing": false, "hidden_act": "gelu", "hidden_dropout_prob": 0.1, "hidden_size": 1024, "initializer_range": 0.02, "intermediate_size": 4096, "layer_norm_eps": 1e-12, "max_position_embeddings": 512, "model_type": "bert", "num_attention_heads": 16, "num_hidden_layers": 24, "pad_token_id": 0, "position_embedding_type": "absolute", "type_vocab_size": 2, "vocab_size": 30522}, "eval_metrics": {"exact_match": 78.27814569536424, "f1": 86.23578242662717}, "path": "/data_2to/devel_data/nn_pruning/output/squad_test_large/large_regu_60/checkpoint-221320", "sparse_args": {"ampere_pruning_method": "disabled", "attention_block_cols": 32, "attention_block_rows": 32, "attention_lambda": 1.0, "attention_output_with_dense": 0, "attention_pruning_method": "sigmoied_threshold", "bias_mask": true, "dense_block_cols": 1, "dense_block_rows": 1, "dense_lambda": 1.0, "dense_pruning_method": "sigmoied_threshold:1d_alt", "distil_alpha_ce": 0.1, "distil_alpha_teacher": 0.9, "distil_teacher_name_or_path": "bert-large-uncased-whole-word-masking-finetuned-squad", "distil_temperature": 2.0, "final_ampere_temperature": 20.0, "final_finetune": false, "final_threshold": 0.1, "final_warmup": 10, "initial_ampere_temperature": 0.0, "initial_threshold": 0, "initial_warmup": 1, "mask_init": "constant", "mask_scale": 0.0, "mask_scores_learning_rate": 0.01, "regularization": "l1", "regularization_final_lambda": 60}, "speed": {"cuda_eval_elapsed_time": 26.930138206481935, "eval_elapsed_time": 34.07285923091695}, "speedup": 1.4331301499255447, "stats": {"layers": {"0": {"linear_attention_nnz": 527360, "linear_attention_total": 4194304, "linear_dense_nnz": 71680, "linear_dense_total": 8388608, "linear_nnz": 599040, "linear_total": 12582912, "nnz": 605731, "total": 12596224}, "1": {"linear_attention_nnz": 167936, "linear_attention_total": 4194304, "linear_dense_nnz": 59392, "linear_dense_total": 8388608, "linear_nnz": 227328, "linear_total": 12582912, "nnz": 233661, "total": 12596224}, "10": {"linear_attention_nnz": 719872, "linear_attention_total": 4194304, "linear_dense_nnz": 360448, "linear_dense_total": 8388608, "linear_nnz": 1080320, "linear_total": 12582912, "nnz": 1087568, "total": 12596224}, "11": {"linear_attention_nnz": 775168, "linear_attention_total": 4194304, "linear_dense_nnz": 352256, "linear_dense_total": 8388608, "linear_nnz": 1127424, "linear_total": 12582912, "nnz": 1134732, "total": 12596224}, "12": {"linear_attention_nnz": 614400, "linear_attention_total": 4194304, "linear_dense_nnz": 460800, "linear_dense_total": 8388608, "linear_nnz": 1075200, "linear_total": 12582912, "nnz": 1082273, "total": 12596224}, "13": {"linear_attention_nnz": 1112064, "linear_attention_total": 4194304, "linear_dense_nnz": 382976, "linear_dense_total": 8388608, "linear_nnz": 1495040, "linear_total": 12582912, "nnz": 1502907, "total": 12596224}, "14": {"linear_attention_nnz": 849920, "linear_attention_total": 4194304, "linear_dense_nnz": 276480, "linear_dense_total": 8388608, "linear_nnz": 1126400, "linear_total": 12582912, "nnz": 1134023, "total": 12596224}, "15": {"linear_attention_nnz": 825344, "linear_attention_total": 4194304, "linear_dense_nnz": 258048, "linear_dense_total": 8388608, "linear_nnz": 1083392, "linear_total": 12582912, "nnz": 1090814, "total": 12596224}, "16": {"linear_attention_nnz": 813056, "linear_attention_total": 4194304, "linear_dense_nnz": 147456, "linear_dense_total": 8388608, "linear_nnz": 960512, "linear_total": 12582912, "nnz": 967816, "total": 12596224}, "17": {"linear_attention_nnz": 618496, "linear_attention_total": 4194304, "linear_dense_nnz": 145408, "linear_dense_total": 8388608, "linear_nnz": 763904, "linear_total": 12582912, "nnz": 771239, "total": 12596224}, "18": {"linear_attention_nnz": 572416, "linear_attention_total": 4194304, "linear_dense_nnz": 116736, "linear_dense_total": 8388608, "linear_nnz": 689152, "linear_total": 12582912, "nnz": 696409, "total": 12596224}, "19": {"linear_attention_nnz": 216064, "linear_attention_total": 4194304, "linear_dense_nnz": 100352, "linear_dense_total": 8388608, "linear_nnz": 316416, "linear_total": 12582912, "nnz": 322737, "total": 12596224}, "2": {"linear_attention_nnz": 84992, "linear_attention_total": 4194304, "linear_dense_nnz": 63488, "linear_dense_total": 8388608, "linear_nnz": 148480, "linear_total": 12582912, "nnz": 154687, "total": 12596224}, "20": {"linear_attention_nnz": 165888, "linear_attention_total": 4194304, "linear_dense_nnz": 49152, "linear_dense_total": 8388608, "linear_nnz": 215040, "linear_total": 12582912, "nnz": 221240, "total": 12596224}, "21": {"linear_attention_nnz": 153600, "linear_attention_total": 4194304, "linear_dense_nnz": 40960, "linear_dense_total": 8388608, "linear_nnz": 194560, "linear_total": 12582912, "nnz": 200660, "total": 12596224}, "22": {"linear_attention_nnz": 53248, "linear_attention_total": 4194304, "linear_dense_nnz": 49152, "linear_dense_total": 8388608, "linear_nnz": 102400, "linear_total": 12582912, "nnz": 108184, "total": 12596224}, "23": {"linear_attention_nnz": 26624, "linear_attention_total": 4194304, "linear_dense_nnz": 81920, "linear_dense_total": 8388608, "linear_nnz": 108544, "linear_total": 12582912, "nnz": 114056, "total": 12596224}, "3": {"linear_attention_nnz": 355328, "linear_attention_total": 4194304, "linear_dense_nnz": 100352, "linear_dense_total": 8388608, "linear_nnz": 455680, "linear_total": 12582912, "nnz": 462257, "total": 12596224}, "4": {"linear_attention_nnz": 350208, "linear_attention_total": 4194304, "linear_dense_nnz": 133120, "linear_dense_total": 8388608, "linear_nnz": 483328, "linear_total": 12582912, "nnz": 489921, "total": 12596224}, "5": {"linear_attention_nnz": 24576, "linear_attention_total": 4194304, "linear_dense_nnz": 129024, "linear_dense_total": 8388608, "linear_nnz": 153600, "linear_total": 12582912, "nnz": 159135, "total": 12596224}, "6": {"linear_attention_nnz": 187392, "linear_attention_total": 4194304, "linear_dense_nnz": 155648, "linear_dense_total": 8388608, "linear_nnz": 343040, "linear_total": 12582912, "nnz": 349292, "total": 12596224}, "7": {"linear_attention_nnz": 429056, "linear_attention_total": 4194304, "linear_dense_nnz": 145408, "linear_dense_total": 8388608, "linear_nnz": 574464, "linear_total": 12582912, "nnz": 581223, "total": 12596224}, "8": {"linear_attention_nnz": 129024, "linear_attention_total": 4194304, "linear_dense_nnz": 174080, "linear_dense_total": 8388608, "linear_nnz": 303104, "linear_total": 12582912, "nnz": 309301, "total": 12596224}, "9": {"linear_attention_nnz": 491520, "linear_attention_total": 4194304, "linear_dense_nnz": 274432, "linear_dense_total": 8388608, "linear_nnz": 765952, "linear_total": 12582912, "nnz": 772742, "total": 12596224}}, "linear_nnz": 14392320, "linear_sparsity": 95.23417154947916, "linear_total": 301989888, "nnz": 46337570, "pruned_heads": {"0": [1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 13, 14, 15], "1": [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], "10": [0, 3, 6, 7, 8, 9, 10, 12, 13, 14], "11": [0, 1, 2, 4, 5, 6, 8, 10, 12, 15], "12": [1, 2, 3, 5, 6, 7, 8, 9, 10, 12, 13, 14], "13": [2, 3, 4, 9, 10, 11, 12], "14": [1, 2, 3, 4, 8, 9, 11, 12], "15": [0, 1, 2, 4, 5, 6, 7, 8, 9, 11, 12], "16": [3, 6, 8, 10, 12, 13, 15], "17": [0, 2, 4, 8, 11, 12, 15], "18": [2, 3, 5, 9, 11, 13], "19": [0, 1, 2, 3, 4, 5, 8, 9, 10, 11, 13, 14, 15], "2": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 15], "20": [0, 1, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 15], "21": [0, 2, 3, 4, 5, 6, 8, 10, 11, 12, 13, 14, 15], "22": [0, 1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15], "23": [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13, 14], "3": [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14, 15], "4": [0, 1, 2, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], "5": [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], "6": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15], "7": [0, 1, 2, 4, 6, 8, 10, 11, 12, 13, 14, 15], "8": [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15], "9": [1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 15]}, "total": 334094338, "total_sparsity": 86.13039350580075}, "training_args": {"_n_gpu": -1, "adafactor": false, "adam_beta1": 0.9, "adam_beta2": 0.999, "adam_epsilon": 1e-08, "dataloader_drop_last": false, "dataloader_num_workers": 0, "dataloader_pin_memory": true, "ddp_find_unused_parameters": null, "debug": false, "deepspeed": null, "disable_tqdm": false, "do_eval": 1, "do_predict": false, "do_train": 1, "eval_accumulation_steps": null, "eval_steps": 10000, "evaluation_strategy": "steps", "fp16": false, "fp16_backend": "auto", "fp16_full_eval": false, "fp16_opt_level": "O1", "gradient_accumulation_steps": 1, "greater_is_better": null, "group_by_length": false, "ignore_data_skip": false, "label_names": null, "label_smoothing_factor": 0.0, "learning_rate": 3e-05, "load_best_model_at_end": false, "local_rank": -1, "logging_dir": "output/squad_test_large/large_regu_60", "logging_first_step": false, "logging_steps": 250, "logging_strategy": "steps", "lr_scheduler_type": "linear", "max_grad_norm": 1.0, "max_steps": -1, "metric_for_best_model": null, "no_cuda": false, "num_train_epochs": 20, "optimize_model_before_eval": "disabled", "output_dir": "output/squad_test_large/large_regu_60", "overwrite_output_dir": 1, "past_index": -1, "per_device_eval_batch_size": 8, "per_device_train_batch_size": 8, "per_gpu_eval_batch_size": null, "per_gpu_train_batch_size": null, "prediction_loss_only": false, "remove_unused_columns": true, "report_to": null, "run_name": "output/squad_test_large/large_regu_60", "save_steps": 10000, "save_strategy": "steps", "save_total_limit": 50, "seed": 17, "sharded_ddp": "", "skip_memory_metrics": false, "tpu_metrics_debug": false, "tpu_num_cores": null, "warmup_ratio": 0.0, "warmup_steps": 5400, "weight_decay": 0.0}}, "f1": 86.23578242662717, "fill_rate": 0.12708875868055594, "speedup": 1.4331301499255447}}
