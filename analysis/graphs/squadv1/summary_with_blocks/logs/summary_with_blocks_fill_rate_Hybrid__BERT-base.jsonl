{"fill_rate": 0.24473741319444442, "f1": 88.06903108265608, "meta": {"annotate": "24", "cat_fun_name": "is_new_xp", "checkpoint": {"config": {"_name_or_path": "bert-base-uncased", "architectures": ["BertForQuestionAnswering"], "attention_probs_dropout_prob": 0.1, "gradient_checkpointing": false, "hidden_act": "gelu", "hidden_dropout_prob": 0.1, "hidden_size": 768, "initializer_range": 0.02, "intermediate_size": 3072, "layer_norm_eps": 1e-12, "max_position_embeddings": 512, "model_type": "bert", "num_attention_heads": 12, "num_hidden_layers": 12, "pad_token_id": 0, "position_embedding_type": "absolute", "type_vocab_size": 2, "vocab_size": 30522}, "eval_metrics": {"exact_match": 80.58656575212866, "f1": 88.06903108265608}, "path": "/data_2to/devel_data/nn_pruning/output/squad_test_aws/aws_nn-pruning-v10-a32-l5-dl1--2021-01-21--00-52-16/checkpoint-110660", "sparse_args": {"ampere_pruning_method": "disabled", "attention_block_cols": 32, "attention_block_rows": 32, "attention_lambda": 1.0, "attention_output_with_dense": 0, "attention_pruning_method": "sigmoied_threshold", "bias_mask": true, "dense_block_cols": 1, "dense_block_rows": 1, "dense_lambda": 1.0, "dense_pruning_method": "sigmoied_threshold:1d_alt", "distil_alpha_ce": 0.1, "distil_alpha_teacher": 0.9, "distil_teacher_name_or_path": "csarron/bert-base-uncased-squad-v1", "distil_temperature": 2.0, "final_ampere_temperature": 20.0, "final_threshold": 0.1, "final_warmup": 10, "initial_ampere_temperature": 0.0, "initial_threshold": 0, "initial_warmup": 1, "mask_init": "constant", "mask_scale": 0.0, "mask_scores_learning_rate": 0.01, "regularization": "l1", "regularization_final_lambda": 5.0}, "speed": {"cuda_eval_elapsed_time": 19.595643711090087, "eval_elapsed_time": 26.718373194802552}, "speedup": 1.9695394330694393, "stats": {"layers": {"0": {"linear_attention_nnz": 1055744, "linear_attention_total": 2359296, "linear_dense_nnz": 526848, "linear_dense_total": 4718592, "linear_nnz": 1582592, "linear_total": 7077888, "nnz": 1588759, "total": 7087872}, "1": {"linear_attention_nnz": 809984, "linear_attention_total": 2359296, "linear_dense_nnz": 752640, "linear_dense_total": 4718592, "linear_nnz": 1562624, "linear_total": 7077888, "nnz": 1568650, "total": 7087872}, "10": {"linear_attention_nnz": 652288, "linear_attention_total": 2359296, "linear_dense_nnz": 98304, "linear_dense_total": 4718592, "linear_nnz": 750592, "linear_total": 7077888, "nnz": 756384, "total": 7087872}, "11": {"linear_attention_nnz": 419840, "linear_attention_total": 2359296, "linear_dense_nnz": 262656, "linear_dense_total": 4718592, "linear_nnz": 682496, "linear_total": 7077888, "nnz": 688011, "total": 7087872}, "2": {"linear_attention_nnz": 1316864, "linear_attention_total": 2359296, "linear_dense_nnz": 873984, "linear_dense_total": 4718592, "linear_nnz": 2190848, "linear_total": 7077888, "nnz": 2197625, "total": 7087872}, "3": {"linear_attention_nnz": 1468416, "linear_attention_total": 2359296, "linear_dense_nnz": 952320, "linear_dense_total": 4718592, "linear_nnz": 2420736, "linear_total": 7077888, "nnz": 2427596, "total": 7087872}, "4": {"linear_attention_nnz": 1651712, "linear_attention_total": 2359296, "linear_dense_nnz": 1046016, "linear_dense_total": 4718592, "linear_nnz": 2697728, "linear_total": 7077888, "nnz": 2705001, "total": 7087872}, "5": {"linear_attention_nnz": 1616896, "linear_attention_total": 2359296, "linear_dense_nnz": 986112, "linear_dense_total": 4718592, "linear_nnz": 2603008, "linear_total": 7077888, "nnz": 2610178, "total": 7087872}, "6": {"linear_attention_nnz": 1361920, "linear_attention_total": 2359296, "linear_dense_nnz": 740352, "linear_dense_total": 4718592, "linear_nnz": 2102272, "linear_total": 7077888, "nnz": 2109058, "total": 7087872}, "7": {"linear_attention_nnz": 1265664, "linear_attention_total": 2359296, "linear_dense_nnz": 559104, "linear_dense_total": 4718592, "linear_nnz": 1824768, "linear_total": 7077888, "nnz": 1831244, "total": 7087872}, "8": {"linear_attention_nnz": 1212416, "linear_attention_total": 2359296, "linear_dense_nnz": 293376, "linear_dense_total": 4718592, "linear_nnz": 1505792, "linear_total": 7077888, "nnz": 1512127, "total": 7087872}, "9": {"linear_attention_nnz": 749568, "linear_attention_total": 2359296, "linear_dense_nnz": 113664, "linear_dense_total": 4718592, "linear_nnz": 863232, "linear_total": 7077888, "nnz": 868874, "total": 7087872}}, "linear_nnz": 20786688, "linear_sparsity": 75.52625868055556, "linear_total": 84934656, "nnz": 44702229, "pruned_heads": {"0": [0, 2, 4, 5, 6], "1": [0, 2, 3, 5, 6, 7, 8], "10": [1, 4, 5, 7], "11": [0, 2, 5, 6, 7, 8, 11], "2": [8, 4], "3": [2, 4, 6], "4": [2], "5": [1, 2], "6": [2, 3, 7], "7": [11, 3, 6, 7], "8": [0, 4], "9": [1, 4, 5, 7, 9, 10]}, "total": 108893186, "total_sparsity": 58.94855257518133}, "training_args": {"_n_gpu": -1, "adafactor": false, "adam_beta1": 0.9, "adam_beta2": 0.999, "adam_epsilon": 1e-08, "dataloader_drop_last": false, "dataloader_num_workers": 0, "dataloader_pin_memory": true, "ddp_find_unused_parameters": null, "debug": false, "deepspeed": null, "disable_tqdm": false, "do_eval": 1, "do_predict": false, "do_train": 1, "eval_accumulation_steps": null, "eval_steps": 5000, "evaluation_strategy": "steps", "fp16": false, "fp16_backend": "auto", "fp16_full_eval": false, "fp16_opt_level": "O1", "gradient_accumulation_steps": 1, "greater_is_better": null, "group_by_length": false, "ignore_data_skip": false, "label_names": null, "label_smoothing_factor": 0.0, "learning_rate": 3e-05, "load_best_model_at_end": false, "local_rank": -1, "logging_dir": "/opt/ml/output", "logging_first_step": false, "logging_steps": 250, "logging_strategy": "steps", "lr_scheduler_type": "linear", "max_grad_norm": 1.0, "max_steps": -1, "metric_for_best_model": null, "no_cuda": false, "num_train_epochs": 20.0, "optimize_model_before_eval": "disabled", "output_dir": "/opt/ml/model", "overwrite_output_dir": 1, "past_index": -1, "per_device_eval_batch_size": 8, "per_device_train_batch_size": 16, "per_gpu_eval_batch_size": null, "per_gpu_train_batch_size": null, "prediction_loss_only": false, "remove_unused_columns": true, "report_to": null, "run_name": "/opt/ml/model", "save_steps": 5000, "save_strategy": "steps", "save_total_limit": 50, "seed": 17, "sharded_ddp": false, "skip_memory_metrics": false, "tpu_metrics_debug": false, "tpu_num_cores": null, "warmup_ratio": 0.0, "warmup_steps": 5400, "weight_decay": 0.0}}, "f1": 88.06903108265608, "fill_rate": 0.24473741319444442, "speedup": 1.9695394330694393}}
{"fill_rate": 0.22031129436728392, "f1": 87.56487698206614, "meta": {"annotate": "22", "cat_fun_name": "is_new_xp", "checkpoint": {"config": {"_name_or_path": "bert-base-uncased", "architectures": ["BertForQuestionAnswering"], "attention_probs_dropout_prob": 0.1, "gradient_checkpointing": false, "hidden_act": "gelu", "hidden_dropout_prob": 0.1, "hidden_size": 768, "initializer_range": 0.02, "intermediate_size": 3072, "layer_norm_eps": 1e-12, "max_position_embeddings": 512, "model_type": "bert", "num_attention_heads": 12, "num_hidden_layers": 12, "pad_token_id": 0, "position_embedding_type": "absolute", "type_vocab_size": 2, "vocab_size": 30522}, "eval_metrics": {"exact_match": 80.10406811731315, "f1": 87.56487698206614}, "path": "/data_2to/devel_data/nn_pruning/output/squad_test_aws/aws_nn-pruning-v10-a32-l5-dl2--2021-01-21--00-51-49/checkpoint-110660", "sparse_args": {"ampere_pruning_method": "disabled", "attention_block_cols": 32, "attention_block_rows": 32, "attention_lambda": 1.0, "attention_output_with_dense": 0, "attention_pruning_method": "sigmoied_threshold", "bias_mask": true, "dense_block_cols": 1, "dense_block_rows": 1, "dense_lambda": 2.0, "dense_pruning_method": "sigmoied_threshold:1d_alt", "distil_alpha_ce": 0.1, "distil_alpha_teacher": 0.9, "distil_teacher_name_or_path": "csarron/bert-base-uncased-squad-v1", "distil_temperature": 2.0, "final_ampere_temperature": 20.0, "final_threshold": 0.1, "final_warmup": 10, "initial_ampere_temperature": 0.0, "initial_threshold": 0, "initial_warmup": 1, "mask_init": "constant", "mask_scale": 0.0, "mask_scores_learning_rate": 0.01, "regularization": "l1", "regularization_final_lambda": 5.0}, "speed": {"cuda_eval_elapsed_time": 19.459814723968506, "eval_elapsed_time": 26.6199238197878}, "speedup": 1.9832867657180042, "stats": {"layers": {"0": {"linear_attention_nnz": 1210368, "linear_attention_total": 2359296, "linear_dense_nnz": 210432, "linear_dense_total": 4718592, "linear_nnz": 1420800, "linear_total": 7077888, "nnz": 1426953, "total": 7087872}, "1": {"linear_attention_nnz": 977920, "linear_attention_total": 2359296, "linear_dense_nnz": 403968, "linear_dense_total": 4718592, "linear_nnz": 1381888, "linear_total": 7077888, "nnz": 1387879, "total": 7087872}, "10": {"linear_attention_nnz": 712704, "linear_attention_total": 2359296, "linear_dense_nnz": 69120, "linear_dense_total": 4718592, "linear_nnz": 781824, "linear_total": 7077888, "nnz": 787725, "total": 7087872}, "11": {"linear_attention_nnz": 443392, "linear_attention_total": 2359296, "linear_dense_nnz": 136704, "linear_dense_total": 4718592, "linear_nnz": 580096, "linear_total": 7077888, "nnz": 585529, "total": 7087872}, "2": {"linear_attention_nnz": 1500160, "linear_attention_total": 2359296, "linear_dense_nnz": 513024, "linear_dense_total": 4718592, "linear_nnz": 2013184, "linear_total": 7077888, "nnz": 2019886, "total": 7087872}, "3": {"linear_attention_nnz": 1526784, "linear_attention_total": 2359296, "linear_dense_nnz": 588288, "linear_dense_total": 4718592, "linear_nnz": 2115072, "linear_total": 7077888, "nnz": 2121727, "total": 7087872}, "4": {"linear_attention_nnz": 1734656, "linear_attention_total": 2359296, "linear_dense_nnz": 660480, "linear_dense_total": 4718592, "linear_nnz": 2395136, "linear_total": 7077888, "nnz": 2402190, "total": 7087872}, "5": {"linear_attention_nnz": 1659904, "linear_attention_total": 2359296, "linear_dense_nnz": 551424, "linear_dense_total": 4718592, "linear_nnz": 2211328, "linear_total": 7077888, "nnz": 2218215, "total": 7087872}, "6": {"linear_attention_nnz": 1486848, "linear_attention_total": 2359296, "linear_dense_nnz": 456192, "linear_dense_total": 4718592, "linear_nnz": 1943040, "linear_total": 7077888, "nnz": 1949865, "total": 7087872}, "7": {"linear_attention_nnz": 1254400, "linear_attention_total": 2359296, "linear_dense_nnz": 336384, "linear_dense_total": 4718592, "linear_nnz": 1590784, "linear_total": 7077888, "nnz": 1597115, "total": 7087872}, "8": {"linear_attention_nnz": 1267712, "linear_attention_total": 2359296, "linear_dense_nnz": 173568, "linear_dense_total": 4718592, "linear_nnz": 1441280, "linear_total": 7077888, "nnz": 1447569, "total": 7087872}, "9": {"linear_attention_nnz": 760832, "linear_attention_total": 2359296, "linear_dense_nnz": 76800, "linear_dense_total": 4718592, "linear_nnz": 837632, "linear_total": 7077888, "nnz": 843250, "total": 7087872}}, "linear_nnz": 18712064, "linear_sparsity": 77.96887056327161, "linear_total": 84934656, "nnz": 42626625, "pruned_heads": {"0": [0, 5, 6, 7], "1": [0, 2, 3, 6, 7], "10": [1, 4, 5, 7], "11": [0, 2, 5, 6, 7, 8, 11], "2": [8, 4], "3": [2, 4, 6], "4": [], "5": [1, 2], "6": [3], "7": [11, 3, 6, 7], "8": [0, 4], "9": [1, 4, 5, 7, 9, 10]}, "total": 108893186, "total_sparsity": 60.85464429335368}, "training_args": {"_n_gpu": -1, "adafactor": false, "adam_beta1": 0.9, "adam_beta2": 0.999, "adam_epsilon": 1e-08, "dataloader_drop_last": false, "dataloader_num_workers": 0, "dataloader_pin_memory": true, "ddp_find_unused_parameters": null, "debug": false, "deepspeed": null, "disable_tqdm": false, "do_eval": 1, "do_predict": false, "do_train": 1, "eval_accumulation_steps": null, "eval_steps": 5000, "evaluation_strategy": "steps", "fp16": false, "fp16_backend": "auto", "fp16_full_eval": false, "fp16_opt_level": "O1", "gradient_accumulation_steps": 1, "greater_is_better": null, "group_by_length": false, "ignore_data_skip": false, "label_names": null, "label_smoothing_factor": 0.0, "learning_rate": 3e-05, "load_best_model_at_end": false, "local_rank": -1, "logging_dir": "/opt/ml/output", "logging_first_step": false, "logging_steps": 250, "logging_strategy": "steps", "lr_scheduler_type": "linear", "max_grad_norm": 1.0, "max_steps": -1, "metric_for_best_model": null, "no_cuda": false, "num_train_epochs": 20.0, "optimize_model_before_eval": "disabled", "output_dir": "/opt/ml/model", "overwrite_output_dir": 1, "past_index": -1, "per_device_eval_batch_size": 8, "per_device_train_batch_size": 16, "per_gpu_eval_batch_size": null, "per_gpu_train_batch_size": null, "prediction_loss_only": false, "remove_unused_columns": true, "report_to": null, "run_name": "/opt/ml/model", "save_steps": 5000, "save_strategy": "steps", "save_total_limit": 50, "seed": 17, "sharded_ddp": false, "skip_memory_metrics": false, "tpu_metrics_debug": false, "tpu_num_cores": null, "warmup_ratio": 0.0, "warmup_steps": 5400, "weight_decay": 0.0}}, "f1": 87.56487698206614, "fill_rate": 0.22031129436728392, "speedup": 1.9832867657180042}}
{"fill_rate": 0.21446397569444442, "f1": 87.3881230572442, "meta": {"annotate": "21", "cat_fun_name": "is_new_xp", "checkpoint": {"config": {"_name_or_path": "bert-base-uncased", "architectures": ["BertForQuestionAnswering"], "attention_probs_dropout_prob": 0.1, "gradient_checkpointing": false, "hidden_act": "gelu", "hidden_dropout_prob": 0.1, "hidden_size": 768, "initializer_range": 0.02, "intermediate_size": 3072, "layer_norm_eps": 1e-12, "max_position_embeddings": 512, "model_type": "bert", "num_attention_heads": 12, "num_hidden_layers": 12, "pad_token_id": 0, "position_embedding_type": "absolute", "type_vocab_size": 2, "vocab_size": 30522}, "eval_metrics": {"exact_match": 79.66887417218543, "f1": 87.3881230572442}, "path": "/data_2to/devel_data/nn_pruning/output/squad_test_aws/aws_nn-pruning-v10-a32-l10-dl0-5--2021-01-21--00-54-13/checkpoint-110660", "sparse_args": {"ampere_pruning_method": "disabled", "attention_block_cols": 32, "attention_block_rows": 32, "attention_lambda": 1.0, "attention_output_with_dense": 0, "attention_pruning_method": "sigmoied_threshold", "bias_mask": true, "dense_block_cols": 1, "dense_block_rows": 1, "dense_lambda": 0.5, "dense_pruning_method": "sigmoied_threshold:1d_alt", "distil_alpha_ce": 0.1, "distil_alpha_teacher": 0.9, "distil_teacher_name_or_path": "csarron/bert-base-uncased-squad-v1", "distil_temperature": 2.0, "final_ampere_temperature": 20.0, "final_threshold": 0.1, "final_warmup": 10, "initial_ampere_temperature": 0.0, "initial_threshold": 0, "initial_warmup": 1, "mask_init": "constant", "mask_scale": 0.0, "mask_scores_learning_rate": 0.01, "regularization": "l1", "regularization_final_lambda": 10.0}, "speed": {"cuda_eval_elapsed_time": 17.326403350830077, "eval_elapsed_time": 24.523588876239955}, "speedup": 2.227490161916501, "stats": {"layers": {"0": {"linear_attention_nnz": 643072, "linear_attention_total": 2359296, "linear_dense_nnz": 634368, "linear_dense_total": 4718592, "linear_nnz": 1277440, "linear_total": 7077888, "nnz": 1283261, "total": 7087872}, "1": {"linear_attention_nnz": 622592, "linear_attention_total": 2359296, "linear_dense_nnz": 916992, "linear_dense_total": 4718592, "linear_nnz": 1539584, "linear_total": 7077888, "nnz": 1545525, "total": 7087872}, "10": {"linear_attention_nnz": 463872, "linear_attention_total": 2359296, "linear_dense_nnz": 112128, "linear_dense_total": 4718592, "linear_nnz": 576000, "linear_total": 7077888, "nnz": 581449, "total": 7087872}, "11": {"linear_attention_nnz": 278528, "linear_attention_total": 2359296, "linear_dense_nnz": 313344, "linear_dense_total": 4718592, "linear_nnz": 591872, "linear_total": 7077888, "nnz": 597164, "total": 7087872}, "2": {"linear_attention_nnz": 1051648, "linear_attention_total": 2359296, "linear_dense_nnz": 1016832, "linear_dense_total": 4718592, "linear_nnz": 2068480, "linear_total": 7077888, "nnz": 2075030, "total": 7087872}, "3": {"linear_attention_nnz": 1257472, "linear_attention_total": 2359296, "linear_dense_nnz": 1076736, "linear_dense_total": 4718592, "linear_nnz": 2334208, "linear_total": 7077888, "nnz": 2341053, "total": 7087872}, "4": {"linear_attention_nnz": 1315840, "linear_attention_total": 2359296, "linear_dense_nnz": 1158144, "linear_dense_total": 4718592, "linear_nnz": 2473984, "linear_total": 7077888, "nnz": 2481074, "total": 7087872}, "5": {"linear_attention_nnz": 1004544, "linear_attention_total": 2359296, "linear_dense_nnz": 1073664, "linear_dense_total": 4718592, "linear_nnz": 2078208, "linear_total": 7077888, "nnz": 2084891, "total": 7087872}, "6": {"linear_attention_nnz": 1004544, "linear_attention_total": 2359296, "linear_dense_nnz": 815616, "linear_dense_total": 4718592, "linear_nnz": 1820160, "linear_total": 7077888, "nnz": 1826675, "total": 7087872}, "7": {"linear_attention_nnz": 925696, "linear_attention_total": 2359296, "linear_dense_nnz": 629760, "linear_dense_total": 4718592, "linear_nnz": 1555456, "linear_total": 7077888, "nnz": 1561658, "total": 7087872}, "8": {"linear_attention_nnz": 899072, "linear_attention_total": 2359296, "linear_dense_nnz": 337920, "linear_dense_total": 4718592, "linear_nnz": 1236992, "linear_total": 7077888, "nnz": 1243132, "total": 7087872}, "9": {"linear_attention_nnz": 523264, "linear_attention_total": 2359296, "linear_dense_nnz": 139776, "linear_dense_total": 4718592, "linear_nnz": 663040, "linear_total": 7077888, "nnz": 668507, "total": 7087872}}, "linear_nnz": 18215424, "linear_sparsity": 78.55360243055556, "linear_total": 84934656, "nnz": 42128141, "pruned_heads": {"0": [0, 2, 4, 5, 6, 7, 9, 11], "1": [0, 2, 3, 5, 6, 7, 8, 9], "10": [1, 4, 5, 6, 7, 8], "11": [0, 2, 3, 5, 6, 7, 8, 10, 11], "2": [8, 4, 7], "3": [2, 4, 6, 7], "4": [1, 2], "5": [1, 2, 5, 6, 7], "6": [0, 2, 3, 7], "7": [1, 3, 6, 7, 11], "8": [0, 8, 3, 4], "9": [1, 3, 4, 5, 7, 9, 10]}, "total": 108893186, "total_sparsity": 61.31241765669342}, "training_args": {"_n_gpu": -1, "adafactor": false, "adam_beta1": 0.9, "adam_beta2": 0.999, "adam_epsilon": 1e-08, "dataloader_drop_last": false, "dataloader_num_workers": 0, "dataloader_pin_memory": true, "ddp_find_unused_parameters": null, "debug": false, "deepspeed": null, "disable_tqdm": false, "do_eval": 1, "do_predict": false, "do_train": 1, "eval_accumulation_steps": null, "eval_steps": 5000, "evaluation_strategy": "steps", "fp16": false, "fp16_backend": "auto", "fp16_full_eval": false, "fp16_opt_level": "O1", "gradient_accumulation_steps": 1, "greater_is_better": null, "group_by_length": false, "ignore_data_skip": false, "label_names": null, "label_smoothing_factor": 0.0, "learning_rate": 3e-05, "load_best_model_at_end": false, "local_rank": -1, "logging_dir": "/opt/ml/output", "logging_first_step": false, "logging_steps": 250, "logging_strategy": "steps", "lr_scheduler_type": "linear", "max_grad_norm": 1.0, "max_steps": -1, "metric_for_best_model": null, "no_cuda": false, "num_train_epochs": 20.0, "optimize_model_before_eval": "disabled", "output_dir": "/opt/ml/model", "overwrite_output_dir": 1, "past_index": -1, "per_device_eval_batch_size": 8, "per_device_train_batch_size": 16, "per_gpu_eval_batch_size": null, "per_gpu_train_batch_size": null, "prediction_loss_only": false, "remove_unused_columns": true, "report_to": null, "run_name": "/opt/ml/model", "save_steps": 5000, "save_strategy": "steps", "save_total_limit": 50, "seed": 17, "sharded_ddp": false, "skip_memory_metrics": false, "tpu_metrics_debug": false, "tpu_num_cores": null, "warmup_ratio": 0.0, "warmup_steps": 5400, "weight_decay": 0.0}}, "f1": 87.3881230572442, "fill_rate": 0.21446397569444442, "speedup": 2.227490161916501}}
{"fill_rate": 0.18393735532407407, "f1": 87.14755939306319, "meta": {"annotate": "18", "cat_fun_name": "is_new_xp", "checkpoint": {"config": {"_name_or_path": "bert-base-uncased", "architectures": ["BertForQuestionAnswering"], "attention_probs_dropout_prob": 0.1, "gradient_checkpointing": false, "hidden_act": "gelu", "hidden_dropout_prob": 0.1, "hidden_size": 768, "initializer_range": 0.02, "intermediate_size": 3072, "layer_norm_eps": 1e-12, "max_position_embeddings": 512, "model_type": "bert", "num_attention_heads": 12, "num_hidden_layers": 12, "pad_token_id": 0, "position_embedding_type": "absolute", "type_vocab_size": 2, "vocab_size": 30522}, "eval_metrics": {"exact_match": 79.39451277199622, "f1": 87.14755939306319}, "path": "/data_2to/devel_data/nn_pruning/output/squad_test_aws/aws_nn-pruning-v10-a32-l10-dl1--2021-01-21--00-53-40/checkpoint-110660", "sparse_args": {"ampere_pruning_method": "disabled", "attention_block_cols": 32, "attention_block_rows": 32, "attention_lambda": 1.0, "attention_output_with_dense": 0, "attention_pruning_method": "sigmoied_threshold", "bias_mask": true, "dense_block_cols": 1, "dense_block_rows": 1, "dense_lambda": 1.0, "dense_pruning_method": "sigmoied_threshold:1d_alt", "distil_alpha_ce": 0.1, "distil_alpha_teacher": 0.9, "distil_teacher_name_or_path": "csarron/bert-base-uncased-squad-v1", "distil_temperature": 2.0, "final_ampere_temperature": 20.0, "final_threshold": 0.1, "final_warmup": 10, "initial_ampere_temperature": 0.0, "initial_threshold": 0, "initial_warmup": 1, "mask_init": "constant", "mask_scale": 0.0, "mask_scores_learning_rate": 0.01, "regularization": "l1", "regularization_final_lambda": 10.0}, "speed": {"cuda_eval_elapsed_time": 17.057066314697266, "eval_elapsed_time": 24.182081679347903}, "speedup": 2.262663009764823, "stats": {"layers": {"0": {"linear_attention_nnz": 809984, "linear_attention_total": 2359296, "linear_dense_nnz": 297984, "linear_dense_total": 4718592, "linear_nnz": 1107968, "linear_total": 7077888, "nnz": 1113762, "total": 7087872}, "1": {"linear_attention_nnz": 720896, "linear_attention_total": 2359296, "linear_dense_nnz": 483840, "linear_dense_total": 4718592, "linear_nnz": 1204736, "linear_total": 7077888, "nnz": 1210491, "total": 7087872}, "10": {"linear_attention_nnz": 478208, "linear_attention_total": 2359296, "linear_dense_nnz": 73728, "linear_dense_total": 4718592, "linear_nnz": 551936, "linear_total": 7077888, "nnz": 557392, "total": 7087872}, "11": {"linear_attention_nnz": 312320, "linear_attention_total": 2359296, "linear_dense_nnz": 159744, "linear_dense_total": 4718592, "linear_nnz": 472064, "linear_total": 7077888, "nnz": 477288, "total": 7087872}, "2": {"linear_attention_nnz": 1098752, "linear_attention_total": 2359296, "linear_dense_nnz": 619008, "linear_dense_total": 4718592, "linear_nnz": 1717760, "linear_total": 7077888, "nnz": 1724147, "total": 7087872}, "3": {"linear_attention_nnz": 1309696, "linear_attention_total": 2359296, "linear_dense_nnz": 657408, "linear_dense_total": 4718592, "linear_nnz": 1967104, "linear_total": 7077888, "nnz": 1973708, "total": 7087872}, "4": {"linear_attention_nnz": 1362944, "linear_attention_total": 2359296, "linear_dense_nnz": 705024, "linear_dense_total": 4718592, "linear_nnz": 2067968, "linear_total": 7077888, "nnz": 2074795, "total": 7087872}, "5": {"linear_attention_nnz": 1074176, "linear_attention_total": 2359296, "linear_dense_nnz": 668160, "linear_dense_total": 4718592, "linear_nnz": 1742336, "linear_total": 7077888, "nnz": 1748787, "total": 7087872}, "6": {"linear_attention_nnz": 1049600, "linear_attention_total": 2359296, "linear_dense_nnz": 516096, "linear_dense_total": 4718592, "linear_nnz": 1565696, "linear_total": 7077888, "nnz": 1572016, "total": 7087872}, "7": {"linear_attention_nnz": 958464, "linear_attention_total": 2359296, "linear_dense_nnz": 384000, "linear_dense_total": 4718592, "linear_nnz": 1342464, "linear_total": 7077888, "nnz": 1348506, "total": 7087872}, "8": {"linear_attention_nnz": 949248, "linear_attention_total": 2359296, "linear_dense_nnz": 204288, "linear_dense_total": 4718592, "linear_nnz": 1153536, "linear_total": 7077888, "nnz": 1159685, "total": 7087872}, "9": {"linear_attention_nnz": 636928, "linear_attention_total": 2359296, "linear_dense_nnz": 92160, "linear_dense_total": 4718592, "linear_nnz": 729088, "linear_total": 7077888, "nnz": 734684, "total": 7087872}}, "linear_nnz": 15622656, "linear_sparsity": 81.6062644675926, "linear_total": 84934656, "nnz": 39533983, "pruned_heads": {"0": [0, 1, 2, 4, 5, 6], "1": [0, 2, 3, 5, 6, 7, 8], "10": [1, 4, 5, 6, 7, 8], "11": [0, 2, 3, 5, 6, 7, 8, 10, 11], "2": [8, 4, 7], "3": [2, 4, 6, 7], "4": [1, 2], "5": [1, 2, 6, 7], "6": [0, 2, 3, 7], "7": [1, 3, 6, 7, 11], "8": [0, 8, 4], "9": [1, 4, 5, 7, 9, 10]}, "total": 108893186, "total_sparsity": 63.694713643514845}, "training_args": {"_n_gpu": -1, "adafactor": false, "adam_beta1": 0.9, "adam_beta2": 0.999, "adam_epsilon": 1e-08, "dataloader_drop_last": false, "dataloader_num_workers": 0, "dataloader_pin_memory": true, "ddp_find_unused_parameters": null, "debug": false, "deepspeed": null, "disable_tqdm": false, "do_eval": 1, "do_predict": false, "do_train": 1, "eval_accumulation_steps": null, "eval_steps": 5000, "evaluation_strategy": "steps", "fp16": false, "fp16_backend": "auto", "fp16_full_eval": false, "fp16_opt_level": "O1", "gradient_accumulation_steps": 1, "greater_is_better": null, "group_by_length": false, "ignore_data_skip": false, "label_names": null, "label_smoothing_factor": 0.0, "learning_rate": 3e-05, "load_best_model_at_end": false, "local_rank": -1, "logging_dir": "/opt/ml/output", "logging_first_step": false, "logging_steps": 250, "logging_strategy": "steps", "lr_scheduler_type": "linear", "max_grad_norm": 1.0, "max_steps": -1, "metric_for_best_model": null, "no_cuda": false, "num_train_epochs": 20.0, "optimize_model_before_eval": "disabled", "output_dir": "/opt/ml/model", "overwrite_output_dir": 1, "past_index": -1, "per_device_eval_batch_size": 8, "per_device_train_batch_size": 16, "per_gpu_eval_batch_size": null, "per_gpu_train_batch_size": null, "prediction_loss_only": false, "remove_unused_columns": true, "report_to": null, "run_name": "/opt/ml/model", "save_steps": 5000, "save_strategy": "steps", "save_total_limit": 50, "seed": 17, "sharded_ddp": false, "skip_memory_metrics": false, "tpu_metrics_debug": false, "tpu_num_cores": null, "warmup_ratio": 0.0, "warmup_steps": 5400, "weight_decay": 0.0}}, "f1": 87.14755939306319, "fill_rate": 0.18393735532407407, "speedup": 2.262663009764823}}
{"fill_rate": 0.169071903935185, "f1": 86.51098653495667, "meta": {"annotate": "16", "cat_fun_name": "is_new_xp", "checkpoint": {"config": {"_name_or_path": "bert-base-uncased", "architectures": ["BertForQuestionAnswering"], "attention_probs_dropout_prob": 0.1, "gradient_checkpointing": false, "hidden_act": "gelu", "hidden_dropout_prob": 0.1, "hidden_size": 768, "initializer_range": 0.02, "intermediate_size": 3072, "layer_norm_eps": 1e-12, "max_position_embeddings": 512, "model_type": "bert", "num_attention_heads": 12, "num_hidden_layers": 12, "pad_token_id": 0, "position_embedding_type": "absolute", "type_vocab_size": 2, "vocab_size": 30522}, "eval_metrics": {"exact_match": 78.67549668874172, "f1": 86.51098653495667}, "path": "/data_2to/devel_data/nn_pruning/output/squad_test_aws/aws_nn-pruning-v10-a32-l10-dl2--2021-01-21--00-53-13/checkpoint-110660", "sparse_args": {"ampere_pruning_method": "disabled", "attention_block_cols": 32, "attention_block_rows": 32, "attention_lambda": 1.0, "attention_output_with_dense": 0, "attention_pruning_method": "sigmoied_threshold", "bias_mask": true, "dense_block_cols": 1, "dense_block_rows": 1, "dense_lambda": 2.0, "dense_pruning_method": "sigmoied_threshold:1d_alt", "distil_alpha_ce": 0.1, "distil_alpha_teacher": 0.9, "distil_teacher_name_or_path": "csarron/bert-base-uncased-squad-v1", "distil_temperature": 2.0, "final_ampere_temperature": 20.0, "final_threshold": 0.1, "final_warmup": 10, "initial_ampere_temperature": 0.0, "initial_threshold": 0, "initial_warmup": 1, "mask_init": "constant", "mask_scale": 0.0, "mask_scores_learning_rate": 0.01, "regularization": "l1", "regularization_final_lambda": 10.0}, "speed": {"cuda_eval_elapsed_time": 17.252509830474853, "eval_elapsed_time": 24.480217491276562}, "speedup": 2.2370306340702912, "stats": {"layers": {"0": {"linear_attention_nnz": 864256, "linear_attention_total": 2359296, "linear_dense_nnz": 127488, "linear_dense_total": 4718592, "linear_nnz": 991744, "linear_total": 7077888, "nnz": 997523, "total": 7087872}, "1": {"linear_attention_nnz": 748544, "linear_attention_total": 2359296, "linear_dense_nnz": 216576, "linear_dense_total": 4718592, "linear_nnz": 965120, "linear_total": 7077888, "nnz": 970733, "total": 7087872}, "10": {"linear_attention_nnz": 502784, "linear_attention_total": 2359296, "linear_dense_nnz": 53760, "linear_dense_total": 4718592, "linear_nnz": 556544, "linear_total": 7077888, "nnz": 562083, "total": 7087872}, "11": {"linear_attention_nnz": 360448, "linear_attention_total": 2359296, "linear_dense_nnz": 81408, "linear_dense_total": 4718592, "linear_nnz": 441856, "linear_total": 7077888, "nnz": 447157, "total": 7087872}, "2": {"linear_attention_nnz": 1163264, "linear_attention_total": 2359296, "linear_dense_nnz": 324096, "linear_dense_total": 4718592, "linear_nnz": 1487360, "linear_total": 7077888, "nnz": 1493555, "total": 7087872}, "3": {"linear_attention_nnz": 1389568, "linear_attention_total": 2359296, "linear_dense_nnz": 377856, "linear_dense_total": 4718592, "linear_nnz": 1767424, "linear_total": 7077888, "nnz": 1773910, "total": 7087872}, "4": {"linear_attention_nnz": 1449984, "linear_attention_total": 2359296, "linear_dense_nnz": 414720, "linear_dense_total": 4718592, "linear_nnz": 1864704, "linear_total": 7077888, "nnz": 1871374, "total": 7087872}, "5": {"linear_attention_nnz": 1349632, "linear_attention_total": 2359296, "linear_dense_nnz": 364032, "linear_dense_total": 4718592, "linear_nnz": 1713664, "linear_total": 7077888, "nnz": 1720365, "total": 7087872}, "6": {"linear_attention_nnz": 1187840, "linear_attention_total": 2359296, "linear_dense_nnz": 293376, "linear_dense_total": 4718592, "linear_nnz": 1481216, "linear_total": 7077888, "nnz": 1487647, "total": 7087872}, "7": {"linear_attention_nnz": 964608, "linear_attention_total": 2359296, "linear_dense_nnz": 225792, "linear_dense_total": 4718592, "linear_nnz": 1190400, "linear_total": 7077888, "nnz": 1196403, "total": 7087872}, "8": {"linear_attention_nnz": 1063936, "linear_attention_total": 2359296, "linear_dense_nnz": 127488, "linear_dense_total": 4718592, "linear_nnz": 1191424, "linear_total": 7077888, "nnz": 1197619, "total": 7087872}, "9": {"linear_attention_nnz": 650240, "linear_attention_total": 2359296, "linear_dense_nnz": 58368, "linear_dense_total": 4718592, "linear_nnz": 708608, "linear_total": 7077888, "nnz": 714182, "total": 7087872}}, "linear_nnz": 14360064, "linear_sparsity": 83.0928096064815, "linear_total": 84934656, "nnz": 38271273, "pruned_heads": {"0": [0, 2, 4, 5, 6, 7], "1": [0, 2, 3, 5, 6, 7, 8], "10": [1, 4, 5, 6, 7, 8], "11": [0, 2, 5, 6, 7, 8, 10, 11], "2": [8, 4, 7], "3": [2, 4, 6], "4": [1, 2], "5": [1, 2], "6": [2, 3, 7], "7": [1, 3, 6, 7, 11], "8": [0, 4], "9": [1, 4, 5, 7, 9, 10]}, "total": 108893186, "total_sparsity": 64.85429951512302}, "training_args": {"_n_gpu": -1, "adafactor": false, "adam_beta1": 0.9, "adam_beta2": 0.999, "adam_epsilon": 1e-08, "dataloader_drop_last": false, "dataloader_num_workers": 0, "dataloader_pin_memory": true, "ddp_find_unused_parameters": null, "debug": false, "deepspeed": null, "disable_tqdm": false, "do_eval": 1, "do_predict": false, "do_train": 1, "eval_accumulation_steps": null, "eval_steps": 5000, "evaluation_strategy": "steps", "fp16": false, "fp16_backend": "auto", "fp16_full_eval": false, "fp16_opt_level": "O1", "gradient_accumulation_steps": 1, "greater_is_better": null, "group_by_length": false, "ignore_data_skip": false, "label_names": null, "label_smoothing_factor": 0.0, "learning_rate": 3e-05, "load_best_model_at_end": false, "local_rank": -1, "logging_dir": "/opt/ml/output", "logging_first_step": false, "logging_steps": 250, "logging_strategy": "steps", "lr_scheduler_type": "linear", "max_grad_norm": 1.0, "max_steps": -1, "metric_for_best_model": null, "no_cuda": false, "num_train_epochs": 20.0, "optimize_model_before_eval": "disabled", "output_dir": "/opt/ml/model", "overwrite_output_dir": 1, "past_index": -1, "per_device_eval_batch_size": 8, "per_device_train_batch_size": 16, "per_gpu_eval_batch_size": null, "per_gpu_train_batch_size": null, "prediction_loss_only": false, "remove_unused_columns": true, "report_to": null, "run_name": "/opt/ml/model", "save_steps": 5000, "save_strategy": "steps", "save_total_limit": 50, "seed": 17, "sharded_ddp": false, "skip_memory_metrics": false, "tpu_metrics_debug": false, "tpu_num_cores": null, "warmup_ratio": 0.0, "warmup_steps": 5400, "weight_decay": 0.0}}, "f1": 86.51098653495667, "fill_rate": 0.169071903935185, "speedup": 2.2370306340702912}}
{"fill_rate": 0.15074628665123457, "f1": 86.4116267700138, "meta": {"annotate": "15", "cat_fun_name": "is_new_xp", "checkpoint": {"config": {"_name_or_path": "bert-base-uncased", "architectures": ["BertForQuestionAnswering"], "attention_probs_dropout_prob": 0.1, "gradient_checkpointing": false, "hidden_act": "gelu", "hidden_dropout_prob": 0.1, "hidden_size": 768, "initializer_range": 0.02, "intermediate_size": 3072, "layer_norm_eps": 1e-12, "max_position_embeddings": 512, "model_type": "bert", "num_attention_heads": 12, "num_hidden_layers": 12, "pad_token_id": 0, "position_embedding_type": "absolute", "type_vocab_size": 2, "vocab_size": 30522}, "eval_metrics": {"exact_match": 78.3349101229896, "f1": 86.4116267700138}, "path": "/data_2to/devel_data/nn_pruning/output/squad_test_aws/aws_nn-pruning-v10-a32-l20-dl0-5--2021-01-21--00-55-44/checkpoint-110000", "sparse_args": {"ampere_pruning_method": "disabled", "attention_block_cols": 32, "attention_block_rows": 32, "attention_lambda": 1.0, "attention_output_with_dense": 0, "attention_pruning_method": "sigmoied_threshold", "bias_mask": true, "dense_block_cols": 1, "dense_block_rows": 1, "dense_lambda": 0.5, "dense_pruning_method": "sigmoied_threshold:1d_alt", "distil_alpha_ce": 0.1, "distil_alpha_teacher": 0.9, "distil_teacher_name_or_path": "csarron/bert-base-uncased-squad-v1", "distil_temperature": 2.0, "final_ampere_temperature": 20.0, "final_threshold": 0.1, "final_warmup": 10, "initial_ampere_temperature": 0.0, "initial_threshold": 0, "initial_warmup": 1, "mask_init": "constant", "mask_scale": 0.0, "mask_scores_learning_rate": 0.01, "regularization": "l1", "regularization_final_lambda": 20.0}, "speed": {"cuda_eval_elapsed_time": 14.760263885498047, "eval_elapsed_time": 21.897933847736567}, "speedup": 2.6147495264830645, "stats": {"layers": {"0": {"linear_attention_nnz": 519168, "linear_attention_total": 2359296, "linear_dense_nnz": 411648, "linear_dense_total": 4718592, "linear_nnz": 930816, "linear_total": 7077888, "nnz": 936364, "total": 7087872}, "1": {"linear_attention_nnz": 536576, "linear_attention_total": 2359296, "linear_dense_nnz": 592896, "linear_dense_total": 4718592, "linear_nnz": 1129472, "linear_total": 7077888, "nnz": 1135106, "total": 7087872}, "10": {"linear_attention_nnz": 356352, "linear_attention_total": 2359296, "linear_dense_nnz": 87552, "linear_dense_total": 4718592, "linear_nnz": 443904, "linear_total": 7077888, "nnz": 449209, "total": 7087872}, "11": {"linear_attention_nnz": 226304, "linear_attention_total": 2359296, "linear_dense_nnz": 199680, "linear_dense_total": 4718592, "linear_nnz": 425984, "linear_total": 7077888, "nnz": 431106, "total": 7087872}, "2": {"linear_attention_nnz": 667648, "linear_attention_total": 2359296, "linear_dense_nnz": 698880, "linear_dense_total": 4718592, "linear_nnz": 1366528, "linear_total": 7077888, "nnz": 1372487, "total": 7087872}, "3": {"linear_attention_nnz": 967680, "linear_attention_total": 2359296, "linear_dense_nnz": 714240, "linear_dense_total": 4718592, "linear_nnz": 1681920, "linear_total": 7077888, "nnz": 1688273, "total": 7087872}, "4": {"linear_attention_nnz": 835584, "linear_attention_total": 2359296, "linear_dense_nnz": 834048, "linear_dense_total": 4718592, "linear_nnz": 1669632, "linear_total": 7077888, "nnz": 1675967, "total": 7087872}, "5": {"linear_attention_nnz": 668672, "linear_attention_total": 2359296, "linear_dense_nnz": 743424, "linear_dense_total": 4718592, "linear_nnz": 1412096, "linear_total": 7077888, "nnz": 1418052, "total": 7087872}, "6": {"linear_attention_nnz": 653312, "linear_attention_total": 2359296, "linear_dense_nnz": 568320, "linear_dense_total": 4718592, "linear_nnz": 1221632, "linear_total": 7077888, "nnz": 1227506, "total": 7087872}, "7": {"linear_attention_nnz": 787456, "linear_attention_total": 2359296, "linear_dense_nnz": 450048, "linear_dense_total": 4718592, "linear_nnz": 1237504, "linear_total": 7077888, "nnz": 1243493, "total": 7087872}, "8": {"linear_attention_nnz": 493568, "linear_attention_total": 2359296, "linear_dense_nnz": 264192, "linear_dense_total": 4718592, "linear_nnz": 757760, "linear_total": 7077888, "nnz": 763404, "total": 7087872}, "9": {"linear_attention_nnz": 424960, "linear_attention_total": 2359296, "linear_dense_nnz": 101376, "linear_dense_total": 4718592, "linear_nnz": 526336, "linear_total": 7077888, "nnz": 531586, "total": 7087872}}, "linear_nnz": 12803584, "linear_sparsity": 84.92537133487654, "linear_total": 84934656, "nnz": 36711275, "pruned_heads": {"0": [0, 2, 4, 5, 6, 7, 9, 11], "1": [0, 2, 3, 5, 6, 7, 8, 9], "10": [1, 4, 5, 6, 7, 8, 9], "11": [0, 2, 3, 5, 6, 7, 8, 10, 11], "2": [1, 2, 4, 7, 8, 11], "3": [2, 4, 6, 7, 10], "4": [0, 1, 2, 6, 11], "5": [0, 1, 2, 5, 6, 7, 11], "6": [0, 2, 3, 4, 7, 10], "7": [1, 3, 6, 7, 11], "8": [0, 2, 3, 4, 6, 8], "9": [1, 3, 4, 5, 7, 9, 10]}, "total": 108893186, "total_sparsity": 66.28689420474849}, "training_args": {"_n_gpu": -1, "adafactor": false, "adam_beta1": 0.9, "adam_beta2": 0.999, "adam_epsilon": 1e-08, "dataloader_drop_last": false, "dataloader_num_workers": 0, "dataloader_pin_memory": true, "ddp_find_unused_parameters": null, "debug": false, "deepspeed": null, "disable_tqdm": false, "do_eval": 1, "do_predict": false, "do_train": 1, "eval_accumulation_steps": null, "eval_steps": 5000, "evaluation_strategy": "steps", "fp16": false, "fp16_backend": "auto", "fp16_full_eval": false, "fp16_opt_level": "O1", "gradient_accumulation_steps": 1, "greater_is_better": null, "group_by_length": false, "ignore_data_skip": false, "label_names": null, "label_smoothing_factor": 0.0, "learning_rate": 3e-05, "load_best_model_at_end": false, "local_rank": -1, "logging_dir": "/opt/ml/output", "logging_first_step": false, "logging_steps": 250, "logging_strategy": "steps", "lr_scheduler_type": "linear", "max_grad_norm": 1.0, "max_steps": -1, "metric_for_best_model": null, "no_cuda": false, "num_train_epochs": 20.0, "optimize_model_before_eval": "disabled", "output_dir": "/opt/ml/model", "overwrite_output_dir": 1, "past_index": -1, "per_device_eval_batch_size": 8, "per_device_train_batch_size": 16, "per_gpu_eval_batch_size": null, "per_gpu_train_batch_size": null, "prediction_loss_only": false, "remove_unused_columns": true, "report_to": null, "run_name": "/opt/ml/model", "save_steps": 5000, "save_strategy": "steps", "save_total_limit": 50, "seed": 17, "sharded_ddp": false, "skip_memory_metrics": false, "tpu_metrics_debug": false, "tpu_num_cores": null, "warmup_ratio": 0.0, "warmup_steps": 5400, "weight_decay": 0.0}}, "f1": 86.4116267700138, "fill_rate": 0.15074628665123457, "speedup": 2.6147495264830645}}
{"fill_rate": 0.1279357156635803, "f1": 86.11992485005756, "meta": {"annotate": "12", "cat_fun_name": "is_new_xp", "checkpoint": {"config": {"_name_or_path": "bert-base-uncased", "architectures": ["BertForQuestionAnswering"], "attention_probs_dropout_prob": 0.1, "gradient_checkpointing": false, "hidden_act": "gelu", "hidden_dropout_prob": 0.1, "hidden_size": 768, "initializer_range": 0.02, "intermediate_size": 3072, "layer_norm_eps": 1e-12, "max_position_embeddings": 512, "model_type": "bert", "num_attention_heads": 12, "num_hidden_layers": 12, "pad_token_id": 0, "position_embedding_type": "absolute", "type_vocab_size": 2, "vocab_size": 30522}, "eval_metrics": {"exact_match": 77.8240302743614, "f1": 86.11992485005756}, "path": "/data_2to/devel_data/nn_pruning/output/squad_test_aws/aws_nn-pruning-v10-a32-l20-dl1--2021-01-21--00-55-15/checkpoint-110660", "sparse_args": {"ampere_pruning_method": "disabled", "attention_block_cols": 32, "attention_block_rows": 32, "attention_lambda": 1.0, "attention_output_with_dense": 0, "attention_pruning_method": "sigmoied_threshold", "bias_mask": true, "dense_block_cols": 1, "dense_block_rows": 1, "dense_lambda": 1.0, "dense_pruning_method": "sigmoied_threshold:1d_alt", "distil_alpha_ce": 0.1, "distil_alpha_teacher": 0.9, "distil_teacher_name_or_path": "csarron/bert-base-uncased-squad-v1", "distil_temperature": 2.0, "final_ampere_temperature": 20.0, "final_threshold": 0.1, "final_warmup": 10, "initial_ampere_temperature": 0.0, "initial_threshold": 0, "initial_warmup": 1, "mask_init": "constant", "mask_scale": 0.0, "mask_scores_learning_rate": 0.01, "regularization": "l1", "regularization_final_lambda": 20.0}, "speed": {"cuda_eval_elapsed_time": 14.268565601348877, "eval_elapsed_time": 21.374552259687334}, "speedup": 2.704854439028025, "stats": {"layers": {"0": {"linear_attention_nnz": 550912, "linear_attention_total": 2359296, "linear_dense_nnz": 181248, "linear_dense_total": 4718592, "linear_nnz": 732160, "linear_total": 7077888, "nnz": 737654, "total": 7087872}, "1": {"linear_attention_nnz": 535552, "linear_attention_total": 2359296, "linear_dense_nnz": 299520, "linear_dense_total": 4718592, "linear_nnz": 835072, "linear_total": 7077888, "nnz": 840515, "total": 7087872}, "10": {"linear_attention_nnz": 364544, "linear_attention_total": 2359296, "linear_dense_nnz": 58368, "linear_dense_total": 4718592, "linear_nnz": 422912, "linear_total": 7077888, "nnz": 428102, "total": 7087872}, "11": {"linear_attention_nnz": 239616, "linear_attention_total": 2359296, "linear_dense_nnz": 96768, "linear_dense_total": 4718592, "linear_nnz": 336384, "linear_total": 7077888, "nnz": 341471, "total": 7087872}, "2": {"linear_attention_nnz": 721920, "linear_attention_total": 2359296, "linear_dense_nnz": 407040, "linear_dense_total": 4718592, "linear_nnz": 1128960, "linear_total": 7077888, "nnz": 1134729, "total": 7087872}, "3": {"linear_attention_nnz": 1111040, "linear_attention_total": 2359296, "linear_dense_nnz": 440832, "linear_dense_total": 4718592, "linear_nnz": 1551872, "linear_total": 7077888, "nnz": 1558207, "total": 7087872}, "4": {"linear_attention_nnz": 892928, "linear_attention_total": 2359296, "linear_dense_nnz": 496128, "linear_dense_total": 4718592, "linear_nnz": 1389056, "linear_total": 7077888, "nnz": 1395267, "total": 7087872}, "5": {"linear_attention_nnz": 663552, "linear_attention_total": 2359296, "linear_dense_nnz": 433152, "linear_dense_total": 4718592, "linear_nnz": 1096704, "linear_total": 7077888, "nnz": 1102458, "total": 7087872}, "6": {"linear_attention_nnz": 662528, "linear_attention_total": 2359296, "linear_dense_nnz": 337920, "linear_dense_total": 4718592, "linear_nnz": 1000448, "linear_total": 7077888, "nnz": 1006172, "total": 7087872}, "7": {"linear_attention_nnz": 801792, "linear_attention_total": 2359296, "linear_dense_nnz": 268800, "linear_dense_total": 4718592, "linear_nnz": 1070592, "linear_total": 7077888, "nnz": 1076463, "total": 7087872}, "8": {"linear_attention_nnz": 645120, "linear_attention_total": 2359296, "linear_dense_nnz": 158208, "linear_dense_total": 4718592, "linear_nnz": 803328, "linear_total": 7077888, "nnz": 809127, "total": 7087872}, "9": {"linear_attention_nnz": 424960, "linear_attention_total": 2359296, "linear_dense_nnz": 73728, "linear_dense_total": 4718592, "linear_nnz": 498688, "linear_total": 7077888, "nnz": 503952, "total": 7087872}}, "linear_nnz": 10866176, "linear_sparsity": 87.20642843364197, "linear_total": 84934656, "nnz": 34772839, "pruned_heads": {"0": [0, 2, 4, 5, 6, 7, 9, 11], "1": [0, 2, 3, 5, 6, 7, 8, 9], "10": [1, 4, 5, 6, 7, 8, 9], "11": [0, 2, 3, 5, 6, 7, 8, 10, 11], "2": [1, 2, 4, 7, 8, 11], "3": [2, 4, 6, 7], "4": [1, 2, 4, 6, 11], "5": [0, 1, 2, 5, 6, 7, 11], "6": [0, 2, 3, 4, 7, 10], "7": [1, 3, 6, 7, 11], "8": [0, 2, 3, 4, 8], "9": [1, 3, 4, 5, 7, 9, 10]}, "total": 108893186, "total_sparsity": 68.06702028169144}, "training_args": {"_n_gpu": -1, "adafactor": false, "adam_beta1": 0.9, "adam_beta2": 0.999, "adam_epsilon": 1e-08, "dataloader_drop_last": false, "dataloader_num_workers": 0, "dataloader_pin_memory": true, "ddp_find_unused_parameters": null, "debug": false, "deepspeed": null, "disable_tqdm": false, "do_eval": 1, "do_predict": false, "do_train": 1, "eval_accumulation_steps": null, "eval_steps": 5000, "evaluation_strategy": "steps", "fp16": false, "fp16_backend": "auto", "fp16_full_eval": false, "fp16_opt_level": "O1", "gradient_accumulation_steps": 1, "greater_is_better": null, "group_by_length": false, "ignore_data_skip": false, "label_names": null, "label_smoothing_factor": 0.0, "learning_rate": 3e-05, "load_best_model_at_end": false, "local_rank": -1, "logging_dir": "/opt/ml/output", "logging_first_step": false, "logging_steps": 250, "logging_strategy": "steps", "lr_scheduler_type": "linear", "max_grad_norm": 1.0, "max_steps": -1, "metric_for_best_model": null, "no_cuda": false, "num_train_epochs": 20.0, "optimize_model_before_eval": "disabled", "output_dir": "/opt/ml/model", "overwrite_output_dir": 1, "past_index": -1, "per_device_eval_batch_size": 8, "per_device_train_batch_size": 16, "per_gpu_eval_batch_size": null, "per_gpu_train_batch_size": null, "prediction_loss_only": false, "remove_unused_columns": true, "report_to": null, "run_name": "/opt/ml/model", "save_steps": 5000, "save_strategy": "steps", "save_total_limit": 50, "seed": 17, "sharded_ddp": false, "skip_memory_metrics": false, "tpu_metrics_debug": false, "tpu_num_cores": null, "warmup_ratio": 0.0, "warmup_steps": 5400, "weight_decay": 0.0}}, "f1": 86.11992485005756, "fill_rate": 0.1279357156635803, "speedup": 2.704854439028025}}
{"fill_rate": 0.12381847993827155, "f1": 85.69020560735045, "meta": {"annotate": "12", "cat_fun_name": "is_new_xp", "checkpoint": {"config": {"_name_or_path": "bert-base-uncased", "architectures": ["BertForQuestionAnswering"], "attention_probs_dropout_prob": 0.1, "gradient_checkpointing": false, "hidden_act": "gelu", "hidden_dropout_prob": 0.1, "hidden_size": 768, "initializer_range": 0.02, "intermediate_size": 3072, "layer_norm_eps": 1e-12, "max_position_embeddings": 512, "model_type": "bert", "num_attention_heads": 12, "num_hidden_layers": 12, "pad_token_id": 0, "position_embedding_type": "absolute", "type_vocab_size": 2, "vocab_size": 30522}, "eval_metrics": {"exact_match": 77.37937559129612, "f1": 85.69020560735045}, "path": "/data_2to/devel_data/nn_pruning/output/squad_test_aws/aws_nn-pruning-v10-a32-l30-dl0-5--2021-01-23--20-19-50/checkpoint-110660", "sparse_args": {"ampere_pruning_method": "disabled", "attention_block_cols": 32, "attention_block_rows": 32, "attention_lambda": 1.0, "attention_output_with_dense": 0, "attention_pruning_method": "sigmoied_threshold", "bias_mask": true, "dense_block_cols": 1, "dense_block_rows": 1, "dense_lambda": 0.5, "dense_pruning_method": "sigmoied_threshold:1d_alt", "distil_alpha_ce": 0.1, "distil_alpha_teacher": 0.9, "distil_teacher_name_or_path": "csarron/bert-base-uncased-squad-v1", "distil_temperature": 2.0, "final_ampere_temperature": 20.0, "final_threshold": 0.1, "final_warmup": 10, "initial_ampere_temperature": 0.0, "initial_threshold": 0, "initial_warmup": 1, "mask_init": "constant", "mask_scale": 0.0, "mask_scores_learning_rate": 0.01, "regularization": "l1", "regularization_final_lambda": 30.0}, "speed": {"cuda_eval_elapsed_time": 13.492438529968261, "eval_elapsed_time": 20.86975116888061}, "speedup": 2.860446087610368, "stats": {"layers": {"0": {"linear_attention_nnz": 451584, "linear_attention_total": 2359296, "linear_dense_nnz": 290304, "linear_dense_total": 4718592, "linear_nnz": 741888, "linear_total": 7077888, "nnz": 747293, "total": 7087872}, "1": {"linear_attention_nnz": 495616, "linear_attention_total": 2359296, "linear_dense_nnz": 459264, "linear_dense_total": 4718592, "linear_nnz": 954880, "linear_total": 7077888, "nnz": 960395, "total": 7087872}, "10": {"linear_attention_nnz": 296960, "linear_attention_total": 2359296, "linear_dense_nnz": 73728, "linear_dense_total": 4718592, "linear_nnz": 370688, "linear_total": 7077888, "nnz": 375792, "total": 7087872}, "11": {"linear_attention_nnz": 194560, "linear_attention_total": 2359296, "linear_dense_nnz": 153600, "linear_dense_total": 4718592, "linear_nnz": 348160, "linear_total": 7077888, "nnz": 353092, "total": 7087872}, "2": {"linear_attention_nnz": 583680, "linear_attention_total": 2359296, "linear_dense_nnz": 557568, "linear_dense_total": 4718592, "linear_nnz": 1141248, "linear_total": 7077888, "nnz": 1147019, "total": 7087872}, "3": {"linear_attention_nnz": 789504, "linear_attention_total": 2359296, "linear_dense_nnz": 583680, "linear_dense_total": 4718592, "linear_nnz": 1373184, "linear_total": 7077888, "nnz": 1379228, "total": 7087872}, "4": {"linear_attention_nnz": 582656, "linear_attention_total": 2359296, "linear_dense_nnz": 665088, "linear_dense_total": 4718592, "linear_nnz": 1247744, "linear_total": 7077888, "nnz": 1253617, "total": 7087872}, "5": {"linear_attention_nnz": 548864, "linear_attention_total": 2359296, "linear_dense_nnz": 614400, "linear_dense_total": 4718592, "linear_nnz": 1163264, "linear_total": 7077888, "nnz": 1169040, "total": 7087872}, "6": {"linear_attention_nnz": 578560, "linear_attention_total": 2359296, "linear_dense_nnz": 463872, "linear_dense_total": 4718592, "linear_nnz": 1042432, "linear_total": 7077888, "nnz": 1048302, "total": 7087872}, "7": {"linear_attention_nnz": 715776, "linear_attention_total": 2359296, "linear_dense_nnz": 370176, "linear_dense_total": 4718592, "linear_nnz": 1085952, "linear_total": 7077888, "nnz": 1091889, "total": 7087872}, "8": {"linear_attention_nnz": 375808, "linear_attention_total": 2359296, "linear_dense_nnz": 235008, "linear_dense_total": 4718592, "linear_nnz": 610816, "linear_total": 7077888, "nnz": 616217, "total": 7087872}, "9": {"linear_attention_nnz": 347136, "linear_attention_total": 2359296, "linear_dense_nnz": 89088, "linear_dense_total": 4718592, "linear_nnz": 436224, "linear_total": 7077888, "nnz": 441306, "total": 7087872}}, "linear_nnz": 10516480, "linear_sparsity": 87.61815200617285, "linear_total": 84934656, "nnz": 34421912, "pruned_heads": {"0": [0, 2, 4, 5, 6, 7, 9, 11], "1": [0, 2, 3, 5, 6, 7, 8, 9], "10": [1, 4, 5, 6, 7, 8, 9], "11": [0, 2, 3, 5, 6, 7, 8, 10, 11], "2": [1, 2, 3, 4, 7, 8, 11], "3": [2, 3, 4, 6, 7, 10], "4": [0, 1, 2, 6, 7, 11], "5": [0, 1, 2, 4, 5, 6, 7, 11], "6": [0, 2, 3, 4, 7, 10], "7": [1, 3, 6, 7, 11], "8": [0, 1, 2, 3, 4, 5, 6, 8], "9": [1, 3, 4, 5, 7, 9, 10]}, "total": 108893186, "total_sparsity": 68.3892874619354}, "training_args": {"_n_gpu": -1, "adafactor": false, "adam_beta1": 0.9, "adam_beta2": 0.999, "adam_epsilon": 1e-08, "dataloader_drop_last": false, "dataloader_num_workers": 0, "dataloader_pin_memory": true, "ddp_find_unused_parameters": null, "debug": false, "deepspeed": null, "disable_tqdm": false, "do_eval": 1, "do_predict": false, "do_train": 1, "eval_accumulation_steps": null, "eval_steps": 5000, "evaluation_strategy": "steps", "fp16": false, "fp16_backend": "auto", "fp16_full_eval": false, "fp16_opt_level": "O1", "gradient_accumulation_steps": 1, "greater_is_better": null, "group_by_length": false, "ignore_data_skip": false, "label_names": null, "label_smoothing_factor": 0.0, "learning_rate": 3e-05, "load_best_model_at_end": false, "local_rank": -1, "logging_dir": "/opt/ml/output", "logging_first_step": false, "logging_steps": 250, "logging_strategy": "steps", "lr_scheduler_type": "linear", "max_grad_norm": 1.0, "max_steps": -1, "metric_for_best_model": null, "no_cuda": false, "num_train_epochs": 20.0, "optimize_model_before_eval": "disabled", "output_dir": "/opt/ml/model", "overwrite_output_dir": 1, "past_index": -1, "per_device_eval_batch_size": 8, "per_device_train_batch_size": 16, "per_gpu_eval_batch_size": null, "per_gpu_train_batch_size": null, "prediction_loss_only": false, "remove_unused_columns": true, "report_to": null, "run_name": "/opt/ml/model", "save_steps": 5000, "save_strategy": "steps", "save_total_limit": 50, "seed": 17, "sharded_ddp": false, "skip_memory_metrics": false, "tpu_metrics_debug": false, "tpu_num_cores": null, "warmup_ratio": 0.0, "warmup_steps": 5400, "weight_decay": 0.0}}, "f1": 85.69020560735045, "fill_rate": 0.12381847993827155, "speedup": 2.860446087610368}}
{"fill_rate": 0.11965904706790131, "f1": 85.26341062121247, "meta": {"annotate": "11", "cat_fun_name": "is_new_xp", "checkpoint": {"config": {"_name_or_path": "bert-base-uncased", "architectures": ["BertForQuestionAnswering"], "attention_probs_dropout_prob": 0.1, "gradient_checkpointing": false, "hidden_act": "gelu", "hidden_dropout_prob": 0.1, "hidden_size": 768, "initializer_range": 0.02, "intermediate_size": 3072, "layer_norm_eps": 1e-12, "max_position_embeddings": 512, "model_type": "bert", "num_attention_heads": 12, "num_hidden_layers": 12, "pad_token_id": 0, "position_embedding_type": "absolute", "type_vocab_size": 2, "vocab_size": 30522}, "eval_metrics": {"exact_match": 76.9914853358562, "f1": 85.26341062121247}, "path": "/data_2to/devel_data/nn_pruning/output/squad_test_aws/aws_nn-pruning-v10-a32-l20-dl2--2021-01-21--00-54-43/checkpoint-110660", "sparse_args": {"ampere_pruning_method": "disabled", "attention_block_cols": 32, "attention_block_rows": 32, "attention_lambda": 1.0, "attention_output_with_dense": 0, "attention_pruning_method": "sigmoied_threshold", "bias_mask": true, "dense_block_cols": 1, "dense_block_rows": 1, "dense_lambda": 2.0, "dense_pruning_method": "sigmoied_threshold:1d_alt", "distil_alpha_ce": 0.1, "distil_alpha_teacher": 0.9, "distil_teacher_name_or_path": "csarron/bert-base-uncased-squad-v1", "distil_temperature": 2.0, "final_ampere_temperature": 20.0, "final_threshold": 0.1, "final_warmup": 10, "initial_ampere_temperature": 0.0, "initial_threshold": 0, "initial_warmup": 1, "mask_init": "constant", "mask_scale": 0.0, "mask_scores_learning_rate": 0.01, "regularization": "l1", "regularization_final_lambda": 20.0}, "speed": {"cuda_eval_elapsed_time": 14.846498733520509, "eval_elapsed_time": 21.962527931667864}, "speedup": 2.599561936999493, "stats": {"layers": {"0": {"linear_attention_nnz": 598016, "linear_attention_total": 2359296, "linear_dense_nnz": 76800, "linear_dense_total": 4718592, "linear_nnz": 674816, "linear_total": 7077888, "nnz": 680306, "total": 7087872}, "1": {"linear_attention_nnz": 621568, "linear_attention_total": 2359296, "linear_dense_nnz": 129024, "linear_dense_total": 4718592, "linear_nnz": 750592, "linear_total": 7077888, "nnz": 756020, "total": 7087872}, "10": {"linear_attention_nnz": 395264, "linear_attention_total": 2359296, "linear_dense_nnz": 36864, "linear_dense_total": 4718592, "linear_nnz": 432128, "linear_total": 7077888, "nnz": 437432, "total": 7087872}, "11": {"linear_attention_nnz": 238592, "linear_attention_total": 2359296, "linear_dense_nnz": 52224, "linear_dense_total": 4718592, "linear_nnz": 290816, "linear_total": 7077888, "nnz": 295682, "total": 7087872}, "2": {"linear_attention_nnz": 937984, "linear_attention_total": 2359296, "linear_dense_nnz": 199680, "linear_dense_total": 4718592, "linear_nnz": 1137664, "linear_total": 7077888, "nnz": 1143554, "total": 7087872}, "3": {"linear_attention_nnz": 1193984, "linear_attention_total": 2359296, "linear_dense_nnz": 264192, "linear_dense_total": 4718592, "linear_nnz": 1458176, "linear_total": 7077888, "nnz": 1464428, "total": 7087872}, "4": {"linear_attention_nnz": 1057792, "linear_attention_total": 2359296, "linear_dense_nnz": 278016, "linear_dense_total": 4718592, "linear_nnz": 1335808, "linear_total": 7077888, "nnz": 1342037, "total": 7087872}, "5": {"linear_attention_nnz": 614400, "linear_attention_total": 2359296, "linear_dense_nnz": 228864, "linear_dense_total": 4718592, "linear_nnz": 843264, "linear_total": 7077888, "nnz": 848853, "total": 7087872}, "6": {"linear_attention_nnz": 759808, "linear_attention_total": 2359296, "linear_dense_nnz": 188928, "linear_dense_total": 4718592, "linear_nnz": 948736, "linear_total": 7077888, "nnz": 954619, "total": 7087872}, "7": {"linear_attention_nnz": 830464, "linear_attention_total": 2359296, "linear_dense_nnz": 148992, "linear_dense_total": 4718592, "linear_nnz": 979456, "linear_total": 7077888, "nnz": 985313, "total": 7087872}, "8": {"linear_attention_nnz": 753664, "linear_attention_total": 2359296, "linear_dense_nnz": 79872, "linear_dense_total": 4718592, "linear_nnz": 833536, "linear_total": 7077888, "nnz": 839444, "total": 7087872}, "9": {"linear_attention_nnz": 432128, "linear_attention_total": 2359296, "linear_dense_nnz": 46080, "linear_dense_total": 4718592, "linear_nnz": 478208, "linear_total": 7077888, "nnz": 483454, "total": 7087872}}, "linear_nnz": 10163200, "linear_sparsity": 88.03409529320987, "linear_total": 84934656, "nnz": 34069864, "pruned_heads": {"0": [0, 1, 2, 4, 5, 6, 7], "1": [0, 2, 3, 5, 6, 7, 8], "10": [1, 4, 5, 6, 7, 8], "11": [0, 2, 3, 5, 6, 7, 8, 10, 11], "2": [8, 11, 4, 7], "3": [2, 4, 6, 7], "4": [1, 2, 11, 4], "5": [0, 1, 2, 5, 6, 7, 11], "6": [0, 2, 3, 4, 7], "7": [1, 3, 6, 7, 11], "8": [0, 8, 3, 4], "9": [1, 3, 4, 5, 7, 9, 10]}, "total": 108893186, "total_sparsity": 68.71258409134985}, "training_args": {"_n_gpu": -1, "adafactor": false, "adam_beta1": 0.9, "adam_beta2": 0.999, "adam_epsilon": 1e-08, "dataloader_drop_last": false, "dataloader_num_workers": 0, "dataloader_pin_memory": true, "ddp_find_unused_parameters": null, "debug": false, "deepspeed": null, "disable_tqdm": false, "do_eval": 1, "do_predict": false, "do_train": 1, "eval_accumulation_steps": null, "eval_steps": 5000, "evaluation_strategy": "steps", "fp16": false, "fp16_backend": "auto", "fp16_full_eval": false, "fp16_opt_level": "O1", "gradient_accumulation_steps": 1, "greater_is_better": null, "group_by_length": false, "ignore_data_skip": false, "label_names": null, "label_smoothing_factor": 0.0, "learning_rate": 3e-05, "load_best_model_at_end": false, "local_rank": -1, "logging_dir": "/opt/ml/output", "logging_first_step": false, "logging_steps": 250, "logging_strategy": "steps", "lr_scheduler_type": "linear", "max_grad_norm": 1.0, "max_steps": -1, "metric_for_best_model": null, "no_cuda": false, "num_train_epochs": 20.0, "optimize_model_before_eval": "disabled", "output_dir": "/opt/ml/model", "overwrite_output_dir": 1, "past_index": -1, "per_device_eval_batch_size": 8, "per_device_train_batch_size": 16, "per_gpu_eval_batch_size": null, "per_gpu_train_batch_size": null, "prediction_loss_only": false, "remove_unused_columns": true, "report_to": null, "run_name": "/opt/ml/model", "save_steps": 5000, "save_strategy": "steps", "save_total_limit": 50, "seed": 17, "sharded_ddp": false, "skip_memory_metrics": false, "tpu_metrics_debug": false, "tpu_num_cores": null, "warmup_ratio": 0.0, "warmup_steps": 5400, "weight_decay": 0.0}}, "f1": 85.26341062121247, "fill_rate": 0.11965904706790131, "speedup": 2.599561936999493}}
