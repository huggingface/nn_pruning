{"fill_rate": 0.5023148148148149, "f1": 90.32458147221426, "meta": {"annotate": "18", "cat_fun_name": "is_new_xp", "checkpoint": {"config": {"_name_or_path": "bert-large-uncased", "architectures": ["BertForQuestionAnswering"], "attention_probs_dropout_prob": 0.1, "gradient_checkpointing": false, "hidden_act": "gelu", "hidden_dropout_prob": 0.1, "hidden_size": 1024, "initializer_range": 0.02, "intermediate_size": 4096, "layer_norm_eps": 1e-12, "max_position_embeddings": 512, "model_type": "bert", "num_attention_heads": 16, "num_hidden_layers": 24, "pad_token_id": 0, "position_embedding_type": "absolute", "type_vocab_size": 2, "vocab_size": 30522}, "eval_metrics": {"exact_match": 83.78429517502366, "f1": 90.32458147221426}, "path": "/data_2to/devel_data/nn_pruning/output/squad_test_large/large_regu_10_d0.25/checkpoint-210000", "sparse_args": {"ampere_pruning_method": "disabled", "attention_block_cols": 32, "attention_block_rows": 32, "attention_lambda": 1.0, "attention_output_with_dense": 0, "attention_pruning_method": "sigmoied_threshold", "bias_mask": true, "dense_block_cols": 1, "dense_block_rows": 1, "dense_lambda": 0.25, "dense_pruning_method": "sigmoied_threshold:1d_alt", "distil_alpha_ce": 0.1, "distil_alpha_teacher": 0.9, "distil_teacher_name_or_path": "bert-large-uncased-whole-word-masking-finetuned-squad", "distil_temperature": 2.0, "final_ampere_temperature": 20.0, "final_finetune": false, "final_threshold": 0.1, "final_warmup": 10, "initial_ampere_temperature": 0.0, "initial_threshold": 0, "initial_warmup": 1, "mask_init": "constant", "mask_scale": 0.0, "mask_scores_learning_rate": 0.01, "regularization": "l1", "regularization_final_lambda": 10}, "speed": {"cuda_eval_elapsed_time": 41.496326583862306, "eval_elapsed_time": 49.08256564009935}, "speedup": 0.9300676995438012, "stats": {"layers": {"0": {"linear_attention_nnz": 783360, "linear_attention_total": 4194304, "linear_dense_nnz": 835584, "linear_dense_total": 8388608, "linear_nnz": 1618944, "linear_total": 12582912, "nnz": 1626424, "total": 12596224}, "1": {"linear_attention_nnz": 326656, "linear_attention_total": 4194304, "linear_dense_nnz": 1275904, "linear_dense_total": 8388608, "linear_nnz": 1602560, "linear_total": 12582912, "nnz": 1609647, "total": 12596224}, "10": {"linear_attention_nnz": 1636352, "linear_attention_total": 4194304, "linear_dense_nnz": 2410496, "linear_dense_total": 8388608, "linear_nnz": 4046848, "linear_total": 12582912, "nnz": 4056121, "total": 12596224}, "11": {"linear_attention_nnz": 1575936, "linear_attention_total": 4194304, "linear_dense_nnz": 2510848, "linear_dense_total": 8388608, "linear_nnz": 4086784, "linear_total": 12582912, "nnz": 4095818, "total": 12596224}, "12": {"linear_attention_nnz": 1203200, "linear_attention_total": 4194304, "linear_dense_nnz": 2660352, "linear_dense_total": 8388608, "linear_nnz": 3863552, "linear_total": 12582912, "nnz": 3872307, "total": 12596224}, "13": {"linear_attention_nnz": 2030592, "linear_attention_total": 4194304, "linear_dense_nnz": 2605056, "linear_dense_total": 8388608, "linear_nnz": 4635648, "linear_total": 12582912, "nnz": 4645176, "total": 12596224}, "14": {"linear_attention_nnz": 1785856, "linear_attention_total": 4194304, "linear_dense_nnz": 2299904, "linear_dense_total": 8388608, "linear_nnz": 4085760, "linear_total": 12582912, "nnz": 4094851, "total": 12596224}, "15": {"linear_attention_nnz": 1946624, "linear_attention_total": 4194304, "linear_dense_nnz": 1699840, "linear_dense_total": 8388608, "linear_nnz": 3646464, "linear_total": 12582912, "nnz": 3655358, "total": 12596224}, "16": {"linear_attention_nnz": 1647616, "linear_attention_total": 4194304, "linear_dense_nnz": 1402880, "linear_dense_total": 8388608, "linear_nnz": 3050496, "linear_total": 12582912, "nnz": 3059149, "total": 12596224}, "17": {"linear_attention_nnz": 1538048, "linear_attention_total": 4194304, "linear_dense_nnz": 1097728, "linear_dense_total": 8388608, "linear_nnz": 2635776, "linear_total": 12582912, "nnz": 2644472, "total": 12596224}, "18": {"linear_attention_nnz": 1169408, "linear_attention_total": 4194304, "linear_dense_nnz": 901120, "linear_dense_total": 8388608, "linear_nnz": 2070528, "linear_total": 12582912, "nnz": 2078488, "total": 12596224}, "19": {"linear_attention_nnz": 607232, "linear_attention_total": 4194304, "linear_dense_nnz": 739328, "linear_dense_total": 8388608, "linear_nnz": 1346560, "linear_total": 12582912, "nnz": 1353929, "total": 12596224}, "2": {"linear_attention_nnz": 305152, "linear_attention_total": 4194304, "linear_dense_nnz": 1359872, "linear_dense_total": 8388608, "linear_nnz": 1665024, "linear_total": 12582912, "nnz": 1672152, "total": 12596224}, "20": {"linear_attention_nnz": 396288, "linear_attention_total": 4194304, "linear_dense_nnz": 358400, "linear_dense_total": 8388608, "linear_nnz": 754688, "linear_total": 12582912, "nnz": 761551, "total": 12596224}, "21": {"linear_attention_nnz": 284672, "linear_attention_total": 4194304, "linear_dense_nnz": 194560, "linear_dense_total": 8388608, "linear_nnz": 479232, "linear_total": 12582912, "nnz": 485695, "total": 12596224}, "22": {"linear_attention_nnz": 70656, "linear_attention_total": 4194304, "linear_dense_nnz": 180224, "linear_dense_total": 8388608, "linear_nnz": 250880, "linear_total": 12582912, "nnz": 256728, "total": 12596224}, "23": {"linear_attention_nnz": 111616, "linear_attention_total": 4194304, "linear_dense_nnz": 323584, "linear_dense_total": 8388608, "linear_nnz": 435200, "linear_total": 12582912, "nnz": 441598, "total": 12596224}, "3": {"linear_attention_nnz": 626688, "linear_attention_total": 4194304, "linear_dense_nnz": 1685504, "linear_dense_total": 8388608, "linear_nnz": 2312192, "linear_total": 12582912, "nnz": 2319831, "total": 12596224}, "4": {"linear_attention_nnz": 369664, "linear_attention_total": 4194304, "linear_dense_nnz": 1767424, "linear_dense_total": 8388608, "linear_nnz": 2137088, "linear_total": 12582912, "nnz": 2144479, "total": 12596224}, "5": {"linear_attention_nnz": 463872, "linear_attention_total": 4194304, "linear_dense_nnz": 1873920, "linear_dense_total": 8388608, "linear_nnz": 2337792, "linear_total": 12582912, "nnz": 2345331, "total": 12596224}, "6": {"linear_attention_nnz": 294912, "linear_attention_total": 4194304, "linear_dense_nnz": 2054144, "linear_dense_total": 8388608, "linear_nnz": 2349056, "linear_total": 12582912, "nnz": 2356491, "total": 12596224}, "7": {"linear_attention_nnz": 613376, "linear_attention_total": 4194304, "linear_dense_nnz": 1773568, "linear_dense_total": 8388608, "linear_nnz": 2386944, "linear_total": 12582912, "nnz": 2394690, "total": 12596224}, "8": {"linear_attention_nnz": 208896, "linear_attention_total": 4194304, "linear_dense_nnz": 1968128, "linear_dense_total": 8388608, "linear_nnz": 2177024, "linear_total": 12582912, "nnz": 2184321, "total": 12596224}, "9": {"linear_attention_nnz": 923648, "linear_attention_total": 4194304, "linear_dense_nnz": 1986560, "linear_dense_total": 8388608, "linear_nnz": 2910208, "linear_total": 12582912, "nnz": 2918282, "total": 12596224}}, "linear_nnz": 56885248, "linear_sparsity": 81.16319444444444, "linear_total": 301989888, "nnz": 88857851, "pruned_heads": {"0": [4, 5, 7, 8, 9, 10, 11, 13, 14, 15], "1": [0, 1, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], "10": [0, 7, 8, 10, 12, 13], "11": [0, 1, 2, 4, 5, 8, 10], "12": [2, 3, 5, 6, 7, 8, 10, 13], "13": [10, 2, 3, 12], "14": [1, 2, 3, 4, 8, 11], "15": [0, 5, 6, 7, 11, 12], "16": [3, 6, 8, 10, 13, 15], "17": [0, 2, 11, 15], "18": [2, 3, 5, 9, 11, 12, 13], "19": [0, 2, 3, 4, 9, 10, 11, 13, 15], "2": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 15], "20": [1, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 15], "21": [2, 3, 4, 5, 6, 8, 10, 11, 12, 13, 14, 15], "22": [0, 1, 2, 3, 4, 5, 8, 9, 10, 11, 12, 13, 14, 15], "23": [1, 2, 4, 5, 6, 7, 9, 10, 12, 13, 14], "3": [0, 2, 3, 4, 5, 6, 7, 8, 10, 13, 14, 15], "4": [0, 1, 2, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], "5": [0, 1, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13, 14], "6": [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15], "7": [0, 1, 2, 4, 5, 6, 8, 10, 11, 13, 14, 15], "8": [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 12, 13, 14, 15], "9": [1, 2, 3, 4, 5, 6, 8, 9, 12, 13, 15]}, "total": 334094338, "total_sparsity": 73.40336518962498}, "training_args": {"_n_gpu": -1, "adafactor": false, "adam_beta1": 0.9, "adam_beta2": 0.999, "adam_epsilon": 1e-08, "dataloader_drop_last": false, "dataloader_num_workers": 0, "dataloader_pin_memory": true, "ddp_find_unused_parameters": null, "debug": false, "deepspeed": null, "disable_tqdm": false, "do_eval": 1, "do_predict": false, "do_train": 1, "eval_accumulation_steps": null, "eval_steps": 10000, "evaluation_strategy": "steps", "fp16": false, "fp16_backend": "auto", "fp16_full_eval": false, "fp16_opt_level": "O1", "gradient_accumulation_steps": 1, "greater_is_better": null, "group_by_length": false, "ignore_data_skip": false, "label_names": null, "label_smoothing_factor": 0.0, "learning_rate": 3e-05, "load_best_model_at_end": false, "local_rank": -1, "logging_dir": "output/squad_test_large/squad_test_large_regu_10_d0.25", "logging_first_step": false, "logging_steps": 250, "logging_strategy": "steps", "lr_scheduler_type": "linear", "max_grad_norm": 1.0, "max_steps": -1, "metric_for_best_model": null, "no_cuda": false, "num_train_epochs": 20, "optimize_model_before_eval": "disabled", "output_dir": "output/squad_test_large/squad_test_large_regu_10_d0.25", "overwrite_output_dir": 1, "past_index": -1, "per_device_eval_batch_size": 8, "per_device_train_batch_size": 8, "per_gpu_eval_batch_size": null, "per_gpu_train_batch_size": null, "prediction_loss_only": false, "remove_unused_columns": true, "report_to": null, "run_name": "output/squad_test_large/squad_test_large_regu_10_d0.25", "save_steps": 10000, "save_strategy": "steps", "save_total_limit": 50, "seed": 17, "sharded_ddp": "", "skip_memory_metrics": false, "tpu_metrics_debug": false, "tpu_num_cores": null, "warmup_ratio": 0.0, "warmup_steps": 5400, "weight_decay": 0.0}}, "f1": 90.32458147221426, "fill_rate": 0.5023148148148149, "speedup": 0.9300676995438012}}
{"fill_rate": 0.4998734085648149, "f1": 90.22195941338013, "meta": {"annotate": "18", "cat_fun_name": "is_new_xp", "checkpoint": {"config": {"_name_or_path": "bert-large-uncased", "architectures": ["BertForQuestionAnswering"], "attention_probs_dropout_prob": 0.1, "gradient_checkpointing": false, "hidden_act": "gelu", "hidden_dropout_prob": 0.1, "hidden_size": 1024, "initializer_range": 0.02, "intermediate_size": 4096, "layer_norm_eps": 1e-12, "max_position_embeddings": 512, "model_type": "bert", "num_attention_heads": 16, "num_hidden_layers": 24, "pad_token_id": 0, "position_embedding_type": "absolute", "type_vocab_size": 2, "vocab_size": 30522}, "eval_metrics": {"exact_match": 83.66130558183538, "f1": 90.22195941338013}, "path": "/data_2to/devel_data/nn_pruning/output/squad_test_large/large_regu_10_d0.25/checkpoint-221320", "sparse_args": {"ampere_pruning_method": "disabled", "attention_block_cols": 32, "attention_block_rows": 32, "attention_lambda": 1.0, "attention_output_with_dense": 0, "attention_pruning_method": "sigmoied_threshold", "bias_mask": true, "dense_block_cols": 1, "dense_block_rows": 1, "dense_lambda": 0.25, "dense_pruning_method": "sigmoied_threshold:1d_alt", "distil_alpha_ce": 0.1, "distil_alpha_teacher": 0.9, "distil_teacher_name_or_path": "bert-large-uncased-whole-word-masking-finetuned-squad", "distil_temperature": 2.0, "final_ampere_temperature": 20.0, "final_finetune": false, "final_threshold": 0.1, "final_warmup": 10, "initial_ampere_temperature": 0.0, "initial_threshold": 0, "initial_warmup": 1, "mask_init": "constant", "mask_scale": 0.0, "mask_scores_learning_rate": 0.01, "regularization": "l1", "regularization_final_lambda": 10}, "speed": {"cuda_eval_elapsed_time": 41.275371505737304, "eval_elapsed_time": 48.98561626393348}, "speedup": 0.9350465325310627, "stats": {"layers": {"0": {"linear_attention_nnz": 766976, "linear_attention_total": 4194304, "linear_dense_nnz": 831488, "linear_dense_total": 8388608, "linear_nnz": 1598464, "linear_total": 12582912, "nnz": 1605910, "total": 12596224}, "1": {"linear_attention_nnz": 338944, "linear_attention_total": 4194304, "linear_dense_nnz": 1273856, "linear_dense_total": 8388608, "linear_nnz": 1612800, "linear_total": 12582912, "nnz": 1619886, "total": 12596224}, "10": {"linear_attention_nnz": 1596416, "linear_attention_total": 4194304, "linear_dense_nnz": 2408448, "linear_dense_total": 8388608, "linear_nnz": 4004864, "linear_total": 12582912, "nnz": 4014136, "total": 12596224}, "11": {"linear_attention_nnz": 1615872, "linear_attention_total": 4194304, "linear_dense_nnz": 2508800, "linear_dense_total": 8388608, "linear_nnz": 4124672, "linear_total": 12582912, "nnz": 4133705, "total": 12596224}, "12": {"linear_attention_nnz": 1205248, "linear_attention_total": 4194304, "linear_dense_nnz": 2658304, "linear_dense_total": 8388608, "linear_nnz": 3863552, "linear_total": 12582912, "nnz": 3872306, "total": 12596224}, "13": {"linear_attention_nnz": 2006016, "linear_attention_total": 4194304, "linear_dense_nnz": 2603008, "linear_dense_total": 8388608, "linear_nnz": 4609024, "linear_total": 12582912, "nnz": 4618551, "total": 12596224}, "14": {"linear_attention_nnz": 1718272, "linear_attention_total": 4194304, "linear_dense_nnz": 2299904, "linear_dense_total": 8388608, "linear_nnz": 4018176, "linear_total": 12582912, "nnz": 4027267, "total": 12596224}, "15": {"linear_attention_nnz": 1935360, "linear_attention_total": 4194304, "linear_dense_nnz": 1699840, "linear_dense_total": 8388608, "linear_nnz": 3635200, "linear_total": 12582912, "nnz": 3644094, "total": 12596224}, "16": {"linear_attention_nnz": 1612800, "linear_attention_total": 4194304, "linear_dense_nnz": 1402880, "linear_dense_total": 8388608, "linear_nnz": 3015680, "linear_total": 12582912, "nnz": 3024333, "total": 12596224}, "17": {"linear_attention_nnz": 1502208, "linear_attention_total": 4194304, "linear_dense_nnz": 1097728, "linear_dense_total": 8388608, "linear_nnz": 2599936, "linear_total": 12582912, "nnz": 2608632, "total": 12596224}, "18": {"linear_attention_nnz": 1167360, "linear_attention_total": 4194304, "linear_dense_nnz": 901120, "linear_dense_total": 8388608, "linear_nnz": 2068480, "linear_total": 12582912, "nnz": 2076440, "total": 12596224}, "19": {"linear_attention_nnz": 601088, "linear_attention_total": 4194304, "linear_dense_nnz": 739328, "linear_dense_total": 8388608, "linear_nnz": 1340416, "linear_total": 12582912, "nnz": 1347785, "total": 12596224}, "2": {"linear_attention_nnz": 305152, "linear_attention_total": 4194304, "linear_dense_nnz": 1357824, "linear_dense_total": 8388608, "linear_nnz": 1662976, "linear_total": 12582912, "nnz": 1670103, "total": 12596224}, "20": {"linear_attention_nnz": 364544, "linear_attention_total": 4194304, "linear_dense_nnz": 356352, "linear_dense_total": 8388608, "linear_nnz": 720896, "linear_total": 12582912, "nnz": 727758, "total": 12596224}, "21": {"linear_attention_nnz": 274432, "linear_attention_total": 4194304, "linear_dense_nnz": 194560, "linear_dense_total": 8388608, "linear_nnz": 468992, "linear_total": 12582912, "nnz": 475519, "total": 12596224}, "22": {"linear_attention_nnz": 70656, "linear_attention_total": 4194304, "linear_dense_nnz": 180224, "linear_dense_total": 8388608, "linear_nnz": 250880, "linear_total": 12582912, "nnz": 256728, "total": 12596224}, "23": {"linear_attention_nnz": 102400, "linear_attention_total": 4194304, "linear_dense_nnz": 321536, "linear_dense_total": 8388608, "linear_nnz": 423936, "linear_total": 12582912, "nnz": 430301, "total": 12596224}, "3": {"linear_attention_nnz": 621568, "linear_attention_total": 4194304, "linear_dense_nnz": 1685504, "linear_dense_total": 8388608, "linear_nnz": 2307072, "linear_total": 12582912, "nnz": 2314711, "total": 12596224}, "4": {"linear_attention_nnz": 377856, "linear_attention_total": 4194304, "linear_dense_nnz": 1767424, "linear_dense_total": 8388608, "linear_nnz": 2145280, "linear_total": 12582912, "nnz": 2152671, "total": 12596224}, "5": {"linear_attention_nnz": 460800, "linear_attention_total": 4194304, "linear_dense_nnz": 1871872, "linear_dense_total": 8388608, "linear_nnz": 2332672, "linear_total": 12582912, "nnz": 2340210, "total": 12596224}, "6": {"linear_attention_nnz": 309248, "linear_attention_total": 4194304, "linear_dense_nnz": 2054144, "linear_dense_total": 8388608, "linear_nnz": 2363392, "linear_total": 12582912, "nnz": 2370827, "total": 12596224}, "7": {"linear_attention_nnz": 583680, "linear_attention_total": 4194304, "linear_dense_nnz": 1773568, "linear_dense_total": 8388608, "linear_nnz": 2357248, "linear_total": 12582912, "nnz": 2364994, "total": 12596224}, "8": {"linear_attention_nnz": 215040, "linear_attention_total": 4194304, "linear_dense_nnz": 1966080, "linear_dense_total": 8388608, "linear_nnz": 2181120, "linear_total": 12582912, "nnz": 2188448, "total": 12596224}, "9": {"linear_attention_nnz": 916480, "linear_attention_total": 4194304, "linear_dense_nnz": 1986560, "linear_dense_total": 8388608, "linear_nnz": 2903040, "linear_total": 12582912, "nnz": 2911082, "total": 12596224}}, "linear_nnz": 56608768, "linear_sparsity": 81.25474717881944, "linear_total": 301989888, "nnz": 88581359, "pruned_heads": {"0": [4, 5, 7, 8, 9, 10, 11, 13, 14, 15], "1": [0, 1, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], "10": [0, 7, 8, 10, 12, 13], "11": [0, 1, 2, 4, 5, 8, 10], "12": [2, 3, 5, 6, 7, 8, 10, 13], "13": [10, 2, 3, 12], "14": [1, 2, 3, 4, 8, 11], "15": [0, 5, 6, 7, 11, 12], "16": [3, 6, 8, 10, 13, 15], "17": [0, 2, 11, 15], "18": [2, 3, 5, 9, 11, 12, 13], "19": [0, 2, 3, 4, 9, 10, 11, 13, 15], "2": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 15], "20": [1, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 15], "21": [2, 3, 4, 5, 6, 8, 10, 11, 12, 13, 14, 15], "22": [0, 1, 2, 3, 4, 5, 8, 9, 10, 11, 12, 13, 14, 15], "23": [1, 2, 4, 5, 6, 7, 9, 10, 12, 13, 14], "3": [0, 2, 3, 4, 5, 6, 7, 8, 10, 13, 14, 15], "4": [0, 1, 2, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], "5": [0, 1, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13, 14], "6": [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15], "7": [0, 1, 2, 4, 5, 6, 8, 10, 11, 13, 14, 15], "8": [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 12, 13, 14, 15], "9": [1, 2, 3, 4, 5, 6, 8, 9, 12, 13, 15]}, "total": 334094338, "total_sparsity": 73.4861238504437}, "training_args": {"_n_gpu": -1, "adafactor": false, "adam_beta1": 0.9, "adam_beta2": 0.999, "adam_epsilon": 1e-08, "dataloader_drop_last": false, "dataloader_num_workers": 0, "dataloader_pin_memory": true, "ddp_find_unused_parameters": null, "debug": false, "deepspeed": null, "disable_tqdm": false, "do_eval": 1, "do_predict": false, "do_train": 1, "eval_accumulation_steps": null, "eval_steps": 10000, "evaluation_strategy": "steps", "fp16": false, "fp16_backend": "auto", "fp16_full_eval": false, "fp16_opt_level": "O1", "gradient_accumulation_steps": 1, "greater_is_better": null, "group_by_length": false, "ignore_data_skip": false, "label_names": null, "label_smoothing_factor": 0.0, "learning_rate": 3e-05, "load_best_model_at_end": false, "local_rank": -1, "logging_dir": "output/squad_test_large/squad_test_large_regu_10_d0.25", "logging_first_step": false, "logging_steps": 250, "logging_strategy": "steps", "lr_scheduler_type": "linear", "max_grad_norm": 1.0, "max_steps": -1, "metric_for_best_model": null, "no_cuda": false, "num_train_epochs": 20, "optimize_model_before_eval": "disabled", "output_dir": "output/squad_test_large/squad_test_large_regu_10_d0.25", "overwrite_output_dir": 1, "past_index": -1, "per_device_eval_batch_size": 8, "per_device_train_batch_size": 8, "per_gpu_eval_batch_size": null, "per_gpu_train_batch_size": null, "prediction_loss_only": false, "remove_unused_columns": true, "report_to": null, "run_name": "output/squad_test_large/squad_test_large_regu_10_d0.25", "save_steps": 10000, "save_strategy": "steps", "save_total_limit": 50, "seed": 17, "sharded_ddp": "", "skip_memory_metrics": false, "tpu_metrics_debug": false, "tpu_num_cores": null, "warmup_ratio": 0.0, "warmup_steps": 5400, "weight_decay": 0.0}}, "f1": 90.22195941338013, "fill_rate": 0.4998734085648149, "speedup": 0.9350465325310627}}
{"fill_rate": 0.3219943576388893, "f1": 89.03656646065757, "meta": {"annotate": "12", "cat_fun_name": "is_new_xp", "checkpoint": {"config": {"_name_or_path": "bert-large-uncased", "architectures": ["BertForQuestionAnswering"], "attention_probs_dropout_prob": 0.1, "gradient_checkpointing": false, "hidden_act": "gelu", "hidden_dropout_prob": 0.1, "hidden_size": 1024, "initializer_range": 0.02, "intermediate_size": 4096, "layer_norm_eps": 1e-12, "max_position_embeddings": 512, "model_type": "bert", "num_attention_heads": 16, "num_hidden_layers": 24, "pad_token_id": 0, "position_embedding_type": "absolute", "type_vocab_size": 2, "vocab_size": 30522}, "eval_metrics": {"exact_match": 82.13812677388836, "f1": 89.03656646065757}, "path": "/data_2to/devel_data/nn_pruning/output/squad_test_large/large_regu_10/checkpoint-220000", "sparse_args": {"ampere_pruning_method": "disabled", "attention_block_cols": 32, "attention_block_rows": 32, "attention_lambda": 1.0, "attention_output_with_dense": 0, "attention_pruning_method": "sigmoied_threshold", "bias_mask": true, "dense_block_cols": 1, "dense_block_rows": 1, "dense_lambda": 1.0, "dense_pruning_method": "sigmoied_threshold:1d_alt", "distil_alpha_ce": 0.1, "distil_alpha_teacher": 0.9, "distil_teacher_name_or_path": "bert-large-uncased-whole-word-masking-finetuned-squad", "distil_temperature": 2.0, "final_ampere_temperature": 20.0, "final_finetune": false, "final_threshold": 0.1, "final_warmup": 10, "initial_ampere_temperature": 0.0, "initial_threshold": 0, "initial_warmup": 1, "mask_init": "constant", "mask_scale": 0.0, "mask_scores_learning_rate": 0.01, "regularization": "l1", "regularization_final_lambda": 10}, "speed": {"cuda_eval_elapsed_time": 37.54432637023926, "eval_elapsed_time": 44.93571184715256}, "speedup": 1.0279687168915141, "stats": {"layers": {"0": {"linear_attention_nnz": 989184, "linear_attention_total": 4194304, "linear_dense_nnz": 192512, "linear_dense_total": 8388608, "linear_nnz": 1181696, "linear_total": 12582912, "nnz": 1188862, "total": 12596224}, "1": {"linear_attention_nnz": 323584, "linear_attention_total": 4194304, "linear_dense_nnz": 270336, "linear_dense_total": 8388608, "linear_nnz": 593920, "linear_total": 12582912, "nnz": 600612, "total": 12596224}, "10": {"linear_attention_nnz": 1745920, "linear_attention_total": 4194304, "linear_dense_nnz": 995328, "linear_dense_total": 8388608, "linear_nnz": 2741248, "linear_total": 12582912, "nnz": 2749670, "total": 12596224}, "11": {"linear_attention_nnz": 1902592, "linear_attention_total": 4194304, "linear_dense_nnz": 1032192, "linear_dense_total": 8388608, "linear_nnz": 2934784, "linear_total": 12582912, "nnz": 2943384, "total": 12596224}, "12": {"linear_attention_nnz": 1782784, "linear_attention_total": 4194304, "linear_dense_nnz": 1241088, "linear_dense_total": 8388608, "linear_nnz": 3023872, "linear_total": 12582912, "nnz": 3032670, "total": 12596224}, "13": {"linear_attention_nnz": 2147328, "linear_attention_total": 4194304, "linear_dense_nnz": 1179648, "linear_dense_total": 8388608, "linear_nnz": 3326976, "linear_total": 12582912, "nnz": 3335936, "total": 12596224}, "14": {"linear_attention_nnz": 1917952, "linear_attention_total": 4194304, "linear_dense_nnz": 909312, "linear_dense_total": 8388608, "linear_nnz": 2827264, "linear_total": 12582912, "nnz": 2835836, "total": 12596224}, "15": {"linear_attention_nnz": 2049024, "linear_attention_total": 4194304, "linear_dense_nnz": 681984, "linear_dense_total": 8388608, "linear_nnz": 2731008, "linear_total": 12582912, "nnz": 2739405, "total": 12596224}, "16": {"linear_attention_nnz": 1820672, "linear_attention_total": 4194304, "linear_dense_nnz": 473088, "linear_dense_total": 8388608, "linear_nnz": 2293760, "linear_total": 12582912, "nnz": 2302087, "total": 12596224}, "17": {"linear_attention_nnz": 1562624, "linear_attention_total": 4194304, "linear_dense_nnz": 368640, "linear_dense_total": 8388608, "linear_nnz": 1931264, "linear_total": 12582912, "nnz": 1939508, "total": 12596224}, "18": {"linear_attention_nnz": 1390592, "linear_attention_total": 4194304, "linear_dense_nnz": 321536, "linear_dense_total": 8388608, "linear_nnz": 1712128, "linear_total": 12582912, "nnz": 1720221, "total": 12596224}, "19": {"linear_attention_nnz": 688128, "linear_attention_total": 4194304, "linear_dense_nnz": 270336, "linear_dense_total": 8388608, "linear_nnz": 958464, "linear_total": 12582912, "nnz": 965700, "total": 12596224}, "2": {"linear_attention_nnz": 286720, "linear_attention_total": 4194304, "linear_dense_nnz": 286720, "linear_dense_total": 8388608, "linear_nnz": 573440, "linear_total": 12582912, "nnz": 580044, "total": 12596224}, "20": {"linear_attention_nnz": 326656, "linear_attention_total": 4194304, "linear_dense_nnz": 112640, "linear_dense_total": 8388608, "linear_nnz": 439296, "linear_total": 12582912, "nnz": 445879, "total": 12596224}, "21": {"linear_attention_nnz": 344064, "linear_attention_total": 4194304, "linear_dense_nnz": 77824, "linear_dense_total": 8388608, "linear_nnz": 421888, "linear_total": 12582912, "nnz": 428614, "total": 12596224}, "22": {"linear_attention_nnz": 129024, "linear_attention_total": 4194304, "linear_dense_nnz": 79872, "linear_dense_total": 8388608, "linear_nnz": 208896, "linear_total": 12582912, "nnz": 215079, "total": 12596224}, "23": {"linear_attention_nnz": 116736, "linear_attention_total": 4194304, "linear_dense_nnz": 182272, "linear_dense_total": 8388608, "linear_nnz": 299008, "linear_total": 12582912, "nnz": 305273, "total": 12596224}, "3": {"linear_attention_nnz": 801792, "linear_attention_total": 4194304, "linear_dense_nnz": 413696, "linear_dense_total": 8388608, "linear_nnz": 1215488, "linear_total": 12582912, "nnz": 1222666, "total": 12596224}, "4": {"linear_attention_nnz": 396288, "linear_attention_total": 4194304, "linear_dense_nnz": 466944, "linear_dense_total": 8388608, "linear_nnz": 863232, "linear_total": 12582912, "nnz": 869988, "total": 12596224}, "5": {"linear_attention_nnz": 405504, "linear_attention_total": 4194304, "linear_dense_nnz": 552960, "linear_dense_total": 8388608, "linear_nnz": 958464, "linear_total": 12582912, "nnz": 965294, "total": 12596224}, "6": {"linear_attention_nnz": 520192, "linear_attention_total": 4194304, "linear_dense_nnz": 604160, "linear_dense_total": 8388608, "linear_nnz": 1124352, "linear_total": 12582912, "nnz": 1131335, "total": 12596224}, "7": {"linear_attention_nnz": 764928, "linear_attention_total": 4194304, "linear_dense_nnz": 438272, "linear_dense_total": 8388608, "linear_nnz": 1203200, "linear_total": 12582912, "nnz": 1210390, "total": 12596224}, "8": {"linear_attention_nnz": 423936, "linear_attention_total": 4194304, "linear_dense_nnz": 659456, "linear_dense_total": 8388608, "linear_nnz": 1083392, "linear_total": 12582912, "nnz": 1090434, "total": 12596224}, "9": {"linear_attention_nnz": 1070080, "linear_attention_total": 4194304, "linear_dense_nnz": 747520, "linear_dense_total": 8388608, "linear_nnz": 1817600, "linear_total": 12582912, "nnz": 1825165, "total": 12596224}}, "linear_nnz": 36464640, "linear_sparsity": 87.92521158854166, "linear_total": 301989888, "nnz": 68429014, "pruned_heads": {"0": [2, 3, 4, 7, 8, 9, 10, 13, 14, 15], "1": [0, 1, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], "10": [7, 8, 10, 12, 13, 14], "11": [0, 2, 4, 5, 8, 10], "12": [10, 3, 13, 6], "13": [2, 10, 4, 12], "14": [2, 3, 4, 8, 11], "15": [0, 5, 6, 7, 11, 12], "16": [3, 6, 8, 13, 15], "17": [0, 2, 4, 11, 15], "18": [2, 3, 5, 11, 13], "19": [0, 2, 3, 4, 9, 10, 11, 15], "2": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 15], "20": [0, 1, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 15], "21": [2, 4, 5, 6, 8, 10, 11, 12, 13, 14, 15], "22": [0, 1, 2, 3, 4, 7, 8, 9, 10, 11, 12, 13, 14], "23": [1, 2, 3, 4, 5, 6, 7, 9, 10, 12, 13, 14], "3": [0, 2, 3, 4, 5, 6, 7, 8, 10, 14, 15], "4": [0, 1, 2, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], "5": [0, 1, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15], "6": [0, 1, 2, 3, 5, 6, 8, 9, 10, 11, 13, 14, 15], "7": [0, 1, 2, 4, 5, 6, 8, 10, 11, 13, 14], "8": [0, 1, 2, 3, 4, 5, 6, 8, 12, 13, 14, 15], "9": [1, 2, 3, 4, 5, 6, 8, 12, 13, 15]}, "total": 334094338, "total_sparsity": 79.51805636406804}, "training_args": {"_n_gpu": -1, "adafactor": false, "adam_beta1": 0.9, "adam_beta2": 0.999, "adam_epsilon": 1e-08, "dataloader_drop_last": false, "dataloader_num_workers": 0, "dataloader_pin_memory": true, "ddp_find_unused_parameters": null, "debug": false, "deepspeed": null, "disable_tqdm": false, "do_eval": 1, "do_predict": false, "do_train": 1, "eval_accumulation_steps": null, "eval_steps": 5000, "evaluation_strategy": "steps", "fp16": false, "fp16_backend": "auto", "fp16_full_eval": false, "fp16_opt_level": "O1", "gradient_accumulation_steps": 1, "greater_is_better": null, "group_by_length": false, "ignore_data_skip": false, "label_names": null, "label_smoothing_factor": 0.0, "learning_rate": 3e-05, "load_best_model_at_end": false, "local_rank": -1, "logging_dir": "output/squad_test_large/squad_test_large_regu-10", "logging_first_step": false, "logging_steps": 250, "logging_strategy": "steps", "lr_scheduler_type": "linear", "max_grad_norm": 1.0, "max_steps": -1, "metric_for_best_model": null, "no_cuda": false, "num_train_epochs": 20, "optimize_model_before_eval": "disabled", "output_dir": "output/squad_test_large/squad_test_large_regu-10", "overwrite_output_dir": 1, "past_index": -1, "per_device_eval_batch_size": 8, "per_device_train_batch_size": 8, "per_gpu_eval_batch_size": null, "per_gpu_train_batch_size": null, "prediction_loss_only": false, "remove_unused_columns": true, "report_to": null, "run_name": "output/squad_test_large/squad_test_large_regu-10", "save_steps": 5000, "save_strategy": "steps", "save_total_limit": 50, "seed": 17, "sharded_ddp": "", "skip_memory_metrics": false, "tpu_metrics_debug": false, "tpu_num_cores": null, "warmup_ratio": 0.0, "warmup_steps": 5400, "weight_decay": 0.0}}, "f1": 89.03656646065757, "fill_rate": 0.3219943576388893, "speedup": 1.0279687168915141}}
{"fill_rate": 0.23756691261574106, "f1": 87.8561484925226, "meta": {"annotate": "8", "cat_fun_name": "is_new_xp", "checkpoint": {"config": {"_name_or_path": "bert-large-uncased", "architectures": ["BertForQuestionAnswering"], "attention_probs_dropout_prob": 0.1, "gradient_checkpointing": false, "hidden_act": "gelu", "hidden_dropout_prob": 0.1, "hidden_size": 1024, "initializer_range": 0.02, "intermediate_size": 4096, "layer_norm_eps": 1e-12, "max_position_embeddings": 512, "model_type": "bert", "num_attention_heads": 16, "num_hidden_layers": 24, "pad_token_id": 0, "position_embedding_type": "absolute", "type_vocab_size": 2, "vocab_size": 30522}, "eval_metrics": {"exact_match": 80.59602649006622, "f1": 87.8561484925226}, "path": "/data_2to/devel_data/nn_pruning/output/squad_test_large/large_regu_40_d0.25/checkpoint-220000", "sparse_args": {"ampere_pruning_method": "disabled", "attention_block_cols": 32, "attention_block_rows": 32, "attention_lambda": 1.0, "attention_output_with_dense": 0, "attention_pruning_method": "sigmoied_threshold", "bias_mask": true, "dense_block_cols": 1, "dense_block_rows": 1, "dense_lambda": 0.25, "dense_pruning_method": "sigmoied_threshold:1d_alt", "distil_alpha_ce": 0.1, "distil_alpha_teacher": 0.9, "distil_teacher_name_or_path": "bert-large-uncased-whole-word-masking-finetuned-squad", "distil_temperature": 2.0, "final_ampere_temperature": 20.0, "final_finetune": false, "final_threshold": 0.1, "final_warmup": 10, "initial_ampere_temperature": 0.0, "initial_threshold": 0, "initial_warmup": 1, "mask_init": "constant", "mask_scale": 0.0, "mask_scores_learning_rate": 0.01, "regularization": "l1", "regularization_final_lambda": 40}, "speed": {"cuda_eval_elapsed_time": 29.83378296661377, "eval_elapsed_time": 37.31617963500321}, "speedup": 1.2936473074353696, "stats": {"layers": {"0": {"linear_attention_nnz": 340992, "linear_attention_total": 4194304, "linear_dense_nnz": 253952, "linear_dense_total": 8388608, "linear_nnz": 594944, "linear_total": 12582912, "nnz": 601564, "total": 12596224}, "1": {"linear_attention_nnz": 141312, "linear_attention_total": 4194304, "linear_dense_nnz": 432128, "linear_dense_total": 8388608, "linear_nnz": 573440, "linear_total": 12582912, "nnz": 579955, "total": 12596224}, "10": {"linear_attention_nnz": 832512, "linear_attention_total": 4194304, "linear_dense_nnz": 1210368, "linear_dense_total": 8388608, "linear_nnz": 2042880, "linear_total": 12582912, "nnz": 2050735, "total": 12596224}, "11": {"linear_attention_nnz": 765952, "linear_attention_total": 4194304, "linear_dense_nnz": 1277952, "linear_dense_total": 8388608, "linear_nnz": 2043904, "linear_total": 12582912, "nnz": 2051536, "total": 12596224}, "12": {"linear_attention_nnz": 720896, "linear_attention_total": 4194304, "linear_dense_nnz": 1400832, "linear_dense_total": 8388608, "linear_nnz": 2121728, "linear_total": 12582912, "nnz": 2129420, "total": 12596224}, "13": {"linear_attention_nnz": 1234944, "linear_attention_total": 4194304, "linear_dense_nnz": 1464320, "linear_dense_total": 8388608, "linear_nnz": 2699264, "linear_total": 12582912, "nnz": 2707787, "total": 12596224}, "14": {"linear_attention_nnz": 879616, "linear_attention_total": 4194304, "linear_dense_nnz": 1122304, "linear_dense_total": 8388608, "linear_nnz": 2001920, "linear_total": 12582912, "nnz": 2009956, "total": 12596224}, "15": {"linear_attention_nnz": 917504, "linear_attention_total": 4194304, "linear_dense_nnz": 778240, "linear_dense_total": 8388608, "linear_nnz": 1695744, "linear_total": 12582912, "nnz": 1703324, "total": 12596224}, "16": {"linear_attention_nnz": 793600, "linear_attention_total": 4194304, "linear_dense_nnz": 532480, "linear_dense_total": 8388608, "linear_nnz": 1326080, "linear_total": 12582912, "nnz": 1333572, "total": 12596224}, "17": {"linear_attention_nnz": 726016, "linear_attention_total": 4194304, "linear_dense_nnz": 456704, "linear_dense_total": 8388608, "linear_nnz": 1182720, "linear_total": 12582912, "nnz": 1190495, "total": 12596224}, "18": {"linear_attention_nnz": 656384, "linear_attention_total": 4194304, "linear_dense_nnz": 440320, "linear_dense_total": 8388608, "linear_nnz": 1096704, "linear_total": 12582912, "nnz": 1104087, "total": 12596224}, "19": {"linear_attention_nnz": 281600, "linear_attention_total": 4194304, "linear_dense_nnz": 362496, "linear_dense_total": 8388608, "linear_nnz": 644096, "linear_total": 12582912, "nnz": 650801, "total": 12596224}, "2": {"linear_attention_nnz": 238592, "linear_attention_total": 4194304, "linear_dense_nnz": 450560, "linear_dense_total": 8388608, "linear_nnz": 689152, "linear_total": 12582912, "nnz": 695836, "total": 12596224}, "20": {"linear_attention_nnz": 137216, "linear_attention_total": 4194304, "linear_dense_nnz": 184320, "linear_dense_total": 8388608, "linear_nnz": 321536, "linear_total": 12582912, "nnz": 327738, "total": 12596224}, "21": {"linear_attention_nnz": 175104, "linear_attention_total": 4194304, "linear_dense_nnz": 112640, "linear_dense_total": 8388608, "linear_nnz": 287744, "linear_total": 12582912, "nnz": 293879, "total": 12596224}, "22": {"linear_attention_nnz": 54272, "linear_attention_total": 4194304, "linear_dense_nnz": 114688, "linear_dense_total": 8388608, "linear_nnz": 168960, "linear_total": 12582912, "nnz": 174872, "total": 12596224}, "23": {"linear_attention_nnz": 24576, "linear_attention_total": 4194304, "linear_dense_nnz": 184320, "linear_dense_total": 8388608, "linear_nnz": 208896, "linear_total": 12582912, "nnz": 214458, "total": 12596224}, "3": {"linear_attention_nnz": 320512, "linear_attention_total": 4194304, "linear_dense_nnz": 548864, "linear_dense_total": 8388608, "linear_nnz": 869376, "linear_total": 12582912, "nnz": 876172, "total": 12596224}, "4": {"linear_attention_nnz": 332800, "linear_attention_total": 4194304, "linear_dense_nnz": 614400, "linear_dense_total": 8388608, "linear_nnz": 947200, "linear_total": 12582912, "nnz": 954028, "total": 12596224}, "5": {"linear_attention_nnz": 147456, "linear_attention_total": 4194304, "linear_dense_nnz": 839680, "linear_dense_total": 8388608, "linear_nnz": 987136, "linear_total": 12582912, "nnz": 993786, "total": 12596224}, "6": {"linear_attention_nnz": 166912, "linear_attention_total": 4194304, "linear_dense_nnz": 858112, "linear_dense_total": 8388608, "linear_nnz": 1025024, "linear_total": 12582912, "nnz": 1031555, "total": 12596224}, "7": {"linear_attention_nnz": 376832, "linear_attention_total": 4194304, "linear_dense_nnz": 636928, "linear_dense_total": 8388608, "linear_nnz": 1013760, "linear_total": 12582912, "nnz": 1020759, "total": 12596224}, "8": {"linear_attention_nnz": 145408, "linear_attention_total": 4194304, "linear_dense_nnz": 847872, "linear_dense_total": 8388608, "linear_nnz": 993280, "linear_total": 12582912, "nnz": 999934, "total": 12596224}, "9": {"linear_attention_nnz": 466944, "linear_attention_total": 4194304, "linear_dense_nnz": 901120, "linear_dense_total": 8388608, "linear_nnz": 1368064, "linear_total": 12582912, "nnz": 1375160, "total": 12596224}}, "linear_nnz": 26903552, "linear_sparsity": 91.09124077690971, "linear_total": 301989888, "nnz": 58856371, "pruned_heads": {"0": [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 13, 14, 15], "1": [0, 1, 2, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], "10": [0, 3, 6, 7, 8, 10, 12, 13, 14], "11": [0, 1, 2, 4, 5, 6, 7, 8, 10, 12, 15], "12": [2, 3, 5, 6, 7, 8, 9, 10, 12, 13, 14], "13": [2, 3, 4, 10, 11, 12], "14": [1, 2, 3, 4, 8, 9, 11, 13], "15": [0, 1, 2, 5, 6, 7, 8, 9, 11, 12], "16": [3, 6, 7, 8, 10, 12, 13, 15], "17": [0, 2, 4, 11, 12, 15], "18": [2, 3, 5, 9, 11, 12, 13], "19": [0, 1, 2, 3, 4, 5, 9, 10, 11, 13, 15], "2": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 15], "20": [0, 1, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15], "21": [0, 2, 3, 4, 5, 6, 8, 10, 11, 12, 13, 14, 15], "22": [0, 1, 2, 3, 4, 7, 8, 9, 10, 11, 12, 13, 14], "23": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14], "3": [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14, 15], "4": [0, 1, 2, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], "5": [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], "6": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15], "7": [0, 1, 2, 4, 5, 6, 8, 10, 11, 12, 13, 14, 15], "8": [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 12, 13, 14, 15], "9": [1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 15]}, "total": 334094338, "total_sparsity": 82.38330785480117}, "training_args": {"_n_gpu": -1, "adafactor": false, "adam_beta1": 0.9, "adam_beta2": 0.999, "adam_epsilon": 1e-08, "dataloader_drop_last": false, "dataloader_num_workers": 0, "dataloader_pin_memory": true, "ddp_find_unused_parameters": null, "debug": false, "deepspeed": null, "disable_tqdm": false, "do_eval": 1, "do_predict": false, "do_train": 1, "eval_accumulation_steps": null, "eval_steps": 10000, "evaluation_strategy": "steps", "fp16": false, "fp16_backend": "auto", "fp16_full_eval": false, "fp16_opt_level": "O1", "gradient_accumulation_steps": 1, "greater_is_better": null, "group_by_length": false, "ignore_data_skip": false, "label_names": null, "label_smoothing_factor": 0.0, "learning_rate": 3e-05, "load_best_model_at_end": false, "local_rank": -1, "logging_dir": "output/squad_test_large/squad_test_large_regu_40_d0.25", "logging_first_step": false, "logging_steps": 250, "logging_strategy": "steps", "lr_scheduler_type": "linear", "max_grad_norm": 1.0, "max_steps": -1, "metric_for_best_model": null, "no_cuda": false, "num_train_epochs": 20, "optimize_model_before_eval": "disabled", "output_dir": "output/squad_test_large/squad_test_large_regu_40_d0.25", "overwrite_output_dir": 1, "past_index": -1, "per_device_eval_batch_size": 8, "per_device_train_batch_size": 8, "per_gpu_eval_batch_size": null, "per_gpu_train_batch_size": null, "prediction_loss_only": false, "remove_unused_columns": true, "report_to": null, "run_name": "output/squad_test_large/squad_test_large_regu_40_d0.25", "save_steps": 10000, "save_strategy": "steps", "save_total_limit": 50, "seed": 17, "sharded_ddp": "", "skip_memory_metrics": false, "tpu_metrics_debug": false, "tpu_num_cores": null, "warmup_ratio": 0.0, "warmup_steps": 5400, "weight_decay": 0.0}}, "f1": 87.8561484925226, "fill_rate": 0.23756691261574106, "speedup": 1.2936473074353696}}
{"fill_rate": 0.18968822337962976, "f1": 86.9851273164745, "meta": {"annotate": "7", "cat_fun_name": "is_new_xp", "checkpoint": {"config": {"_name_or_path": "bert-large-uncased", "architectures": ["BertForQuestionAnswering"], "attention_probs_dropout_prob": 0.1, "gradient_checkpointing": false, "hidden_act": "gelu", "hidden_dropout_prob": 0.1, "hidden_size": 1024, "initializer_range": 0.02, "intermediate_size": 4096, "layer_norm_eps": 1e-12, "max_position_embeddings": 512, "model_type": "bert", "num_attention_heads": 16, "num_hidden_layers": 24, "pad_token_id": 0, "position_embedding_type": "absolute", "type_vocab_size": 2, "vocab_size": 30522}, "eval_metrics": {"exact_match": 79.50804162724693, "f1": 86.9851273164745}, "path": "/data_2to/devel_data/nn_pruning/output/squad_test_large/large_regu_60_d0.25/checkpoint-221320", "sparse_args": {"ampere_pruning_method": "disabled", "attention_block_cols": 32, "attention_block_rows": 32, "attention_lambda": 1.0, "attention_output_with_dense": 0, "attention_pruning_method": "sigmoied_threshold", "bias_mask": true, "dense_block_cols": 1, "dense_block_rows": 1, "dense_lambda": 0.25, "dense_pruning_method": "sigmoied_threshold:1d_alt", "distil_alpha_ce": 0.1, "distil_alpha_teacher": 0.9, "distil_teacher_name_or_path": "bert-large-uncased-whole-word-masking-finetuned-squad", "distil_temperature": 2.0, "final_ampere_temperature": 20.0, "final_finetune": false, "final_threshold": 0.1, "final_warmup": 10, "initial_ampere_temperature": 0.0, "initial_threshold": 0, "initial_warmup": 1, "mask_init": "constant", "mask_scale": 0.0, "mask_scores_learning_rate": 0.01, "regularization": "l1", "regularization_final_lambda": 60}, "speed": {"cuda_eval_elapsed_time": 28.35688896179199, "eval_elapsed_time": 35.278680617921054}, "speedup": 1.3610235261481995, "stats": {"layers": {"0": {"linear_attention_nnz": 388096, "linear_attention_total": 4194304, "linear_dense_nnz": 231424, "linear_dense_total": 8388608, "linear_nnz": 619520, "linear_total": 12582912, "nnz": 626257, "total": 12596224}, "1": {"linear_attention_nnz": 78848, "linear_attention_total": 4194304, "linear_dense_nnz": 290816, "linear_dense_total": 8388608, "linear_nnz": 369664, "linear_total": 12582912, "nnz": 375982, "total": 12596224}, "10": {"linear_attention_nnz": 696320, "linear_attention_total": 4194304, "linear_dense_nnz": 923648, "linear_dense_total": 8388608, "linear_nnz": 1619968, "linear_total": 12582912, "nnz": 1627427, "total": 12596224}, "11": {"linear_attention_nnz": 627712, "linear_attention_total": 4194304, "linear_dense_nnz": 1075200, "linear_dense_total": 8388608, "linear_nnz": 1702912, "linear_total": 12582912, "nnz": 1710349, "total": 12596224}, "12": {"linear_attention_nnz": 573440, "linear_attention_total": 4194304, "linear_dense_nnz": 1126400, "linear_dense_total": 8388608, "linear_nnz": 1699840, "linear_total": 12582912, "nnz": 1707206, "total": 12596224}, "13": {"linear_attention_nnz": 932864, "linear_attention_total": 4194304, "linear_dense_nnz": 1179648, "linear_dense_total": 8388608, "linear_nnz": 2112512, "linear_total": 12582912, "nnz": 2120576, "total": 12596224}, "14": {"linear_attention_nnz": 676864, "linear_attention_total": 4194304, "linear_dense_nnz": 929792, "linear_dense_total": 8388608, "linear_nnz": 1606656, "linear_total": 12582912, "nnz": 1614374, "total": 12596224}, "15": {"linear_attention_nnz": 807936, "linear_attention_total": 4194304, "linear_dense_nnz": 622592, "linear_dense_total": 8388608, "linear_nnz": 1430528, "linear_total": 12582912, "nnz": 1438000, "total": 12596224}, "16": {"linear_attention_nnz": 628736, "linear_attention_total": 4194304, "linear_dense_nnz": 403456, "linear_dense_total": 8388608, "linear_nnz": 1032192, "linear_total": 12582912, "nnz": 1039525, "total": 12596224}, "17": {"linear_attention_nnz": 567296, "linear_attention_total": 4194304, "linear_dense_nnz": 360448, "linear_dense_total": 8388608, "linear_nnz": 927744, "linear_total": 12582912, "nnz": 935024, "total": 12596224}, "18": {"linear_attention_nnz": 482304, "linear_attention_total": 4194304, "linear_dense_nnz": 335872, "linear_dense_total": 8388608, "linear_nnz": 818176, "linear_total": 12582912, "nnz": 825348, "total": 12596224}, "19": {"linear_attention_nnz": 198656, "linear_attention_total": 4194304, "linear_dense_nnz": 307200, "linear_dense_total": 8388608, "linear_nnz": 505856, "linear_total": 12582912, "nnz": 512118, "total": 12596224}, "2": {"linear_attention_nnz": 220160, "linear_attention_total": 4194304, "linear_dense_nnz": 331776, "linear_dense_total": 8388608, "linear_nnz": 551936, "linear_total": 12582912, "nnz": 558530, "total": 12596224}, "20": {"linear_attention_nnz": 115712, "linear_attention_total": 4194304, "linear_dense_nnz": 165888, "linear_dense_total": 8388608, "linear_nnz": 281600, "linear_total": 12582912, "nnz": 287633, "total": 12596224}, "21": {"linear_attention_nnz": 151552, "linear_attention_total": 4194304, "linear_dense_nnz": 75776, "linear_dense_total": 8388608, "linear_nnz": 227328, "linear_total": 12582912, "nnz": 233509, "total": 12596224}, "22": {"linear_attention_nnz": 46080, "linear_attention_total": 4194304, "linear_dense_nnz": 100352, "linear_dense_total": 8388608, "linear_nnz": 146432, "linear_total": 12582912, "nnz": 152209, "total": 12596224}, "23": {"linear_attention_nnz": 24576, "linear_attention_total": 4194304, "linear_dense_nnz": 184320, "linear_dense_total": 8388608, "linear_nnz": 208896, "linear_total": 12582912, "nnz": 214394, "total": 12596224}, "3": {"linear_attention_nnz": 301056, "linear_attention_total": 4194304, "linear_dense_nnz": 432128, "linear_dense_total": 8388608, "linear_nnz": 733184, "linear_total": 12582912, "nnz": 739891, "total": 12596224}, "4": {"linear_attention_nnz": 313344, "linear_attention_total": 4194304, "linear_dense_nnz": 452608, "linear_dense_total": 8388608, "linear_nnz": 765952, "linear_total": 12582912, "nnz": 772669, "total": 12596224}, "5": {"linear_attention_nnz": 24576, "linear_attention_total": 4194304, "linear_dense_nnz": 614400, "linear_dense_total": 8388608, "linear_nnz": 638976, "linear_total": 12582912, "nnz": 644684, "total": 12596224}, "6": {"linear_attention_nnz": 155648, "linear_attention_total": 4194304, "linear_dense_nnz": 598016, "linear_dense_total": 8388608, "linear_nnz": 753664, "linear_total": 12582912, "nnz": 760036, "total": 12596224}, "7": {"linear_attention_nnz": 324608, "linear_attention_total": 4194304, "linear_dense_nnz": 466944, "linear_dense_total": 8388608, "linear_nnz": 791552, "linear_total": 12582912, "nnz": 798276, "total": 12596224}, "8": {"linear_attention_nnz": 97280, "linear_attention_total": 4194304, "linear_dense_nnz": 673792, "linear_dense_total": 8388608, "linear_nnz": 771072, "linear_total": 12582912, "nnz": 777449, "total": 12596224}, "9": {"linear_attention_nnz": 473088, "linear_attention_total": 4194304, "linear_dense_nnz": 692224, "linear_dense_total": 8388608, "linear_nnz": 1165312, "linear_total": 12582912, "nnz": 1172306, "total": 12596224}}, "linear_nnz": 21481472, "linear_sparsity": 92.88669162326389, "linear_total": 301989888, "nnz": 53428734, "pruned_heads": {"0": [0, 1, 2, 3, 4, 7, 8, 9, 10, 11, 13, 14, 15], "1": [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], "10": [0, 3, 6, 7, 8, 10, 12, 13, 14, 15], "11": [0, 1, 2, 4, 5, 6, 7, 8, 10, 12, 15], "12": [1, 2, 3, 5, 6, 7, 8, 9, 10, 12, 13, 14], "13": [2, 3, 4, 9, 10, 11, 12, 13], "14": [1, 2, 3, 4, 8, 9, 11, 12], "15": [0, 1, 2, 5, 6, 7, 8, 9, 11, 12], "16": [3, 6, 7, 8, 10, 12, 13, 15], "17": [0, 2, 4, 8, 11, 12, 15], "18": [2, 3, 5, 9, 10, 11, 12, 13, 15], "19": [0, 1, 2, 3, 4, 5, 8, 9, 10, 11, 13, 14, 15], "2": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 15], "20": [0, 1, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15], "21": [0, 2, 3, 4, 5, 6, 8, 10, 11, 12, 13, 14, 15], "22": [0, 1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15], "23": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14], "3": [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14, 15], "4": [0, 1, 2, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], "5": [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], "6": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15], "7": [0, 1, 2, 4, 5, 6, 8, 10, 11, 12, 13, 14, 15], "8": [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15], "9": [1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 15]}, "total": 334094338, "total_sparsity": 84.00789001099444}, "training_args": {"_n_gpu": -1, "adafactor": false, "adam_beta1": 0.9, "adam_beta2": 0.999, "adam_epsilon": 1e-08, "dataloader_drop_last": false, "dataloader_num_workers": 0, "dataloader_pin_memory": true, "ddp_find_unused_parameters": null, "debug": false, "deepspeed": null, "disable_tqdm": false, "do_eval": 1, "do_predict": false, "do_train": 1, "eval_accumulation_steps": null, "eval_steps": 10000, "evaluation_strategy": "steps", "fp16": false, "fp16_backend": "auto", "fp16_full_eval": false, "fp16_opt_level": "O1", "gradient_accumulation_steps": 1, "greater_is_better": null, "group_by_length": false, "ignore_data_skip": false, "label_names": null, "label_smoothing_factor": 0.0, "learning_rate": 3e-05, "load_best_model_at_end": false, "local_rank": -1, "logging_dir": "output/squad_test_large/large_regu_60_d0.25", "logging_first_step": false, "logging_steps": 250, "logging_strategy": "steps", "lr_scheduler_type": "linear", "max_grad_norm": 1.0, "max_steps": -1, "metric_for_best_model": null, "no_cuda": false, "num_train_epochs": 20, "optimize_model_before_eval": "disabled", "output_dir": "output/squad_test_large/large_regu_60_d0.25", "overwrite_output_dir": 1, "past_index": -1, "per_device_eval_batch_size": 8, "per_device_train_batch_size": 8, "per_gpu_eval_batch_size": null, "per_gpu_train_batch_size": null, "prediction_loss_only": false, "remove_unused_columns": true, "report_to": null, "run_name": "output/squad_test_large/large_regu_60_d0.25", "save_steps": 10000, "save_strategy": "steps", "save_total_limit": 50, "seed": 17, "sharded_ddp": "", "skip_memory_metrics": false, "tpu_metrics_debug": false, "tpu_num_cores": null, "warmup_ratio": 0.0, "warmup_steps": 5400, "weight_decay": 0.0}}, "f1": 86.9851273164745, "fill_rate": 0.18968822337962976, "speedup": 1.3610235261481995}}
{"fill_rate": 0.15945999710648154, "f1": 86.66302391758462, "meta": {"annotate": "5", "cat_fun_name": "is_new_xp", "checkpoint": {"config": {"_name_or_path": "bert-large-uncased", "architectures": ["BertForQuestionAnswering"], "attention_probs_dropout_prob": 0.1, "gradient_checkpointing": false, "hidden_act": "gelu", "hidden_dropout_prob": 0.1, "hidden_size": 1024, "initializer_range": 0.02, "intermediate_size": 4096, "layer_norm_eps": 1e-12, "max_position_embeddings": 512, "model_type": "bert", "num_attention_heads": 16, "num_hidden_layers": 24, "pad_token_id": 0, "position_embedding_type": "absolute", "type_vocab_size": 2, "vocab_size": 30522}, "eval_metrics": {"exact_match": 78.92147587511826, "f1": 86.66302391758462}, "path": "/data_2to/devel_data/nn_pruning/output/squad_test_large/large_regu_40/checkpoint-221320", "sparse_args": {"ampere_pruning_method": "disabled", "attention_block_cols": 32, "attention_block_rows": 32, "attention_lambda": 1.0, "attention_output_with_dense": 0, "attention_pruning_method": "sigmoied_threshold", "bias_mask": true, "dense_block_cols": 1, "dense_block_rows": 1, "dense_lambda": 1.0, "dense_pruning_method": "sigmoied_threshold:1d_alt", "distil_alpha_ce": 0.1, "distil_alpha_teacher": 0.9, "distil_teacher_name_or_path": "bert-large-uncased-whole-word-masking-finetuned-squad", "distil_temperature": 2.0, "final_ampere_temperature": 20.0, "final_finetune": false, "final_threshold": 0.1, "final_warmup": 10, "initial_ampere_temperature": 0.0, "initial_threshold": 0, "initial_warmup": 1, "mask_init": "constant", "mask_scale": 0.0, "mask_scores_learning_rate": 0.01, "regularization": "l1", "regularization_final_lambda": 40}, "speed": {"cuda_eval_elapsed_time": 28.611265159606933, "eval_elapsed_time": 36.00721236690879}, "speedup": 1.3489229780673324, "stats": {"layers": {"0": {"linear_attention_nnz": 668672, "linear_attention_total": 4194304, "linear_dense_nnz": 88064, "linear_dense_total": 8388608, "linear_nnz": 756736, "linear_total": 12582912, "nnz": 763595, "total": 12596224}, "1": {"linear_attention_nnz": 232448, "linear_attention_total": 4194304, "linear_dense_nnz": 102400, "linear_dense_total": 8388608, "linear_nnz": 334848, "linear_total": 12582912, "nnz": 341330, "total": 12596224}, "10": {"linear_attention_nnz": 864256, "linear_attention_total": 4194304, "linear_dense_nnz": 442368, "linear_dense_total": 8388608, "linear_nnz": 1306624, "linear_total": 12582912, "nnz": 1314200, "total": 12596224}, "11": {"linear_attention_nnz": 985088, "linear_attention_total": 4194304, "linear_dense_nnz": 462848, "linear_dense_total": 8388608, "linear_nnz": 1447936, "linear_total": 12582912, "nnz": 1455586, "total": 12596224}, "12": {"linear_attention_nnz": 726016, "linear_attention_total": 4194304, "linear_dense_nnz": 557056, "linear_dense_total": 8388608, "linear_nnz": 1283072, "linear_total": 12582912, "nnz": 1290384, "total": 12596224}, "13": {"linear_attention_nnz": 1306624, "linear_attention_total": 4194304, "linear_dense_nnz": 507904, "linear_dense_total": 8388608, "linear_nnz": 1814528, "linear_total": 12582912, "nnz": 1822616, "total": 12596224}, "14": {"linear_attention_nnz": 1107968, "linear_attention_total": 4194304, "linear_dense_nnz": 362496, "linear_dense_total": 8388608, "linear_nnz": 1470464, "linear_total": 12582912, "nnz": 1478321, "total": 12596224}, "15": {"linear_attention_nnz": 1074176, "linear_attention_total": 4194304, "linear_dense_nnz": 278528, "linear_dense_total": 8388608, "linear_nnz": 1352704, "linear_total": 12582912, "nnz": 1360360, "total": 12596224}, "16": {"linear_attention_nnz": 951296, "linear_attention_total": 4194304, "linear_dense_nnz": 188416, "linear_dense_total": 8388608, "linear_nnz": 1139712, "linear_total": 12582912, "nnz": 1147196, "total": 12596224}, "17": {"linear_attention_nnz": 795648, "linear_attention_total": 4194304, "linear_dense_nnz": 188416, "linear_dense_total": 8388608, "linear_nnz": 984064, "linear_total": 12582912, "nnz": 991868, "total": 12596224}, "18": {"linear_attention_nnz": 706560, "linear_attention_total": 4194304, "linear_dense_nnz": 141312, "linear_dense_total": 8388608, "linear_nnz": 847872, "linear_total": 12582912, "nnz": 855333, "total": 12596224}, "19": {"linear_attention_nnz": 290816, "linear_attention_total": 4194304, "linear_dense_nnz": 137216, "linear_dense_total": 8388608, "linear_nnz": 428032, "linear_total": 12582912, "nnz": 434563, "total": 12596224}, "2": {"linear_attention_nnz": 146432, "linear_attention_total": 4194304, "linear_dense_nnz": 90112, "linear_dense_total": 8388608, "linear_nnz": 236544, "linear_total": 12582912, "nnz": 242732, "total": 12596224}, "20": {"linear_attention_nnz": 186368, "linear_attention_total": 4194304, "linear_dense_nnz": 57344, "linear_dense_total": 8388608, "linear_nnz": 243712, "linear_total": 12582912, "nnz": 249916, "total": 12596224}, "21": {"linear_attention_nnz": 194560, "linear_attention_total": 4194304, "linear_dense_nnz": 40960, "linear_dense_total": 8388608, "linear_nnz": 235520, "linear_total": 12582912, "nnz": 241748, "total": 12596224}, "22": {"linear_attention_nnz": 46080, "linear_attention_total": 4194304, "linear_dense_nnz": 40960, "linear_dense_total": 8388608, "linear_nnz": 87040, "linear_total": 12582912, "nnz": 92724, "total": 12596224}, "23": {"linear_attention_nnz": 54272, "linear_attention_total": 4194304, "linear_dense_nnz": 102400, "linear_dense_total": 8388608, "linear_nnz": 156672, "linear_total": 12582912, "nnz": 162450, "total": 12596224}, "3": {"linear_attention_nnz": 359424, "linear_attention_total": 4194304, "linear_dense_nnz": 155648, "linear_dense_total": 8388608, "linear_nnz": 515072, "linear_total": 12582912, "nnz": 521644, "total": 12596224}, "4": {"linear_attention_nnz": 349184, "linear_attention_total": 4194304, "linear_dense_nnz": 143360, "linear_dense_total": 8388608, "linear_nnz": 492544, "linear_total": 12582912, "nnz": 499142, "total": 12596224}, "5": {"linear_attention_nnz": 270336, "linear_attention_total": 4194304, "linear_dense_nnz": 167936, "linear_dense_total": 8388608, "linear_nnz": 438272, "linear_total": 12582912, "nnz": 444850, "total": 12596224}, "6": {"linear_attention_nnz": 196608, "linear_attention_total": 4194304, "linear_dense_nnz": 212992, "linear_dense_total": 8388608, "linear_nnz": 409600, "linear_total": 12582912, "nnz": 415976, "total": 12596224}, "7": {"linear_attention_nnz": 494592, "linear_attention_total": 4194304, "linear_dense_nnz": 178176, "linear_dense_total": 8388608, "linear_nnz": 672768, "linear_total": 12582912, "nnz": 679575, "total": 12596224}, "8": {"linear_attention_nnz": 173056, "linear_attention_total": 4194304, "linear_dense_nnz": 229376, "linear_dense_total": 8388608, "linear_nnz": 402432, "linear_total": 12582912, "nnz": 408880, "total": 12596224}, "9": {"linear_attention_nnz": 630784, "linear_attention_total": 4194304, "linear_dense_nnz": 370688, "linear_dense_total": 8388608, "linear_nnz": 1001472, "linear_total": 12582912, "nnz": 1008469, "total": 12596224}}, "linear_nnz": 18058240, "linear_sparsity": 94.02025010850694, "linear_total": 301989888, "nnz": 50008420, "pruned_heads": {"0": [1, 2, 3, 4, 7, 8, 9, 10, 11, 13, 14, 15], "1": [0, 1, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], "10": [0, 3, 6, 7, 8, 10, 12, 13, 14], "11": [0, 1, 2, 4, 5, 6, 8, 10, 12], "12": [1, 2, 3, 5, 6, 7, 8, 10, 12, 13, 14], "13": [2, 3, 4, 10, 11, 12], "14": [1, 2, 3, 4, 8, 11], "15": [0, 2, 5, 6, 7, 8, 9, 11, 12], "16": [3, 6, 8, 10, 12, 13, 15], "17": [0, 2, 4, 11, 12, 15], "18": [2, 3, 5, 9, 11, 12, 13], "19": [0, 1, 2, 3, 4, 5, 9, 10, 11, 13, 14, 15], "2": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], "20": [0, 1, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 15], "21": [0, 2, 3, 4, 5, 6, 8, 10, 11, 12, 13, 14, 15], "22": [0, 1, 2, 3, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15], "23": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14], "3": [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14, 15], "4": [0, 1, 2, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], "5": [0, 1, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15], "6": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15], "7": [0, 1, 2, 4, 6, 8, 10, 11, 12, 13, 14, 15], "8": [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 12, 13, 14, 15], "9": [1, 2, 3, 4, 5, 6, 7, 8, 9, 12, 13, 15]}, "total": 334094338, "total_sparsity": 85.0316469595483}, "training_args": {"_n_gpu": -1, "adafactor": false, "adam_beta1": 0.9, "adam_beta2": 0.999, "adam_epsilon": 1e-08, "dataloader_drop_last": false, "dataloader_num_workers": 0, "dataloader_pin_memory": true, "ddp_find_unused_parameters": null, "debug": false, "deepspeed": null, "disable_tqdm": false, "do_eval": 1, "do_predict": false, "do_train": 1, "eval_accumulation_steps": null, "eval_steps": 10000, "evaluation_strategy": "steps", "fp16": false, "fp16_backend": "auto", "fp16_full_eval": false, "fp16_opt_level": "O1", "gradient_accumulation_steps": 1, "greater_is_better": null, "group_by_length": false, "ignore_data_skip": false, "label_names": null, "label_smoothing_factor": 0.0, "learning_rate": 3e-05, "load_best_model_at_end": false, "local_rank": -1, "logging_dir": "output/squad_test_large/squad_test_large_regu_40", "logging_first_step": false, "logging_steps": 250, "logging_strategy": "steps", "lr_scheduler_type": "linear", "max_grad_norm": 1.0, "max_steps": -1, "metric_for_best_model": null, "no_cuda": false, "num_train_epochs": 20, "optimize_model_before_eval": "disabled", "output_dir": "output/squad_test_large/squad_test_large_regu_40", "overwrite_output_dir": 1, "past_index": -1, "per_device_eval_batch_size": 8, "per_device_train_batch_size": 8, "per_gpu_eval_batch_size": null, "per_gpu_train_batch_size": null, "prediction_loss_only": false, "remove_unused_columns": true, "report_to": null, "run_name": "output/squad_test_large/squad_test_large_regu_40", "save_steps": 10000, "save_strategy": "steps", "save_total_limit": 50, "seed": 17, "sharded_ddp": "", "skip_memory_metrics": false, "tpu_metrics_debug": false, "tpu_num_cores": null, "warmup_ratio": 0.0, "warmup_steps": 5400, "weight_decay": 0.0}}, "f1": 86.66302391758462, "fill_rate": 0.15945999710648154, "speedup": 1.3489229780673324}}
{"fill_rate": 0.12708875868055594, "f1": 86.23578242662717, "meta": {"annotate": "4", "cat_fun_name": "is_new_xp", "checkpoint": {"config": {"_name_or_path": "bert-large-uncased", "architectures": ["BertForQuestionAnswering"], "attention_probs_dropout_prob": 0.1, "gradient_checkpointing": false, "hidden_act": "gelu", "hidden_dropout_prob": 0.1, "hidden_size": 1024, "initializer_range": 0.02, "intermediate_size": 4096, "layer_norm_eps": 1e-12, "max_position_embeddings": 512, "model_type": "bert", "num_attention_heads": 16, "num_hidden_layers": 24, "pad_token_id": 0, "position_embedding_type": "absolute", "type_vocab_size": 2, "vocab_size": 30522}, "eval_metrics": {"exact_match": 78.27814569536424, "f1": 86.23578242662717}, "path": "/data_2to/devel_data/nn_pruning/output/squad_test_large/large_regu_60/checkpoint-221320", "sparse_args": {"ampere_pruning_method": "disabled", "attention_block_cols": 32, "attention_block_rows": 32, "attention_lambda": 1.0, "attention_output_with_dense": 0, "attention_pruning_method": "sigmoied_threshold", "bias_mask": true, "dense_block_cols": 1, "dense_block_rows": 1, "dense_lambda": 1.0, "dense_pruning_method": "sigmoied_threshold:1d_alt", "distil_alpha_ce": 0.1, "distil_alpha_teacher": 0.9, "distil_teacher_name_or_path": "bert-large-uncased-whole-word-masking-finetuned-squad", "distil_temperature": 2.0, "final_ampere_temperature": 20.0, "final_finetune": false, "final_threshold": 0.1, "final_warmup": 10, "initial_ampere_temperature": 0.0, "initial_threshold": 0, "initial_warmup": 1, "mask_init": "constant", "mask_scale": 0.0, "mask_scores_learning_rate": 0.01, "regularization": "l1", "regularization_final_lambda": 60}, "speed": {"cuda_eval_elapsed_time": 26.930138206481935, "eval_elapsed_time": 34.07285923091695}, "speedup": 1.4331301499255447, "stats": {"layers": {"0": {"linear_attention_nnz": 527360, "linear_attention_total": 4194304, "linear_dense_nnz": 71680, "linear_dense_total": 8388608, "linear_nnz": 599040, "linear_total": 12582912, "nnz": 605731, "total": 12596224}, "1": {"linear_attention_nnz": 167936, "linear_attention_total": 4194304, "linear_dense_nnz": 59392, "linear_dense_total": 8388608, "linear_nnz": 227328, "linear_total": 12582912, "nnz": 233661, "total": 12596224}, "10": {"linear_attention_nnz": 719872, "linear_attention_total": 4194304, "linear_dense_nnz": 360448, "linear_dense_total": 8388608, "linear_nnz": 1080320, "linear_total": 12582912, "nnz": 1087568, "total": 12596224}, "11": {"linear_attention_nnz": 775168, "linear_attention_total": 4194304, "linear_dense_nnz": 352256, "linear_dense_total": 8388608, "linear_nnz": 1127424, "linear_total": 12582912, "nnz": 1134732, "total": 12596224}, "12": {"linear_attention_nnz": 614400, "linear_attention_total": 4194304, "linear_dense_nnz": 460800, "linear_dense_total": 8388608, "linear_nnz": 1075200, "linear_total": 12582912, "nnz": 1082273, "total": 12596224}, "13": {"linear_attention_nnz": 1112064, "linear_attention_total": 4194304, "linear_dense_nnz": 382976, "linear_dense_total": 8388608, "linear_nnz": 1495040, "linear_total": 12582912, "nnz": 1502907, "total": 12596224}, "14": {"linear_attention_nnz": 849920, "linear_attention_total": 4194304, "linear_dense_nnz": 276480, "linear_dense_total": 8388608, "linear_nnz": 1126400, "linear_total": 12582912, "nnz": 1134023, "total": 12596224}, "15": {"linear_attention_nnz": 825344, "linear_attention_total": 4194304, "linear_dense_nnz": 258048, "linear_dense_total": 8388608, "linear_nnz": 1083392, "linear_total": 12582912, "nnz": 1090814, "total": 12596224}, "16": {"linear_attention_nnz": 813056, "linear_attention_total": 4194304, "linear_dense_nnz": 147456, "linear_dense_total": 8388608, "linear_nnz": 960512, "linear_total": 12582912, "nnz": 967816, "total": 12596224}, "17": {"linear_attention_nnz": 618496, "linear_attention_total": 4194304, "linear_dense_nnz": 145408, "linear_dense_total": 8388608, "linear_nnz": 763904, "linear_total": 12582912, "nnz": 771239, "total": 12596224}, "18": {"linear_attention_nnz": 572416, "linear_attention_total": 4194304, "linear_dense_nnz": 116736, "linear_dense_total": 8388608, "linear_nnz": 689152, "linear_total": 12582912, "nnz": 696409, "total": 12596224}, "19": {"linear_attention_nnz": 216064, "linear_attention_total": 4194304, "linear_dense_nnz": 100352, "linear_dense_total": 8388608, "linear_nnz": 316416, "linear_total": 12582912, "nnz": 322737, "total": 12596224}, "2": {"linear_attention_nnz": 84992, "linear_attention_total": 4194304, "linear_dense_nnz": 63488, "linear_dense_total": 8388608, "linear_nnz": 148480, "linear_total": 12582912, "nnz": 154687, "total": 12596224}, "20": {"linear_attention_nnz": 165888, "linear_attention_total": 4194304, "linear_dense_nnz": 49152, "linear_dense_total": 8388608, "linear_nnz": 215040, "linear_total": 12582912, "nnz": 221240, "total": 12596224}, "21": {"linear_attention_nnz": 153600, "linear_attention_total": 4194304, "linear_dense_nnz": 40960, "linear_dense_total": 8388608, "linear_nnz": 194560, "linear_total": 12582912, "nnz": 200660, "total": 12596224}, "22": {"linear_attention_nnz": 53248, "linear_attention_total": 4194304, "linear_dense_nnz": 49152, "linear_dense_total": 8388608, "linear_nnz": 102400, "linear_total": 12582912, "nnz": 108184, "total": 12596224}, "23": {"linear_attention_nnz": 26624, "linear_attention_total": 4194304, "linear_dense_nnz": 81920, "linear_dense_total": 8388608, "linear_nnz": 108544, "linear_total": 12582912, "nnz": 114056, "total": 12596224}, "3": {"linear_attention_nnz": 355328, "linear_attention_total": 4194304, "linear_dense_nnz": 100352, "linear_dense_total": 8388608, "linear_nnz": 455680, "linear_total": 12582912, "nnz": 462257, "total": 12596224}, "4": {"linear_attention_nnz": 350208, "linear_attention_total": 4194304, "linear_dense_nnz": 133120, "linear_dense_total": 8388608, "linear_nnz": 483328, "linear_total": 12582912, "nnz": 489921, "total": 12596224}, "5": {"linear_attention_nnz": 24576, "linear_attention_total": 4194304, "linear_dense_nnz": 129024, "linear_dense_total": 8388608, "linear_nnz": 153600, "linear_total": 12582912, "nnz": 159135, "total": 12596224}, "6": {"linear_attention_nnz": 187392, "linear_attention_total": 4194304, "linear_dense_nnz": 155648, "linear_dense_total": 8388608, "linear_nnz": 343040, "linear_total": 12582912, "nnz": 349292, "total": 12596224}, "7": {"linear_attention_nnz": 429056, "linear_attention_total": 4194304, "linear_dense_nnz": 145408, "linear_dense_total": 8388608, "linear_nnz": 574464, "linear_total": 12582912, "nnz": 581223, "total": 12596224}, "8": {"linear_attention_nnz": 129024, "linear_attention_total": 4194304, "linear_dense_nnz": 174080, "linear_dense_total": 8388608, "linear_nnz": 303104, "linear_total": 12582912, "nnz": 309301, "total": 12596224}, "9": {"linear_attention_nnz": 491520, "linear_attention_total": 4194304, "linear_dense_nnz": 274432, "linear_dense_total": 8388608, "linear_nnz": 765952, "linear_total": 12582912, "nnz": 772742, "total": 12596224}}, "linear_nnz": 14392320, "linear_sparsity": 95.23417154947916, "linear_total": 301989888, "nnz": 46337570, "pruned_heads": {"0": [1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 13, 14, 15], "1": [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], "10": [0, 3, 6, 7, 8, 9, 10, 12, 13, 14], "11": [0, 1, 2, 4, 5, 6, 8, 10, 12, 15], "12": [1, 2, 3, 5, 6, 7, 8, 9, 10, 12, 13, 14], "13": [2, 3, 4, 9, 10, 11, 12], "14": [1, 2, 3, 4, 8, 9, 11, 12], "15": [0, 1, 2, 4, 5, 6, 7, 8, 9, 11, 12], "16": [3, 6, 8, 10, 12, 13, 15], "17": [0, 2, 4, 8, 11, 12, 15], "18": [2, 3, 5, 9, 11, 13], "19": [0, 1, 2, 3, 4, 5, 8, 9, 10, 11, 13, 14, 15], "2": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 15], "20": [0, 1, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 15], "21": [0, 2, 3, 4, 5, 6, 8, 10, 11, 12, 13, 14, 15], "22": [0, 1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15], "23": [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13, 14], "3": [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14, 15], "4": [0, 1, 2, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], "5": [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], "6": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15], "7": [0, 1, 2, 4, 6, 8, 10, 11, 12, 13, 14, 15], "8": [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15], "9": [1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 15]}, "total": 334094338, "total_sparsity": 86.13039350580075}, "training_args": {"_n_gpu": -1, "adafactor": false, "adam_beta1": 0.9, "adam_beta2": 0.999, "adam_epsilon": 1e-08, "dataloader_drop_last": false, "dataloader_num_workers": 0, "dataloader_pin_memory": true, "ddp_find_unused_parameters": null, "debug": false, "deepspeed": null, "disable_tqdm": false, "do_eval": 1, "do_predict": false, "do_train": 1, "eval_accumulation_steps": null, "eval_steps": 10000, "evaluation_strategy": "steps", "fp16": false, "fp16_backend": "auto", "fp16_full_eval": false, "fp16_opt_level": "O1", "gradient_accumulation_steps": 1, "greater_is_better": null, "group_by_length": false, "ignore_data_skip": false, "label_names": null, "label_smoothing_factor": 0.0, "learning_rate": 3e-05, "load_best_model_at_end": false, "local_rank": -1, "logging_dir": "output/squad_test_large/large_regu_60", "logging_first_step": false, "logging_steps": 250, "logging_strategy": "steps", "lr_scheduler_type": "linear", "max_grad_norm": 1.0, "max_steps": -1, "metric_for_best_model": null, "no_cuda": false, "num_train_epochs": 20, "optimize_model_before_eval": "disabled", "output_dir": "output/squad_test_large/large_regu_60", "overwrite_output_dir": 1, "past_index": -1, "per_device_eval_batch_size": 8, "per_device_train_batch_size": 8, "per_gpu_eval_batch_size": null, "per_gpu_train_batch_size": null, "prediction_loss_only": false, "remove_unused_columns": true, "report_to": null, "run_name": "output/squad_test_large/large_regu_60", "save_steps": 10000, "save_strategy": "steps", "save_total_limit": 50, "seed": 17, "sharded_ddp": "", "skip_memory_metrics": false, "tpu_metrics_debug": false, "tpu_num_cores": null, "warmup_ratio": 0.0, "warmup_steps": 5400, "weight_decay": 0.0}}, "f1": 86.23578242662717, "fill_rate": 0.12708875868055594, "speedup": 1.4331301499255447}}
