{"fill_rate": 0.27223186728395055, "f1": 88.32616013981377, "meta": {"annotate": "27", "cat_fun_name": "is_new_xp", "checkpoint": {"config": {"_name_or_path": "bert-base-uncased", "architectures": ["BertForQuestionAnswering"], "attention_probs_dropout_prob": 0.1, "gradient_checkpointing": false, "hidden_act": "gelu", "hidden_dropout_prob": 0.1, "hidden_size": 768, "initializer_range": 0.02, "intermediate_size": 3072, "layer_norm_eps": 1e-12, "max_position_embeddings": 512, "model_type": "bert", "num_attention_heads": 12, "num_hidden_layers": 12, "pad_token_id": 0, "position_embedding_type": "absolute", "type_vocab_size": 2, "vocab_size": 30522}, "eval_metrics": {"exact_match": 81.30558183538317, "f1": 88.32616013981377}, "path": "/data_2to/devel_data/nn_pruning/output/squad_test_9_fullpatch4/hp_od-__data_2to__devel_data__nn_pruning__output__squad_test_9_fullpatch4___es-steps_nte20_ls250_stl50_est5000_rn-__data_2to__devel_data__nn_pruning__output__squad_test_9_fullpatch4_--6cb2db64e9a885f1/checkpoint-110000", "sparse_args": {"ampere_pruning_method": "disabled", "attention_block_cols": 32, "attention_block_rows": 32, "attention_lambda": 1.0, "attention_output_with_dense": 0, "attention_pruning_method": "sigmoied_threshold", "bias_mask": true, "dense_block_cols": 1, "dense_block_rows": 1, "dense_lambda": 1.0, "dense_pruning_method": "sigmoied_threshold:1d_alt", "distil_alpha_ce": 0.1, "distil_alpha_teacher": 0.9, "distil_teacher_name_or_path": "bert-large-uncased-whole-word-masking-finetuned-squad", "distil_temperature": 2.0, "final_ampere_temperature": 20.0, "final_finetune": false, "final_threshold": 0.1, "final_warmup": 10, "gelu_patch": 1, "gelu_patch_steps": 50000, "initial_ampere_temperature": 0.0, "initial_threshold": 0, "initial_warmup": 1, "layer_norm_patch": 1, "layer_norm_patch_start_delta": 0.99, "layer_norm_patch_steps": 50000, "linear_min_parameters": 0, "mask_init": "constant", "mask_scale": 0.0, "mask_scores_learning_rate": 0.01, "regularization": "l1", "regularization_final_lambda": 10}, "speed": {"cuda_eval_elapsed_time": 19.66401289367676, "eval_elapsed_time": 26.647668646648526}, "speedup": 1.9626916038984936, "stats": {"layers": {"0": {"linear_attention_nnz": 920576, "linear_attention_total": 2359296, "linear_dense_nnz": 1188864, "linear_dense_total": 4718592, "linear_nnz": 2109440, "linear_total": 7077888, "nnz": 2115942, "total": 7087872}, "1": {"linear_attention_nnz": 709632, "linear_attention_total": 2359296, "linear_dense_nnz": 1187328, "linear_dense_total": 4718592, "linear_nnz": 1896960, "linear_total": 7077888, "nnz": 1903205, "total": 7087872}, "10": {"linear_attention_nnz": 617472, "linear_attention_total": 2359296, "linear_dense_nnz": 552960, "linear_dense_total": 4718592, "linear_nnz": 1170432, "linear_total": 7077888, "nnz": 1176200, "total": 7087872}, "11": {"linear_attention_nnz": 423936, "linear_attention_total": 2359296, "linear_dense_nnz": 806400, "linear_dense_total": 4718592, "linear_nnz": 1230336, "linear_total": 7077888, "nnz": 1236333, "total": 7087872}, "2": {"linear_attention_nnz": 1210368, "linear_attention_total": 2359296, "linear_dense_nnz": 1371648, "linear_dense_total": 4718592, "linear_nnz": 2582016, "linear_total": 7077888, "nnz": 2589021, "total": 7087872}, "3": {"linear_attention_nnz": 1433600, "linear_attention_total": 2359296, "linear_dense_nnz": 1310208, "linear_dense_total": 4718592, "linear_nnz": 2743808, "linear_total": 7077888, "nnz": 2750901, "total": 7087872}, "4": {"linear_attention_nnz": 1558528, "linear_attention_total": 2359296, "linear_dense_nnz": 1219584, "linear_dense_total": 4718592, "linear_nnz": 2778112, "linear_total": 7077888, "nnz": 2785338, "total": 7087872}, "5": {"linear_attention_nnz": 1038336, "linear_attention_total": 2359296, "linear_dense_nnz": 1213440, "linear_dense_total": 4718592, "linear_nnz": 2251776, "linear_total": 7077888, "nnz": 2258486, "total": 7087872}, "6": {"linear_attention_nnz": 1107968, "linear_attention_total": 2359296, "linear_dense_nnz": 967680, "linear_dense_total": 4718592, "linear_nnz": 2075648, "linear_total": 7077888, "nnz": 2082422, "total": 7087872}, "7": {"linear_attention_nnz": 1108992, "linear_attention_total": 2359296, "linear_dense_nnz": 766464, "linear_dense_total": 4718592, "linear_nnz": 1875456, "linear_total": 7077888, "nnz": 1881875, "total": 7087872}, "8": {"linear_attention_nnz": 1062912, "linear_attention_total": 2359296, "linear_dense_nnz": 399360, "linear_dense_total": 4718592, "linear_nnz": 1462272, "linear_total": 7077888, "nnz": 1468548, "total": 7087872}, "9": {"linear_attention_nnz": 670720, "linear_attention_total": 2359296, "linear_dense_nnz": 274944, "linear_dense_total": 4718592, "linear_nnz": 945664, "linear_total": 7077888, "nnz": 951443, "total": 7087872}}, "linear_nnz": 23121920, "linear_sparsity": 72.77681327160495, "linear_total": 84934656, "nnz": 47038436, "pruned_heads": {"0": [0, 2, 4, 5, 6], "1": [0, 2, 3, 5, 6, 7, 8], "10": [1, 2, 4, 5, 6, 7, 8], "11": [0, 5, 7, 8, 10, 11], "2": [8, 4, 7], "3": [2, 4, 6], "4": [1, 2], "5": [1, 2, 6, 7, 11], "6": [10, 2, 3], "7": [1, 3, 6, 7, 11], "8": [0, 3, 4], "9": [1, 4, 5, 7, 9, 10]}, "total": 108893186, "total_sparsity": 56.8031410156371}, "training_args": {"_n_gpu": -1, "adafactor": false, "adam_beta1": 0.9, "adam_beta2": 0.999, "adam_epsilon": 1e-08, "dataloader_drop_last": false, "dataloader_num_workers": 0, "dataloader_pin_memory": true, "ddp_find_unused_parameters": null, "debug": false, "deepspeed": null, "disable_tqdm": false, "do_eval": 1, "do_predict": false, "do_train": 1, "eval_accumulation_steps": null, "eval_steps": 5000, "evaluation_strategy": "steps", "fp16": false, "fp16_backend": "auto", "fp16_full_eval": false, "fp16_opt_level": "O1", "gradient_accumulation_steps": 1, "greater_is_better": null, "group_by_length": false, "ignore_data_skip": false, "label_names": null, "label_smoothing_factor": 0.0, "learning_rate": 3e-05, "load_best_model_at_end": false, "local_rank": -1, "logging_dir": "/data_2to/devel_data/nn_pruning/output/squad_test_9_fullpatch4/", "logging_first_step": false, "logging_steps": 250, "logging_strategy": "steps", "lr_scheduler_type": "linear", "max_grad_norm": 1.0, "max_steps": -1, "metric_for_best_model": null, "no_cuda": false, "num_train_epochs": 20, "optimize_model_before_eval": "disabled", "output_dir": "/data_2to/devel_data/nn_pruning/output/squad_test_9_fullpatch4/", "overwrite_output_dir": 1, "past_index": -1, "per_device_eval_batch_size": 8, "per_device_train_batch_size": 16, "per_gpu_eval_batch_size": null, "per_gpu_train_batch_size": null, "prediction_loss_only": false, "remove_unused_columns": true, "report_to": null, "run_name": "/data_2to/devel_data/nn_pruning/output/squad_test_9_fullpatch4/", "save_steps": 5000, "save_strategy": "steps", "save_total_limit": 50, "seed": 17, "sharded_ddp": "", "skip_memory_metrics": false, "tpu_metrics_debug": false, "tpu_num_cores": null, "warmup_ratio": 0.0, "warmup_steps": 5400, "weight_decay": 0.0}}, "f1": 88.32616013981377, "fill_rate": 0.27223186728395055, "speedup": 1.9626916038984936}}
{"fill_rate": 0.1894651813271605, "f1": 86.94398255916529, "meta": {"annotate": "18", "cat_fun_name": "is_new_xp", "checkpoint": {"config": {"_name_or_path": "bert-base-uncased", "architectures": ["BertForQuestionAnswering"], "attention_probs_dropout_prob": 0.1, "gradient_checkpointing": false, "hidden_act": "gelu", "hidden_dropout_prob": 0.1, "hidden_size": 768, "initializer_range": 0.02, "intermediate_size": 3072, "layer_norm_eps": 1e-12, "max_position_embeddings": 512, "model_type": "bert", "num_attention_heads": 12, "num_hidden_layers": 12, "pad_token_id": 0, "position_embedding_type": "absolute", "type_vocab_size": 2, "vocab_size": 30522}, "eval_metrics": {"exact_match": 79.60264900662251, "f1": 86.94398255916529}, "path": "/data_2to/devel_data/nn_pruning/output/squad_test_9_fullpatch4/hp_od-__data_2to__devel_data__nn_pruning__output__squad_test_9_fullpatch4___es-steps_nte20_ls250_stl50_est5000_rn-__data_2to__devel_data__nn_pruning__output__squad_test_9_fullpatch4_--75942d701c2bed7e/checkpoint-110000", "sparse_args": {"ampere_pruning_method": "disabled", "attention_block_cols": 32, "attention_block_rows": 32, "attention_lambda": 1.0, "attention_output_with_dense": 0, "attention_pruning_method": "sigmoied_threshold", "bias_mask": true, "dense_block_cols": 1, "dense_block_rows": 1, "dense_lambda": 1.0, "dense_pruning_method": "sigmoied_threshold:1d_alt", "distil_alpha_ce": 0.1, "distil_alpha_teacher": 0.9, "distil_teacher_name_or_path": "bert-large-uncased-whole-word-masking-finetuned-squad", "distil_temperature": 2.0, "final_ampere_temperature": 20.0, "final_finetune": false, "final_threshold": 0.1, "final_warmup": 10, "gelu_patch": 1, "gelu_patch_steps": 50000, "initial_ampere_temperature": 0.0, "initial_threshold": 0, "initial_warmup": 1, "layer_norm_patch": 1, "layer_norm_patch_start_delta": 0.99, "layer_norm_patch_steps": 50000, "linear_min_parameters": 0, "mask_init": "constant", "mask_scale": 0.0, "mask_scores_learning_rate": 0.01, "regularization": "l1", "regularization_final_lambda": 20}, "speed": {"cuda_eval_elapsed_time": 16.995676197052003, "eval_elapsed_time": 23.85530902631581}, "speedup": 2.2708359795690574, "stats": {"layers": {"0": {"linear_attention_nnz": 726016, "linear_attention_total": 2359296, "linear_dense_nnz": 569856, "linear_dense_total": 4718592, "linear_nnz": 1295872, "linear_total": 7077888, "nnz": 1301779, "total": 7087872}, "1": {"linear_attention_nnz": 521216, "linear_attention_total": 2359296, "linear_dense_nnz": 681984, "linear_dense_total": 4718592, "linear_nnz": 1203200, "linear_total": 7077888, "nnz": 1209020, "total": 7087872}, "10": {"linear_attention_nnz": 500736, "linear_attention_total": 2359296, "linear_dense_nnz": 324096, "linear_dense_total": 4718592, "linear_nnz": 824832, "linear_total": 7077888, "nnz": 830451, "total": 7087872}, "11": {"linear_attention_nnz": 302080, "linear_attention_total": 2359296, "linear_dense_nnz": 482304, "linear_dense_total": 4718592, "linear_nnz": 784384, "linear_total": 7077888, "nnz": 789786, "total": 7087872}, "2": {"linear_attention_nnz": 843776, "linear_attention_total": 2359296, "linear_dense_nnz": 832512, "linear_dense_total": 4718592, "linear_nnz": 1676288, "linear_total": 7077888, "nnz": 1682526, "total": 7087872}, "3": {"linear_attention_nnz": 1219584, "linear_attention_total": 2359296, "linear_dense_nnz": 877056, "linear_dense_total": 4718592, "linear_nnz": 2096640, "linear_total": 7077888, "nnz": 2103355, "total": 7087872}, "4": {"linear_attention_nnz": 1117184, "linear_attention_total": 2359296, "linear_dense_nnz": 850944, "linear_dense_total": 4718592, "linear_nnz": 1968128, "linear_total": 7077888, "nnz": 1974826, "total": 7087872}, "5": {"linear_attention_nnz": 769024, "linear_attention_total": 2359296, "linear_dense_nnz": 827904, "linear_dense_total": 4718592, "linear_nnz": 1596928, "linear_total": 7077888, "nnz": 1603131, "total": 7087872}, "6": {"linear_attention_nnz": 732160, "linear_attention_total": 2359296, "linear_dense_nnz": 700416, "linear_dense_total": 4718592, "linear_nnz": 1432576, "linear_total": 7077888, "nnz": 1438664, "total": 7087872}, "7": {"linear_attention_nnz": 946176, "linear_attention_total": 2359296, "linear_dense_nnz": 532992, "linear_dense_total": 4718592, "linear_nnz": 1479168, "linear_total": 7077888, "nnz": 1485403, "total": 7087872}, "8": {"linear_attention_nnz": 797696, "linear_attention_total": 2359296, "linear_dense_nnz": 285696, "linear_dense_total": 4718592, "linear_nnz": 1083392, "linear_total": 7077888, "nnz": 1089402, "total": 7087872}, "9": {"linear_attention_nnz": 510976, "linear_attention_total": 2359296, "linear_dense_nnz": 139776, "linear_dense_total": 4718592, "linear_nnz": 650752, "linear_total": 7077888, "nnz": 656283, "total": 7087872}}, "linear_nnz": 16092160, "linear_sparsity": 81.05348186728395, "linear_total": 84934656, "nnz": 40003348, "pruned_heads": {"0": [0, 2, 4, 5, 6, 7, 11], "1": [0, 2, 3, 5, 6, 7, 8, 9], "10": [1, 2, 4, 5, 6, 7, 8], "11": [0, 2, 3, 5, 7, 8, 10, 11], "2": [1, 4, 5, 7, 8], "3": [2, 4, 6], "4": [1, 2, 7], "5": [1, 2, 5, 6, 7, 11], "6": [0, 2, 3, 6, 7, 10], "7": [1, 3, 6, 7, 11], "8": [0, 8, 3, 4], "9": [1, 4, 5, 7, 9, 10]}, "total": 108893186, "total_sparsity": 63.26368116366804}, "training_args": {"_n_gpu": -1, "adafactor": false, "adam_beta1": 0.9, "adam_beta2": 0.999, "adam_epsilon": 1e-08, "dataloader_drop_last": false, "dataloader_num_workers": 0, "dataloader_pin_memory": true, "ddp_find_unused_parameters": null, "debug": false, "deepspeed": null, "disable_tqdm": false, "do_eval": 1, "do_predict": false, "do_train": 1, "eval_accumulation_steps": null, "eval_steps": 5000, "evaluation_strategy": "steps", "fp16": false, "fp16_backend": "auto", "fp16_full_eval": false, "fp16_opt_level": "O1", "gradient_accumulation_steps": 1, "greater_is_better": null, "group_by_length": false, "ignore_data_skip": false, "label_names": null, "label_smoothing_factor": 0.0, "learning_rate": 3e-05, "load_best_model_at_end": false, "local_rank": -1, "logging_dir": "/data_2to/devel_data/nn_pruning/output/squad_test_9_fullpatch4/", "logging_first_step": false, "logging_steps": 250, "logging_strategy": "steps", "lr_scheduler_type": "linear", "max_grad_norm": 1.0, "max_steps": -1, "metric_for_best_model": null, "no_cuda": false, "num_train_epochs": 20, "optimize_model_before_eval": "disabled", "output_dir": "/data_2to/devel_data/nn_pruning/output/squad_test_9_fullpatch4/", "overwrite_output_dir": 1, "past_index": -1, "per_device_eval_batch_size": 8, "per_device_train_batch_size": 16, "per_gpu_eval_batch_size": null, "per_gpu_train_batch_size": null, "prediction_loss_only": false, "remove_unused_columns": true, "report_to": null, "run_name": "/data_2to/devel_data/nn_pruning/output/squad_test_9_fullpatch4/", "save_steps": 5000, "save_strategy": "steps", "save_total_limit": 50, "seed": 17, "sharded_ddp": "", "skip_memory_metrics": false, "tpu_metrics_debug": false, "tpu_num_cores": null, "warmup_ratio": 0.0, "warmup_steps": 5400, "weight_decay": 0.0}}, "f1": 86.94398255916529, "fill_rate": 0.1894651813271605, "speedup": 2.2708359795690574}}
{"fill_rate": 0.17993465470679015, "f1": 85.89097404430157, "meta": {"annotate": "17", "cat_fun_name": "is_new_xp", "checkpoint": {"config": {"_name_or_path": "bert-base-uncased", "architectures": ["BertForQuestionAnswering"], "attention_probs_dropout_prob": 0.1, "gradient_checkpointing": false, "hidden_act": "gelu", "hidden_dropout_prob": 0.1, "hidden_size": 768, "initializer_range": 0.02, "intermediate_size": 3072, "layer_norm_eps": 1e-12, "max_position_embeddings": 512, "model_type": "bert", "num_attention_heads": 12, "num_hidden_layers": 12, "pad_token_id": 0, "position_embedding_type": "absolute", "type_vocab_size": 2, "vocab_size": 30522}, "eval_metrics": {"exact_match": 78.09839167455061, "f1": 85.89097404430157}, "path": "/data_2to/devel_data/nn_pruning/output/squad_test_9_fullpatch4/hp_od-__data_2to__devel_data__nn_pruning__output__squad_test_9_fullpatch4___es-steps_nte20_ls250_stl50_est5000_rn-__data_2to__devel_data__nn_pruning__output__squad_test_9_fullpatch4_--6b7cbdb694e8fe5f/checkpoint-65000", "sparse_args": {"ampere_pruning_method": "disabled", "attention_block_cols": 32, "attention_block_rows": 32, "attention_lambda": 1.0, "attention_output_with_dense": 0, "attention_pruning_method": "sigmoied_threshold", "bias_mask": true, "dense_block_cols": 1, "dense_block_rows": 1, "dense_lambda": 1.0, "dense_pruning_method": "sigmoied_threshold:1d_alt", "distil_alpha_ce": 0.1, "distil_alpha_teacher": 0.9, "distil_teacher_name_or_path": "bert-large-uncased-whole-word-masking-finetuned-squad", "distil_temperature": 2.0, "final_ampere_temperature": 20.0, "final_finetune": false, "final_threshold": 0.1, "final_warmup": 10, "gelu_patch": 1, "gelu_patch_steps": 50000, "initial_ampere_temperature": 0.0, "initial_threshold": 0, "initial_warmup": 1, "layer_norm_patch": 1, "layer_norm_patch_start_delta": 0.99, "layer_norm_patch_steps": 50000, "linear_min_parameters": 0, "mask_init": "constant", "mask_scale": 0.0, "mask_scores_learning_rate": 0.01, "regularization": "l1", "regularization_final_lambda": 30}, "speed": {"cuda_eval_elapsed_time": 16.425722427368164, "eval_elapsed_time": 23.391399671323597}, "speedup": 2.349631389184198, "stats": {"layers": {"0": {"linear_attention_nnz": 709632, "linear_attention_total": 2359296, "linear_dense_nnz": 462336, "linear_dense_total": 4718592, "linear_nnz": 1171968, "linear_total": 7077888, "nnz": 1177805, "total": 7087872}, "1": {"linear_attention_nnz": 603136, "linear_attention_total": 2359296, "linear_dense_nnz": 551424, "linear_dense_total": 4718592, "linear_nnz": 1154560, "linear_total": 7077888, "nnz": 1160391, "total": 7087872}, "10": {"linear_attention_nnz": 531456, "linear_attention_total": 2359296, "linear_dense_nnz": 267264, "linear_dense_total": 4718592, "linear_nnz": 798720, "linear_total": 7077888, "nnz": 804302, "total": 7087872}, "11": {"linear_attention_nnz": 321536, "linear_attention_total": 2359296, "linear_dense_nnz": 450048, "linear_dense_total": 4718592, "linear_nnz": 771584, "linear_total": 7077888, "nnz": 776965, "total": 7087872}, "2": {"linear_attention_nnz": 1000448, "linear_attention_total": 2359296, "linear_dense_nnz": 717312, "linear_dense_total": 4718592, "linear_nnz": 1717760, "linear_total": 7077888, "nnz": 1724211, "total": 7087872}, "3": {"linear_attention_nnz": 1271808, "linear_attention_total": 2359296, "linear_dense_nnz": 723456, "linear_dense_total": 4718592, "linear_nnz": 1995264, "linear_total": 7077888, "nnz": 2001847, "total": 7087872}, "4": {"linear_attention_nnz": 873472, "linear_attention_total": 2359296, "linear_dense_nnz": 721920, "linear_dense_total": 4718592, "linear_nnz": 1595392, "linear_total": 7077888, "nnz": 1601622, "total": 7087872}, "5": {"linear_attention_nnz": 835584, "linear_attention_total": 2359296, "linear_dense_nnz": 632832, "linear_dense_total": 4718592, "linear_nnz": 1468416, "linear_total": 7077888, "nnz": 1474524, "total": 7087872}, "6": {"linear_attention_nnz": 783360, "linear_attention_total": 2359296, "linear_dense_nnz": 595968, "linear_dense_total": 4718592, "linear_nnz": 1379328, "linear_total": 7077888, "nnz": 1385444, "total": 7087872}, "7": {"linear_attention_nnz": 1017856, "linear_attention_total": 2359296, "linear_dense_nnz": 483840, "linear_dense_total": 4718592, "linear_nnz": 1501696, "linear_total": 7077888, "nnz": 1507899, "total": 7087872}, "8": {"linear_attention_nnz": 829440, "linear_attention_total": 2359296, "linear_dense_nnz": 242688, "linear_dense_total": 4718592, "linear_nnz": 1072128, "linear_total": 7077888, "nnz": 1078142, "total": 7087872}, "9": {"linear_attention_nnz": 522240, "linear_attention_total": 2359296, "linear_dense_nnz": 133632, "linear_dense_total": 4718592, "linear_nnz": 655872, "linear_total": 7077888, "nnz": 661271, "total": 7087872}}, "linear_nnz": 15282688, "linear_sparsity": 82.00653452932099, "linear_total": 84934656, "nnz": 39193145, "pruned_heads": {"0": [0, 2, 4, 5, 6, 11], "1": [0, 2, 3, 5, 6, 7, 8], "10": [1, 2, 4, 5, 6, 7, 8], "11": [0, 2, 3, 5, 7, 8, 10, 11], "2": [8, 4, 7], "3": [2, 4, 6, 7], "4": [1, 2, 6, 7, 11], "5": [1, 2, 5, 6, 7, 11], "6": [0, 2, 3, 6, 7, 10], "7": [1, 3, 6, 7, 11], "8": [0, 8, 4], "9": [1, 2, 4, 5, 7, 9, 10]}, "total": 108893186, "total_sparsity": 64.00771578122438}, "training_args": {"_n_gpu": -1, "adafactor": false, "adam_beta1": 0.9, "adam_beta2": 0.999, "adam_epsilon": 1e-08, "dataloader_drop_last": false, "dataloader_num_workers": 0, "dataloader_pin_memory": true, "ddp_find_unused_parameters": null, "debug": false, "deepspeed": null, "disable_tqdm": false, "do_eval": 1, "do_predict": false, "do_train": 1, "eval_accumulation_steps": null, "eval_steps": 5000, "evaluation_strategy": "steps", "fp16": false, "fp16_backend": "auto", "fp16_full_eval": false, "fp16_opt_level": "O1", "gradient_accumulation_steps": 1, "greater_is_better": null, "group_by_length": false, "ignore_data_skip": false, "label_names": null, "label_smoothing_factor": 0.0, "learning_rate": 3e-05, "load_best_model_at_end": false, "local_rank": -1, "logging_dir": "/data_2to/devel_data/nn_pruning/output/squad_test_9_fullpatch4/", "logging_first_step": false, "logging_steps": 250, "logging_strategy": "steps", "lr_scheduler_type": "linear", "max_grad_norm": 1.0, "max_steps": -1, "metric_for_best_model": null, "no_cuda": false, "num_train_epochs": 20, "optimize_model_before_eval": "disabled", "output_dir": "/data_2to/devel_data/nn_pruning/output/squad_test_9_fullpatch4/", "overwrite_output_dir": 1, "past_index": -1, "per_device_eval_batch_size": 8, "per_device_train_batch_size": 16, "per_gpu_eval_batch_size": null, "per_gpu_train_batch_size": null, "prediction_loss_only": false, "remove_unused_columns": true, "report_to": null, "run_name": "/data_2to/devel_data/nn_pruning/output/squad_test_9_fullpatch4/", "save_steps": 5000, "save_strategy": "steps", "save_total_limit": 50, "seed": 17, "sharded_ddp": "", "skip_memory_metrics": false, "tpu_metrics_debug": false, "tpu_num_cores": null, "warmup_ratio": 0.0, "warmup_steps": 5400, "weight_decay": 0.0}}, "f1": 85.89097404430157, "fill_rate": 0.17993465470679015, "speedup": 2.349631389184198}}
{"fill_rate": 0.155249324845679, "f1": 85.63059701238892, "meta": {"annotate": "15", "cat_fun_name": "is_new_xp", "checkpoint": {"config": {"_name_or_path": "bert-base-uncased", "architectures": ["BertForQuestionAnswering"], "attention_probs_dropout_prob": 0.1, "gradient_checkpointing": false, "hidden_act": "gelu", "hidden_dropout_prob": 0.1, "hidden_size": 768, "initializer_range": 0.02, "intermediate_size": 3072, "layer_norm_eps": 1e-12, "max_position_embeddings": 512, "model_type": "bert", "num_attention_heads": 12, "num_hidden_layers": 12, "pad_token_id": 0, "position_embedding_type": "absolute", "type_vocab_size": 2, "vocab_size": 30522}, "eval_metrics": {"exact_match": 77.42667928098392, "f1": 85.63059701238892}, "path": "/data_2to/devel_data/nn_pruning/output/squad_test_9_fullpatch4/hp_od-__data_2to__devel_data__nn_pruning__output__squad_test_9_fullpatch4___es-steps_nte20_ls250_stl50_est5000_rn-__data_2to__devel_data__nn_pruning__output__squad_test_9_fullpatch4_--6b7cbdb694e8fe5f/checkpoint-95000", "sparse_args": {"ampere_pruning_method": "disabled", "attention_block_cols": 32, "attention_block_rows": 32, "attention_lambda": 1.0, "attention_output_with_dense": 0, "attention_pruning_method": "sigmoied_threshold", "bias_mask": true, "dense_block_cols": 1, "dense_block_rows": 1, "dense_lambda": 1.0, "dense_pruning_method": "sigmoied_threshold:1d_alt", "distil_alpha_ce": 0.1, "distil_alpha_teacher": 0.9, "distil_teacher_name_or_path": "bert-large-uncased-whole-word-masking-finetuned-squad", "distil_temperature": 2.0, "final_ampere_temperature": 20.0, "final_finetune": false, "final_threshold": 0.1, "final_warmup": 10, "gelu_patch": 1, "gelu_patch_steps": 50000, "initial_ampere_temperature": 0.0, "initial_threshold": 0, "initial_warmup": 1, "layer_norm_patch": 1, "layer_norm_patch_start_delta": 0.99, "layer_norm_patch_steps": 50000, "linear_min_parameters": 0, "mask_init": "constant", "mask_scale": 0.0, "mask_scores_learning_rate": 0.01, "regularization": "l1", "regularization_final_lambda": 30}, "speed": {"cuda_eval_elapsed_time": 15.290082546234132, "eval_elapsed_time": 22.249811742454767}, "speedup": 2.5241454968388446, "stats": {"layers": {"0": {"linear_attention_nnz": 613376, "linear_attention_total": 2359296, "linear_dense_nnz": 400896, "linear_dense_total": 4718592, "linear_nnz": 1014272, "linear_total": 7077888, "nnz": 1019909, "total": 7087872}, "1": {"linear_attention_nnz": 542720, "linear_attention_total": 2359296, "linear_dense_nnz": 494592, "linear_dense_total": 4718592, "linear_nnz": 1037312, "linear_total": 7077888, "nnz": 1043010, "total": 7087872}, "10": {"linear_attention_nnz": 417792, "linear_attention_total": 2359296, "linear_dense_nnz": 231936, "linear_dense_total": 4718592, "linear_nnz": 649728, "linear_total": 7077888, "nnz": 655095, "total": 7087872}, "11": {"linear_attention_nnz": 276480, "linear_attention_total": 2359296, "linear_dense_nnz": 345600, "linear_dense_total": 4718592, "linear_nnz": 622080, "linear_total": 7077888, "nnz": 627329, "total": 7087872}, "2": {"linear_attention_nnz": 825344, "linear_attention_total": 2359296, "linear_dense_nnz": 685056, "linear_dense_total": 4718592, "linear_nnz": 1510400, "linear_total": 7077888, "nnz": 1516542, "total": 7087872}, "3": {"linear_attention_nnz": 1183744, "linear_attention_total": 2359296, "linear_dense_nnz": 686592, "linear_dense_total": 4718592, "linear_nnz": 1870336, "linear_total": 7077888, "nnz": 1876863, "total": 7087872}, "4": {"linear_attention_nnz": 764928, "linear_attention_total": 2359296, "linear_dense_nnz": 674304, "linear_dense_total": 4718592, "linear_nnz": 1439232, "linear_total": 7077888, "nnz": 1445303, "total": 7087872}, "5": {"linear_attention_nnz": 518144, "linear_attention_total": 2359296, "linear_dense_nnz": 595968, "linear_dense_total": 4718592, "linear_nnz": 1114112, "linear_total": 7077888, "nnz": 1119780, "total": 7087872}, "6": {"linear_attention_nnz": 677888, "linear_attention_total": 2359296, "linear_dense_nnz": 552960, "linear_dense_total": 4718592, "linear_nnz": 1230848, "linear_total": 7077888, "nnz": 1236776, "total": 7087872}, "7": {"linear_attention_nnz": 875520, "linear_attention_total": 2359296, "linear_dense_nnz": 437760, "linear_dense_total": 4718592, "linear_nnz": 1313280, "linear_total": 7077888, "nnz": 1319357, "total": 7087872}, "8": {"linear_attention_nnz": 623616, "linear_attention_total": 2359296, "linear_dense_nnz": 228864, "linear_dense_total": 4718592, "linear_nnz": 852480, "linear_total": 7077888, "nnz": 858261, "total": 7087872}, "9": {"linear_attention_nnz": 401408, "linear_attention_total": 2359296, "linear_dense_nnz": 130560, "linear_dense_total": 4718592, "linear_nnz": 531968, "linear_total": 7077888, "nnz": 537333, "total": 7087872}}, "linear_nnz": 13186048, "linear_sparsity": 84.4750675154321, "linear_total": 84934656, "nnz": 37094280, "pruned_heads": {"0": [0, 2, 4, 5, 6, 7, 11], "1": [0, 2, 3, 5, 6, 7, 8], "10": [1, 2, 4, 5, 6, 7, 8], "11": [0, 2, 3, 5, 7, 8, 10, 11], "2": [8, 1, 4, 7], "3": [2, 4, 6, 7], "4": [1, 2, 6, 7, 8, 11], "5": [0, 1, 2, 3, 5, 6, 7, 11], "6": [0, 2, 3, 6, 7, 10], "7": [1, 3, 6, 7, 11], "8": [0, 4, 5, 7, 8], "9": [1, 2, 4, 5, 7, 9, 10]}, "total": 108893186, "total_sparsity": 65.9351687992672}, "training_args": {"_n_gpu": -1, "adafactor": false, "adam_beta1": 0.9, "adam_beta2": 0.999, "adam_epsilon": 1e-08, "dataloader_drop_last": false, "dataloader_num_workers": 0, "dataloader_pin_memory": true, "ddp_find_unused_parameters": null, "debug": false, "deepspeed": null, "disable_tqdm": false, "do_eval": 1, "do_predict": false, "do_train": 1, "eval_accumulation_steps": null, "eval_steps": 5000, "evaluation_strategy": "steps", "fp16": false, "fp16_backend": "auto", "fp16_full_eval": false, "fp16_opt_level": "O1", "gradient_accumulation_steps": 1, "greater_is_better": null, "group_by_length": false, "ignore_data_skip": false, "label_names": null, "label_smoothing_factor": 0.0, "learning_rate": 3e-05, "load_best_model_at_end": false, "local_rank": -1, "logging_dir": "/data_2to/devel_data/nn_pruning/output/squad_test_9_fullpatch4/", "logging_first_step": false, "logging_steps": 250, "logging_strategy": "steps", "lr_scheduler_type": "linear", "max_grad_norm": 1.0, "max_steps": -1, "metric_for_best_model": null, "no_cuda": false, "num_train_epochs": 20, "optimize_model_before_eval": "disabled", "output_dir": "/data_2to/devel_data/nn_pruning/output/squad_test_9_fullpatch4/", "overwrite_output_dir": 1, "past_index": -1, "per_device_eval_batch_size": 8, "per_device_train_batch_size": 16, "per_gpu_eval_batch_size": null, "per_gpu_train_batch_size": null, "prediction_loss_only": false, "remove_unused_columns": true, "report_to": null, "run_name": "/data_2to/devel_data/nn_pruning/output/squad_test_9_fullpatch4/", "save_steps": 5000, "save_strategy": "steps", "save_total_limit": 50, "seed": 17, "sharded_ddp": "", "skip_memory_metrics": false, "tpu_metrics_debug": false, "tpu_num_cores": null, "warmup_ratio": 0.0, "warmup_steps": 5400, "weight_decay": 0.0}}, "f1": 85.63059701238892, "fill_rate": 0.155249324845679, "speedup": 2.5241454968388446}}
{"fill_rate": 0.15110797646604934, "f1": 85.58086718082839, "meta": {"annotate": "15", "cat_fun_name": "is_new_xp", "checkpoint": {"config": {"_name_or_path": "bert-base-uncased", "architectures": ["BertForQuestionAnswering"], "attention_probs_dropout_prob": 0.1, "gradient_checkpointing": false, "hidden_act": "gelu", "hidden_dropout_prob": 0.1, "hidden_size": 768, "initializer_range": 0.02, "intermediate_size": 3072, "layer_norm_eps": 1e-12, "max_position_embeddings": 512, "model_type": "bert", "num_attention_heads": 12, "num_hidden_layers": 12, "pad_token_id": 0, "position_embedding_type": "absolute", "type_vocab_size": 2, "vocab_size": 30522}, "eval_metrics": {"exact_match": 77.6158940397351, "f1": 85.58086718082839}, "path": "/data_2to/devel_data/nn_pruning/output/squad_test_9_fullpatch4/hp_od-__data_2to__devel_data__nn_pruning__output__squad_test_9_fullpatch4___es-steps_nte20_ls250_stl50_est5000_rn-__data_2to__devel_data__nn_pruning__output__squad_test_9_fullpatch4_--6b7cbdb694e8fe5f/checkpoint-110000", "sparse_args": {"ampere_pruning_method": "disabled", "attention_block_cols": 32, "attention_block_rows": 32, "attention_lambda": 1.0, "attention_output_with_dense": 0, "attention_pruning_method": "sigmoied_threshold", "bias_mask": true, "dense_block_cols": 1, "dense_block_rows": 1, "dense_lambda": 1.0, "dense_pruning_method": "sigmoied_threshold:1d_alt", "distil_alpha_ce": 0.1, "distil_alpha_teacher": 0.9, "distil_teacher_name_or_path": "bert-large-uncased-whole-word-masking-finetuned-squad", "distil_temperature": 2.0, "final_ampere_temperature": 20.0, "final_finetune": false, "final_threshold": 0.1, "final_warmup": 10, "gelu_patch": 1, "gelu_patch_steps": 50000, "initial_ampere_temperature": 0.0, "initial_threshold": 0, "initial_warmup": 1, "layer_norm_patch": 1, "layer_norm_patch_start_delta": 0.99, "layer_norm_patch_steps": 50000, "linear_min_parameters": 0, "mask_init": "constant", "mask_scale": 0.0, "mask_scores_learning_rate": 0.01, "regularization": "l1", "regularization_final_lambda": 30}, "speed": {"cuda_eval_elapsed_time": 15.16314505004883, "eval_elapsed_time": 22.14020838122815}, "speedup": 2.5452762522539354, "stats": {"layers": {"0": {"linear_attention_nnz": 607232, "linear_attention_total": 2359296, "linear_dense_nnz": 391680, "linear_dense_total": 4718592, "linear_nnz": 998912, "linear_total": 7077888, "nnz": 1004543, "total": 7087872}, "1": {"linear_attention_nnz": 525312, "linear_attention_total": 2359296, "linear_dense_nnz": 488448, "linear_dense_total": 4718592, "linear_nnz": 1013760, "linear_total": 7077888, "nnz": 1019454, "total": 7087872}, "10": {"linear_attention_nnz": 400384, "linear_attention_total": 2359296, "linear_dense_nnz": 228864, "linear_dense_total": 4718592, "linear_nnz": 629248, "linear_total": 7077888, "nnz": 634581, "total": 7087872}, "11": {"linear_attention_nnz": 268288, "linear_attention_total": 2359296, "linear_dense_nnz": 337920, "linear_dense_total": 4718592, "linear_nnz": 606208, "linear_total": 7077888, "nnz": 611452, "total": 7087872}, "2": {"linear_attention_nnz": 774144, "linear_attention_total": 2359296, "linear_dense_nnz": 685056, "linear_dense_total": 4718592, "linear_nnz": 1459200, "linear_total": 7077888, "nnz": 1465310, "total": 7087872}, "3": {"linear_attention_nnz": 1130496, "linear_attention_total": 2359296, "linear_dense_nnz": 683520, "linear_dense_total": 4718592, "linear_nnz": 1814016, "linear_total": 7077888, "nnz": 1820509, "total": 7087872}, "4": {"linear_attention_nnz": 743424, "linear_attention_total": 2359296, "linear_dense_nnz": 668160, "linear_dense_total": 4718592, "linear_nnz": 1411584, "linear_total": 7077888, "nnz": 1417651, "total": 7087872}, "5": {"linear_attention_nnz": 513024, "linear_attention_total": 2359296, "linear_dense_nnz": 591360, "linear_dense_total": 4718592, "linear_nnz": 1104384, "linear_total": 7077888, "nnz": 1110049, "total": 7087872}, "6": {"linear_attention_nnz": 641024, "linear_attention_total": 2359296, "linear_dense_nnz": 551424, "linear_dense_total": 4718592, "linear_nnz": 1192448, "linear_total": 7077888, "nnz": 1198375, "total": 7087872}, "7": {"linear_attention_nnz": 849920, "linear_attention_total": 2359296, "linear_dense_nnz": 436224, "linear_dense_total": 4718592, "linear_nnz": 1286144, "linear_total": 7077888, "nnz": 1292220, "total": 7087872}, "8": {"linear_attention_nnz": 576512, "linear_attention_total": 2359296, "linear_dense_nnz": 225792, "linear_dense_total": 4718592, "linear_nnz": 802304, "linear_total": 7077888, "nnz": 808083, "total": 7087872}, "9": {"linear_attention_nnz": 387072, "linear_attention_total": 2359296, "linear_dense_nnz": 129024, "linear_dense_total": 4718592, "linear_nnz": 516096, "linear_total": 7077888, "nnz": 521396, "total": 7087872}}, "linear_nnz": 12834304, "linear_sparsity": 84.88920235339506, "linear_total": 84934656, "nnz": 36742345, "pruned_heads": {"0": [0, 2, 4, 5, 6, 7, 11], "1": [0, 2, 3, 5, 6, 7, 8], "10": [1, 2, 4, 5, 6, 7, 8], "11": [0, 2, 3, 5, 7, 8, 10, 11], "2": [1, 2, 4, 7, 8], "3": [2, 4, 6, 7], "4": [1, 2, 6, 7, 8, 11], "5": [0, 1, 2, 3, 5, 6, 7, 11], "6": [0, 2, 3, 6, 7, 10], "7": [1, 3, 6, 7, 11], "8": [0, 4, 5, 7, 8], "9": [1, 2, 4, 5, 7, 9, 10]}, "total": 108893186, "total_sparsity": 66.25836165726659}, "training_args": {"_n_gpu": -1, "adafactor": false, "adam_beta1": 0.9, "adam_beta2": 0.999, "adam_epsilon": 1e-08, "dataloader_drop_last": false, "dataloader_num_workers": 0, "dataloader_pin_memory": true, "ddp_find_unused_parameters": null, "debug": false, "deepspeed": null, "disable_tqdm": false, "do_eval": 1, "do_predict": false, "do_train": 1, "eval_accumulation_steps": null, "eval_steps": 5000, "evaluation_strategy": "steps", "fp16": false, "fp16_backend": "auto", "fp16_full_eval": false, "fp16_opt_level": "O1", "gradient_accumulation_steps": 1, "greater_is_better": null, "group_by_length": false, "ignore_data_skip": false, "label_names": null, "label_smoothing_factor": 0.0, "learning_rate": 3e-05, "load_best_model_at_end": false, "local_rank": -1, "logging_dir": "/data_2to/devel_data/nn_pruning/output/squad_test_9_fullpatch4/", "logging_first_step": false, "logging_steps": 250, "logging_strategy": "steps", "lr_scheduler_type": "linear", "max_grad_norm": 1.0, "max_steps": -1, "metric_for_best_model": null, "no_cuda": false, "num_train_epochs": 20, "optimize_model_before_eval": "disabled", "output_dir": "/data_2to/devel_data/nn_pruning/output/squad_test_9_fullpatch4/", "overwrite_output_dir": 1, "past_index": -1, "per_device_eval_batch_size": 8, "per_device_train_batch_size": 16, "per_gpu_eval_batch_size": null, "per_gpu_train_batch_size": null, "prediction_loss_only": false, "remove_unused_columns": true, "report_to": null, "run_name": "/data_2to/devel_data/nn_pruning/output/squad_test_9_fullpatch4/", "save_steps": 5000, "save_strategy": "steps", "save_total_limit": 50, "seed": 17, "sharded_ddp": "", "skip_memory_metrics": false, "tpu_metrics_debug": false, "tpu_num_cores": null, "warmup_ratio": 0.0, "warmup_steps": 5400, "weight_decay": 0.0}}, "f1": 85.58086718082839, "fill_rate": 0.15110797646604934, "speedup": 2.5452762522539354}}
