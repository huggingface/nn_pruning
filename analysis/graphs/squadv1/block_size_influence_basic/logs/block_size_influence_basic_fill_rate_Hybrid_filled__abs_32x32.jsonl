{"fill_rate": 0.3628472222222222, "f1": 88.72194531479171, "meta": {"annotate": "36", "cat_fun_name": "is_new_xp", "checkpoint": {"config": {"_name_or_path": "/home/lagunas/devel/hf/nn_pruning/nn_pruning/analysis/tmp_finetune", "architectures": ["BertForQuestionAnswering"], "attention_probs_dropout_prob": 0.1, "gradient_checkpointing": false, "hidden_act": "gelu", "hidden_dropout_prob": 0.1, "hidden_size": 768, "initializer_range": 0.02, "intermediate_size": 3072, "layer_norm_eps": 1e-12, "max_position_embeddings": 512, "model_type": "bert", "num_attention_heads": 12, "num_hidden_layers": 12, "pad_token_id": 0, "position_embedding_type": "absolute", "pruned_heads": {"0": [2, 4, 5, 6, 7], "1": [0, 2, 3, 5, 6, 7, 8], "10": [1, 4, 5, 6, 7], "11": [0, 2, 5, 6, 7, 8, 11], "2": [8, 4, 7], "3": [2, 4, 6], "4": [2], "5": [1, 2], "6": [2, 3, 7], "7": [11, 3, 6, 7], "8": [0, 4], "9": [1, 4, 5, 7, 9, 10]}, "type_vocab_size": 2, "vocab_size": 30522}, "eval_metrics": {"exact_match": 81.69347209082308, "f1": 88.72194531479171}, "path": "/data_2to/devel_data/nn_pruning/output/squad_test_final_fine_tune/fine_tuned_aws_nn-pruning-v10-a32-l5-dl0-5--2021-01-21--00-52-45/checkpoint-22132", "source_checkpoint": "/data_2to/devel_data/nn_pruning/output/squad_test_aws/aws_nn-pruning-v10-a32-l5-dl0-5--2021-01-21--00-52-45/checkpoint-95000", "sparse_args": {"ampere_pruning_method": "disabled", "attention_block_cols": 1, "attention_block_rows": 1, "attention_lambda": 1.0, "attention_output_with_dense": 0, "attention_pruning_method": "topK", "bias_mask": true, "dense_block_cols": 1, "dense_block_rows": 1, "dense_lambda": 1.0, "dense_pruning_method": "topK", "distil_alpha_ce": 0.1, "distil_alpha_teacher": 0.9, "distil_teacher_name_or_path": "csarron/bert-base-uncased-squad-v1", "distil_temperature": 2.0, "final_ampere_temperature": 20.0, "final_finetune": 1, "final_threshold": 0.5, "final_warmup": 0, "initial_ampere_temperature": 0.0, "initial_threshold": 1.0, "initial_warmup": 0, "mask_init": "constant", "mask_scale": 0.0, "mask_scores_learning_rate": 0.01, "regularization": "", "regularization_final_lambda": 0}, "speed": {"cuda_eval_elapsed_time": 20.951393741607667, "eval_elapsed_time": 28.213609586004168}, "speedup": 1.8420919143305463, "stats": {"layers": {"0": {"linear_attention_nnz": 1376256, "linear_attention_total": 2359296, "linear_dense_nnz": 1125888, "linear_dense_total": 4718592, "linear_nnz": 2502144, "linear_total": 7077888, "nnz": 2508829, "total": 7086912}, "1": {"linear_attention_nnz": 983040, "linear_attention_total": 2359296, "linear_dense_nnz": 1285632, "linear_dense_total": 4718592, "linear_nnz": 2268672, "linear_total": 7077888, "nnz": 2275077, "total": 7086528}, "10": {"linear_attention_nnz": 1376256, "linear_attention_total": 2359296, "linear_dense_nnz": 168960, "linear_dense_total": 4718592, "linear_nnz": 1545216, "linear_total": 7077888, "nnz": 1551278, "total": 7086912}, "11": {"linear_attention_nnz": 983040, "linear_attention_total": 2359296, "linear_dense_nnz": 485376, "linear_dense_total": 4718592, "linear_nnz": 1468416, "linear_total": 7077888, "nnz": 1474300, "total": 7086528}, "2": {"linear_attention_nnz": 1769472, "linear_attention_total": 2359296, "linear_dense_nnz": 1523712, "linear_dense_total": 4718592, "linear_nnz": 3293184, "linear_total": 7077888, "nnz": 3300512, "total": 7087296}, "3": {"linear_attention_nnz": 1769472, "linear_attention_total": 2359296, "linear_dense_nnz": 1555968, "linear_dense_total": 4718592, "linear_nnz": 3325440, "linear_total": 7077888, "nnz": 3332789, "total": 7087296}, "4": {"linear_attention_nnz": 2162688, "linear_attention_total": 2359296, "linear_dense_nnz": 1617408, "linear_dense_total": 4718592, "linear_nnz": 3780096, "linear_total": 7077888, "nnz": 3787869, "total": 7087680}, "5": {"linear_attention_nnz": 1966080, "linear_attention_total": 2359296, "linear_dense_nnz": 1514496, "linear_dense_total": 4718592, "linear_nnz": 3480576, "linear_total": 7077888, "nnz": 3488090, "total": 7087488}, "6": {"linear_attention_nnz": 1769472, "linear_attention_total": 2359296, "linear_dense_nnz": 1135104, "linear_dense_total": 4718592, "linear_nnz": 2904576, "linear_total": 7077888, "nnz": 2911651, "total": 7087296}, "7": {"linear_attention_nnz": 1572864, "linear_attention_total": 2359296, "linear_dense_nnz": 847872, "linear_dense_total": 4718592, "linear_nnz": 2420736, "linear_total": 7077888, "nnz": 2427432, "total": 7087104}, "8": {"linear_attention_nnz": 1966080, "linear_attention_total": 2359296, "linear_dense_nnz": 474624, "linear_dense_total": 4718592, "linear_nnz": 2440704, "linear_total": 7077888, "nnz": 2447541, "total": 7087488}, "9": {"linear_attention_nnz": 1179648, "linear_attention_total": 2359296, "linear_dense_nnz": 208896, "linear_dense_total": 4718592, "linear_nnz": 1388544, "linear_total": 7077888, "nnz": 1394440, "total": 7086720}}, "linear_nnz": 30818304, "linear_sparsity": 63.71527777777778, "linear_total": 84934656, "nnz": 54738530, "pruned_heads": {"0": [2, 4, 5, 6, 7], "1": [0, 2, 3, 5, 6, 7, 8], "10": [1, 4, 5, 6, 7], "11": [0, 2, 5, 6, 7, 8, 11], "2": [8, 4, 7], "3": [2, 4, 6], "4": [2], "5": [1, 2], "6": [2, 3, 7], "7": [11, 3, 6, 7], "8": [0, 4], "9": [1, 4, 5, 7, 9, 10]}, "total": 108883970, "total_sparsity": 49.72765045212808}, "training_args": {"_n_gpu": -1, "adafactor": false, "adam_beta1": 0.9, "adam_beta2": 0.999, "adam_epsilon": 1e-08, "dataloader_drop_last": false, "dataloader_num_workers": 0, "dataloader_pin_memory": true, "ddp_find_unused_parameters": null, "debug": false, "deepspeed": null, "disable_tqdm": false, "do_eval": 1, "do_predict": false, "do_train": 1, "eval_accumulation_steps": null, "eval_steps": 2500, "evaluation_strategy": "steps", "fp16": false, "fp16_backend": "auto", "fp16_full_eval": false, "fp16_opt_level": "O1", "gradient_accumulation_steps": 1, "greater_is_better": null, "group_by_length": false, "ignore_data_skip": false, "label_names": null, "label_smoothing_factor": 0.0, "learning_rate": 3e-05, "load_best_model_at_end": false, "local_rank": -1, "logging_dir": "/data_2to/devel_data/nn_pruning/output/squad_test_final_fine_tune/fine_tuned_aws_nn-pruning-v10-a32-l5-dl0-5--2021-01-21--00-52-45", "logging_first_step": false, "logging_steps": 250, "logging_strategy": "steps", "lr_scheduler_type": "linear", "max_grad_norm": 1.0, "max_steps": -1, "metric_for_best_model": null, "no_cuda": false, "num_train_epochs": 4, "optimize_model_before_eval": "disabled", "output_dir": "/data_2to/devel_data/nn_pruning/output/squad_test_final_fine_tune/fine_tuned_aws_nn-pruning-v10-a32-l5-dl0-5--2021-01-21--00-52-45", "overwrite_output_dir": 1, "past_index": -1, "per_device_eval_batch_size": 128, "per_device_train_batch_size": 16, "per_gpu_eval_batch_size": null, "per_gpu_train_batch_size": null, "prediction_loss_only": false, "remove_unused_columns": true, "report_to": null, "run_name": "/data_2to/devel_data/nn_pruning/output/squad_test_final_fine_tune/fine_tuned_aws_nn-pruning-v10-a32-l5-dl0-5--2021-01-21--00-52-45", "save_steps": 2500, "save_strategy": "steps", "save_total_limit": 50, "seed": 17, "sharded_ddp": "", "skip_memory_metrics": false, "tpu_metrics_debug": false, "tpu_num_cores": null, "warmup_ratio": 0.0, "warmup_steps": 10, "weight_decay": 0.0}}, "f1": 88.72194531479171, "fill_rate": 0.3628472222222222, "speedup": 1.8420919143305463}}
{"fill_rate": 0.31168619791666674, "f1": 88.26868699204444, "meta": {"annotate": "31", "cat_fun_name": "is_new_xp", "checkpoint": {"config": {"_name_or_path": "/home/lagunas/devel/hf/nn_pruning/nn_pruning/analysis/tmp_finetune", "architectures": ["BertForQuestionAnswering"], "attention_probs_dropout_prob": 0.1, "gradient_checkpointing": false, "hidden_act": "gelu", "hidden_dropout_prob": 0.1, "hidden_size": 768, "initializer_range": 0.02, "intermediate_size": 3072, "layer_norm_eps": 1e-12, "max_position_embeddings": 512, "model_type": "bert", "num_attention_heads": 12, "num_hidden_layers": 12, "pad_token_id": 0, "position_embedding_type": "absolute", "pruned_heads": {"0": [0, 2, 4, 5, 6], "1": [0, 2, 3, 5, 6, 7, 8], "10": [1, 4, 5, 7], "11": [0, 2, 5, 6, 7, 8, 11], "2": [8, 4], "3": [2, 4, 6], "4": [2], "5": [1, 2], "6": [2, 3, 7], "7": [11, 3, 6, 7], "8": [0, 4], "9": [1, 4, 5, 7, 9, 10]}, "type_vocab_size": 2, "vocab_size": 30522}, "eval_metrics": {"exact_match": 80.86092715231788, "f1": 88.26868699204444}, "path": "/data_2to/devel_data/nn_pruning/output/squad_test_final_fine_tune/fine_tuned_aws_nn-pruning-v10-a32-l5-dl1--2021-01-21--00-52-16/checkpoint-20000", "source_checkpoint": "/data_2to/devel_data/nn_pruning/output/squad_test_aws/aws_nn-pruning-v10-a32-l5-dl1--2021-01-21--00-52-16/checkpoint-110660", "sparse_args": {"ampere_pruning_method": "disabled", "attention_block_cols": 1, "attention_block_rows": 1, "attention_lambda": 1.0, "attention_output_with_dense": 0, "attention_pruning_method": "topK", "bias_mask": true, "dense_block_cols": 1, "dense_block_rows": 1, "dense_lambda": 1.0, "dense_pruning_method": "topK", "distil_alpha_ce": 0.1, "distil_alpha_teacher": 0.9, "distil_teacher_name_or_path": "csarron/bert-base-uncased-squad-v1", "distil_temperature": 2.0, "final_ampere_temperature": 20.0, "final_finetune": 1, "final_threshold": 0.5, "final_warmup": 0, "initial_ampere_temperature": 0.0, "initial_threshold": 1.0, "initial_warmup": 0, "mask_init": "constant", "mask_scale": 0.0, "mask_scores_learning_rate": 0.01, "regularization": "", "regularization_final_lambda": 0}, "speed": {"cuda_eval_elapsed_time": 19.458871116638186, "eval_elapsed_time": 26.62503844080493}, "speedup": 1.98338294004996, "stats": {"layers": {"0": {"linear_attention_nnz": 1376256, "linear_attention_total": 2359296, "linear_dense_nnz": 526848, "linear_dense_total": 4718592, "linear_nnz": 1903104, "linear_total": 7077888, "nnz": 1909399, "total": 7086912}, "1": {"linear_attention_nnz": 983040, "linear_attention_total": 2359296, "linear_dense_nnz": 752640, "linear_dense_total": 4718592, "linear_nnz": 1735680, "linear_total": 7077888, "nnz": 1741738, "total": 7086528}, "10": {"linear_attention_nnz": 1572864, "linear_attention_total": 2359296, "linear_dense_nnz": 98304, "linear_dense_total": 4718592, "linear_nnz": 1671168, "linear_total": 7077888, "nnz": 1677376, "total": 7087104}, "11": {"linear_attention_nnz": 983040, "linear_attention_total": 2359296, "linear_dense_nnz": 262656, "linear_dense_total": 4718592, "linear_nnz": 1245696, "linear_total": 7077888, "nnz": 1251435, "total": 7086528}, "2": {"linear_attention_nnz": 1966080, "linear_attention_total": 2359296, "linear_dense_nnz": 873984, "linear_dense_total": 4718592, "linear_nnz": 2840064, "linear_total": 7077888, "nnz": 2847161, "total": 7087488}, "3": {"linear_attention_nnz": 1769472, "linear_attention_total": 2359296, "linear_dense_nnz": 952320, "linear_dense_total": 4718592, "linear_nnz": 2721792, "linear_total": 7077888, "nnz": 2728748, "total": 7087296}, "4": {"linear_attention_nnz": 2162688, "linear_attention_total": 2359296, "linear_dense_nnz": 1046016, "linear_dense_total": 4718592, "linear_nnz": 3208704, "linear_total": 7077888, "nnz": 3216105, "total": 7087680}, "5": {"linear_attention_nnz": 1966080, "linear_attention_total": 2359296, "linear_dense_nnz": 986112, "linear_dense_total": 4718592, "linear_nnz": 2952192, "linear_total": 7077888, "nnz": 2959362, "total": 7087488}, "6": {"linear_attention_nnz": 1769472, "linear_attention_total": 2359296, "linear_dense_nnz": 740352, "linear_dense_total": 4718592, "linear_nnz": 2509824, "linear_total": 7077888, "nnz": 2516642, "total": 7087296}, "7": {"linear_attention_nnz": 1572864, "linear_attention_total": 2359296, "linear_dense_nnz": 559104, "linear_dense_total": 4718592, "linear_nnz": 2131968, "linear_total": 7077888, "nnz": 2138476, "total": 7087104}, "8": {"linear_attention_nnz": 1966080, "linear_attention_total": 2359296, "linear_dense_nnz": 293376, "linear_dense_total": 4718592, "linear_nnz": 2259456, "linear_total": 7077888, "nnz": 2266175, "total": 7087488}, "9": {"linear_attention_nnz": 1179648, "linear_attention_total": 2359296, "linear_dense_nnz": 113664, "linear_dense_total": 4718592, "linear_nnz": 1293312, "linear_total": 7077888, "nnz": 1299146, "total": 7086720}}, "linear_nnz": 26472960, "linear_sparsity": 68.83138020833333, "linear_total": 84934656, "nnz": 50390485, "pruned_heads": {"0": [0, 2, 4, 5, 6], "1": [0, 2, 3, 5, 6, 7, 8], "10": [1, 4, 5, 7], "11": [0, 2, 5, 6, 7, 8, 11], "2": [8, 4], "3": [2, 4, 6], "4": [2], "5": [1, 2], "6": [2, 3, 7], "7": [11, 3, 6, 7], "8": [0, 4], "9": [1, 4, 5, 7, 9, 10]}, "total": 108884354, "total_sparsity": 53.72109660493554}, "training_args": {"_n_gpu": -1, "adafactor": false, "adam_beta1": 0.9, "adam_beta2": 0.999, "adam_epsilon": 1e-08, "dataloader_drop_last": false, "dataloader_num_workers": 0, "dataloader_pin_memory": true, "ddp_find_unused_parameters": null, "debug": false, "deepspeed": null, "disable_tqdm": false, "do_eval": 1, "do_predict": false, "do_train": 1, "eval_accumulation_steps": null, "eval_steps": 2500, "evaluation_strategy": "steps", "fp16": false, "fp16_backend": "auto", "fp16_full_eval": false, "fp16_opt_level": "O1", "gradient_accumulation_steps": 1, "greater_is_better": null, "group_by_length": false, "ignore_data_skip": false, "label_names": null, "label_smoothing_factor": 0.0, "learning_rate": 3e-05, "load_best_model_at_end": false, "local_rank": -1, "logging_dir": "/data_2to/devel_data/nn_pruning/output/squad_test_final_fine_tune/fine_tuned_aws_nn-pruning-v10-a32-l5-dl1--2021-01-21--00-52-16", "logging_first_step": false, "logging_steps": 250, "logging_strategy": "steps", "lr_scheduler_type": "linear", "max_grad_norm": 1.0, "max_steps": -1, "metric_for_best_model": null, "no_cuda": false, "num_train_epochs": 4, "optimize_model_before_eval": "disabled", "output_dir": "/data_2to/devel_data/nn_pruning/output/squad_test_final_fine_tune/fine_tuned_aws_nn-pruning-v10-a32-l5-dl1--2021-01-21--00-52-16", "overwrite_output_dir": 1, "past_index": -1, "per_device_eval_batch_size": 128, "per_device_train_batch_size": 16, "per_gpu_eval_batch_size": null, "per_gpu_train_batch_size": null, "prediction_loss_only": false, "remove_unused_columns": true, "report_to": null, "run_name": "/data_2to/devel_data/nn_pruning/output/squad_test_final_fine_tune/fine_tuned_aws_nn-pruning-v10-a32-l5-dl1--2021-01-21--00-52-16", "save_steps": 2500, "save_strategy": "steps", "save_total_limit": 50, "seed": 17, "sharded_ddp": "", "skip_memory_metrics": false, "tpu_metrics_debug": false, "tpu_num_cores": null, "warmup_ratio": 0.0, "warmup_steps": 10, "weight_decay": 0.0}}, "f1": 88.26868699204444, "fill_rate": 0.31168619791666674, "speedup": 1.98338294004996}}
{"fill_rate": 0.279712818287037, "f1": 88.06386432532665, "meta": {"annotate": "27", "cat_fun_name": "is_new_xp", "checkpoint": {"config": {"_name_or_path": "/home/lagunas/devel/hf/nn_pruning/nn_pruning/analysis/tmp_finetune", "architectures": ["BertForQuestionAnswering"], "attention_probs_dropout_prob": 0.1, "gradient_checkpointing": false, "hidden_act": "gelu", "hidden_dropout_prob": 0.1, "hidden_size": 768, "initializer_range": 0.02, "intermediate_size": 3072, "layer_norm_eps": 1e-12, "max_position_embeddings": 512, "model_type": "bert", "num_attention_heads": 12, "num_hidden_layers": 12, "pad_token_id": 0, "position_embedding_type": "absolute", "pruned_heads": {"0": [0, 2, 4, 5, 6, 7, 9, 11], "1": [0, 2, 3, 5, 6, 7, 8, 9], "10": [1, 4, 5, 6, 7, 8], "11": [0, 2, 3, 5, 6, 7, 8, 10, 11], "2": [8, 4, 7], "3": [2, 4, 6, 7], "4": [1, 2], "5": [1, 2, 5, 6, 7], "6": [0, 2, 3, 7], "7": [1, 3, 6, 7, 11], "8": [0, 8, 3, 4], "9": [1, 3, 4, 5, 7, 9, 10]}, "type_vocab_size": 2, "vocab_size": 30522}, "eval_metrics": {"exact_match": 80.69063386944181, "f1": 88.06386432532665}, "path": "/data_2to/devel_data/nn_pruning/output/squad_test_final_fine_tune/fine_tuned_aws_nn-pruning-v10-a32-l10-dl0-5--2021-01-21--00-54-13/checkpoint-22132", "source_checkpoint": "/data_2to/devel_data/nn_pruning/output/squad_test_aws/aws_nn-pruning-v10-a32-l10-dl0-5--2021-01-21--00-54-13/checkpoint-110660", "sparse_args": {"ampere_pruning_method": "disabled", "attention_block_cols": 1, "attention_block_rows": 1, "attention_lambda": 1.0, "attention_output_with_dense": 0, "attention_pruning_method": "topK", "bias_mask": true, "dense_block_cols": 1, "dense_block_rows": 1, "dense_lambda": 1.0, "dense_pruning_method": "topK", "distil_alpha_ce": 0.1, "distil_alpha_teacher": 0.9, "distil_teacher_name_or_path": "csarron/bert-base-uncased-squad-v1", "distil_temperature": 2.0, "final_ampere_temperature": 20.0, "final_finetune": 1, "final_threshold": 0.5, "final_warmup": 0, "initial_ampere_temperature": 0.0, "initial_threshold": 1.0, "initial_warmup": 0, "mask_init": "constant", "mask_scale": 0.0, "mask_scores_learning_rate": 0.01, "regularization": "", "regularization_final_lambda": 0}, "speed": {"cuda_eval_elapsed_time": 17.390718185424806, "eval_elapsed_time": 24.534384376835078}, "speedup": 2.2192523962418718, "stats": {"layers": {"0": {"linear_attention_nnz": 786432, "linear_attention_total": 2359296, "linear_dense_nnz": 634368, "linear_dense_total": 4718592, "linear_nnz": 1420800, "linear_total": 7077888, "nnz": 1426589, "total": 7086336}, "1": {"linear_attention_nnz": 786432, "linear_attention_total": 2359296, "linear_dense_nnz": 916992, "linear_dense_total": 4718592, "linear_nnz": 1703424, "linear_total": 7077888, "nnz": 1709397, "total": 7086336}, "10": {"linear_attention_nnz": 1179648, "linear_attention_total": 2359296, "linear_dense_nnz": 112128, "linear_dense_total": 4718592, "linear_nnz": 1291776, "linear_total": 7077888, "nnz": 1297609, "total": 7086720}, "11": {"linear_attention_nnz": 589824, "linear_attention_total": 2359296, "linear_dense_nnz": 313344, "linear_dense_total": 4718592, "linear_nnz": 903168, "linear_total": 7077888, "nnz": 908556, "total": 7086144}, "2": {"linear_attention_nnz": 1769472, "linear_attention_total": 2359296, "linear_dense_nnz": 1016832, "linear_dense_total": 4718592, "linear_nnz": 2786304, "linear_total": 7077888, "nnz": 2793302, "total": 7087296}, "3": {"linear_attention_nnz": 1572864, "linear_attention_total": 2359296, "linear_dense_nnz": 1076736, "linear_dense_total": 4718592, "linear_nnz": 2649600, "linear_total": 7077888, "nnz": 2656445, "total": 7087104}, "4": {"linear_attention_nnz": 1966080, "linear_attention_total": 2359296, "linear_dense_nnz": 1158144, "linear_dense_total": 4718592, "linear_nnz": 3124224, "linear_total": 7077888, "nnz": 3131506, "total": 7087488}, "5": {"linear_attention_nnz": 1376256, "linear_attention_total": 2359296, "linear_dense_nnz": 1073664, "linear_dense_total": 4718592, "linear_nnz": 2449920, "linear_total": 7077888, "nnz": 2456571, "total": 7086912}, "6": {"linear_attention_nnz": 1572864, "linear_attention_total": 2359296, "linear_dense_nnz": 815616, "linear_dense_total": 4718592, "linear_nnz": 2388480, "linear_total": 7077888, "nnz": 2395155, "total": 7087104}, "7": {"linear_attention_nnz": 1376256, "linear_attention_total": 2359296, "linear_dense_nnz": 629760, "linear_dense_total": 4718592, "linear_nnz": 2006016, "linear_total": 7077888, "nnz": 2012378, "total": 7086912}, "8": {"linear_attention_nnz": 1572864, "linear_attention_total": 2359296, "linear_dense_nnz": 337920, "linear_dense_total": 4718592, "linear_nnz": 1910784, "linear_total": 7077888, "nnz": 1917148, "total": 7087104}, "9": {"linear_attention_nnz": 983040, "linear_attention_total": 2359296, "linear_dense_nnz": 139776, "linear_dense_total": 4718592, "linear_nnz": 1122816, "linear_total": 7077888, "nnz": 1128475, "total": 7086528}}, "linear_nnz": 23757312, "linear_sparsity": 72.0287181712963, "linear_total": 84934656, "nnz": 47671853, "pruned_heads": {"0": [0, 2, 4, 5, 6, 7, 9, 11], "1": [0, 2, 3, 5, 6, 7, 8, 9], "10": [1, 4, 5, 6, 7, 8], "11": [0, 2, 3, 5, 6, 7, 8, 10, 11], "2": [8, 4, 7], "3": [2, 4, 6, 7], "4": [1, 2], "5": [1, 2, 5, 6, 7], "6": [0, 2, 3, 7], "7": [1, 3, 6, 7, 11], "8": [0, 8, 3, 4], "9": [1, 3, 4, 5, 7, 9, 10]}, "total": 108880706, "total_sparsity": 56.216436546618276}, "training_args": {"_n_gpu": -1, "adafactor": false, "adam_beta1": 0.9, "adam_beta2": 0.999, "adam_epsilon": 1e-08, "dataloader_drop_last": false, "dataloader_num_workers": 0, "dataloader_pin_memory": true, "ddp_find_unused_parameters": null, "debug": false, "deepspeed": null, "disable_tqdm": false, "do_eval": 1, "do_predict": false, "do_train": 1, "eval_accumulation_steps": null, "eval_steps": 2500, "evaluation_strategy": "steps", "fp16": false, "fp16_backend": "auto", "fp16_full_eval": false, "fp16_opt_level": "O1", "gradient_accumulation_steps": 1, "greater_is_better": null, "group_by_length": false, "ignore_data_skip": false, "label_names": null, "label_smoothing_factor": 0.0, "learning_rate": 3e-05, "load_best_model_at_end": false, "local_rank": -1, "logging_dir": "/data_2to/devel_data/nn_pruning/output/squad_test_final_fine_tune/fine_tuned_aws_nn-pruning-v10-a32-l10-dl0-5--2021-01-21--00-54-13", "logging_first_step": false, "logging_steps": 250, "logging_strategy": "steps", "lr_scheduler_type": "linear", "max_grad_norm": 1.0, "max_steps": -1, "metric_for_best_model": null, "no_cuda": false, "num_train_epochs": 4, "optimize_model_before_eval": "disabled", "output_dir": "/data_2to/devel_data/nn_pruning/output/squad_test_final_fine_tune/fine_tuned_aws_nn-pruning-v10-a32-l10-dl0-5--2021-01-21--00-54-13", "overwrite_output_dir": 1, "past_index": -1, "per_device_eval_batch_size": 128, "per_device_train_batch_size": 16, "per_gpu_eval_batch_size": null, "per_gpu_train_batch_size": null, "prediction_loss_only": false, "remove_unused_columns": true, "report_to": null, "run_name": "/data_2to/devel_data/nn_pruning/output/squad_test_final_fine_tune/fine_tuned_aws_nn-pruning-v10-a32-l10-dl0-5--2021-01-21--00-54-13", "save_steps": 2500, "save_strategy": "steps", "save_total_limit": 50, "seed": 17, "sharded_ddp": "", "skip_memory_metrics": false, "tpu_metrics_debug": false, "tpu_num_cores": null, "warmup_ratio": 0.0, "warmup_steps": 10, "weight_decay": 0.0}}, "f1": 88.06386432532665, "fill_rate": 0.279712818287037, "speedup": 2.2192523962418718}}
{"fill_rate": 0.2539966724537037, "f1": 87.68464122182475, "meta": {"annotate": "25", "cat_fun_name": "is_new_xp", "checkpoint": {"config": {"_name_or_path": "/home/lagunas/devel/hf/nn_pruning/nn_pruning/analysis/tmp_finetune", "architectures": ["BertForQuestionAnswering"], "attention_probs_dropout_prob": 0.1, "gradient_checkpointing": false, "hidden_act": "gelu", "hidden_dropout_prob": 0.1, "hidden_size": 768, "initializer_range": 0.02, "intermediate_size": 3072, "layer_norm_eps": 1e-12, "max_position_embeddings": 512, "model_type": "bert", "num_attention_heads": 12, "num_hidden_layers": 12, "pad_token_id": 0, "position_embedding_type": "absolute", "pruned_heads": {"0": [0, 1, 2, 4, 5, 6], "1": [0, 2, 3, 5, 6, 7, 8], "10": [1, 4, 5, 6, 7, 8], "11": [0, 2, 3, 5, 6, 7, 8, 10, 11], "2": [8, 4, 7], "3": [2, 4, 6, 7], "4": [1, 2], "5": [1, 2, 6, 7], "6": [0, 2, 3, 7], "7": [1, 3, 6, 7, 11], "8": [0, 8, 4], "9": [1, 4, 5, 7, 9, 10]}, "type_vocab_size": 2, "vocab_size": 30522}, "eval_metrics": {"exact_match": 80.23651844843897, "f1": 87.68464122182475}, "path": "/data_2to/devel_data/nn_pruning/output/squad_test_final_fine_tune/fine_tuned_aws_nn-pruning-v10-a32-l10-dl1--2021-01-21--00-53-40/checkpoint-22132", "source_checkpoint": "/data_2to/devel_data/nn_pruning/output/squad_test_aws/aws_nn-pruning-v10-a32-l10-dl1--2021-01-21--00-53-40/checkpoint-110660", "sparse_args": {"ampere_pruning_method": "disabled", "attention_block_cols": 1, "attention_block_rows": 1, "attention_lambda": 1.0, "attention_output_with_dense": 0, "attention_pruning_method": "topK", "bias_mask": true, "dense_block_cols": 1, "dense_block_rows": 1, "dense_lambda": 1.0, "dense_pruning_method": "topK", "distil_alpha_ce": 0.1, "distil_alpha_teacher": 0.9, "distil_teacher_name_or_path": "csarron/bert-base-uncased-squad-v1", "distil_temperature": 2.0, "final_ampere_temperature": 20.0, "final_finetune": 1, "final_threshold": 0.5, "final_warmup": 0, "initial_ampere_temperature": 0.0, "initial_threshold": 1.0, "initial_warmup": 0, "mask_init": "constant", "mask_scale": 0.0, "mask_scores_learning_rate": 0.01, "regularization": "", "regularization_final_lambda": 0}, "speed": {"cuda_eval_elapsed_time": 17.154361824035647, "eval_elapsed_time": 24.304617804009467}, "speedup": 2.249829716853412, "stats": {"layers": {"0": {"linear_attention_nnz": 1179648, "linear_attention_total": 2359296, "linear_dense_nnz": 297984, "linear_dense_total": 4718592, "linear_nnz": 1477632, "linear_total": 7077888, "nnz": 1483586, "total": 7086720}, "1": {"linear_attention_nnz": 983040, "linear_attention_total": 2359296, "linear_dense_nnz": 483840, "linear_dense_total": 4718592, "linear_nnz": 1466880, "linear_total": 7077888, "nnz": 1472763, "total": 7086528}, "10": {"linear_attention_nnz": 1179648, "linear_attention_total": 2359296, "linear_dense_nnz": 73728, "linear_dense_total": 4718592, "linear_nnz": 1253376, "linear_total": 7077888, "nnz": 1259184, "total": 7086720}, "11": {"linear_attention_nnz": 589824, "linear_attention_total": 2359296, "linear_dense_nnz": 159744, "linear_dense_total": 4718592, "linear_nnz": 749568, "linear_total": 7077888, "nnz": 754856, "total": 7086144}, "2": {"linear_attention_nnz": 1769472, "linear_attention_total": 2359296, "linear_dense_nnz": 619008, "linear_dense_total": 4718592, "linear_nnz": 2388480, "linear_total": 7077888, "nnz": 2395219, "total": 7087296}, "3": {"linear_attention_nnz": 1572864, "linear_attention_total": 2359296, "linear_dense_nnz": 657408, "linear_dense_total": 4718592, "linear_nnz": 2230272, "linear_total": 7077888, "nnz": 2236844, "total": 7087104}, "4": {"linear_attention_nnz": 1966080, "linear_attention_total": 2359296, "linear_dense_nnz": 705024, "linear_dense_total": 4718592, "linear_nnz": 2671104, "linear_total": 7077888, "nnz": 2678091, "total": 7087488}, "5": {"linear_attention_nnz": 1572864, "linear_attention_total": 2359296, "linear_dense_nnz": 668160, "linear_dense_total": 4718592, "linear_nnz": 2241024, "linear_total": 7077888, "nnz": 2247603, "total": 7087104}, "6": {"linear_attention_nnz": 1572864, "linear_attention_total": 2359296, "linear_dense_nnz": 516096, "linear_dense_total": 4718592, "linear_nnz": 2088960, "linear_total": 7077888, "nnz": 2095440, "total": 7087104}, "7": {"linear_attention_nnz": 1376256, "linear_attention_total": 2359296, "linear_dense_nnz": 384000, "linear_dense_total": 4718592, "linear_nnz": 1760256, "linear_total": 7077888, "nnz": 1766458, "total": 7086912}, "8": {"linear_attention_nnz": 1769472, "linear_attention_total": 2359296, "linear_dense_nnz": 204288, "linear_dense_total": 4718592, "linear_nnz": 1973760, "linear_total": 7077888, "nnz": 1980229, "total": 7087296}, "9": {"linear_attention_nnz": 1179648, "linear_attention_total": 2359296, "linear_dense_nnz": 92160, "linear_dense_total": 4718592, "linear_nnz": 1271808, "linear_total": 7077888, "nnz": 1277628, "total": 7086720}}, "linear_nnz": 21573120, "linear_sparsity": 74.60033275462963, "linear_total": 84934656, "nnz": 45486623, "pruned_heads": {"0": [0, 1, 2, 4, 5, 6], "1": [0, 2, 3, 5, 6, 7, 8], "10": [1, 4, 5, 6, 7, 8], "11": [0, 2, 3, 5, 6, 7, 8, 10, 11], "2": [8, 4, 7], "3": [2, 4, 6, 7], "4": [1, 2], "5": [1, 2, 6, 7], "6": [0, 2, 3, 7], "7": [1, 3, 6, 7, 11], "8": [0, 8, 4], "9": [1, 4, 5, 7, 9, 10]}, "total": 108881858, "total_sparsity": 58.223873255359024}, "training_args": {"_n_gpu": -1, "adafactor": false, "adam_beta1": 0.9, "adam_beta2": 0.999, "adam_epsilon": 1e-08, "dataloader_drop_last": false, "dataloader_num_workers": 0, "dataloader_pin_memory": true, "ddp_find_unused_parameters": null, "debug": false, "deepspeed": null, "disable_tqdm": false, "do_eval": 1, "do_predict": false, "do_train": 1, "eval_accumulation_steps": null, "eval_steps": 2500, "evaluation_strategy": "steps", "fp16": false, "fp16_backend": "auto", "fp16_full_eval": false, "fp16_opt_level": "O1", "gradient_accumulation_steps": 1, "greater_is_better": null, "group_by_length": false, "ignore_data_skip": false, "label_names": null, "label_smoothing_factor": 0.0, "learning_rate": 3e-05, "load_best_model_at_end": false, "local_rank": -1, "logging_dir": "/data_2to/devel_data/nn_pruning/output/squad_test_final_fine_tune/fine_tuned_aws_nn-pruning-v10-a32-l10-dl1--2021-01-21--00-53-40", "logging_first_step": false, "logging_steps": 250, "logging_strategy": "steps", "lr_scheduler_type": "linear", "max_grad_norm": 1.0, "max_steps": -1, "metric_for_best_model": null, "no_cuda": false, "num_train_epochs": 4, "optimize_model_before_eval": "disabled", "output_dir": "/data_2to/devel_data/nn_pruning/output/squad_test_final_fine_tune/fine_tuned_aws_nn-pruning-v10-a32-l10-dl1--2021-01-21--00-53-40", "overwrite_output_dir": 1, "past_index": -1, "per_device_eval_batch_size": 128, "per_device_train_batch_size": 16, "per_gpu_eval_batch_size": null, "per_gpu_train_batch_size": null, "prediction_loss_only": false, "remove_unused_columns": true, "report_to": null, "run_name": "/data_2to/devel_data/nn_pruning/output/squad_test_final_fine_tune/fine_tuned_aws_nn-pruning-v10-a32-l10-dl1--2021-01-21--00-53-40", "save_steps": 2500, "save_strategy": "steps", "save_total_limit": 50, "seed": 17, "sharded_ddp": "", "skip_memory_metrics": false, "tpu_metrics_debug": false, "tpu_num_cores": null, "warmup_ratio": 0.0, "warmup_steps": 10, "weight_decay": 0.0}}, "f1": 87.68464122182475, "fill_rate": 0.2539966724537037, "speedup": 2.249829716853412}}
{"fill_rate": 0.21717664930555558, "f1": 87.22907143184382, "meta": {"annotate": "21", "cat_fun_name": "is_new_xp", "checkpoint": {"config": {"_name_or_path": "/home/lagunas/devel/hf/nn_pruning/nn_pruning/analysis/tmp_finetune", "architectures": ["BertForQuestionAnswering"], "attention_probs_dropout_prob": 0.1, "gradient_checkpointing": false, "hidden_act": "gelu", "hidden_dropout_prob": 0.1, "hidden_size": 768, "initializer_range": 0.02, "intermediate_size": 3072, "layer_norm_eps": 1e-12, "max_position_embeddings": 512, "model_type": "bert", "num_attention_heads": 12, "num_hidden_layers": 12, "pad_token_id": 0, "position_embedding_type": "absolute", "pruned_heads": {"0": [0, 2, 4, 5, 6, 7, 9, 11], "1": [0, 2, 3, 5, 6, 7, 8, 9], "10": [1, 4, 5, 6, 7, 8, 9], "11": [0, 2, 3, 5, 6, 7, 8, 10, 11], "2": [1, 2, 4, 7, 8, 11], "3": [2, 4, 6, 7, 10], "4": [0, 1, 2, 6, 11], "5": [0, 1, 2, 5, 6, 7, 11], "6": [0, 2, 3, 4, 7, 10], "7": [1, 3, 6, 7, 11], "8": [0, 2, 3, 4, 6, 8], "9": [1, 3, 4, 5, 7, 9, 10]}, "type_vocab_size": 2, "vocab_size": 30522}, "eval_metrics": {"exact_match": 79.4228949858089, "f1": 87.22907143184382}, "path": "/data_2to/devel_data/nn_pruning/output/squad_test_final_fine_tune/fine_tuned_aws_nn-pruning-v10-a32-l20-dl0-5--2021-01-21--00-55-44/checkpoint-22132", "source_checkpoint": "/data_2to/devel_data/nn_pruning/output/squad_test_aws/aws_nn-pruning-v10-a32-l20-dl0-5--2021-01-21--00-55-44/checkpoint-110000", "sparse_args": {"ampere_pruning_method": "disabled", "attention_block_cols": 1, "attention_block_rows": 1, "attention_lambda": 1.0, "attention_output_with_dense": 0, "attention_pruning_method": "topK", "bias_mask": true, "dense_block_cols": 1, "dense_block_rows": 1, "dense_lambda": 1.0, "dense_pruning_method": "topK", "distil_alpha_ce": 0.1, "distil_alpha_teacher": 0.9, "distil_teacher_name_or_path": "csarron/bert-base-uncased-squad-v1", "distil_temperature": 2.0, "final_ampere_temperature": 20.0, "final_finetune": 1, "final_threshold": 0.5, "final_warmup": 0, "initial_ampere_temperature": 0.0, "initial_threshold": 1.0, "initial_warmup": 0, "mask_init": "constant", "mask_scale": 0.0, "mask_scores_learning_rate": 0.01, "regularization": "", "regularization_final_lambda": 0}, "speed": {"cuda_eval_elapsed_time": 14.848762104034424, "eval_elapsed_time": 22.048566517885774}, "speedup": 2.5991656903766382, "stats": {"layers": {"0": {"linear_attention_nnz": 786432, "linear_attention_total": 2359296, "linear_dense_nnz": 411648, "linear_dense_total": 4718592, "linear_nnz": 1198080, "linear_total": 7077888, "nnz": 1203724, "total": 7086336}, "1": {"linear_attention_nnz": 786432, "linear_attention_total": 2359296, "linear_dense_nnz": 592896, "linear_dense_total": 4718592, "linear_nnz": 1379328, "linear_total": 7077888, "nnz": 1385090, "total": 7086336}, "10": {"linear_attention_nnz": 983040, "linear_attention_total": 2359296, "linear_dense_nnz": 87552, "linear_dense_total": 4718592, "linear_nnz": 1070592, "linear_total": 7077888, "nnz": 1076217, "total": 7086528}, "11": {"linear_attention_nnz": 589824, "linear_attention_total": 2359296, "linear_dense_nnz": 199680, "linear_dense_total": 4718592, "linear_nnz": 789504, "linear_total": 7077888, "nnz": 794818, "total": 7086144}, "2": {"linear_attention_nnz": 1179648, "linear_attention_total": 2359296, "linear_dense_nnz": 698880, "linear_dense_total": 4718592, "linear_nnz": 1878528, "linear_total": 7077888, "nnz": 1884743, "total": 7086720}, "3": {"linear_attention_nnz": 1376256, "linear_attention_total": 2359296, "linear_dense_nnz": 714240, "linear_dense_total": 4718592, "linear_nnz": 2090496, "linear_total": 7077888, "nnz": 2096913, "total": 7086912}, "4": {"linear_attention_nnz": 1376256, "linear_attention_total": 2359296, "linear_dense_nnz": 834048, "linear_dense_total": 4718592, "linear_nnz": 2210304, "linear_total": 7077888, "nnz": 2216799, "total": 7086912}, "5": {"linear_attention_nnz": 983040, "linear_attention_total": 2359296, "linear_dense_nnz": 743424, "linear_dense_total": 4718592, "linear_nnz": 1726464, "linear_total": 7077888, "nnz": 1732516, "total": 7086528}, "6": {"linear_attention_nnz": 1179648, "linear_attention_total": 2359296, "linear_dense_nnz": 568320, "linear_dense_total": 4718592, "linear_nnz": 1747968, "linear_total": 7077888, "nnz": 1754098, "total": 7086720}, "7": {"linear_attention_nnz": 1376256, "linear_attention_total": 2359296, "linear_dense_nnz": 450048, "linear_dense_total": 4718592, "linear_nnz": 1826304, "linear_total": 7077888, "nnz": 1832549, "total": 7086912}, "8": {"linear_attention_nnz": 1179648, "linear_attention_total": 2359296, "linear_dense_nnz": 264192, "linear_dense_total": 4718592, "linear_nnz": 1443840, "linear_total": 7077888, "nnz": 1449772, "total": 7086720}, "9": {"linear_attention_nnz": 983040, "linear_attention_total": 2359296, "linear_dense_nnz": 101376, "linear_dense_total": 4718592, "linear_nnz": 1084416, "linear_total": 7077888, "nnz": 1090050, "total": 7086528}}, "linear_nnz": 18445824, "linear_sparsity": 78.28233506944444, "linear_total": 84934656, "nnz": 42356011, "pruned_heads": {"0": [0, 2, 4, 5, 6, 7, 9, 11], "1": [0, 2, 3, 5, 6, 7, 8, 9], "10": [1, 4, 5, 6, 7, 8, 9], "11": [0, 2, 3, 5, 6, 7, 8, 10, 11], "2": [1, 2, 4, 7, 8, 11], "3": [2, 4, 6, 7, 10], "4": [0, 1, 2, 6, 11], "5": [0, 1, 2, 5, 6, 7, 11], "6": [0, 2, 3, 4, 7, 10], "7": [1, 3, 6, 7, 11], "8": [0, 2, 3, 4, 6, 8], "9": [1, 3, 4, 5, 7, 9, 10]}, "total": 108878018, "total_sparsity": 61.097738755677945}, "training_args": {"_n_gpu": -1, "adafactor": false, "adam_beta1": 0.9, "adam_beta2": 0.999, "adam_epsilon": 1e-08, "dataloader_drop_last": false, "dataloader_num_workers": 0, "dataloader_pin_memory": true, "ddp_find_unused_parameters": null, "debug": false, "deepspeed": null, "disable_tqdm": false, "do_eval": 1, "do_predict": false, "do_train": 1, "eval_accumulation_steps": null, "eval_steps": 2500, "evaluation_strategy": "steps", "fp16": false, "fp16_backend": "auto", "fp16_full_eval": false, "fp16_opt_level": "O1", "gradient_accumulation_steps": 1, "greater_is_better": null, "group_by_length": false, "ignore_data_skip": false, "label_names": null, "label_smoothing_factor": 0.0, "learning_rate": 3e-05, "load_best_model_at_end": false, "local_rank": -1, "logging_dir": "/data_2to/devel_data/nn_pruning/output/squad_test_final_fine_tune/fine_tuned_aws_nn-pruning-v10-a32-l20-dl0-5--2021-01-21--00-55-44", "logging_first_step": false, "logging_steps": 250, "logging_strategy": "steps", "lr_scheduler_type": "linear", "max_grad_norm": 1.0, "max_steps": -1, "metric_for_best_model": null, "no_cuda": false, "num_train_epochs": 4, "optimize_model_before_eval": "disabled", "output_dir": "/data_2to/devel_data/nn_pruning/output/squad_test_final_fine_tune/fine_tuned_aws_nn-pruning-v10-a32-l20-dl0-5--2021-01-21--00-55-44", "overwrite_output_dir": 1, "past_index": -1, "per_device_eval_batch_size": 128, "per_device_train_batch_size": 16, "per_gpu_eval_batch_size": null, "per_gpu_train_batch_size": null, "prediction_loss_only": false, "remove_unused_columns": true, "report_to": null, "run_name": "/data_2to/devel_data/nn_pruning/output/squad_test_final_fine_tune/fine_tuned_aws_nn-pruning-v10-a32-l20-dl0-5--2021-01-21--00-55-44", "save_steps": 2500, "save_strategy": "steps", "save_total_limit": 50, "seed": 17, "sharded_ddp": "", "skip_memory_metrics": false, "tpu_metrics_debug": false, "tpu_num_cores": null, "warmup_ratio": 0.0, "warmup_steps": 10, "weight_decay": 0.0}}, "f1": 87.22907143184382, "fill_rate": 0.21717664930555558, "speedup": 2.5991656903766382}}
{"fill_rate": 0.1933774594907408, "f1": 86.75497848244157, "meta": {"annotate": "19", "cat_fun_name": "is_new_xp", "checkpoint": {"config": {"_name_or_path": "/home/lagunas/devel/hf/nn_pruning/nn_pruning/analysis/tmp_finetune", "architectures": ["BertForQuestionAnswering"], "attention_probs_dropout_prob": 0.1, "gradient_checkpointing": false, "hidden_act": "gelu", "hidden_dropout_prob": 0.1, "hidden_size": 768, "initializer_range": 0.02, "intermediate_size": 3072, "layer_norm_eps": 1e-12, "max_position_embeddings": 512, "model_type": "bert", "num_attention_heads": 12, "num_hidden_layers": 12, "pad_token_id": 0, "position_embedding_type": "absolute", "pruned_heads": {"0": [0, 2, 4, 5, 6, 7, 9, 11], "1": [0, 2, 3, 5, 6, 7, 8, 9], "10": [1, 4, 5, 6, 7, 8, 9], "11": [0, 2, 3, 5, 6, 7, 8, 10, 11], "2": [1, 2, 4, 7, 8, 11], "3": [2, 4, 6, 7], "4": [1, 2, 4, 6, 11], "5": [0, 1, 2, 5, 6, 7, 11], "6": [0, 2, 3, 4, 7, 10], "7": [1, 3, 6, 7, 11], "8": [0, 2, 3, 4, 8], "9": [1, 3, 4, 5, 7, 9, 10]}, "type_vocab_size": 2, "vocab_size": 30522}, "eval_metrics": {"exact_match": 78.82686849574267, "f1": 86.75497848244157}, "path": "/data_2to/devel_data/nn_pruning/output/squad_test_final_fine_tune/fine_tuned_aws_nn-pruning-v10-a32-l20-dl1--2021-01-21--00-55-15/checkpoint-22132", "source_checkpoint": "/data_2to/devel_data/nn_pruning/output/squad_test_aws/aws_nn-pruning-v10-a32-l20-dl1--2021-01-21--00-55-15/checkpoint-110660", "sparse_args": {"ampere_pruning_method": "disabled", "attention_block_cols": 1, "attention_block_rows": 1, "attention_lambda": 1.0, "attention_output_with_dense": 0, "attention_pruning_method": "topK", "bias_mask": true, "dense_block_cols": 1, "dense_block_rows": 1, "dense_lambda": 1.0, "dense_pruning_method": "topK", "distil_alpha_ce": 0.1, "distil_alpha_teacher": 0.9, "distil_teacher_name_or_path": "csarron/bert-base-uncased-squad-v1", "distil_temperature": 2.0, "final_ampere_temperature": 20.0, "final_finetune": 1, "final_threshold": 0.5, "final_warmup": 0, "initial_ampere_temperature": 0.0, "initial_threshold": 1.0, "initial_warmup": 0, "mask_init": "constant", "mask_scale": 0.0, "mask_scores_learning_rate": 0.01, "regularization": "", "regularization_final_lambda": 0}, "speed": {"cuda_eval_elapsed_time": 14.354346725463868, "eval_elapsed_time": 21.489493974950165}, "speedup": 2.68869031405704, "stats": {"layers": {"0": {"linear_attention_nnz": 786432, "linear_attention_total": 2359296, "linear_dense_nnz": 181248, "linear_dense_total": 4718592, "linear_nnz": 967680, "linear_total": 7077888, "nnz": 973174, "total": 7086336}, "1": {"linear_attention_nnz": 786432, "linear_attention_total": 2359296, "linear_dense_nnz": 299520, "linear_dense_total": 4718592, "linear_nnz": 1085952, "linear_total": 7077888, "nnz": 1091523, "total": 7086336}, "10": {"linear_attention_nnz": 983040, "linear_attention_total": 2359296, "linear_dense_nnz": 58368, "linear_dense_total": 4718592, "linear_nnz": 1041408, "linear_total": 7077888, "nnz": 1047014, "total": 7086528}, "11": {"linear_attention_nnz": 589824, "linear_attention_total": 2359296, "linear_dense_nnz": 96768, "linear_dense_total": 4718592, "linear_nnz": 686592, "linear_total": 7077888, "nnz": 691839, "total": 7086144}, "2": {"linear_attention_nnz": 1179648, "linear_attention_total": 2359296, "linear_dense_nnz": 407040, "linear_dense_total": 4718592, "linear_nnz": 1586688, "linear_total": 7077888, "nnz": 1592713, "total": 7086720}, "3": {"linear_attention_nnz": 1572864, "linear_attention_total": 2359296, "linear_dense_nnz": 440832, "linear_dense_total": 4718592, "linear_nnz": 2013696, "linear_total": 7077888, "nnz": 2020127, "total": 7087104}, "4": {"linear_attention_nnz": 1376256, "linear_attention_total": 2359296, "linear_dense_nnz": 496128, "linear_dense_total": 4718592, "linear_nnz": 1872384, "linear_total": 7077888, "nnz": 1878659, "total": 7086912}, "5": {"linear_attention_nnz": 983040, "linear_attention_total": 2359296, "linear_dense_nnz": 433152, "linear_dense_total": 4718592, "linear_nnz": 1416192, "linear_total": 7077888, "nnz": 1422042, "total": 7086528}, "6": {"linear_attention_nnz": 1179648, "linear_attention_total": 2359296, "linear_dense_nnz": 337920, "linear_dense_total": 4718592, "linear_nnz": 1517568, "linear_total": 7077888, "nnz": 1523548, "total": 7086720}, "7": {"linear_attention_nnz": 1376256, "linear_attention_total": 2359296, "linear_dense_nnz": 268800, "linear_dense_total": 4718592, "linear_nnz": 1645056, "linear_total": 7077888, "nnz": 1651183, "total": 7086912}, "8": {"linear_attention_nnz": 1376256, "linear_attention_total": 2359296, "linear_dense_nnz": 158208, "linear_dense_total": 4718592, "linear_nnz": 1534464, "linear_total": 7077888, "nnz": 1540519, "total": 7086912}, "9": {"linear_attention_nnz": 983040, "linear_attention_total": 2359296, "linear_dense_nnz": 73728, "linear_dense_total": 4718592, "linear_nnz": 1056768, "linear_total": 7077888, "nnz": 1062384, "total": 7086528}}, "linear_nnz": 16424448, "linear_sparsity": 80.66225405092592, "linear_total": 84934656, "nnz": 40333447, "pruned_heads": {"0": [0, 2, 4, 5, 6, 7, 9, 11], "1": [0, 2, 3, 5, 6, 7, 8, 9], "10": [1, 4, 5, 6, 7, 8, 9], "11": [0, 2, 3, 5, 6, 7, 8, 10, 11], "2": [1, 2, 4, 7, 8, 11], "3": [2, 4, 6, 7], "4": [1, 2, 4, 6, 11], "5": [0, 1, 2, 5, 6, 7, 11], "6": [0, 2, 3, 4, 7, 10], "7": [1, 3, 6, 7, 11], "8": [0, 2, 3, 4, 8], "9": [1, 3, 4, 5, 7, 9, 10]}, "total": 108878402, "total_sparsity": 62.95551159907728}, "training_args": {"_n_gpu": -1, "adafactor": false, "adam_beta1": 0.9, "adam_beta2": 0.999, "adam_epsilon": 1e-08, "dataloader_drop_last": false, "dataloader_num_workers": 0, "dataloader_pin_memory": true, "ddp_find_unused_parameters": null, "debug": false, "deepspeed": null, "disable_tqdm": false, "do_eval": 1, "do_predict": false, "do_train": 1, "eval_accumulation_steps": null, "eval_steps": 2500, "evaluation_strategy": "steps", "fp16": false, "fp16_backend": "auto", "fp16_full_eval": false, "fp16_opt_level": "O1", "gradient_accumulation_steps": 1, "greater_is_better": null, "group_by_length": false, "ignore_data_skip": false, "label_names": null, "label_smoothing_factor": 0.0, "learning_rate": 3e-05, "load_best_model_at_end": false, "local_rank": -1, "logging_dir": "/data_2to/devel_data/nn_pruning/output/squad_test_final_fine_tune/fine_tuned_aws_nn-pruning-v10-a32-l20-dl1--2021-01-21--00-55-15", "logging_first_step": false, "logging_steps": 250, "logging_strategy": "steps", "lr_scheduler_type": "linear", "max_grad_norm": 1.0, "max_steps": -1, "metric_for_best_model": null, "no_cuda": false, "num_train_epochs": 4, "optimize_model_before_eval": "disabled", "output_dir": "/data_2to/devel_data/nn_pruning/output/squad_test_final_fine_tune/fine_tuned_aws_nn-pruning-v10-a32-l20-dl1--2021-01-21--00-55-15", "overwrite_output_dir": 1, "past_index": -1, "per_device_eval_batch_size": 128, "per_device_train_batch_size": 16, "per_gpu_eval_batch_size": null, "per_gpu_train_batch_size": null, "prediction_loss_only": false, "remove_unused_columns": true, "report_to": null, "run_name": "/data_2to/devel_data/nn_pruning/output/squad_test_final_fine_tune/fine_tuned_aws_nn-pruning-v10-a32-l20-dl1--2021-01-21--00-55-15", "save_steps": 2500, "save_strategy": "steps", "save_total_limit": 50, "seed": 17, "sharded_ddp": "", "skip_memory_metrics": false, "tpu_metrics_debug": false, "tpu_num_cores": null, "warmup_ratio": 0.0, "warmup_steps": 10, "weight_decay": 0.0}}, "f1": 86.75497848244157, "fill_rate": 0.1933774594907408, "speedup": 2.68869031405704}}
