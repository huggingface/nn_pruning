{"speedup": 1.8420919143305463, "f1": 88.72194531479171, "meta": {"annotate": "36", "cat_fun_name": "is_new_xp", "checkpoint": {"config": {"_name_or_path": "/home/lagunas/devel/hf/nn_pruning/nn_pruning/analysis/tmp_finetune", "architectures": ["BertForQuestionAnswering"], "attention_probs_dropout_prob": 0.1, "gradient_checkpointing": false, "hidden_act": "gelu", "hidden_dropout_prob": 0.1, "hidden_size": 768, "initializer_range": 0.02, "intermediate_size": 3072, "layer_norm_eps": 1e-12, "max_position_embeddings": 512, "model_type": "bert", "num_attention_heads": 12, "num_hidden_layers": 12, "pad_token_id": 0, "position_embedding_type": "absolute", "pruned_heads": {"0": [2, 4, 5, 6, 7], "1": [0, 2, 3, 5, 6, 7, 8], "10": [1, 4, 5, 6, 7], "11": [0, 2, 5, 6, 7, 8, 11], "2": [8, 4, 7], "3": [2, 4, 6], "4": [2], "5": [1, 2], "6": [2, 3, 7], "7": [11, 3, 6, 7], "8": [0, 4], "9": [1, 4, 5, 7, 9, 10]}, "type_vocab_size": 2, "vocab_size": 30522}, "eval_metrics": {"exact_match": 81.69347209082308, "f1": 88.72194531479171}, "path": "/data_2to/devel_data/nn_pruning/output/squad_test_final_fine_tune/fine_tuned_aws_nn-pruning-v10-a32-l5-dl0-5--2021-01-21--00-52-45/checkpoint-22132", "source_checkpoint": "/data_2to/devel_data/nn_pruning/output/squad_test_aws/aws_nn-pruning-v10-a32-l5-dl0-5--2021-01-21--00-52-45/checkpoint-95000", "sparse_args": {"ampere_pruning_method": "disabled", "attention_block_cols": 1, "attention_block_rows": 1, "attention_lambda": 1.0, "attention_output_with_dense": 0, "attention_pruning_method": "topK", "bias_mask": true, "dense_block_cols": 1, "dense_block_rows": 1, "dense_lambda": 1.0, "dense_pruning_method": "topK", "distil_alpha_ce": 0.1, "distil_alpha_teacher": 0.9, "distil_teacher_name_or_path": "csarron/bert-base-uncased-squad-v1", "distil_temperature": 2.0, "final_ampere_temperature": 20.0, "final_finetune": 1, "final_threshold": 0.5, "final_warmup": 0, "initial_ampere_temperature": 0.0, "initial_threshold": 1.0, "initial_warmup": 0, "mask_init": "constant", "mask_scale": 0.0, "mask_scores_learning_rate": 0.01, "regularization": "", "regularization_final_lambda": 0}, "speed": {"cuda_eval_elapsed_time": 20.951393741607667, "eval_elapsed_time": 28.213609586004168}, "speedup": 1.8420919143305463, "stats": {"layers": {"0": {"linear_attention_nnz": 1376256, "linear_attention_total": 2359296, "linear_dense_nnz": 1125888, "linear_dense_total": 4718592, "linear_nnz": 2502144, "linear_total": 7077888, "nnz": 2508829, "total": 7086912}, "1": {"linear_attention_nnz": 983040, "linear_attention_total": 2359296, "linear_dense_nnz": 1285632, "linear_dense_total": 4718592, "linear_nnz": 2268672, "linear_total": 7077888, "nnz": 2275077, "total": 7086528}, "10": {"linear_attention_nnz": 1376256, "linear_attention_total": 2359296, "linear_dense_nnz": 168960, "linear_dense_total": 4718592, "linear_nnz": 1545216, "linear_total": 7077888, "nnz": 1551278, "total": 7086912}, "11": {"linear_attention_nnz": 983040, "linear_attention_total": 2359296, "linear_dense_nnz": 485376, "linear_dense_total": 4718592, "linear_nnz": 1468416, "linear_total": 7077888, "nnz": 1474300, "total": 7086528}, "2": {"linear_attention_nnz": 1769472, "linear_attention_total": 2359296, "linear_dense_nnz": 1523712, "linear_dense_total": 4718592, "linear_nnz": 3293184, "linear_total": 7077888, "nnz": 3300512, "total": 7087296}, "3": {"linear_attention_nnz": 1769472, "linear_attention_total": 2359296, "linear_dense_nnz": 1555968, "linear_dense_total": 4718592, "linear_nnz": 3325440, "linear_total": 7077888, "nnz": 3332789, "total": 7087296}, "4": {"linear_attention_nnz": 2162688, "linear_attention_total": 2359296, "linear_dense_nnz": 1617408, "linear_dense_total": 4718592, "linear_nnz": 3780096, "linear_total": 7077888, "nnz": 3787869, "total": 7087680}, "5": {"linear_attention_nnz": 1966080, "linear_attention_total": 2359296, "linear_dense_nnz": 1514496, "linear_dense_total": 4718592, "linear_nnz": 3480576, "linear_total": 7077888, "nnz": 3488090, "total": 7087488}, "6": {"linear_attention_nnz": 1769472, "linear_attention_total": 2359296, "linear_dense_nnz": 1135104, "linear_dense_total": 4718592, "linear_nnz": 2904576, "linear_total": 7077888, "nnz": 2911651, "total": 7087296}, "7": {"linear_attention_nnz": 1572864, "linear_attention_total": 2359296, "linear_dense_nnz": 847872, "linear_dense_total": 4718592, "linear_nnz": 2420736, "linear_total": 7077888, "nnz": 2427432, "total": 7087104}, "8": {"linear_attention_nnz": 1966080, "linear_attention_total": 2359296, "linear_dense_nnz": 474624, "linear_dense_total": 4718592, "linear_nnz": 2440704, "linear_total": 7077888, "nnz": 2447541, "total": 7087488}, "9": {"linear_attention_nnz": 1179648, "linear_attention_total": 2359296, "linear_dense_nnz": 208896, "linear_dense_total": 4718592, "linear_nnz": 1388544, "linear_total": 7077888, "nnz": 1394440, "total": 7086720}}, "linear_nnz": 30818304, "linear_sparsity": 63.71527777777778, "linear_total": 84934656, "nnz": 54738530, "pruned_heads": {"0": [2, 4, 5, 6, 7], "1": [0, 2, 3, 5, 6, 7, 8], "10": [1, 4, 5, 6, 7], "11": [0, 2, 5, 6, 7, 8, 11], "2": [8, 4, 7], "3": [2, 4, 6], "4": [2], "5": [1, 2], "6": [2, 3, 7], "7": [11, 3, 6, 7], "8": [0, 4], "9": [1, 4, 5, 7, 9, 10]}, "total": 108883970, "total_sparsity": 49.72765045212808}, "training_args": {"_n_gpu": -1, "adafactor": false, "adam_beta1": 0.9, "adam_beta2": 0.999, "adam_epsilon": 1e-08, "dataloader_drop_last": false, "dataloader_num_workers": 0, "dataloader_pin_memory": true, "ddp_find_unused_parameters": null, "debug": false, "deepspeed": null, "disable_tqdm": false, "do_eval": 1, "do_predict": false, "do_train": 1, "eval_accumulation_steps": null, "eval_steps": 2500, "evaluation_strategy": "steps", "fp16": false, "fp16_backend": "auto", "fp16_full_eval": false, "fp16_opt_level": "O1", "gradient_accumulation_steps": 1, "greater_is_better": null, "group_by_length": false, "ignore_data_skip": false, "label_names": null, "label_smoothing_factor": 0.0, "learning_rate": 3e-05, "load_best_model_at_end": false, "local_rank": -1, "logging_dir": "/data_2to/devel_data/nn_pruning/output/squad_test_final_fine_tune/fine_tuned_aws_nn-pruning-v10-a32-l5-dl0-5--2021-01-21--00-52-45", "logging_first_step": false, "logging_steps": 250, "logging_strategy": "steps", "lr_scheduler_type": "linear", "max_grad_norm": 1.0, "max_steps": -1, "metric_for_best_model": null, "no_cuda": false, "num_train_epochs": 4, "optimize_model_before_eval": "disabled", "output_dir": "/data_2to/devel_data/nn_pruning/output/squad_test_final_fine_tune/fine_tuned_aws_nn-pruning-v10-a32-l5-dl0-5--2021-01-21--00-52-45", "overwrite_output_dir": 1, "past_index": -1, "per_device_eval_batch_size": 128, "per_device_train_batch_size": 16, "per_gpu_eval_batch_size": null, "per_gpu_train_batch_size": null, "prediction_loss_only": false, "remove_unused_columns": true, "report_to": null, "run_name": "/data_2to/devel_data/nn_pruning/output/squad_test_final_fine_tune/fine_tuned_aws_nn-pruning-v10-a32-l5-dl0-5--2021-01-21--00-52-45", "save_steps": 2500, "save_strategy": "steps", "save_total_limit": 50, "seed": 17, "sharded_ddp": "", "skip_memory_metrics": false, "tpu_metrics_debug": false, "tpu_num_cores": null, "warmup_ratio": 0.0, "warmup_steps": 10, "weight_decay": 0.0}}, "f1": 88.72194531479171, "fill_rate": 0.3628472222222222, "speedup": 1.8420919143305463}}
{"speedup": 1.98338294004996, "f1": 88.26868699204444, "meta": {"annotate": "31", "cat_fun_name": "is_new_xp", "checkpoint": {"config": {"_name_or_path": "/home/lagunas/devel/hf/nn_pruning/nn_pruning/analysis/tmp_finetune", "architectures": ["BertForQuestionAnswering"], "attention_probs_dropout_prob": 0.1, "gradient_checkpointing": false, "hidden_act": "gelu", "hidden_dropout_prob": 0.1, "hidden_size": 768, "initializer_range": 0.02, "intermediate_size": 3072, "layer_norm_eps": 1e-12, "max_position_embeddings": 512, "model_type": "bert", "num_attention_heads": 12, "num_hidden_layers": 12, "pad_token_id": 0, "position_embedding_type": "absolute", "pruned_heads": {"0": [0, 2, 4, 5, 6], "1": [0, 2, 3, 5, 6, 7, 8], "10": [1, 4, 5, 7], "11": [0, 2, 5, 6, 7, 8, 11], "2": [8, 4], "3": [2, 4, 6], "4": [2], "5": [1, 2], "6": [2, 3, 7], "7": [11, 3, 6, 7], "8": [0, 4], "9": [1, 4, 5, 7, 9, 10]}, "type_vocab_size": 2, "vocab_size": 30522}, "eval_metrics": {"exact_match": 80.86092715231788, "f1": 88.26868699204444}, "path": "/data_2to/devel_data/nn_pruning/output/squad_test_final_fine_tune/fine_tuned_aws_nn-pruning-v10-a32-l5-dl1--2021-01-21--00-52-16/checkpoint-20000", "source_checkpoint": "/data_2to/devel_data/nn_pruning/output/squad_test_aws/aws_nn-pruning-v10-a32-l5-dl1--2021-01-21--00-52-16/checkpoint-110660", "sparse_args": {"ampere_pruning_method": "disabled", "attention_block_cols": 1, "attention_block_rows": 1, "attention_lambda": 1.0, "attention_output_with_dense": 0, "attention_pruning_method": "topK", "bias_mask": true, "dense_block_cols": 1, "dense_block_rows": 1, "dense_lambda": 1.0, "dense_pruning_method": "topK", "distil_alpha_ce": 0.1, "distil_alpha_teacher": 0.9, "distil_teacher_name_or_path": "csarron/bert-base-uncased-squad-v1", "distil_temperature": 2.0, "final_ampere_temperature": 20.0, "final_finetune": 1, "final_threshold": 0.5, "final_warmup": 0, "initial_ampere_temperature": 0.0, "initial_threshold": 1.0, "initial_warmup": 0, "mask_init": "constant", "mask_scale": 0.0, "mask_scores_learning_rate": 0.01, "regularization": "", "regularization_final_lambda": 0}, "speed": {"cuda_eval_elapsed_time": 19.458871116638186, "eval_elapsed_time": 26.62503844080493}, "speedup": 1.98338294004996, "stats": {"layers": {"0": {"linear_attention_nnz": 1376256, "linear_attention_total": 2359296, "linear_dense_nnz": 526848, "linear_dense_total": 4718592, "linear_nnz": 1903104, "linear_total": 7077888, "nnz": 1909399, "total": 7086912}, "1": {"linear_attention_nnz": 983040, "linear_attention_total": 2359296, "linear_dense_nnz": 752640, "linear_dense_total": 4718592, "linear_nnz": 1735680, "linear_total": 7077888, "nnz": 1741738, "total": 7086528}, "10": {"linear_attention_nnz": 1572864, "linear_attention_total": 2359296, "linear_dense_nnz": 98304, "linear_dense_total": 4718592, "linear_nnz": 1671168, "linear_total": 7077888, "nnz": 1677376, "total": 7087104}, "11": {"linear_attention_nnz": 983040, "linear_attention_total": 2359296, "linear_dense_nnz": 262656, "linear_dense_total": 4718592, "linear_nnz": 1245696, "linear_total": 7077888, "nnz": 1251435, "total": 7086528}, "2": {"linear_attention_nnz": 1966080, "linear_attention_total": 2359296, "linear_dense_nnz": 873984, "linear_dense_total": 4718592, "linear_nnz": 2840064, "linear_total": 7077888, "nnz": 2847161, "total": 7087488}, "3": {"linear_attention_nnz": 1769472, "linear_attention_total": 2359296, "linear_dense_nnz": 952320, "linear_dense_total": 4718592, "linear_nnz": 2721792, "linear_total": 7077888, "nnz": 2728748, "total": 7087296}, "4": {"linear_attention_nnz": 2162688, "linear_attention_total": 2359296, "linear_dense_nnz": 1046016, "linear_dense_total": 4718592, "linear_nnz": 3208704, "linear_total": 7077888, "nnz": 3216105, "total": 7087680}, "5": {"linear_attention_nnz": 1966080, "linear_attention_total": 2359296, "linear_dense_nnz": 986112, "linear_dense_total": 4718592, "linear_nnz": 2952192, "linear_total": 7077888, "nnz": 2959362, "total": 7087488}, "6": {"linear_attention_nnz": 1769472, "linear_attention_total": 2359296, "linear_dense_nnz": 740352, "linear_dense_total": 4718592, "linear_nnz": 2509824, "linear_total": 7077888, "nnz": 2516642, "total": 7087296}, "7": {"linear_attention_nnz": 1572864, "linear_attention_total": 2359296, "linear_dense_nnz": 559104, "linear_dense_total": 4718592, "linear_nnz": 2131968, "linear_total": 7077888, "nnz": 2138476, "total": 7087104}, "8": {"linear_attention_nnz": 1966080, "linear_attention_total": 2359296, "linear_dense_nnz": 293376, "linear_dense_total": 4718592, "linear_nnz": 2259456, "linear_total": 7077888, "nnz": 2266175, "total": 7087488}, "9": {"linear_attention_nnz": 1179648, "linear_attention_total": 2359296, "linear_dense_nnz": 113664, "linear_dense_total": 4718592, "linear_nnz": 1293312, "linear_total": 7077888, "nnz": 1299146, "total": 7086720}}, "linear_nnz": 26472960, "linear_sparsity": 68.83138020833333, "linear_total": 84934656, "nnz": 50390485, "pruned_heads": {"0": [0, 2, 4, 5, 6], "1": [0, 2, 3, 5, 6, 7, 8], "10": [1, 4, 5, 7], "11": [0, 2, 5, 6, 7, 8, 11], "2": [8, 4], "3": [2, 4, 6], "4": [2], "5": [1, 2], "6": [2, 3, 7], "7": [11, 3, 6, 7], "8": [0, 4], "9": [1, 4, 5, 7, 9, 10]}, "total": 108884354, "total_sparsity": 53.72109660493554}, "training_args": {"_n_gpu": -1, "adafactor": false, "adam_beta1": 0.9, "adam_beta2": 0.999, "adam_epsilon": 1e-08, "dataloader_drop_last": false, "dataloader_num_workers": 0, "dataloader_pin_memory": true, "ddp_find_unused_parameters": null, "debug": false, "deepspeed": null, "disable_tqdm": false, "do_eval": 1, "do_predict": false, "do_train": 1, "eval_accumulation_steps": null, "eval_steps": 2500, "evaluation_strategy": "steps", "fp16": false, "fp16_backend": "auto", "fp16_full_eval": false, "fp16_opt_level": "O1", "gradient_accumulation_steps": 1, "greater_is_better": null, "group_by_length": false, "ignore_data_skip": false, "label_names": null, "label_smoothing_factor": 0.0, "learning_rate": 3e-05, "load_best_model_at_end": false, "local_rank": -1, "logging_dir": "/data_2to/devel_data/nn_pruning/output/squad_test_final_fine_tune/fine_tuned_aws_nn-pruning-v10-a32-l5-dl1--2021-01-21--00-52-16", "logging_first_step": false, "logging_steps": 250, "logging_strategy": "steps", "lr_scheduler_type": "linear", "max_grad_norm": 1.0, "max_steps": -1, "metric_for_best_model": null, "no_cuda": false, "num_train_epochs": 4, "optimize_model_before_eval": "disabled", "output_dir": "/data_2to/devel_data/nn_pruning/output/squad_test_final_fine_tune/fine_tuned_aws_nn-pruning-v10-a32-l5-dl1--2021-01-21--00-52-16", "overwrite_output_dir": 1, "past_index": -1, "per_device_eval_batch_size": 128, "per_device_train_batch_size": 16, "per_gpu_eval_batch_size": null, "per_gpu_train_batch_size": null, "prediction_loss_only": false, "remove_unused_columns": true, "report_to": null, "run_name": "/data_2to/devel_data/nn_pruning/output/squad_test_final_fine_tune/fine_tuned_aws_nn-pruning-v10-a32-l5-dl1--2021-01-21--00-52-16", "save_steps": 2500, "save_strategy": "steps", "save_total_limit": 50, "seed": 17, "sharded_ddp": "", "skip_memory_metrics": false, "tpu_metrics_debug": false, "tpu_num_cores": null, "warmup_ratio": 0.0, "warmup_steps": 10, "weight_decay": 0.0}}, "f1": 88.26868699204444, "fill_rate": 0.31168619791666674, "speedup": 1.98338294004996}}
{"speedup": 2.0930209740713988, "f1": 88.20260662536118, "meta": {"annotate": "33", "cat_fun_name": "is_new_xp", "checkpoint": {"config": {"_name_or_path": "/home/lagunas/devel/hf/nn_pruning/nn_pruning/analysis/tmp_finetune", "architectures": ["BertForQuestionAnswering"], "attention_probs_dropout_prob": 0.1, "gradient_checkpointing": false, "hidden_act": "gelu", "hidden_dropout_prob": 0.1, "hidden_size": 768, "initializer_range": 0.02, "intermediate_size": 3072, "layer_norm_eps": 1e-12, "max_position_embeddings": 512, "model_type": "bert", "num_attention_heads": 12, "num_hidden_layers": 12, "pad_token_id": 0, "position_embedding_type": "absolute", "pruned_heads": {"0": [0, 2, 4, 5, 6, 7, 9, 11], "1": [0, 2, 3, 5, 6, 7, 8, 9], "10": [1, 4, 5, 6, 7, 8], "11": [0, 2, 3, 5, 6, 7, 8, 10, 11], "2": [8, 11, 4, 7], "3": [2, 4, 6, 7], "4": [1, 2, 11], "5": [1, 2, 5, 6, 7, 11], "6": [0, 2, 3, 7, 10], "7": [1, 3, 6, 7, 11], "8": [0, 8, 3, 4], "9": [1, 4, 5, 7, 9, 10]}, "type_vocab_size": 2, "vocab_size": 30522}, "eval_metrics": {"exact_match": 80.80416272469253, "f1": 88.20260662536118}, "path": "/data_2to/devel_data/nn_pruning/output/squad_test_final_fine_tune/fine_tuned_hp_od-output__squad_test3_es-steps_nte20_ls250_est5000_rn-output__squad_test3_dpm-sigmoied_threshold:1d_alt_apme-sigmoied_threshold_aowd0_bm1_abr32_abc32_it0_fw10_r-l1_rfl10_dl0.25_dtnop-csarron__bert-base-uncased-squad-v1/checkpoint-15000", "source_checkpoint": "/data_2to/devel_data/nn_pruning/output/squad_test3/hp_od-output__squad_test3_es-steps_nte20_ls250_est5000_rn-output__squad_test3_dpm-sigmoied_threshold:1d_alt_apme-sigmoied_threshold_aowd0_bm1_abr32_abc32_it0_fw10_r-l1_rfl10_dl0.25_dtnop-csarron__bert-base-uncased-squad-v1/checkpoint-90000", "sparse_args": {"ampere_pruning_method": "disabled", "attention_block_cols": 1, "attention_block_rows": 1, "attention_lambda": 1.0, "attention_output_with_dense": 0, "attention_pruning_method": "topK", "bias_mask": true, "dense_block_cols": 1, "dense_block_rows": 1, "dense_lambda": 1.0, "dense_pruning_method": "topK", "distil_alpha_ce": 0.1, "distil_alpha_teacher": 0.9, "distil_teacher_name_or_path": "csarron/bert-base-uncased-squad-v1", "distil_temperature": 2.0, "final_ampere_temperature": 20.0, "final_finetune": 1, "final_threshold": 0.5, "final_warmup": 0, "initial_ampere_temperature": 0.0, "initial_threshold": 1.0, "initial_warmup": 0, "mask_init": "constant", "mask_scale": 0.0, "mask_scores_learning_rate": 0.01, "regularization": "", "regularization_final_lambda": 0}, "speed": {"cuda_eval_elapsed_time": 18.439563426971436, "eval_elapsed_time": 25.7331585730426}, "speedup": 2.0930209740713988, "stats": {"layers": {"0": {"linear_attention_nnz": 786432, "linear_attention_total": 2359296, "linear_dense_nnz": 1339392, "linear_dense_total": 4718592, "linear_nnz": 2125824, "linear_total": 7077888, "nnz": 2132072, "total": 7086336}, "1": {"linear_attention_nnz": 786432, "linear_attention_total": 2359296, "linear_dense_nnz": 1571328, "linear_dense_total": 4718592, "linear_nnz": 2357760, "linear_total": 7077888, "nnz": 2364159, "total": 7086336}, "10": {"linear_attention_nnz": 1179648, "linear_attention_total": 2359296, "linear_dense_nnz": 187392, "linear_dense_total": 4718592, "linear_nnz": 1367040, "linear_total": 7077888, "nnz": 1372922, "total": 7086720}, "11": {"linear_attention_nnz": 589824, "linear_attention_total": 2359296, "linear_dense_nnz": 574464, "linear_dense_total": 4718592, "linear_nnz": 1164288, "linear_total": 7077888, "nnz": 1169846, "total": 7086144}, "2": {"linear_attention_nnz": 1572864, "linear_attention_total": 2359296, "linear_dense_nnz": 1744896, "linear_dense_total": 4718592, "linear_nnz": 3317760, "linear_total": 7077888, "nnz": 3325040, "total": 7087104}, "3": {"linear_attention_nnz": 1572864, "linear_attention_total": 2359296, "linear_dense_nnz": 1761792, "linear_dense_total": 4718592, "linear_nnz": 3334656, "linear_total": 7077888, "nnz": 3341947, "total": 7087104}, "4": {"linear_attention_nnz": 1769472, "linear_attention_total": 2359296, "linear_dense_nnz": 1726464, "linear_dense_total": 4718592, "linear_nnz": 3495936, "linear_total": 7077888, "nnz": 3503396, "total": 7087296}, "5": {"linear_attention_nnz": 1179648, "linear_attention_total": 2359296, "linear_dense_nnz": 1629696, "linear_dense_total": 4718592, "linear_nnz": 2809344, "linear_total": 7077888, "nnz": 2816165, "total": 7086720}, "6": {"linear_attention_nnz": 1376256, "linear_attention_total": 2359296, "linear_dense_nnz": 1270272, "linear_dense_total": 4718592, "linear_nnz": 2646528, "linear_total": 7077888, "nnz": 2653307, "total": 7086912}, "7": {"linear_attention_nnz": 1376256, "linear_attention_total": 2359296, "linear_dense_nnz": 987648, "linear_dense_total": 4718592, "linear_nnz": 2363904, "linear_total": 7077888, "nnz": 2370499, "total": 7086912}, "8": {"linear_attention_nnz": 1572864, "linear_attention_total": 2359296, "linear_dense_nnz": 546816, "linear_dense_total": 4718592, "linear_nnz": 2119680, "linear_total": 7077888, "nnz": 2126180, "total": 7087104}, "9": {"linear_attention_nnz": 1179648, "linear_attention_total": 2359296, "linear_dense_nnz": 248832, "linear_dense_total": 4718592, "linear_nnz": 1428480, "linear_total": 7077888, "nnz": 1434402, "total": 7086720}}, "linear_nnz": 28531200, "linear_sparsity": 66.40805844907408, "linear_total": 84934656, "nnz": 52448657, "pruned_heads": {"0": [0, 2, 4, 5, 6, 7, 9, 11], "1": [0, 2, 3, 5, 6, 7, 8, 9], "10": [1, 4, 5, 6, 7, 8], "11": [0, 2, 3, 5, 6, 7, 8, 10, 11], "2": [8, 11, 4, 7], "3": [2, 4, 6, 7], "4": [1, 2, 11], "5": [1, 2, 5, 6, 7, 11], "6": [0, 2, 3, 7, 10], "7": [1, 3, 6, 7, 11], "8": [0, 8, 3, 4], "9": [1, 4, 5, 7, 9, 10]}, "total": 108880130, "total_sparsity": 51.82899120344548}, "training_args": {"_n_gpu": -1, "adafactor": false, "adam_beta1": 0.9, "adam_beta2": 0.999, "adam_epsilon": 1e-08, "dataloader_drop_last": false, "dataloader_num_workers": 0, "dataloader_pin_memory": true, "ddp_find_unused_parameters": null, "debug": false, "deepspeed": null, "disable_tqdm": false, "do_eval": 1, "do_predict": false, "do_train": 1, "eval_accumulation_steps": null, "eval_steps": 2500, "evaluation_strategy": "steps", "fp16": false, "fp16_backend": "auto", "fp16_full_eval": false, "fp16_opt_level": "O1", "gradient_accumulation_steps": 1, "greater_is_better": null, "group_by_length": false, "ignore_data_skip": false, "label_names": null, "label_smoothing_factor": 0.0, "learning_rate": 3e-05, "load_best_model_at_end": false, "local_rank": -1, "logging_dir": "/data_2to/devel_data/nn_pruning/output/squad_test_final_fine_tune/fine_tuned_hp_od-output__squad_test3_es-steps_nte20_ls250_est5000_rn-output__squad_test3_dpm-sigmoied_threshold:1d_alt_apme-sigmoied_threshold_aowd0_bm1_abr32_abc32_it0_fw10_r-l1_rfl10_dl0.25_dtnop-csarron__bert-base-uncased-squad-v1", "logging_first_step": false, "logging_steps": 250, "logging_strategy": "steps", "lr_scheduler_type": "linear", "max_grad_norm": 1.0, "max_steps": -1, "metric_for_best_model": null, "no_cuda": false, "num_train_epochs": 4, "optimize_model_before_eval": "disabled", "output_dir": "/data_2to/devel_data/nn_pruning/output/squad_test_final_fine_tune/fine_tuned_hp_od-output__squad_test3_es-steps_nte20_ls250_est5000_rn-output__squad_test3_dpm-sigmoied_threshold:1d_alt_apme-sigmoied_threshold_aowd0_bm1_abr32_abc32_it0_fw10_r-l1_rfl10_dl0.25_dtnop-csarron__bert-base-uncased-squad-v1", "overwrite_output_dir": 1, "past_index": -1, "per_device_eval_batch_size": 8, "per_device_train_batch_size": 16, "per_gpu_eval_batch_size": null, "per_gpu_train_batch_size": null, "prediction_loss_only": false, "remove_unused_columns": true, "report_to": null, "run_name": "/data_2to/devel_data/nn_pruning/output/squad_test_final_fine_tune/fine_tuned_hp_od-output__squad_test3_es-steps_nte20_ls250_est5000_rn-output__squad_test3_dpm-sigmoied_threshold:1d_alt_apme-sigmoied_threshold_aowd0_bm1_abr32_abc32_it0_fw10_r-l1_rfl10_dl0.25_dtnop-csarron__bert-base-uncased-squad-v1", "save_steps": 2500, "save_strategy": "steps", "save_total_limit": 50, "seed": 17, "sharded_ddp": "", "skip_memory_metrics": false, "tpu_metrics_debug": false, "tpu_num_cores": null, "warmup_ratio": 0.0, "warmup_steps": 10, "weight_decay": 0.0}}, "f1": 88.20260662536118, "fill_rate": 0.3359194155092592, "speedup": 2.0930209740713988}}
{"speedup": 2.094444154371984, "f1": 88.11014400914335, "meta": {"annotate": "33", "cat_fun_name": "is_new_xp", "checkpoint": {"config": {"_name_or_path": "/home/lagunas/devel/hf/nn_pruning/nn_pruning/analysis/tmp_finetune", "architectures": ["BertForQuestionAnswering"], "attention_probs_dropout_prob": 0.1, "gradient_checkpointing": false, "hidden_act": "gelu", "hidden_dropout_prob": 0.1, "hidden_size": 768, "initializer_range": 0.02, "intermediate_size": 3072, "layer_norm_eps": 1e-12, "max_position_embeddings": 512, "model_type": "bert", "num_attention_heads": 12, "num_hidden_layers": 12, "pad_token_id": 0, "position_embedding_type": "absolute", "pruned_heads": {"0": [0, 2, 4, 5, 6, 7, 9, 11], "1": [0, 2, 3, 5, 6, 7, 8, 9], "10": [1, 4, 5, 6, 7, 8], "11": [0, 2, 3, 5, 6, 7, 8, 10, 11], "2": [8, 11, 4, 7], "3": [2, 4, 6, 7], "4": [1, 2, 11], "5": [1, 2, 5, 6, 7, 11], "6": [0, 2, 3, 7, 10], "7": [1, 3, 6, 7, 11], "8": [0, 8, 3, 4], "9": [1, 4, 5, 7, 9, 10]}, "type_vocab_size": 2, "vocab_size": 30522}, "eval_metrics": {"exact_match": 80.68117313150425, "f1": 88.11014400914335}, "path": "/data_2to/devel_data/nn_pruning/output/squad_test_final_fine_tune/fine_tuned_hp_od-output__squad_test3_es-steps_nte20_ls250_est5000_rn-output__squad_test3_dpm-sigmoied_threshold:1d_alt_apme-sigmoied_threshold_aowd0_bm1_abr32_abc32_it0_fw10_r-l1_rfl10_dl0.25_dtnop-csarron__bert-base-uncased-squad-v1/checkpoint-22132", "source_checkpoint": "/data_2to/devel_data/nn_pruning/output/squad_test3/hp_od-output__squad_test3_es-steps_nte20_ls250_est5000_rn-output__squad_test3_dpm-sigmoied_threshold:1d_alt_apme-sigmoied_threshold_aowd0_bm1_abr32_abc32_it0_fw10_r-l1_rfl10_dl0.25_dtnop-csarron__bert-base-uncased-squad-v1/checkpoint-90000", "sparse_args": {"ampere_pruning_method": "disabled", "attention_block_cols": 1, "attention_block_rows": 1, "attention_lambda": 1.0, "attention_output_with_dense": 0, "attention_pruning_method": "topK", "bias_mask": true, "dense_block_cols": 1, "dense_block_rows": 1, "dense_lambda": 1.0, "dense_pruning_method": "topK", "distil_alpha_ce": 0.1, "distil_alpha_teacher": 0.9, "distil_teacher_name_or_path": "csarron/bert-base-uncased-squad-v1", "distil_temperature": 2.0, "final_ampere_temperature": 20.0, "final_finetune": 1, "final_threshold": 0.5, "final_warmup": 0, "initial_ampere_temperature": 0.0, "initial_threshold": 1.0, "initial_warmup": 0, "mask_init": "constant", "mask_scale": 0.0, "mask_scores_learning_rate": 0.01, "regularization": "", "regularization_final_lambda": 0}, "speed": {"cuda_eval_elapsed_time": 18.42703369522095, "eval_elapsed_time": 25.61402732366696}, "speedup": 2.094444154371984, "stats": {"layers": {"0": {"linear_attention_nnz": 786432, "linear_attention_total": 2359296, "linear_dense_nnz": 1339392, "linear_dense_total": 4718592, "linear_nnz": 2125824, "linear_total": 7077888, "nnz": 2132072, "total": 7086336}, "1": {"linear_attention_nnz": 786432, "linear_attention_total": 2359296, "linear_dense_nnz": 1571328, "linear_dense_total": 4718592, "linear_nnz": 2357760, "linear_total": 7077888, "nnz": 2364159, "total": 7086336}, "10": {"linear_attention_nnz": 1179648, "linear_attention_total": 2359296, "linear_dense_nnz": 187392, "linear_dense_total": 4718592, "linear_nnz": 1367040, "linear_total": 7077888, "nnz": 1372922, "total": 7086720}, "11": {"linear_attention_nnz": 589824, "linear_attention_total": 2359296, "linear_dense_nnz": 574464, "linear_dense_total": 4718592, "linear_nnz": 1164288, "linear_total": 7077888, "nnz": 1169846, "total": 7086144}, "2": {"linear_attention_nnz": 1572864, "linear_attention_total": 2359296, "linear_dense_nnz": 1744896, "linear_dense_total": 4718592, "linear_nnz": 3317760, "linear_total": 7077888, "nnz": 3325040, "total": 7087104}, "3": {"linear_attention_nnz": 1572864, "linear_attention_total": 2359296, "linear_dense_nnz": 1761792, "linear_dense_total": 4718592, "linear_nnz": 3334656, "linear_total": 7077888, "nnz": 3341947, "total": 7087104}, "4": {"linear_attention_nnz": 1769472, "linear_attention_total": 2359296, "linear_dense_nnz": 1726464, "linear_dense_total": 4718592, "linear_nnz": 3495936, "linear_total": 7077888, "nnz": 3503396, "total": 7087296}, "5": {"linear_attention_nnz": 1179648, "linear_attention_total": 2359296, "linear_dense_nnz": 1629696, "linear_dense_total": 4718592, "linear_nnz": 2809344, "linear_total": 7077888, "nnz": 2816165, "total": 7086720}, "6": {"linear_attention_nnz": 1376256, "linear_attention_total": 2359296, "linear_dense_nnz": 1270272, "linear_dense_total": 4718592, "linear_nnz": 2646528, "linear_total": 7077888, "nnz": 2653307, "total": 7086912}, "7": {"linear_attention_nnz": 1376256, "linear_attention_total": 2359296, "linear_dense_nnz": 987648, "linear_dense_total": 4718592, "linear_nnz": 2363904, "linear_total": 7077888, "nnz": 2370499, "total": 7086912}, "8": {"linear_attention_nnz": 1572864, "linear_attention_total": 2359296, "linear_dense_nnz": 546816, "linear_dense_total": 4718592, "linear_nnz": 2119680, "linear_total": 7077888, "nnz": 2126180, "total": 7087104}, "9": {"linear_attention_nnz": 1179648, "linear_attention_total": 2359296, "linear_dense_nnz": 248832, "linear_dense_total": 4718592, "linear_nnz": 1428480, "linear_total": 7077888, "nnz": 1434402, "total": 7086720}}, "linear_nnz": 28531200, "linear_sparsity": 66.40805844907408, "linear_total": 84934656, "nnz": 52448657, "pruned_heads": {"0": [0, 2, 4, 5, 6, 7, 9, 11], "1": [0, 2, 3, 5, 6, 7, 8, 9], "10": [1, 4, 5, 6, 7, 8], "11": [0, 2, 3, 5, 6, 7, 8, 10, 11], "2": [8, 11, 4, 7], "3": [2, 4, 6, 7], "4": [1, 2, 11], "5": [1, 2, 5, 6, 7, 11], "6": [0, 2, 3, 7, 10], "7": [1, 3, 6, 7, 11], "8": [0, 8, 3, 4], "9": [1, 4, 5, 7, 9, 10]}, "total": 108880130, "total_sparsity": 51.82899120344548}, "training_args": {"_n_gpu": -1, "adafactor": false, "adam_beta1": 0.9, "adam_beta2": 0.999, "adam_epsilon": 1e-08, "dataloader_drop_last": false, "dataloader_num_workers": 0, "dataloader_pin_memory": true, "ddp_find_unused_parameters": null, "debug": false, "deepspeed": null, "disable_tqdm": false, "do_eval": 1, "do_predict": false, "do_train": 1, "eval_accumulation_steps": null, "eval_steps": 2500, "evaluation_strategy": "steps", "fp16": false, "fp16_backend": "auto", "fp16_full_eval": false, "fp16_opt_level": "O1", "gradient_accumulation_steps": 1, "greater_is_better": null, "group_by_length": false, "ignore_data_skip": false, "label_names": null, "label_smoothing_factor": 0.0, "learning_rate": 3e-05, "load_best_model_at_end": false, "local_rank": -1, "logging_dir": "/data_2to/devel_data/nn_pruning/output/squad_test_final_fine_tune/fine_tuned_hp_od-output__squad_test3_es-steps_nte20_ls250_est5000_rn-output__squad_test3_dpm-sigmoied_threshold:1d_alt_apme-sigmoied_threshold_aowd0_bm1_abr32_abc32_it0_fw10_r-l1_rfl10_dl0.25_dtnop-csarron__bert-base-uncased-squad-v1", "logging_first_step": false, "logging_steps": 250, "logging_strategy": "steps", "lr_scheduler_type": "linear", "max_grad_norm": 1.0, "max_steps": -1, "metric_for_best_model": null, "no_cuda": false, "num_train_epochs": 4, "optimize_model_before_eval": "disabled", "output_dir": "/data_2to/devel_data/nn_pruning/output/squad_test_final_fine_tune/fine_tuned_hp_od-output__squad_test3_es-steps_nte20_ls250_est5000_rn-output__squad_test3_dpm-sigmoied_threshold:1d_alt_apme-sigmoied_threshold_aowd0_bm1_abr32_abc32_it0_fw10_r-l1_rfl10_dl0.25_dtnop-csarron__bert-base-uncased-squad-v1", "overwrite_output_dir": 1, "past_index": -1, "per_device_eval_batch_size": 8, "per_device_train_batch_size": 16, "per_gpu_eval_batch_size": null, "per_gpu_train_batch_size": null, "prediction_loss_only": false, "remove_unused_columns": true, "report_to": null, "run_name": "/data_2to/devel_data/nn_pruning/output/squad_test_final_fine_tune/fine_tuned_hp_od-output__squad_test3_es-steps_nte20_ls250_est5000_rn-output__squad_test3_dpm-sigmoied_threshold:1d_alt_apme-sigmoied_threshold_aowd0_bm1_abr32_abc32_it0_fw10_r-l1_rfl10_dl0.25_dtnop-csarron__bert-base-uncased-squad-v1", "save_steps": 2500, "save_strategy": "steps", "save_total_limit": 50, "seed": 17, "sharded_ddp": "", "skip_memory_metrics": false, "tpu_metrics_debug": false, "tpu_num_cores": null, "warmup_ratio": 0.0, "warmup_steps": 10, "weight_decay": 0.0}}, "f1": 88.11014400914335, "fill_rate": 0.3359194155092592, "speedup": 2.094444154371984}}
{"speedup": 2.2192523962418718, "f1": 88.06386432532665, "meta": {"annotate": "27", "cat_fun_name": "is_new_xp", "checkpoint": {"config": {"_name_or_path": "/home/lagunas/devel/hf/nn_pruning/nn_pruning/analysis/tmp_finetune", "architectures": ["BertForQuestionAnswering"], "attention_probs_dropout_prob": 0.1, "gradient_checkpointing": false, "hidden_act": "gelu", "hidden_dropout_prob": 0.1, "hidden_size": 768, "initializer_range": 0.02, "intermediate_size": 3072, "layer_norm_eps": 1e-12, "max_position_embeddings": 512, "model_type": "bert", "num_attention_heads": 12, "num_hidden_layers": 12, "pad_token_id": 0, "position_embedding_type": "absolute", "pruned_heads": {"0": [0, 2, 4, 5, 6, 7, 9, 11], "1": [0, 2, 3, 5, 6, 7, 8, 9], "10": [1, 4, 5, 6, 7, 8], "11": [0, 2, 3, 5, 6, 7, 8, 10, 11], "2": [8, 4, 7], "3": [2, 4, 6, 7], "4": [1, 2], "5": [1, 2, 5, 6, 7], "6": [0, 2, 3, 7], "7": [1, 3, 6, 7, 11], "8": [0, 8, 3, 4], "9": [1, 3, 4, 5, 7, 9, 10]}, "type_vocab_size": 2, "vocab_size": 30522}, "eval_metrics": {"exact_match": 80.69063386944181, "f1": 88.06386432532665}, "path": "/data_2to/devel_data/nn_pruning/output/squad_test_final_fine_tune/fine_tuned_aws_nn-pruning-v10-a32-l10-dl0-5--2021-01-21--00-54-13/checkpoint-22132", "source_checkpoint": "/data_2to/devel_data/nn_pruning/output/squad_test_aws/aws_nn-pruning-v10-a32-l10-dl0-5--2021-01-21--00-54-13/checkpoint-110660", "sparse_args": {"ampere_pruning_method": "disabled", "attention_block_cols": 1, "attention_block_rows": 1, "attention_lambda": 1.0, "attention_output_with_dense": 0, "attention_pruning_method": "topK", "bias_mask": true, "dense_block_cols": 1, "dense_block_rows": 1, "dense_lambda": 1.0, "dense_pruning_method": "topK", "distil_alpha_ce": 0.1, "distil_alpha_teacher": 0.9, "distil_teacher_name_or_path": "csarron/bert-base-uncased-squad-v1", "distil_temperature": 2.0, "final_ampere_temperature": 20.0, "final_finetune": 1, "final_threshold": 0.5, "final_warmup": 0, "initial_ampere_temperature": 0.0, "initial_threshold": 1.0, "initial_warmup": 0, "mask_init": "constant", "mask_scale": 0.0, "mask_scores_learning_rate": 0.01, "regularization": "", "regularization_final_lambda": 0}, "speed": {"cuda_eval_elapsed_time": 17.390718185424806, "eval_elapsed_time": 24.534384376835078}, "speedup": 2.2192523962418718, "stats": {"layers": {"0": {"linear_attention_nnz": 786432, "linear_attention_total": 2359296, "linear_dense_nnz": 634368, "linear_dense_total": 4718592, "linear_nnz": 1420800, "linear_total": 7077888, "nnz": 1426589, "total": 7086336}, "1": {"linear_attention_nnz": 786432, "linear_attention_total": 2359296, "linear_dense_nnz": 916992, "linear_dense_total": 4718592, "linear_nnz": 1703424, "linear_total": 7077888, "nnz": 1709397, "total": 7086336}, "10": {"linear_attention_nnz": 1179648, "linear_attention_total": 2359296, "linear_dense_nnz": 112128, "linear_dense_total": 4718592, "linear_nnz": 1291776, "linear_total": 7077888, "nnz": 1297609, "total": 7086720}, "11": {"linear_attention_nnz": 589824, "linear_attention_total": 2359296, "linear_dense_nnz": 313344, "linear_dense_total": 4718592, "linear_nnz": 903168, "linear_total": 7077888, "nnz": 908556, "total": 7086144}, "2": {"linear_attention_nnz": 1769472, "linear_attention_total": 2359296, "linear_dense_nnz": 1016832, "linear_dense_total": 4718592, "linear_nnz": 2786304, "linear_total": 7077888, "nnz": 2793302, "total": 7087296}, "3": {"linear_attention_nnz": 1572864, "linear_attention_total": 2359296, "linear_dense_nnz": 1076736, "linear_dense_total": 4718592, "linear_nnz": 2649600, "linear_total": 7077888, "nnz": 2656445, "total": 7087104}, "4": {"linear_attention_nnz": 1966080, "linear_attention_total": 2359296, "linear_dense_nnz": 1158144, "linear_dense_total": 4718592, "linear_nnz": 3124224, "linear_total": 7077888, "nnz": 3131506, "total": 7087488}, "5": {"linear_attention_nnz": 1376256, "linear_attention_total": 2359296, "linear_dense_nnz": 1073664, "linear_dense_total": 4718592, "linear_nnz": 2449920, "linear_total": 7077888, "nnz": 2456571, "total": 7086912}, "6": {"linear_attention_nnz": 1572864, "linear_attention_total": 2359296, "linear_dense_nnz": 815616, "linear_dense_total": 4718592, "linear_nnz": 2388480, "linear_total": 7077888, "nnz": 2395155, "total": 7087104}, "7": {"linear_attention_nnz": 1376256, "linear_attention_total": 2359296, "linear_dense_nnz": 629760, "linear_dense_total": 4718592, "linear_nnz": 2006016, "linear_total": 7077888, "nnz": 2012378, "total": 7086912}, "8": {"linear_attention_nnz": 1572864, "linear_attention_total": 2359296, "linear_dense_nnz": 337920, "linear_dense_total": 4718592, "linear_nnz": 1910784, "linear_total": 7077888, "nnz": 1917148, "total": 7087104}, "9": {"linear_attention_nnz": 983040, "linear_attention_total": 2359296, "linear_dense_nnz": 139776, "linear_dense_total": 4718592, "linear_nnz": 1122816, "linear_total": 7077888, "nnz": 1128475, "total": 7086528}}, "linear_nnz": 23757312, "linear_sparsity": 72.0287181712963, "linear_total": 84934656, "nnz": 47671853, "pruned_heads": {"0": [0, 2, 4, 5, 6, 7, 9, 11], "1": [0, 2, 3, 5, 6, 7, 8, 9], "10": [1, 4, 5, 6, 7, 8], "11": [0, 2, 3, 5, 6, 7, 8, 10, 11], "2": [8, 4, 7], "3": [2, 4, 6, 7], "4": [1, 2], "5": [1, 2, 5, 6, 7], "6": [0, 2, 3, 7], "7": [1, 3, 6, 7, 11], "8": [0, 8, 3, 4], "9": [1, 3, 4, 5, 7, 9, 10]}, "total": 108880706, "total_sparsity": 56.216436546618276}, "training_args": {"_n_gpu": -1, "adafactor": false, "adam_beta1": 0.9, "adam_beta2": 0.999, "adam_epsilon": 1e-08, "dataloader_drop_last": false, "dataloader_num_workers": 0, "dataloader_pin_memory": true, "ddp_find_unused_parameters": null, "debug": false, "deepspeed": null, "disable_tqdm": false, "do_eval": 1, "do_predict": false, "do_train": 1, "eval_accumulation_steps": null, "eval_steps": 2500, "evaluation_strategy": "steps", "fp16": false, "fp16_backend": "auto", "fp16_full_eval": false, "fp16_opt_level": "O1", "gradient_accumulation_steps": 1, "greater_is_better": null, "group_by_length": false, "ignore_data_skip": false, "label_names": null, "label_smoothing_factor": 0.0, "learning_rate": 3e-05, "load_best_model_at_end": false, "local_rank": -1, "logging_dir": "/data_2to/devel_data/nn_pruning/output/squad_test_final_fine_tune/fine_tuned_aws_nn-pruning-v10-a32-l10-dl0-5--2021-01-21--00-54-13", "logging_first_step": false, "logging_steps": 250, "logging_strategy": "steps", "lr_scheduler_type": "linear", "max_grad_norm": 1.0, "max_steps": -1, "metric_for_best_model": null, "no_cuda": false, "num_train_epochs": 4, "optimize_model_before_eval": "disabled", "output_dir": "/data_2to/devel_data/nn_pruning/output/squad_test_final_fine_tune/fine_tuned_aws_nn-pruning-v10-a32-l10-dl0-5--2021-01-21--00-54-13", "overwrite_output_dir": 1, "past_index": -1, "per_device_eval_batch_size": 128, "per_device_train_batch_size": 16, "per_gpu_eval_batch_size": null, "per_gpu_train_batch_size": null, "prediction_loss_only": false, "remove_unused_columns": true, "report_to": null, "run_name": "/data_2to/devel_data/nn_pruning/output/squad_test_final_fine_tune/fine_tuned_aws_nn-pruning-v10-a32-l10-dl0-5--2021-01-21--00-54-13", "save_steps": 2500, "save_strategy": "steps", "save_total_limit": 50, "seed": 17, "sharded_ddp": "", "skip_memory_metrics": false, "tpu_metrics_debug": false, "tpu_num_cores": null, "warmup_ratio": 0.0, "warmup_steps": 10, "weight_decay": 0.0}}, "f1": 88.06386432532665, "fill_rate": 0.279712818287037, "speedup": 2.2192523962418718}}
{"speedup": 2.436764806371294, "f1": 87.70940223967354, "meta": {"annotate": "26", "cat_fun_name": "is_new_xp", "checkpoint": {"config": {"_name_or_path": "/home/lagunas/devel/hf/nn_pruning/nn_pruning/analysis/tmp_finetune", "architectures": ["BertForQuestionAnswering"], "attention_probs_dropout_prob": 0.1, "gradient_checkpointing": false, "hidden_act": "gelu", "hidden_dropout_prob": 0.1, "hidden_size": 768, "initializer_range": 0.02, "intermediate_size": 3072, "layer_norm_eps": 1e-12, "max_position_embeddings": 512, "model_type": "bert", "num_attention_heads": 12, "num_hidden_layers": 12, "pad_token_id": 0, "position_embedding_type": "absolute", "pruned_heads": {"0": [0, 2, 4, 5, 6, 7, 9, 11], "1": [0, 2, 3, 5, 6, 7, 8, 9], "10": [1, 4, 5, 6, 7, 8, 9], "11": [0, 2, 3, 5, 6, 7, 8, 10, 11], "2": [1, 2, 4, 7, 8, 11], "3": [2, 4, 6, 7, 10], "4": [0, 1, 2, 6, 11], "5": [0, 1, 2, 5, 6, 7, 11], "6": [0, 2, 3, 4, 7, 10], "7": [1, 3, 6, 7, 11], "8": [0, 1, 2, 3, 4, 6, 8], "9": [1, 3, 4, 5, 7, 9, 10]}, "type_vocab_size": 2, "vocab_size": 30522}, "eval_metrics": {"exact_match": 80.02838221381268, "f1": 87.70940223967354}, "path": "/data_2to/devel_data/nn_pruning/output/squad_test_final_fine_tune/fine_tuned_hp_od-output__squad_test3_es-steps_nte20_ls250_est5000_rn-output__squad_test3_dpm-sigmoied_threshold:1d_alt_apme-sigmoied_threshold_aowd0_bm1_abr32_abc32_it0_fw10_r-l1_rfl20_dl0.25_dtnop-csarron__bert-base-uncased-squad-v1/checkpoint-22132", "source_checkpoint": "/data_2to/devel_data/nn_pruning/output/squad_test3/hp_od-output__squad_test3_es-steps_nte20_ls250_est5000_rn-output__squad_test3_dpm-sigmoied_threshold:1d_alt_apme-sigmoied_threshold_aowd0_bm1_abr32_abc32_it0_fw10_r-l1_rfl20_dl0.25_dtnop-csarron__bert-base-uncased-squad-v1/checkpoint-90000", "sparse_args": {"ampere_pruning_method": "disabled", "attention_block_cols": 1, "attention_block_rows": 1, "attention_lambda": 1.0, "attention_output_with_dense": 0, "attention_pruning_method": "topK", "bias_mask": true, "dense_block_cols": 1, "dense_block_rows": 1, "dense_lambda": 1.0, "dense_pruning_method": "topK", "distil_alpha_ce": 0.1, "distil_alpha_teacher": 0.9, "distil_teacher_name_or_path": "csarron/bert-base-uncased-squad-v1", "distil_temperature": 2.0, "final_ampere_temperature": 20.0, "final_finetune": 1, "final_threshold": 0.5, "final_warmup": 0, "initial_ampere_temperature": 0.0, "initial_threshold": 1.0, "initial_warmup": 0, "mask_init": "constant", "mask_scale": 0.0, "mask_scores_learning_rate": 0.01, "regularization": "", "regularization_final_lambda": 0}, "speed": {"cuda_eval_elapsed_time": 15.838374267578125, "eval_elapsed_time": 22.999519595876336}, "speedup": 2.436764806371294, "stats": {"layers": {"0": {"linear_attention_nnz": 786432, "linear_attention_total": 2359296, "linear_dense_nnz": 847872, "linear_dense_total": 4718592, "linear_nnz": 1634304, "linear_total": 7077888, "nnz": 1640232, "total": 7086336}, "1": {"linear_attention_nnz": 786432, "linear_attention_total": 2359296, "linear_dense_nnz": 1101312, "linear_dense_total": 4718592, "linear_nnz": 1887744, "linear_total": 7077888, "nnz": 1893837, "total": 7086336}, "10": {"linear_attention_nnz": 983040, "linear_attention_total": 2359296, "linear_dense_nnz": 147456, "linear_dense_total": 4718592, "linear_nnz": 1130496, "linear_total": 7077888, "nnz": 1136160, "total": 7086528}, "11": {"linear_attention_nnz": 589824, "linear_attention_total": 2359296, "linear_dense_nnz": 365568, "linear_dense_total": 4718592, "linear_nnz": 955392, "linear_total": 7077888, "nnz": 960814, "total": 7086144}, "2": {"linear_attention_nnz": 1179648, "linear_attention_total": 2359296, "linear_dense_nnz": 1221120, "linear_dense_total": 4718592, "linear_nnz": 2400768, "linear_total": 7077888, "nnz": 2407323, "total": 7086720}, "3": {"linear_attention_nnz": 1376256, "linear_attention_total": 2359296, "linear_dense_nnz": 1211904, "linear_dense_total": 4718592, "linear_nnz": 2588160, "linear_total": 7077888, "nnz": 2594901, "total": 7086912}, "4": {"linear_attention_nnz": 1376256, "linear_attention_total": 2359296, "linear_dense_nnz": 1279488, "linear_dense_total": 4718592, "linear_nnz": 2655744, "linear_total": 7077888, "nnz": 2662529, "total": 7086912}, "5": {"linear_attention_nnz": 983040, "linear_attention_total": 2359296, "linear_dense_nnz": 1216512, "linear_dense_total": 4718592, "linear_nnz": 2199552, "linear_total": 7077888, "nnz": 2205912, "total": 7086528}, "6": {"linear_attention_nnz": 1179648, "linear_attention_total": 2359296, "linear_dense_nnz": 952320, "linear_dense_total": 4718592, "linear_nnz": 2131968, "linear_total": 7077888, "nnz": 2138348, "total": 7086720}, "7": {"linear_attention_nnz": 1376256, "linear_attention_total": 2359296, "linear_dense_nnz": 715776, "linear_dense_total": 4718592, "linear_nnz": 2092032, "linear_total": 7077888, "nnz": 2098450, "total": 7086912}, "8": {"linear_attention_nnz": 983040, "linear_attention_total": 2359296, "linear_dense_nnz": 434688, "linear_dense_total": 4718592, "linear_nnz": 1417728, "linear_total": 7077888, "nnz": 1423579, "total": 7086528}, "9": {"linear_attention_nnz": 983040, "linear_attention_total": 2359296, "linear_dense_nnz": 172032, "linear_dense_total": 4718592, "linear_nnz": 1155072, "linear_total": 7077888, "nnz": 1160752, "total": 7086528}}, "linear_nnz": 22248960, "linear_sparsity": 73.80461516203704, "linear_total": 84934656, "nnz": 46161559, "pruned_heads": {"0": [0, 2, 4, 5, 6, 7, 9, 11], "1": [0, 2, 3, 5, 6, 7, 8, 9], "10": [1, 4, 5, 6, 7, 8, 9], "11": [0, 2, 3, 5, 6, 7, 8, 10, 11], "2": [1, 2, 4, 7, 8, 11], "3": [2, 4, 6, 7, 10], "4": [0, 1, 2, 6, 11], "5": [0, 1, 2, 5, 6, 7, 11], "6": [0, 2, 3, 4, 7, 10], "7": [1, 3, 6, 7, 11], "8": [0, 1, 2, 3, 4, 6, 8], "9": [1, 3, 4, 5, 7, 9, 10]}, "total": 108877826, "total_sparsity": 57.602424023418685}, "training_args": {"_n_gpu": -1, "adafactor": false, "adam_beta1": 0.9, "adam_beta2": 0.999, "adam_epsilon": 1e-08, "dataloader_drop_last": false, "dataloader_num_workers": 0, "dataloader_pin_memory": true, "ddp_find_unused_parameters": null, "debug": false, "deepspeed": null, "disable_tqdm": false, "do_eval": 1, "do_predict": false, "do_train": 1, "eval_accumulation_steps": null, "eval_steps": 2500, "evaluation_strategy": "steps", "fp16": false, "fp16_backend": "auto", "fp16_full_eval": false, "fp16_opt_level": "O1", "gradient_accumulation_steps": 1, "greater_is_better": null, "group_by_length": false, "ignore_data_skip": false, "label_names": null, "label_smoothing_factor": 0.0, "learning_rate": 3e-05, "load_best_model_at_end": false, "local_rank": -1, "logging_dir": "/data_2to/devel_data/nn_pruning/output/squad_test_final_fine_tune/fine_tuned_hp_od-output__squad_test3_es-steps_nte20_ls250_est5000_rn-output__squad_test3_dpm-sigmoied_threshold:1d_alt_apme-sigmoied_threshold_aowd0_bm1_abr32_abc32_it0_fw10_r-l1_rfl20_dl0.25_dtnop-csarron__bert-base-uncased-squad-v1", "logging_first_step": false, "logging_steps": 250, "logging_strategy": "steps", "lr_scheduler_type": "linear", "max_grad_norm": 1.0, "max_steps": -1, "metric_for_best_model": null, "no_cuda": false, "num_train_epochs": 4, "optimize_model_before_eval": "disabled", "output_dir": "/data_2to/devel_data/nn_pruning/output/squad_test_final_fine_tune/fine_tuned_hp_od-output__squad_test3_es-steps_nte20_ls250_est5000_rn-output__squad_test3_dpm-sigmoied_threshold:1d_alt_apme-sigmoied_threshold_aowd0_bm1_abr32_abc32_it0_fw10_r-l1_rfl20_dl0.25_dtnop-csarron__bert-base-uncased-squad-v1", "overwrite_output_dir": 1, "past_index": -1, "per_device_eval_batch_size": 8, "per_device_train_batch_size": 16, "per_gpu_eval_batch_size": null, "per_gpu_train_batch_size": null, "prediction_loss_only": false, "remove_unused_columns": true, "report_to": null, "run_name": "/data_2to/devel_data/nn_pruning/output/squad_test_final_fine_tune/fine_tuned_hp_od-output__squad_test3_es-steps_nte20_ls250_est5000_rn-output__squad_test3_dpm-sigmoied_threshold:1d_alt_apme-sigmoied_threshold_aowd0_bm1_abr32_abc32_it0_fw10_r-l1_rfl20_dl0.25_dtnop-csarron__bert-base-uncased-squad-v1", "save_steps": 2500, "save_strategy": "steps", "save_total_limit": 50, "seed": 17, "sharded_ddp": "", "skip_memory_metrics": false, "tpu_metrics_debug": false, "tpu_num_cores": null, "warmup_ratio": 0.0, "warmup_steps": 10, "weight_decay": 0.0}}, "f1": 87.70940223967354, "fill_rate": 0.26195384837962965, "speedup": 2.436764806371294}}
{"speedup": 2.5991656903766382, "f1": 87.22907143184382, "meta": {"annotate": "21", "cat_fun_name": "is_new_xp", "checkpoint": {"config": {"_name_or_path": "/home/lagunas/devel/hf/nn_pruning/nn_pruning/analysis/tmp_finetune", "architectures": ["BertForQuestionAnswering"], "attention_probs_dropout_prob": 0.1, "gradient_checkpointing": false, "hidden_act": "gelu", "hidden_dropout_prob": 0.1, "hidden_size": 768, "initializer_range": 0.02, "intermediate_size": 3072, "layer_norm_eps": 1e-12, "max_position_embeddings": 512, "model_type": "bert", "num_attention_heads": 12, "num_hidden_layers": 12, "pad_token_id": 0, "position_embedding_type": "absolute", "pruned_heads": {"0": [0, 2, 4, 5, 6, 7, 9, 11], "1": [0, 2, 3, 5, 6, 7, 8, 9], "10": [1, 4, 5, 6, 7, 8, 9], "11": [0, 2, 3, 5, 6, 7, 8, 10, 11], "2": [1, 2, 4, 7, 8, 11], "3": [2, 4, 6, 7, 10], "4": [0, 1, 2, 6, 11], "5": [0, 1, 2, 5, 6, 7, 11], "6": [0, 2, 3, 4, 7, 10], "7": [1, 3, 6, 7, 11], "8": [0, 2, 3, 4, 6, 8], "9": [1, 3, 4, 5, 7, 9, 10]}, "type_vocab_size": 2, "vocab_size": 30522}, "eval_metrics": {"exact_match": 79.4228949858089, "f1": 87.22907143184382}, "path": "/data_2to/devel_data/nn_pruning/output/squad_test_final_fine_tune/fine_tuned_aws_nn-pruning-v10-a32-l20-dl0-5--2021-01-21--00-55-44/checkpoint-22132", "source_checkpoint": "/data_2to/devel_data/nn_pruning/output/squad_test_aws/aws_nn-pruning-v10-a32-l20-dl0-5--2021-01-21--00-55-44/checkpoint-110000", "sparse_args": {"ampere_pruning_method": "disabled", "attention_block_cols": 1, "attention_block_rows": 1, "attention_lambda": 1.0, "attention_output_with_dense": 0, "attention_pruning_method": "topK", "bias_mask": true, "dense_block_cols": 1, "dense_block_rows": 1, "dense_lambda": 1.0, "dense_pruning_method": "topK", "distil_alpha_ce": 0.1, "distil_alpha_teacher": 0.9, "distil_teacher_name_or_path": "csarron/bert-base-uncased-squad-v1", "distil_temperature": 2.0, "final_ampere_temperature": 20.0, "final_finetune": 1, "final_threshold": 0.5, "final_warmup": 0, "initial_ampere_temperature": 0.0, "initial_threshold": 1.0, "initial_warmup": 0, "mask_init": "constant", "mask_scale": 0.0, "mask_scores_learning_rate": 0.01, "regularization": "", "regularization_final_lambda": 0}, "speed": {"cuda_eval_elapsed_time": 14.848762104034424, "eval_elapsed_time": 22.048566517885774}, "speedup": 2.5991656903766382, "stats": {"layers": {"0": {"linear_attention_nnz": 786432, "linear_attention_total": 2359296, "linear_dense_nnz": 411648, "linear_dense_total": 4718592, "linear_nnz": 1198080, "linear_total": 7077888, "nnz": 1203724, "total": 7086336}, "1": {"linear_attention_nnz": 786432, "linear_attention_total": 2359296, "linear_dense_nnz": 592896, "linear_dense_total": 4718592, "linear_nnz": 1379328, "linear_total": 7077888, "nnz": 1385090, "total": 7086336}, "10": {"linear_attention_nnz": 983040, "linear_attention_total": 2359296, "linear_dense_nnz": 87552, "linear_dense_total": 4718592, "linear_nnz": 1070592, "linear_total": 7077888, "nnz": 1076217, "total": 7086528}, "11": {"linear_attention_nnz": 589824, "linear_attention_total": 2359296, "linear_dense_nnz": 199680, "linear_dense_total": 4718592, "linear_nnz": 789504, "linear_total": 7077888, "nnz": 794818, "total": 7086144}, "2": {"linear_attention_nnz": 1179648, "linear_attention_total": 2359296, "linear_dense_nnz": 698880, "linear_dense_total": 4718592, "linear_nnz": 1878528, "linear_total": 7077888, "nnz": 1884743, "total": 7086720}, "3": {"linear_attention_nnz": 1376256, "linear_attention_total": 2359296, "linear_dense_nnz": 714240, "linear_dense_total": 4718592, "linear_nnz": 2090496, "linear_total": 7077888, "nnz": 2096913, "total": 7086912}, "4": {"linear_attention_nnz": 1376256, "linear_attention_total": 2359296, "linear_dense_nnz": 834048, "linear_dense_total": 4718592, "linear_nnz": 2210304, "linear_total": 7077888, "nnz": 2216799, "total": 7086912}, "5": {"linear_attention_nnz": 983040, "linear_attention_total": 2359296, "linear_dense_nnz": 743424, "linear_dense_total": 4718592, "linear_nnz": 1726464, "linear_total": 7077888, "nnz": 1732516, "total": 7086528}, "6": {"linear_attention_nnz": 1179648, "linear_attention_total": 2359296, "linear_dense_nnz": 568320, "linear_dense_total": 4718592, "linear_nnz": 1747968, "linear_total": 7077888, "nnz": 1754098, "total": 7086720}, "7": {"linear_attention_nnz": 1376256, "linear_attention_total": 2359296, "linear_dense_nnz": 450048, "linear_dense_total": 4718592, "linear_nnz": 1826304, "linear_total": 7077888, "nnz": 1832549, "total": 7086912}, "8": {"linear_attention_nnz": 1179648, "linear_attention_total": 2359296, "linear_dense_nnz": 264192, "linear_dense_total": 4718592, "linear_nnz": 1443840, "linear_total": 7077888, "nnz": 1449772, "total": 7086720}, "9": {"linear_attention_nnz": 983040, "linear_attention_total": 2359296, "linear_dense_nnz": 101376, "linear_dense_total": 4718592, "linear_nnz": 1084416, "linear_total": 7077888, "nnz": 1090050, "total": 7086528}}, "linear_nnz": 18445824, "linear_sparsity": 78.28233506944444, "linear_total": 84934656, "nnz": 42356011, "pruned_heads": {"0": [0, 2, 4, 5, 6, 7, 9, 11], "1": [0, 2, 3, 5, 6, 7, 8, 9], "10": [1, 4, 5, 6, 7, 8, 9], "11": [0, 2, 3, 5, 6, 7, 8, 10, 11], "2": [1, 2, 4, 7, 8, 11], "3": [2, 4, 6, 7, 10], "4": [0, 1, 2, 6, 11], "5": [0, 1, 2, 5, 6, 7, 11], "6": [0, 2, 3, 4, 7, 10], "7": [1, 3, 6, 7, 11], "8": [0, 2, 3, 4, 6, 8], "9": [1, 3, 4, 5, 7, 9, 10]}, "total": 108878018, "total_sparsity": 61.097738755677945}, "training_args": {"_n_gpu": -1, "adafactor": false, "adam_beta1": 0.9, "adam_beta2": 0.999, "adam_epsilon": 1e-08, "dataloader_drop_last": false, "dataloader_num_workers": 0, "dataloader_pin_memory": true, "ddp_find_unused_parameters": null, "debug": false, "deepspeed": null, "disable_tqdm": false, "do_eval": 1, "do_predict": false, "do_train": 1, "eval_accumulation_steps": null, "eval_steps": 2500, "evaluation_strategy": "steps", "fp16": false, "fp16_backend": "auto", "fp16_full_eval": false, "fp16_opt_level": "O1", "gradient_accumulation_steps": 1, "greater_is_better": null, "group_by_length": false, "ignore_data_skip": false, "label_names": null, "label_smoothing_factor": 0.0, "learning_rate": 3e-05, "load_best_model_at_end": false, "local_rank": -1, "logging_dir": "/data_2to/devel_data/nn_pruning/output/squad_test_final_fine_tune/fine_tuned_aws_nn-pruning-v10-a32-l20-dl0-5--2021-01-21--00-55-44", "logging_first_step": false, "logging_steps": 250, "logging_strategy": "steps", "lr_scheduler_type": "linear", "max_grad_norm": 1.0, "max_steps": -1, "metric_for_best_model": null, "no_cuda": false, "num_train_epochs": 4, "optimize_model_before_eval": "disabled", "output_dir": "/data_2to/devel_data/nn_pruning/output/squad_test_final_fine_tune/fine_tuned_aws_nn-pruning-v10-a32-l20-dl0-5--2021-01-21--00-55-44", "overwrite_output_dir": 1, "past_index": -1, "per_device_eval_batch_size": 128, "per_device_train_batch_size": 16, "per_gpu_eval_batch_size": null, "per_gpu_train_batch_size": null, "prediction_loss_only": false, "remove_unused_columns": true, "report_to": null, "run_name": "/data_2to/devel_data/nn_pruning/output/squad_test_final_fine_tune/fine_tuned_aws_nn-pruning-v10-a32-l20-dl0-5--2021-01-21--00-55-44", "save_steps": 2500, "save_strategy": "steps", "save_total_limit": 50, "seed": 17, "sharded_ddp": "", "skip_memory_metrics": false, "tpu_metrics_debug": false, "tpu_num_cores": null, "warmup_ratio": 0.0, "warmup_steps": 10, "weight_decay": 0.0}}, "f1": 87.22907143184382, "fill_rate": 0.21717664930555558, "speedup": 2.5991656903766382}}
{"speedup": 2.68869031405704, "f1": 86.75497848244157, "meta": {"annotate": "19", "cat_fun_name": "is_new_xp", "checkpoint": {"config": {"_name_or_path": "/home/lagunas/devel/hf/nn_pruning/nn_pruning/analysis/tmp_finetune", "architectures": ["BertForQuestionAnswering"], "attention_probs_dropout_prob": 0.1, "gradient_checkpointing": false, "hidden_act": "gelu", "hidden_dropout_prob": 0.1, "hidden_size": 768, "initializer_range": 0.02, "intermediate_size": 3072, "layer_norm_eps": 1e-12, "max_position_embeddings": 512, "model_type": "bert", "num_attention_heads": 12, "num_hidden_layers": 12, "pad_token_id": 0, "position_embedding_type": "absolute", "pruned_heads": {"0": [0, 2, 4, 5, 6, 7, 9, 11], "1": [0, 2, 3, 5, 6, 7, 8, 9], "10": [1, 4, 5, 6, 7, 8, 9], "11": [0, 2, 3, 5, 6, 7, 8, 10, 11], "2": [1, 2, 4, 7, 8, 11], "3": [2, 4, 6, 7], "4": [1, 2, 4, 6, 11], "5": [0, 1, 2, 5, 6, 7, 11], "6": [0, 2, 3, 4, 7, 10], "7": [1, 3, 6, 7, 11], "8": [0, 2, 3, 4, 8], "9": [1, 3, 4, 5, 7, 9, 10]}, "type_vocab_size": 2, "vocab_size": 30522}, "eval_metrics": {"exact_match": 78.82686849574267, "f1": 86.75497848244157}, "path": "/data_2to/devel_data/nn_pruning/output/squad_test_final_fine_tune/fine_tuned_aws_nn-pruning-v10-a32-l20-dl1--2021-01-21--00-55-15/checkpoint-22132", "source_checkpoint": "/data_2to/devel_data/nn_pruning/output/squad_test_aws/aws_nn-pruning-v10-a32-l20-dl1--2021-01-21--00-55-15/checkpoint-110660", "sparse_args": {"ampere_pruning_method": "disabled", "attention_block_cols": 1, "attention_block_rows": 1, "attention_lambda": 1.0, "attention_output_with_dense": 0, "attention_pruning_method": "topK", "bias_mask": true, "dense_block_cols": 1, "dense_block_rows": 1, "dense_lambda": 1.0, "dense_pruning_method": "topK", "distil_alpha_ce": 0.1, "distil_alpha_teacher": 0.9, "distil_teacher_name_or_path": "csarron/bert-base-uncased-squad-v1", "distil_temperature": 2.0, "final_ampere_temperature": 20.0, "final_finetune": 1, "final_threshold": 0.5, "final_warmup": 0, "initial_ampere_temperature": 0.0, "initial_threshold": 1.0, "initial_warmup": 0, "mask_init": "constant", "mask_scale": 0.0, "mask_scores_learning_rate": 0.01, "regularization": "", "regularization_final_lambda": 0}, "speed": {"cuda_eval_elapsed_time": 14.354346725463868, "eval_elapsed_time": 21.489493974950165}, "speedup": 2.68869031405704, "stats": {"layers": {"0": {"linear_attention_nnz": 786432, "linear_attention_total": 2359296, "linear_dense_nnz": 181248, "linear_dense_total": 4718592, "linear_nnz": 967680, "linear_total": 7077888, "nnz": 973174, "total": 7086336}, "1": {"linear_attention_nnz": 786432, "linear_attention_total": 2359296, "linear_dense_nnz": 299520, "linear_dense_total": 4718592, "linear_nnz": 1085952, "linear_total": 7077888, "nnz": 1091523, "total": 7086336}, "10": {"linear_attention_nnz": 983040, "linear_attention_total": 2359296, "linear_dense_nnz": 58368, "linear_dense_total": 4718592, "linear_nnz": 1041408, "linear_total": 7077888, "nnz": 1047014, "total": 7086528}, "11": {"linear_attention_nnz": 589824, "linear_attention_total": 2359296, "linear_dense_nnz": 96768, "linear_dense_total": 4718592, "linear_nnz": 686592, "linear_total": 7077888, "nnz": 691839, "total": 7086144}, "2": {"linear_attention_nnz": 1179648, "linear_attention_total": 2359296, "linear_dense_nnz": 407040, "linear_dense_total": 4718592, "linear_nnz": 1586688, "linear_total": 7077888, "nnz": 1592713, "total": 7086720}, "3": {"linear_attention_nnz": 1572864, "linear_attention_total": 2359296, "linear_dense_nnz": 440832, "linear_dense_total": 4718592, "linear_nnz": 2013696, "linear_total": 7077888, "nnz": 2020127, "total": 7087104}, "4": {"linear_attention_nnz": 1376256, "linear_attention_total": 2359296, "linear_dense_nnz": 496128, "linear_dense_total": 4718592, "linear_nnz": 1872384, "linear_total": 7077888, "nnz": 1878659, "total": 7086912}, "5": {"linear_attention_nnz": 983040, "linear_attention_total": 2359296, "linear_dense_nnz": 433152, "linear_dense_total": 4718592, "linear_nnz": 1416192, "linear_total": 7077888, "nnz": 1422042, "total": 7086528}, "6": {"linear_attention_nnz": 1179648, "linear_attention_total": 2359296, "linear_dense_nnz": 337920, "linear_dense_total": 4718592, "linear_nnz": 1517568, "linear_total": 7077888, "nnz": 1523548, "total": 7086720}, "7": {"linear_attention_nnz": 1376256, "linear_attention_total": 2359296, "linear_dense_nnz": 268800, "linear_dense_total": 4718592, "linear_nnz": 1645056, "linear_total": 7077888, "nnz": 1651183, "total": 7086912}, "8": {"linear_attention_nnz": 1376256, "linear_attention_total": 2359296, "linear_dense_nnz": 158208, "linear_dense_total": 4718592, "linear_nnz": 1534464, "linear_total": 7077888, "nnz": 1540519, "total": 7086912}, "9": {"linear_attention_nnz": 983040, "linear_attention_total": 2359296, "linear_dense_nnz": 73728, "linear_dense_total": 4718592, "linear_nnz": 1056768, "linear_total": 7077888, "nnz": 1062384, "total": 7086528}}, "linear_nnz": 16424448, "linear_sparsity": 80.66225405092592, "linear_total": 84934656, "nnz": 40333447, "pruned_heads": {"0": [0, 2, 4, 5, 6, 7, 9, 11], "1": [0, 2, 3, 5, 6, 7, 8, 9], "10": [1, 4, 5, 6, 7, 8, 9], "11": [0, 2, 3, 5, 6, 7, 8, 10, 11], "2": [1, 2, 4, 7, 8, 11], "3": [2, 4, 6, 7], "4": [1, 2, 4, 6, 11], "5": [0, 1, 2, 5, 6, 7, 11], "6": [0, 2, 3, 4, 7, 10], "7": [1, 3, 6, 7, 11], "8": [0, 2, 3, 4, 8], "9": [1, 3, 4, 5, 7, 9, 10]}, "total": 108878402, "total_sparsity": 62.95551159907728}, "training_args": {"_n_gpu": -1, "adafactor": false, "adam_beta1": 0.9, "adam_beta2": 0.999, "adam_epsilon": 1e-08, "dataloader_drop_last": false, "dataloader_num_workers": 0, "dataloader_pin_memory": true, "ddp_find_unused_parameters": null, "debug": false, "deepspeed": null, "disable_tqdm": false, "do_eval": 1, "do_predict": false, "do_train": 1, "eval_accumulation_steps": null, "eval_steps": 2500, "evaluation_strategy": "steps", "fp16": false, "fp16_backend": "auto", "fp16_full_eval": false, "fp16_opt_level": "O1", "gradient_accumulation_steps": 1, "greater_is_better": null, "group_by_length": false, "ignore_data_skip": false, "label_names": null, "label_smoothing_factor": 0.0, "learning_rate": 3e-05, "load_best_model_at_end": false, "local_rank": -1, "logging_dir": "/data_2to/devel_data/nn_pruning/output/squad_test_final_fine_tune/fine_tuned_aws_nn-pruning-v10-a32-l20-dl1--2021-01-21--00-55-15", "logging_first_step": false, "logging_steps": 250, "logging_strategy": "steps", "lr_scheduler_type": "linear", "max_grad_norm": 1.0, "max_steps": -1, "metric_for_best_model": null, "no_cuda": false, "num_train_epochs": 4, "optimize_model_before_eval": "disabled", "output_dir": "/data_2to/devel_data/nn_pruning/output/squad_test_final_fine_tune/fine_tuned_aws_nn-pruning-v10-a32-l20-dl1--2021-01-21--00-55-15", "overwrite_output_dir": 1, "past_index": -1, "per_device_eval_batch_size": 128, "per_device_train_batch_size": 16, "per_gpu_eval_batch_size": null, "per_gpu_train_batch_size": null, "prediction_loss_only": false, "remove_unused_columns": true, "report_to": null, "run_name": "/data_2to/devel_data/nn_pruning/output/squad_test_final_fine_tune/fine_tuned_aws_nn-pruning-v10-a32-l20-dl1--2021-01-21--00-55-15", "save_steps": 2500, "save_strategy": "steps", "save_total_limit": 50, "seed": 17, "sharded_ddp": "", "skip_memory_metrics": false, "tpu_metrics_debug": false, "tpu_num_cores": null, "warmup_ratio": 0.0, "warmup_steps": 10, "weight_decay": 0.0}}, "f1": 86.75497848244157, "fill_rate": 0.1933774594907408, "speedup": 2.68869031405704}}
{"speedup": 2.799991523936488, "f1": 86.69392512957342, "meta": {"annotate": "20", "cat_fun_name": "is_new_xp", "checkpoint": {"config": {"_name_or_path": "/home/lagunas/devel/hf/nn_pruning/nn_pruning/analysis/tmp_finetune", "architectures": ["BertForQuestionAnswering"], "attention_probs_dropout_prob": 0.1, "gradient_checkpointing": false, "hidden_act": "gelu", "hidden_dropout_prob": 0.1, "hidden_size": 768, "initializer_range": 0.02, "intermediate_size": 3072, "layer_norm_eps": 1e-12, "max_position_embeddings": 512, "model_type": "bert", "num_attention_heads": 12, "num_hidden_layers": 12, "pad_token_id": 0, "position_embedding_type": "absolute", "pruned_heads": {"0": [0, 2, 4, 5, 6, 7, 9, 11], "1": [0, 1, 2, 3, 5, 6, 7, 8, 9], "10": [1, 4, 5, 6, 7, 8, 9], "11": [0, 2, 3, 5, 6, 7, 8, 10, 11], "2": [1, 2, 3, 4, 5, 7, 8, 10, 11], "3": [2, 3, 4, 6, 7, 10], "4": [0, 1, 2, 6, 7, 8, 9, 11], "5": [0, 1, 2, 5, 6, 7, 11], "6": [0, 2, 3, 4, 6, 7, 10], "7": [1, 3, 6, 7, 11], "8": [0, 1, 2, 3, 4, 5, 6, 7, 8], "9": [1, 3, 4, 5, 7, 9, 10]}, "type_vocab_size": 2, "vocab_size": 30522}, "eval_metrics": {"exact_match": 78.63765373699148, "f1": 86.69392512957342}, "path": "/data_2to/devel_data/nn_pruning/output/squad_test_final_fine_tune/fine_tuned_hp_od-output__squad_test3_es-steps_nte20_ls250_est5000_rn-output__squad_test3_dpm-sigmoied_threshold:1d_alt_apme-sigmoied_threshold_aowd0_bm1_abr32_abc32_it0_fw10_r-l1_rfl40_dl0.25_dtnop-csarron__bert-base-uncased-squad-v1/checkpoint-22132", "source_checkpoint": "/data_2to/devel_data/nn_pruning/output/squad_test3/hp_od-output__squad_test3_es-steps_nte20_ls250_est5000_rn-output__squad_test3_dpm-sigmoied_threshold:1d_alt_apme-sigmoied_threshold_aowd0_bm1_abr32_abc32_it0_fw10_r-l1_rfl40_dl0.25_dtnop-csarron__bert-base-uncased-squad-v1/checkpoint-110000", "sparse_args": {"ampere_pruning_method": "disabled", "attention_block_cols": 1, "attention_block_rows": 1, "attention_lambda": 1.0, "attention_output_with_dense": 0, "attention_pruning_method": "topK", "bias_mask": true, "dense_block_cols": 1, "dense_block_rows": 1, "dense_lambda": 1.0, "dense_pruning_method": "topK", "distil_alpha_ce": 0.1, "distil_alpha_teacher": 0.9, "distil_teacher_name_or_path": "csarron/bert-base-uncased-squad-v1", "distil_temperature": 2.0, "final_ampere_temperature": 20.0, "final_finetune": 1, "final_threshold": 0.5, "final_warmup": 0, "initial_ampere_temperature": 0.0, "initial_threshold": 1.0, "initial_warmup": 0, "mask_init": "constant", "mask_scale": 0.0, "mask_scores_learning_rate": 0.01, "regularization": "", "regularization_final_lambda": 0}, "speed": {"cuda_eval_elapsed_time": 13.783753513336181, "eval_elapsed_time": 20.85535095212981}, "speedup": 2.799991523936488, "stats": {"layers": {"0": {"linear_attention_nnz": 786432, "linear_attention_total": 2359296, "linear_dense_nnz": 482304, "linear_dense_total": 4718592, "linear_nnz": 1268736, "linear_total": 7077888, "nnz": 1274426, "total": 7086336}, "1": {"linear_attention_nnz": 589824, "linear_attention_total": 2359296, "linear_dense_nnz": 706560, "linear_dense_total": 4718592, "linear_nnz": 1296384, "linear_total": 7077888, "nnz": 1302028, "total": 7086144}, "10": {"linear_attention_nnz": 983040, "linear_attention_total": 2359296, "linear_dense_nnz": 121344, "linear_dense_total": 4718592, "linear_nnz": 1104384, "linear_total": 7077888, "nnz": 1110031, "total": 7086528}, "11": {"linear_attention_nnz": 589824, "linear_attention_total": 2359296, "linear_dense_nnz": 215040, "linear_dense_total": 4718592, "linear_nnz": 804864, "linear_total": 7077888, "nnz": 810188, "total": 7086144}, "2": {"linear_attention_nnz": 589824, "linear_attention_total": 2359296, "linear_dense_nnz": 850944, "linear_dense_total": 4718592, "linear_nnz": 1440768, "linear_total": 7077888, "nnz": 1446506, "total": 7086144}, "3": {"linear_attention_nnz": 1179648, "linear_attention_total": 2359296, "linear_dense_nnz": 826368, "linear_dense_total": 4718592, "linear_nnz": 2006016, "linear_total": 7077888, "nnz": 2012314, "total": 7086720}, "4": {"linear_attention_nnz": 786432, "linear_attention_total": 2359296, "linear_dense_nnz": 923136, "linear_dense_total": 4718592, "linear_nnz": 1709568, "linear_total": 7077888, "nnz": 1715545, "total": 7086336}, "5": {"linear_attention_nnz": 983040, "linear_attention_total": 2359296, "linear_dense_nnz": 880128, "linear_dense_total": 4718592, "linear_nnz": 1863168, "linear_total": 7077888, "nnz": 1869309, "total": 7086528}, "6": {"linear_attention_nnz": 983040, "linear_attention_total": 2359296, "linear_dense_nnz": 645120, "linear_dense_total": 4718592, "linear_nnz": 1628160, "linear_total": 7077888, "nnz": 1634148, "total": 7086528}, "7": {"linear_attention_nnz": 1376256, "linear_attention_total": 2359296, "linear_dense_nnz": 525312, "linear_dense_total": 4718592, "linear_nnz": 1901568, "linear_total": 7077888, "nnz": 1907862, "total": 7086912}, "8": {"linear_attention_nnz": 589824, "linear_attention_total": 2359296, "linear_dense_nnz": 333312, "linear_dense_total": 4718592, "linear_nnz": 923136, "linear_total": 7077888, "nnz": 928537, "total": 7086144}, "9": {"linear_attention_nnz": 983040, "linear_attention_total": 2359296, "linear_dense_nnz": 113664, "linear_dense_total": 4718592, "linear_nnz": 1096704, "linear_total": 7077888, "nnz": 1102346, "total": 7086528}}, "linear_nnz": 17043456, "linear_sparsity": 79.93344907407408, "linear_total": 84934656, "nnz": 40951962, "pruned_heads": {"0": [0, 2, 4, 5, 6, 7, 9, 11], "1": [0, 1, 2, 3, 5, 6, 7, 8, 9], "10": [1, 4, 5, 6, 7, 8, 9], "11": [0, 2, 3, 5, 6, 7, 8, 10, 11], "2": [1, 2, 3, 4, 5, 7, 8, 10, 11], "3": [2, 3, 4, 6, 7, 10], "4": [0, 1, 2, 6, 7, 8, 9, 11], "5": [0, 1, 2, 5, 6, 7, 11], "6": [0, 2, 3, 4, 6, 7, 10], "7": [1, 3, 6, 7, 11], "8": [0, 1, 2, 3, 4, 5, 6, 7, 8], "9": [1, 3, 4, 5, 7, 9, 10]}, "total": 108875714, "total_sparsity": 62.38650430342987}, "training_args": {"_n_gpu": -1, "adafactor": false, "adam_beta1": 0.9, "adam_beta2": 0.999, "adam_epsilon": 1e-08, "dataloader_drop_last": false, "dataloader_num_workers": 0, "dataloader_pin_memory": true, "ddp_find_unused_parameters": null, "debug": false, "deepspeed": null, "disable_tqdm": false, "do_eval": 1, "do_predict": false, "do_train": 1, "eval_accumulation_steps": null, "eval_steps": 2500, "evaluation_strategy": "steps", "fp16": false, "fp16_backend": "auto", "fp16_full_eval": false, "fp16_opt_level": "O1", "gradient_accumulation_steps": 1, "greater_is_better": null, "group_by_length": false, "ignore_data_skip": false, "label_names": null, "label_smoothing_factor": 0.0, "learning_rate": 3e-05, "load_best_model_at_end": false, "local_rank": -1, "logging_dir": "/data_2to/devel_data/nn_pruning/output/squad_test_final_fine_tune/fine_tuned_hp_od-output__squad_test3_es-steps_nte20_ls250_est5000_rn-output__squad_test3_dpm-sigmoied_threshold:1d_alt_apme-sigmoied_threshold_aowd0_bm1_abr32_abc32_it0_fw10_r-l1_rfl40_dl0.25_dtnop-csarron__bert-base-uncased-squad-v1", "logging_first_step": false, "logging_steps": 250, "logging_strategy": "steps", "lr_scheduler_type": "linear", "max_grad_norm": 1.0, "max_steps": -1, "metric_for_best_model": null, "no_cuda": false, "num_train_epochs": 4, "optimize_model_before_eval": "disabled", "output_dir": "/data_2to/devel_data/nn_pruning/output/squad_test_final_fine_tune/fine_tuned_hp_od-output__squad_test3_es-steps_nte20_ls250_est5000_rn-output__squad_test3_dpm-sigmoied_threshold:1d_alt_apme-sigmoied_threshold_aowd0_bm1_abr32_abc32_it0_fw10_r-l1_rfl40_dl0.25_dtnop-csarron__bert-base-uncased-squad-v1", "overwrite_output_dir": 1, "past_index": -1, "per_device_eval_batch_size": 8, "per_device_train_batch_size": 16, "per_gpu_eval_batch_size": null, "per_gpu_train_batch_size": null, "prediction_loss_only": false, "remove_unused_columns": true, "report_to": null, "run_name": "/data_2to/devel_data/nn_pruning/output/squad_test_final_fine_tune/fine_tuned_hp_od-output__squad_test3_es-steps_nte20_ls250_est5000_rn-output__squad_test3_dpm-sigmoied_threshold:1d_alt_apme-sigmoied_threshold_aowd0_bm1_abr32_abc32_it0_fw10_r-l1_rfl40_dl0.25_dtnop-csarron__bert-base-uncased-squad-v1", "save_steps": 2500, "save_strategy": "steps", "save_total_limit": 50, "seed": 17, "sharded_ddp": "", "skip_memory_metrics": false, "tpu_metrics_debug": false, "tpu_num_cores": null, "warmup_ratio": 0.0, "warmup_steps": 10, "weight_decay": 0.0}}, "f1": 86.69392512957342, "fill_rate": 0.2006655092592592, "speedup": 2.799991523936488}}
