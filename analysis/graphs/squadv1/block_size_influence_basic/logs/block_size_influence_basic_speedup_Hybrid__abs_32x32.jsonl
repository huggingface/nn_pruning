{"speedup": 1.9695394330694393, "f1": 88.06903108265608, "meta": {"annotate": "24", "cat_fun_name": "is_new_xp", "checkpoint": {"config": {"_name_or_path": "bert-base-uncased", "architectures": ["BertForQuestionAnswering"], "attention_probs_dropout_prob": 0.1, "gradient_checkpointing": false, "hidden_act": "gelu", "hidden_dropout_prob": 0.1, "hidden_size": 768, "initializer_range": 0.02, "intermediate_size": 3072, "layer_norm_eps": 1e-12, "max_position_embeddings": 512, "model_type": "bert", "num_attention_heads": 12, "num_hidden_layers": 12, "pad_token_id": 0, "position_embedding_type": "absolute", "type_vocab_size": 2, "vocab_size": 30522}, "eval_metrics": {"exact_match": 80.58656575212866, "f1": 88.06903108265608}, "path": "/data_2to/devel_data/nn_pruning/output/squad_test_aws/aws_nn-pruning-v10-a32-l5-dl1--2021-01-21--00-52-16/checkpoint-110660", "sparse_args": {"ampere_pruning_method": "disabled", "attention_block_cols": 32, "attention_block_rows": 32, "attention_lambda": 1.0, "attention_output_with_dense": 0, "attention_pruning_method": "sigmoied_threshold", "bias_mask": true, "dense_block_cols": 1, "dense_block_rows": 1, "dense_lambda": 1.0, "dense_pruning_method": "sigmoied_threshold:1d_alt", "distil_alpha_ce": 0.1, "distil_alpha_teacher": 0.9, "distil_teacher_name_or_path": "csarron/bert-base-uncased-squad-v1", "distil_temperature": 2.0, "final_ampere_temperature": 20.0, "final_threshold": 0.1, "final_warmup": 10, "initial_ampere_temperature": 0.0, "initial_threshold": 0, "initial_warmup": 1, "mask_init": "constant", "mask_scale": 0.0, "mask_scores_learning_rate": 0.01, "regularization": "l1", "regularization_final_lambda": 5.0}, "speed": {"cuda_eval_elapsed_time": 19.595643711090087, "eval_elapsed_time": 26.718373194802552}, "speedup": 1.9695394330694393, "stats": {"layers": {"0": {"linear_attention_nnz": 1055744, "linear_attention_total": 2359296, "linear_dense_nnz": 526848, "linear_dense_total": 4718592, "linear_nnz": 1582592, "linear_total": 7077888, "nnz": 1588759, "total": 7087872}, "1": {"linear_attention_nnz": 809984, "linear_attention_total": 2359296, "linear_dense_nnz": 752640, "linear_dense_total": 4718592, "linear_nnz": 1562624, "linear_total": 7077888, "nnz": 1568650, "total": 7087872}, "10": {"linear_attention_nnz": 652288, "linear_attention_total": 2359296, "linear_dense_nnz": 98304, "linear_dense_total": 4718592, "linear_nnz": 750592, "linear_total": 7077888, "nnz": 756384, "total": 7087872}, "11": {"linear_attention_nnz": 419840, "linear_attention_total": 2359296, "linear_dense_nnz": 262656, "linear_dense_total": 4718592, "linear_nnz": 682496, "linear_total": 7077888, "nnz": 688011, "total": 7087872}, "2": {"linear_attention_nnz": 1316864, "linear_attention_total": 2359296, "linear_dense_nnz": 873984, "linear_dense_total": 4718592, "linear_nnz": 2190848, "linear_total": 7077888, "nnz": 2197625, "total": 7087872}, "3": {"linear_attention_nnz": 1468416, "linear_attention_total": 2359296, "linear_dense_nnz": 952320, "linear_dense_total": 4718592, "linear_nnz": 2420736, "linear_total": 7077888, "nnz": 2427596, "total": 7087872}, "4": {"linear_attention_nnz": 1651712, "linear_attention_total": 2359296, "linear_dense_nnz": 1046016, "linear_dense_total": 4718592, "linear_nnz": 2697728, "linear_total": 7077888, "nnz": 2705001, "total": 7087872}, "5": {"linear_attention_nnz": 1616896, "linear_attention_total": 2359296, "linear_dense_nnz": 986112, "linear_dense_total": 4718592, "linear_nnz": 2603008, "linear_total": 7077888, "nnz": 2610178, "total": 7087872}, "6": {"linear_attention_nnz": 1361920, "linear_attention_total": 2359296, "linear_dense_nnz": 740352, "linear_dense_total": 4718592, "linear_nnz": 2102272, "linear_total": 7077888, "nnz": 2109058, "total": 7087872}, "7": {"linear_attention_nnz": 1265664, "linear_attention_total": 2359296, "linear_dense_nnz": 559104, "linear_dense_total": 4718592, "linear_nnz": 1824768, "linear_total": 7077888, "nnz": 1831244, "total": 7087872}, "8": {"linear_attention_nnz": 1212416, "linear_attention_total": 2359296, "linear_dense_nnz": 293376, "linear_dense_total": 4718592, "linear_nnz": 1505792, "linear_total": 7077888, "nnz": 1512127, "total": 7087872}, "9": {"linear_attention_nnz": 749568, "linear_attention_total": 2359296, "linear_dense_nnz": 113664, "linear_dense_total": 4718592, "linear_nnz": 863232, "linear_total": 7077888, "nnz": 868874, "total": 7087872}}, "linear_nnz": 20786688, "linear_sparsity": 75.52625868055556, "linear_total": 84934656, "nnz": 44702229, "pruned_heads": {"0": [0, 2, 4, 5, 6], "1": [0, 2, 3, 5, 6, 7, 8], "10": [1, 4, 5, 7], "11": [0, 2, 5, 6, 7, 8, 11], "2": [8, 4], "3": [2, 4, 6], "4": [2], "5": [1, 2], "6": [2, 3, 7], "7": [11, 3, 6, 7], "8": [0, 4], "9": [1, 4, 5, 7, 9, 10]}, "total": 108893186, "total_sparsity": 58.94855257518133}, "training_args": {"_n_gpu": -1, "adafactor": false, "adam_beta1": 0.9, "adam_beta2": 0.999, "adam_epsilon": 1e-08, "dataloader_drop_last": false, "dataloader_num_workers": 0, "dataloader_pin_memory": true, "ddp_find_unused_parameters": null, "debug": false, "deepspeed": null, "disable_tqdm": false, "do_eval": 1, "do_predict": false, "do_train": 1, "eval_accumulation_steps": null, "eval_steps": 5000, "evaluation_strategy": "steps", "fp16": false, "fp16_backend": "auto", "fp16_full_eval": false, "fp16_opt_level": "O1", "gradient_accumulation_steps": 1, "greater_is_better": null, "group_by_length": false, "ignore_data_skip": false, "label_names": null, "label_smoothing_factor": 0.0, "learning_rate": 3e-05, "load_best_model_at_end": false, "local_rank": -1, "logging_dir": "/opt/ml/output", "logging_first_step": false, "logging_steps": 250, "logging_strategy": "steps", "lr_scheduler_type": "linear", "max_grad_norm": 1.0, "max_steps": -1, "metric_for_best_model": null, "no_cuda": false, "num_train_epochs": 20.0, "optimize_model_before_eval": "disabled", "output_dir": "/opt/ml/model", "overwrite_output_dir": 1, "past_index": -1, "per_device_eval_batch_size": 8, "per_device_train_batch_size": 16, "per_gpu_eval_batch_size": null, "per_gpu_train_batch_size": null, "prediction_loss_only": false, "remove_unused_columns": true, "report_to": null, "run_name": "/opt/ml/model", "save_steps": 5000, "save_strategy": "steps", "save_total_limit": 50, "seed": 17, "sharded_ddp": false, "skip_memory_metrics": false, "tpu_metrics_debug": false, "tpu_num_cores": null, "warmup_ratio": 0.0, "warmup_steps": 5400, "weight_decay": 0.0}}, "f1": 88.06903108265608, "fill_rate": 0.24473741319444442, "speedup": 1.9695394330694393}}
{"speedup": 2.1003540884863323, "f1": 87.70461789964966, "meta": {"annotate": "27", "cat_fun_name": "is_new_xp", "checkpoint": {"config": {"_name_or_path": "bert-base-uncased", "architectures": ["BertForQuestionAnswering"], "attention_probs_dropout_prob": 0.1, "gradient_checkpointing": false, "hidden_act": "gelu", "hidden_dropout_prob": 0.1, "hidden_size": 768, "initializer_range": 0.02, "intermediate_size": 3072, "layer_norm_eps": 1e-12, "max_position_embeddings": 512, "model_type": "bert", "num_attention_heads": 12, "num_hidden_layers": 12, "pad_token_id": 0, "position_embedding_type": "absolute", "type_vocab_size": 2, "vocab_size": 30522}, "eval_metrics": {"exact_match": 80.27436140018922, "f1": 87.70461789964966}, "path": "/data_2to/devel_data/nn_pruning/output/squad_test3/hp_od-output__squad_test3_es-steps_nte20_ls250_est5000_rn-output__squad_test3_dpm-sigmoied_threshold:1d_alt_apme-sigmoied_threshold_aowd0_bm1_abr32_abc32_it0_fw10_r-l1_rfl10_dl0.25_dtnop-csarron__bert-base-uncased-squad-v1/checkpoint-90000", "sparse_args": {"ampere_pruning_method": "disabled", "attention_block_cols": 32, "attention_block_rows": 32, "attention_lambda": 1.0, "attention_output_with_dense": 0, "attention_pruning_method": "sigmoied_threshold", "bias_mask": true, "dense_block_cols": 1, "dense_block_rows": 1, "dense_lambda": 0.25, "dense_pruning_method": "sigmoied_threshold:1d_alt", "distil_alpha_ce": 0.1, "distil_alpha_teacher": 0.9, "distil_teacher_name_or_path": "csarron/bert-base-uncased-squad-v1", "distil_temperature": 2.0, "final_ampere_temperature": 20.0, "final_threshold": 0.1, "final_warmup": 10, "initial_ampere_temperature": 0.0, "initial_threshold": 0, "initial_warmup": 1, "mask_init": "constant", "mask_scale": 0.0, "mask_scores_learning_rate": 0.01, "regularization": "l1", "regularization_final_lambda": 10}, "speed": {"cuda_eval_elapsed_time": 18.375184078216552, "eval_elapsed_time": 25.600778602063656}, "speedup": 2.1003540884863323, "stats": {"layers": {"0": {"linear_attention_nnz": 645120, "linear_attention_total": 2359296, "linear_dense_nnz": 1339392, "linear_dense_total": 4718592, "linear_nnz": 1984512, "linear_total": 7077888, "nnz": 1990760, "total": 7087872}, "1": {"linear_attention_nnz": 592896, "linear_attention_total": 2359296, "linear_dense_nnz": 1571328, "linear_dense_total": 4718592, "linear_nnz": 2164224, "linear_total": 7077888, "nnz": 2170591, "total": 7087872}, "10": {"linear_attention_nnz": 480256, "linear_attention_total": 2359296, "linear_dense_nnz": 187392, "linear_dense_total": 4718592, "linear_nnz": 667648, "linear_total": 7077888, "nnz": 673242, "total": 7087872}, "11": {"linear_attention_nnz": 294912, "linear_attention_total": 2359296, "linear_dense_nnz": 574464, "linear_dense_total": 4718592, "linear_nnz": 869376, "linear_total": 7077888, "nnz": 874838, "total": 7087872}, "2": {"linear_attention_nnz": 880640, "linear_attention_total": 2359296, "linear_dense_nnz": 1744896, "linear_dense_total": 4718592, "linear_nnz": 2625536, "linear_total": 7077888, "nnz": 2632432, "total": 7087872}, "3": {"linear_attention_nnz": 1230848, "linear_attention_total": 2359296, "linear_dense_nnz": 1761792, "linear_dense_total": 4718592, "linear_nnz": 2992640, "linear_total": 7077888, "nnz": 2999931, "total": 7087872}, "4": {"linear_attention_nnz": 1214464, "linear_attention_total": 2359296, "linear_dense_nnz": 1726464, "linear_dense_total": 4718592, "linear_nnz": 2940928, "linear_total": 7077888, "nnz": 2948260, "total": 7087872}, "5": {"linear_attention_nnz": 906240, "linear_attention_total": 2359296, "linear_dense_nnz": 1629696, "linear_dense_total": 4718592, "linear_nnz": 2535936, "linear_total": 7077888, "nnz": 2542789, "total": 7087872}, "6": {"linear_attention_nnz": 943104, "linear_attention_total": 2359296, "linear_dense_nnz": 1270272, "linear_dense_total": 4718592, "linear_nnz": 2213376, "linear_total": 7077888, "nnz": 2220027, "total": 7087872}, "7": {"linear_attention_nnz": 935936, "linear_attention_total": 2359296, "linear_dense_nnz": 987648, "linear_dense_total": 4718592, "linear_nnz": 1923584, "linear_total": 7077888, "nnz": 1930019, "total": 7087872}, "8": {"linear_attention_nnz": 872448, "linear_attention_total": 2359296, "linear_dense_nnz": 546816, "linear_dense_total": 4718592, "linear_nnz": 1419264, "linear_total": 7077888, "nnz": 1425508, "total": 7087872}, "9": {"linear_attention_nnz": 634880, "linear_attention_total": 2359296, "linear_dense_nnz": 248832, "linear_dense_total": 4718592, "linear_nnz": 883712, "linear_total": 7077888, "nnz": 889410, "total": 7087872}}, "linear_nnz": 23220736, "linear_sparsity": 72.66046971450618, "linear_total": 84934656, "nnz": 47136529, "pruned_heads": {"0": [0, 2, 4, 5, 6, 7, 9, 11], "1": [0, 2, 3, 5, 6, 7, 8, 9], "10": [1, 4, 5, 6, 7, 8], "11": [0, 2, 3, 5, 6, 7, 8, 10, 11], "2": [8, 11, 4, 7], "3": [2, 4, 6, 7], "4": [1, 2, 11], "5": [1, 2, 5, 6, 7, 11], "6": [0, 2, 3, 7, 10], "7": [1, 3, 6, 7, 11], "8": [0, 8, 3, 4], "9": [1, 4, 5, 7, 9, 10]}, "total": 108893186, "total_sparsity": 56.713059162397904}, "training_args": {"_n_gpu": -1, "adafactor": false, "adam_beta1": 0.9, "adam_beta2": 0.999, "adam_epsilon": 1e-08, "dataloader_drop_last": false, "dataloader_num_workers": 0, "dataloader_pin_memory": true, "ddp_find_unused_parameters": null, "debug": false, "deepspeed": null, "disable_tqdm": false, "do_eval": 1, "do_predict": false, "do_train": 1, "eval_accumulation_steps": null, "eval_steps": 5000, "evaluation_strategy": "steps", "fp16": false, "fp16_backend": "auto", "fp16_full_eval": false, "fp16_opt_level": "O1", "gradient_accumulation_steps": 1, "greater_is_better": null, "group_by_length": false, "ignore_data_skip": false, "label_names": null, "label_smoothing_factor": 0.0, "learning_rate": 3e-05, "load_best_model_at_end": false, "local_rank": -1, "logging_dir": "output/squad_test3", "logging_first_step": false, "logging_steps": 250, "logging_strategy": "steps", "lr_scheduler_type": "linear", "max_grad_norm": 1.0, "max_steps": -1, "metric_for_best_model": null, "no_cuda": false, "num_train_epochs": 20, "optimize_model_before_eval": "disabled", "output_dir": "output/squad_test3", "overwrite_output_dir": 1, "past_index": -1, "per_device_eval_batch_size": 8, "per_device_train_batch_size": 16, "per_gpu_eval_batch_size": null, "per_gpu_train_batch_size": null, "prediction_loss_only": false, "remove_unused_columns": true, "report_to": null, "run_name": "output/squad_test3", "save_steps": 5000, "save_strategy": "steps", "save_total_limit": 5, "seed": 17, "sharded_ddp": "", "skip_memory_metrics": false, "tpu_metrics_debug": false, "tpu_num_cores": null, "warmup_ratio": 0.0, "warmup_steps": 5400, "weight_decay": 0.0}}, "f1": 87.70461789964966, "fill_rate": 0.2733953028549382, "speedup": 2.1003540884863323}}
{"speedup": 2.1124331270315624, "f1": 87.48291010744668, "meta": {"annotate": "26", "cat_fun_name": "is_new_xp", "checkpoint": {"config": {"_name_or_path": "bert-base-uncased", "architectures": ["BertForQuestionAnswering"], "attention_probs_dropout_prob": 0.1, "gradient_checkpointing": false, "hidden_act": "gelu", "hidden_dropout_prob": 0.1, "hidden_size": 768, "initializer_range": 0.02, "intermediate_size": 3072, "layer_norm_eps": 1e-12, "max_position_embeddings": 512, "model_type": "bert", "num_attention_heads": 12, "num_hidden_layers": 12, "pad_token_id": 0, "position_embedding_type": "absolute", "type_vocab_size": 2, "vocab_size": 30522}, "eval_metrics": {"exact_match": 79.80132450331126, "f1": 87.48291010744668}, "path": "/data_2to/devel_data/nn_pruning/output/squad_test3/hp_od-output__squad_test3_es-steps_nte20_ls250_est5000_rn-output__squad_test3_dpm-sigmoied_threshold:1d_alt_apme-sigmoied_threshold_aowd0_bm1_abr32_abc32_it0_fw10_r-l1_rfl10_dl0.25_dtnop-csarron__bert-base-uncased-squad-v1/checkpoint-110000", "sparse_args": {"ampere_pruning_method": "disabled", "attention_block_cols": 32, "attention_block_rows": 32, "attention_lambda": 1.0, "attention_output_with_dense": 0, "attention_pruning_method": "sigmoied_threshold", "bias_mask": true, "dense_block_cols": 1, "dense_block_rows": 1, "dense_lambda": 0.25, "dense_pruning_method": "sigmoied_threshold:1d_alt", "distil_alpha_ce": 0.1, "distil_alpha_teacher": 0.9, "distil_teacher_name_or_path": "csarron/bert-base-uncased-squad-v1", "distil_temperature": 2.0, "final_ampere_temperature": 20.0, "final_threshold": 0.1, "final_warmup": 10, "initial_ampere_temperature": 0.0, "initial_threshold": 0, "initial_warmup": 1, "mask_init": "constant", "mask_scale": 0.0, "mask_scores_learning_rate": 0.01, "regularization": "l1", "regularization_final_lambda": 10}, "speed": {"cuda_eval_elapsed_time": 18.270113506317138, "eval_elapsed_time": 25.450434973929077}, "speedup": 2.1124331270315624, "stats": {"layers": {"0": {"linear_attention_nnz": 627712, "linear_attention_total": 2359296, "linear_dense_nnz": 1281024, "linear_dense_total": 4718592, "linear_nnz": 1908736, "linear_total": 7077888, "nnz": 1914914, "total": 7087872}, "1": {"linear_attention_nnz": 596992, "linear_attention_total": 2359296, "linear_dense_nnz": 1548288, "linear_dense_total": 4718592, "linear_nnz": 2145280, "linear_total": 7077888, "nnz": 2151632, "total": 7087872}, "10": {"linear_attention_nnz": 451584, "linear_attention_total": 2359296, "linear_dense_nnz": 182784, "linear_dense_total": 4718592, "linear_nnz": 634368, "linear_total": 7077888, "nnz": 639895, "total": 7087872}, "11": {"linear_attention_nnz": 268288, "linear_attention_total": 2359296, "linear_dense_nnz": 559104, "linear_dense_total": 4718592, "linear_nnz": 827392, "linear_total": 7077888, "nnz": 832812, "total": 7087872}, "2": {"linear_attention_nnz": 789504, "linear_attention_total": 2359296, "linear_dense_nnz": 1709568, "linear_dense_total": 4718592, "linear_nnz": 2499072, "linear_total": 7077888, "nnz": 2505785, "total": 7087872}, "3": {"linear_attention_nnz": 1180672, "linear_attention_total": 2359296, "linear_dense_nnz": 1740288, "linear_dense_total": 4718592, "linear_nnz": 2920960, "linear_total": 7077888, "nnz": 2928205, "total": 7087872}, "4": {"linear_attention_nnz": 1204224, "linear_attention_total": 2359296, "linear_dense_nnz": 1701888, "linear_dense_total": 4718592, "linear_nnz": 2906112, "linear_total": 7077888, "nnz": 2913428, "total": 7087872}, "5": {"linear_attention_nnz": 916480, "linear_attention_total": 2359296, "linear_dense_nnz": 1600512, "linear_dense_total": 4718592, "linear_nnz": 2516992, "linear_total": 7077888, "nnz": 2523794, "total": 7087872}, "6": {"linear_attention_nnz": 909312, "linear_attention_total": 2359296, "linear_dense_nnz": 1242624, "linear_dense_total": 4718592, "linear_nnz": 2151936, "linear_total": 7077888, "nnz": 2158569, "total": 7087872}, "7": {"linear_attention_nnz": 917504, "linear_attention_total": 2359296, "linear_dense_nnz": 972288, "linear_dense_total": 4718592, "linear_nnz": 1889792, "linear_total": 7077888, "nnz": 1896217, "total": 7087872}, "8": {"linear_attention_nnz": 856064, "linear_attention_total": 2359296, "linear_dense_nnz": 542208, "linear_dense_total": 4718592, "linear_nnz": 1398272, "linear_total": 7077888, "nnz": 1404481, "total": 7087872}, "9": {"linear_attention_nnz": 611328, "linear_attention_total": 2359296, "linear_dense_nnz": 247296, "linear_dense_total": 4718592, "linear_nnz": 858624, "linear_total": 7077888, "nnz": 864321, "total": 7087872}}, "linear_nnz": 22657536, "linear_sparsity": 73.32356770833333, "linear_total": 84934656, "nnz": 46572775, "pruned_heads": {"0": [0, 2, 4, 5, 6, 7, 9, 11], "1": [0, 2, 3, 5, 6, 7, 8, 9], "10": [1, 4, 5, 6, 7, 8], "11": [0, 2, 3, 5, 6, 7, 8, 10, 11], "2": [1, 4, 7, 8, 11], "3": [2, 4, 6, 7], "4": [1, 2, 11], "5": [1, 2, 5, 6, 7, 11], "6": [0, 2, 3, 7, 10], "7": [1, 3, 6, 7, 11], "8": [0, 8, 3, 4], "9": [1, 4, 5, 7, 9, 10]}, "total": 108893186, "total_sparsity": 57.23077199706509}, "training_args": {"_n_gpu": -1, "adafactor": false, "adam_beta1": 0.9, "adam_beta2": 0.999, "adam_epsilon": 1e-08, "dataloader_drop_last": false, "dataloader_num_workers": 0, "dataloader_pin_memory": true, "ddp_find_unused_parameters": null, "debug": false, "deepspeed": null, "disable_tqdm": false, "do_eval": 1, "do_predict": false, "do_train": 1, "eval_accumulation_steps": null, "eval_steps": 5000, "evaluation_strategy": "steps", "fp16": false, "fp16_backend": "auto", "fp16_full_eval": false, "fp16_opt_level": "O1", "gradient_accumulation_steps": 1, "greater_is_better": null, "group_by_length": false, "ignore_data_skip": false, "label_names": null, "label_smoothing_factor": 0.0, "learning_rate": 3e-05, "load_best_model_at_end": false, "local_rank": -1, "logging_dir": "output/squad_test3", "logging_first_step": false, "logging_steps": 250, "logging_strategy": "steps", "lr_scheduler_type": "linear", "max_grad_norm": 1.0, "max_steps": -1, "metric_for_best_model": null, "no_cuda": false, "num_train_epochs": 20, "optimize_model_before_eval": "disabled", "output_dir": "output/squad_test3", "overwrite_output_dir": 1, "past_index": -1, "per_device_eval_batch_size": 8, "per_device_train_batch_size": 16, "per_gpu_eval_batch_size": null, "per_gpu_train_batch_size": null, "prediction_loss_only": false, "remove_unused_columns": true, "report_to": null, "run_name": "output/squad_test3", "save_steps": 5000, "save_strategy": "steps", "save_total_limit": 5, "seed": 17, "sharded_ddp": "", "skip_memory_metrics": false, "tpu_metrics_debug": false, "tpu_num_cores": null, "warmup_ratio": 0.0, "warmup_steps": 5400, "weight_decay": 0.0}}, "f1": 87.48291010744668, "fill_rate": 0.26676432291666674, "speedup": 2.1124331270315624}}
{"speedup": 2.227490161916501, "f1": 87.3881230572442, "meta": {"annotate": "21", "cat_fun_name": "is_new_xp", "checkpoint": {"config": {"_name_or_path": "bert-base-uncased", "architectures": ["BertForQuestionAnswering"], "attention_probs_dropout_prob": 0.1, "gradient_checkpointing": false, "hidden_act": "gelu", "hidden_dropout_prob": 0.1, "hidden_size": 768, "initializer_range": 0.02, "intermediate_size": 3072, "layer_norm_eps": 1e-12, "max_position_embeddings": 512, "model_type": "bert", "num_attention_heads": 12, "num_hidden_layers": 12, "pad_token_id": 0, "position_embedding_type": "absolute", "type_vocab_size": 2, "vocab_size": 30522}, "eval_metrics": {"exact_match": 79.66887417218543, "f1": 87.3881230572442}, "path": "/data_2to/devel_data/nn_pruning/output/squad_test_aws/aws_nn-pruning-v10-a32-l10-dl0-5--2021-01-21--00-54-13/checkpoint-110660", "sparse_args": {"ampere_pruning_method": "disabled", "attention_block_cols": 32, "attention_block_rows": 32, "attention_lambda": 1.0, "attention_output_with_dense": 0, "attention_pruning_method": "sigmoied_threshold", "bias_mask": true, "dense_block_cols": 1, "dense_block_rows": 1, "dense_lambda": 0.5, "dense_pruning_method": "sigmoied_threshold:1d_alt", "distil_alpha_ce": 0.1, "distil_alpha_teacher": 0.9, "distil_teacher_name_or_path": "csarron/bert-base-uncased-squad-v1", "distil_temperature": 2.0, "final_ampere_temperature": 20.0, "final_threshold": 0.1, "final_warmup": 10, "initial_ampere_temperature": 0.0, "initial_threshold": 0, "initial_warmup": 1, "mask_init": "constant", "mask_scale": 0.0, "mask_scores_learning_rate": 0.01, "regularization": "l1", "regularization_final_lambda": 10.0}, "speed": {"cuda_eval_elapsed_time": 17.326403350830077, "eval_elapsed_time": 24.523588876239955}, "speedup": 2.227490161916501, "stats": {"layers": {"0": {"linear_attention_nnz": 643072, "linear_attention_total": 2359296, "linear_dense_nnz": 634368, "linear_dense_total": 4718592, "linear_nnz": 1277440, "linear_total": 7077888, "nnz": 1283261, "total": 7087872}, "1": {"linear_attention_nnz": 622592, "linear_attention_total": 2359296, "linear_dense_nnz": 916992, "linear_dense_total": 4718592, "linear_nnz": 1539584, "linear_total": 7077888, "nnz": 1545525, "total": 7087872}, "10": {"linear_attention_nnz": 463872, "linear_attention_total": 2359296, "linear_dense_nnz": 112128, "linear_dense_total": 4718592, "linear_nnz": 576000, "linear_total": 7077888, "nnz": 581449, "total": 7087872}, "11": {"linear_attention_nnz": 278528, "linear_attention_total": 2359296, "linear_dense_nnz": 313344, "linear_dense_total": 4718592, "linear_nnz": 591872, "linear_total": 7077888, "nnz": 597164, "total": 7087872}, "2": {"linear_attention_nnz": 1051648, "linear_attention_total": 2359296, "linear_dense_nnz": 1016832, "linear_dense_total": 4718592, "linear_nnz": 2068480, "linear_total": 7077888, "nnz": 2075030, "total": 7087872}, "3": {"linear_attention_nnz": 1257472, "linear_attention_total": 2359296, "linear_dense_nnz": 1076736, "linear_dense_total": 4718592, "linear_nnz": 2334208, "linear_total": 7077888, "nnz": 2341053, "total": 7087872}, "4": {"linear_attention_nnz": 1315840, "linear_attention_total": 2359296, "linear_dense_nnz": 1158144, "linear_dense_total": 4718592, "linear_nnz": 2473984, "linear_total": 7077888, "nnz": 2481074, "total": 7087872}, "5": {"linear_attention_nnz": 1004544, "linear_attention_total": 2359296, "linear_dense_nnz": 1073664, "linear_dense_total": 4718592, "linear_nnz": 2078208, "linear_total": 7077888, "nnz": 2084891, "total": 7087872}, "6": {"linear_attention_nnz": 1004544, "linear_attention_total": 2359296, "linear_dense_nnz": 815616, "linear_dense_total": 4718592, "linear_nnz": 1820160, "linear_total": 7077888, "nnz": 1826675, "total": 7087872}, "7": {"linear_attention_nnz": 925696, "linear_attention_total": 2359296, "linear_dense_nnz": 629760, "linear_dense_total": 4718592, "linear_nnz": 1555456, "linear_total": 7077888, "nnz": 1561658, "total": 7087872}, "8": {"linear_attention_nnz": 899072, "linear_attention_total": 2359296, "linear_dense_nnz": 337920, "linear_dense_total": 4718592, "linear_nnz": 1236992, "linear_total": 7077888, "nnz": 1243132, "total": 7087872}, "9": {"linear_attention_nnz": 523264, "linear_attention_total": 2359296, "linear_dense_nnz": 139776, "linear_dense_total": 4718592, "linear_nnz": 663040, "linear_total": 7077888, "nnz": 668507, "total": 7087872}}, "linear_nnz": 18215424, "linear_sparsity": 78.55360243055556, "linear_total": 84934656, "nnz": 42128141, "pruned_heads": {"0": [0, 2, 4, 5, 6, 7, 9, 11], "1": [0, 2, 3, 5, 6, 7, 8, 9], "10": [1, 4, 5, 6, 7, 8], "11": [0, 2, 3, 5, 6, 7, 8, 10, 11], "2": [8, 4, 7], "3": [2, 4, 6, 7], "4": [1, 2], "5": [1, 2, 5, 6, 7], "6": [0, 2, 3, 7], "7": [1, 3, 6, 7, 11], "8": [0, 8, 3, 4], "9": [1, 3, 4, 5, 7, 9, 10]}, "total": 108893186, "total_sparsity": 61.31241765669342}, "training_args": {"_n_gpu": -1, "adafactor": false, "adam_beta1": 0.9, "adam_beta2": 0.999, "adam_epsilon": 1e-08, "dataloader_drop_last": false, "dataloader_num_workers": 0, "dataloader_pin_memory": true, "ddp_find_unused_parameters": null, "debug": false, "deepspeed": null, "disable_tqdm": false, "do_eval": 1, "do_predict": false, "do_train": 1, "eval_accumulation_steps": null, "eval_steps": 5000, "evaluation_strategy": "steps", "fp16": false, "fp16_backend": "auto", "fp16_full_eval": false, "fp16_opt_level": "O1", "gradient_accumulation_steps": 1, "greater_is_better": null, "group_by_length": false, "ignore_data_skip": false, "label_names": null, "label_smoothing_factor": 0.0, "learning_rate": 3e-05, "load_best_model_at_end": false, "local_rank": -1, "logging_dir": "/opt/ml/output", "logging_first_step": false, "logging_steps": 250, "logging_strategy": "steps", "lr_scheduler_type": "linear", "max_grad_norm": 1.0, "max_steps": -1, "metric_for_best_model": null, "no_cuda": false, "num_train_epochs": 20.0, "optimize_model_before_eval": "disabled", "output_dir": "/opt/ml/model", "overwrite_output_dir": 1, "past_index": -1, "per_device_eval_batch_size": 8, "per_device_train_batch_size": 16, "per_gpu_eval_batch_size": null, "per_gpu_train_batch_size": null, "prediction_loss_only": false, "remove_unused_columns": true, "report_to": null, "run_name": "/opt/ml/model", "save_steps": 5000, "save_strategy": "steps", "save_total_limit": 50, "seed": 17, "sharded_ddp": false, "skip_memory_metrics": false, "tpu_metrics_debug": false, "tpu_num_cores": null, "warmup_ratio": 0.0, "warmup_steps": 5400, "weight_decay": 0.0}}, "f1": 87.3881230572442, "fill_rate": 0.21446397569444442, "speedup": 2.227490161916501}}
{"speedup": 2.262663009764823, "f1": 87.14755939306319, "meta": {"annotate": "18", "cat_fun_name": "is_new_xp", "checkpoint": {"config": {"_name_or_path": "bert-base-uncased", "architectures": ["BertForQuestionAnswering"], "attention_probs_dropout_prob": 0.1, "gradient_checkpointing": false, "hidden_act": "gelu", "hidden_dropout_prob": 0.1, "hidden_size": 768, "initializer_range": 0.02, "intermediate_size": 3072, "layer_norm_eps": 1e-12, "max_position_embeddings": 512, "model_type": "bert", "num_attention_heads": 12, "num_hidden_layers": 12, "pad_token_id": 0, "position_embedding_type": "absolute", "type_vocab_size": 2, "vocab_size": 30522}, "eval_metrics": {"exact_match": 79.39451277199622, "f1": 87.14755939306319}, "path": "/data_2to/devel_data/nn_pruning/output/squad_test_aws/aws_nn-pruning-v10-a32-l10-dl1--2021-01-21--00-53-40/checkpoint-110660", "sparse_args": {"ampere_pruning_method": "disabled", "attention_block_cols": 32, "attention_block_rows": 32, "attention_lambda": 1.0, "attention_output_with_dense": 0, "attention_pruning_method": "sigmoied_threshold", "bias_mask": true, "dense_block_cols": 1, "dense_block_rows": 1, "dense_lambda": 1.0, "dense_pruning_method": "sigmoied_threshold:1d_alt", "distil_alpha_ce": 0.1, "distil_alpha_teacher": 0.9, "distil_teacher_name_or_path": "csarron/bert-base-uncased-squad-v1", "distil_temperature": 2.0, "final_ampere_temperature": 20.0, "final_threshold": 0.1, "final_warmup": 10, "initial_ampere_temperature": 0.0, "initial_threshold": 0, "initial_warmup": 1, "mask_init": "constant", "mask_scale": 0.0, "mask_scores_learning_rate": 0.01, "regularization": "l1", "regularization_final_lambda": 10.0}, "speed": {"cuda_eval_elapsed_time": 17.057066314697266, "eval_elapsed_time": 24.182081679347903}, "speedup": 2.262663009764823, "stats": {"layers": {"0": {"linear_attention_nnz": 809984, "linear_attention_total": 2359296, "linear_dense_nnz": 297984, "linear_dense_total": 4718592, "linear_nnz": 1107968, "linear_total": 7077888, "nnz": 1113762, "total": 7087872}, "1": {"linear_attention_nnz": 720896, "linear_attention_total": 2359296, "linear_dense_nnz": 483840, "linear_dense_total": 4718592, "linear_nnz": 1204736, "linear_total": 7077888, "nnz": 1210491, "total": 7087872}, "10": {"linear_attention_nnz": 478208, "linear_attention_total": 2359296, "linear_dense_nnz": 73728, "linear_dense_total": 4718592, "linear_nnz": 551936, "linear_total": 7077888, "nnz": 557392, "total": 7087872}, "11": {"linear_attention_nnz": 312320, "linear_attention_total": 2359296, "linear_dense_nnz": 159744, "linear_dense_total": 4718592, "linear_nnz": 472064, "linear_total": 7077888, "nnz": 477288, "total": 7087872}, "2": {"linear_attention_nnz": 1098752, "linear_attention_total": 2359296, "linear_dense_nnz": 619008, "linear_dense_total": 4718592, "linear_nnz": 1717760, "linear_total": 7077888, "nnz": 1724147, "total": 7087872}, "3": {"linear_attention_nnz": 1309696, "linear_attention_total": 2359296, "linear_dense_nnz": 657408, "linear_dense_total": 4718592, "linear_nnz": 1967104, "linear_total": 7077888, "nnz": 1973708, "total": 7087872}, "4": {"linear_attention_nnz": 1362944, "linear_attention_total": 2359296, "linear_dense_nnz": 705024, "linear_dense_total": 4718592, "linear_nnz": 2067968, "linear_total": 7077888, "nnz": 2074795, "total": 7087872}, "5": {"linear_attention_nnz": 1074176, "linear_attention_total": 2359296, "linear_dense_nnz": 668160, "linear_dense_total": 4718592, "linear_nnz": 1742336, "linear_total": 7077888, "nnz": 1748787, "total": 7087872}, "6": {"linear_attention_nnz": 1049600, "linear_attention_total": 2359296, "linear_dense_nnz": 516096, "linear_dense_total": 4718592, "linear_nnz": 1565696, "linear_total": 7077888, "nnz": 1572016, "total": 7087872}, "7": {"linear_attention_nnz": 958464, "linear_attention_total": 2359296, "linear_dense_nnz": 384000, "linear_dense_total": 4718592, "linear_nnz": 1342464, "linear_total": 7077888, "nnz": 1348506, "total": 7087872}, "8": {"linear_attention_nnz": 949248, "linear_attention_total": 2359296, "linear_dense_nnz": 204288, "linear_dense_total": 4718592, "linear_nnz": 1153536, "linear_total": 7077888, "nnz": 1159685, "total": 7087872}, "9": {"linear_attention_nnz": 636928, "linear_attention_total": 2359296, "linear_dense_nnz": 92160, "linear_dense_total": 4718592, "linear_nnz": 729088, "linear_total": 7077888, "nnz": 734684, "total": 7087872}}, "linear_nnz": 15622656, "linear_sparsity": 81.6062644675926, "linear_total": 84934656, "nnz": 39533983, "pruned_heads": {"0": [0, 1, 2, 4, 5, 6], "1": [0, 2, 3, 5, 6, 7, 8], "10": [1, 4, 5, 6, 7, 8], "11": [0, 2, 3, 5, 6, 7, 8, 10, 11], "2": [8, 4, 7], "3": [2, 4, 6, 7], "4": [1, 2], "5": [1, 2, 6, 7], "6": [0, 2, 3, 7], "7": [1, 3, 6, 7, 11], "8": [0, 8, 4], "9": [1, 4, 5, 7, 9, 10]}, "total": 108893186, "total_sparsity": 63.694713643514845}, "training_args": {"_n_gpu": -1, "adafactor": false, "adam_beta1": 0.9, "adam_beta2": 0.999, "adam_epsilon": 1e-08, "dataloader_drop_last": false, "dataloader_num_workers": 0, "dataloader_pin_memory": true, "ddp_find_unused_parameters": null, "debug": false, "deepspeed": null, "disable_tqdm": false, "do_eval": 1, "do_predict": false, "do_train": 1, "eval_accumulation_steps": null, "eval_steps": 5000, "evaluation_strategy": "steps", "fp16": false, "fp16_backend": "auto", "fp16_full_eval": false, "fp16_opt_level": "O1", "gradient_accumulation_steps": 1, "greater_is_better": null, "group_by_length": false, "ignore_data_skip": false, "label_names": null, "label_smoothing_factor": 0.0, "learning_rate": 3e-05, "load_best_model_at_end": false, "local_rank": -1, "logging_dir": "/opt/ml/output", "logging_first_step": false, "logging_steps": 250, "logging_strategy": "steps", "lr_scheduler_type": "linear", "max_grad_norm": 1.0, "max_steps": -1, "metric_for_best_model": null, "no_cuda": false, "num_train_epochs": 20.0, "optimize_model_before_eval": "disabled", "output_dir": "/opt/ml/model", "overwrite_output_dir": 1, "past_index": -1, "per_device_eval_batch_size": 8, "per_device_train_batch_size": 16, "per_gpu_eval_batch_size": null, "per_gpu_train_batch_size": null, "prediction_loss_only": false, "remove_unused_columns": true, "report_to": null, "run_name": "/opt/ml/model", "save_steps": 5000, "save_strategy": "steps", "save_total_limit": 50, "seed": 17, "sharded_ddp": false, "skip_memory_metrics": false, "tpu_metrics_debug": false, "tpu_num_cores": null, "warmup_ratio": 0.0, "warmup_steps": 5400, "weight_decay": 0.0}}, "f1": 87.14755939306319, "fill_rate": 0.18393735532407407, "speedup": 2.262663009764823}}
{"speedup": 2.471023235070233, "f1": 86.74156854566804, "meta": {"annotate": "19", "cat_fun_name": "is_new_xp", "checkpoint": {"config": {"_name_or_path": "bert-base-uncased", "architectures": ["BertForQuestionAnswering"], "attention_probs_dropout_prob": 0.1, "gradient_checkpointing": false, "hidden_act": "gelu", "hidden_dropout_prob": 0.1, "hidden_size": 768, "initializer_range": 0.02, "intermediate_size": 3072, "layer_norm_eps": 1e-12, "max_position_embeddings": 512, "model_type": "bert", "num_attention_heads": 12, "num_hidden_layers": 12, "pad_token_id": 0, "position_embedding_type": "absolute", "type_vocab_size": 2, "vocab_size": 30522}, "eval_metrics": {"exact_match": 78.80794701986756, "f1": 86.74156854566804}, "path": "/data_2to/devel_data/nn_pruning/output/squad_test3/hp_od-output__squad_test3_es-steps_nte20_ls250_est5000_rn-output__squad_test3_dpm-sigmoied_threshold:1d_alt_apme-sigmoied_threshold_aowd0_bm1_abr32_abc32_it0_fw10_r-l1_rfl20_dl0.25_dtnop-csarron__bert-base-uncased-squad-v1/checkpoint-110000", "sparse_args": {"ampere_pruning_method": "disabled", "attention_block_cols": 32, "attention_block_rows": 32, "attention_lambda": 1.0, "attention_output_with_dense": 0, "attention_pruning_method": "sigmoied_threshold", "bias_mask": true, "dense_block_cols": 1, "dense_block_rows": 1, "dense_lambda": 0.25, "dense_pruning_method": "sigmoied_threshold:1d_alt", "distil_alpha_ce": 0.1, "distil_alpha_teacher": 0.9, "distil_teacher_name_or_path": "csarron/bert-base-uncased-squad-v1", "distil_temperature": 2.0, "final_ampere_temperature": 20.0, "final_threshold": 0.1, "final_warmup": 10, "initial_ampere_temperature": 0.0, "initial_threshold": 0, "initial_warmup": 1, "mask_init": "constant", "mask_scale": 0.0, "mask_scores_learning_rate": 0.01, "regularization": "l1", "regularization_final_lambda": 20}, "speed": {"cuda_eval_elapsed_time": 15.618790004730226, "eval_elapsed_time": 22.811819266993552}, "speedup": 2.471023235070233, "stats": {"layers": {"0": {"linear_attention_nnz": 518144, "linear_attention_total": 2359296, "linear_dense_nnz": 826368, "linear_dense_total": 4718592, "linear_nnz": 1344512, "linear_total": 7077888, "nnz": 1350394, "total": 7087872}, "1": {"linear_attention_nnz": 516096, "linear_attention_total": 2359296, "linear_dense_nnz": 1090560, "linear_dense_total": 4718592, "linear_nnz": 1606656, "linear_total": 7077888, "nnz": 1612614, "total": 7087872}, "10": {"linear_attention_nnz": 324608, "linear_attention_total": 2359296, "linear_dense_nnz": 147456, "linear_dense_total": 4718592, "linear_nnz": 472064, "linear_total": 7077888, "nnz": 477376, "total": 7087872}, "11": {"linear_attention_nnz": 209920, "linear_attention_total": 2359296, "linear_dense_nnz": 345600, "linear_dense_total": 4718592, "linear_nnz": 555520, "linear_total": 7077888, "nnz": 560737, "total": 7087872}, "2": {"linear_attention_nnz": 637952, "linear_attention_total": 2359296, "linear_dense_nnz": 1204224, "linear_dense_total": 4718592, "linear_nnz": 1842176, "linear_total": 7077888, "nnz": 1848464, "total": 7087872}, "3": {"linear_attention_nnz": 913408, "linear_attention_total": 2359296, "linear_dense_nnz": 1184256, "linear_dense_total": 4718592, "linear_nnz": 2097664, "linear_total": 7077888, "nnz": 2104259, "total": 7087872}, "4": {"linear_attention_nnz": 790528, "linear_attention_total": 2359296, "linear_dense_nnz": 1265664, "linear_dense_total": 4718592, "linear_nnz": 2056192, "linear_total": 7077888, "nnz": 2062744, "total": 7087872}, "5": {"linear_attention_nnz": 664576, "linear_attention_total": 2359296, "linear_dense_nnz": 1201152, "linear_dense_total": 4718592, "linear_nnz": 1865728, "linear_total": 7077888, "nnz": 1871982, "total": 7087872}, "6": {"linear_attention_nnz": 629760, "linear_attention_total": 2359296, "linear_dense_nnz": 935424, "linear_dense_total": 4718592, "linear_nnz": 1565184, "linear_total": 7077888, "nnz": 1571297, "total": 7087872}, "7": {"linear_attention_nnz": 787456, "linear_attention_total": 2359296, "linear_dense_nnz": 698880, "linear_dense_total": 4718592, "linear_nnz": 1486336, "linear_total": 7077888, "nnz": 1492487, "total": 7087872}, "8": {"linear_attention_nnz": 415744, "linear_attention_total": 2359296, "linear_dense_nnz": 428544, "linear_dense_total": 4718592, "linear_nnz": 844288, "linear_total": 7077888, "nnz": 849783, "total": 7087872}, "9": {"linear_attention_nnz": 423936, "linear_attention_total": 2359296, "linear_dense_nnz": 168960, "linear_dense_total": 4718592, "linear_nnz": 592896, "linear_total": 7077888, "nnz": 598254, "total": 7087872}}, "linear_nnz": 16329216, "linear_sparsity": 80.7743778935185, "linear_total": 84934656, "nnz": 40239113, "pruned_heads": {"0": [0, 2, 4, 5, 6, 7, 9, 11], "1": [0, 2, 3, 5, 6, 7, 8, 9], "10": [1, 4, 5, 6, 7, 8, 9], "11": [0, 2, 3, 5, 6, 7, 8, 10, 11], "2": [1, 2, 4, 7, 8, 11], "3": [2, 4, 6, 7, 10], "4": [0, 1, 2, 6, 11], "5": [0, 1, 2, 5, 6, 7, 11], "6": [0, 2, 3, 4, 7, 10], "7": [1, 3, 6, 7, 11], "8": [0, 1, 2, 3, 4, 5, 6, 8], "9": [1, 3, 4, 5, 7, 9, 10]}, "total": 108893186, "total_sparsity": 63.04717083032174}, "training_args": {"_n_gpu": -1, "adafactor": false, "adam_beta1": 0.9, "adam_beta2": 0.999, "adam_epsilon": 1e-08, "dataloader_drop_last": false, "dataloader_num_workers": 0, "dataloader_pin_memory": true, "ddp_find_unused_parameters": null, "debug": false, "deepspeed": null, "disable_tqdm": false, "do_eval": 1, "do_predict": false, "do_train": 1, "eval_accumulation_steps": null, "eval_steps": 5000, "evaluation_strategy": "steps", "fp16": false, "fp16_backend": "auto", "fp16_full_eval": false, "fp16_opt_level": "O1", "gradient_accumulation_steps": 1, "greater_is_better": null, "group_by_length": false, "ignore_data_skip": false, "label_names": null, "label_smoothing_factor": 0.0, "learning_rate": 3e-05, "load_best_model_at_end": false, "local_rank": -1, "logging_dir": "output/squad_test3", "logging_first_step": false, "logging_steps": 250, "logging_strategy": "steps", "lr_scheduler_type": "linear", "max_grad_norm": 1.0, "max_steps": -1, "metric_for_best_model": null, "no_cuda": false, "num_train_epochs": 20, "optimize_model_before_eval": "disabled", "output_dir": "output/squad_test3", "overwrite_output_dir": 1, "past_index": -1, "per_device_eval_batch_size": 8, "per_device_train_batch_size": 16, "per_gpu_eval_batch_size": null, "per_gpu_train_batch_size": null, "prediction_loss_only": false, "remove_unused_columns": true, "report_to": null, "run_name": "output/squad_test3", "save_steps": 5000, "save_strategy": "steps", "save_total_limit": 5, "seed": 17, "sharded_ddp": "", "skip_memory_metrics": false, "tpu_metrics_debug": false, "tpu_num_cores": null, "warmup_ratio": 0.0, "warmup_steps": 5400, "weight_decay": 0.0}}, "f1": 86.74156854566804, "fill_rate": 0.192256221064815, "speedup": 2.471023235070233}}
{"speedup": 2.61711931355729, "f1": 86.39441106336629, "meta": {"annotate": "15", "cat_fun_name": "is_new_xp", "checkpoint": {"config": {"_name_or_path": "bert-base-uncased", "architectures": ["BertForQuestionAnswering"], "attention_probs_dropout_prob": 0.1, "gradient_checkpointing": false, "hidden_act": "gelu", "hidden_dropout_prob": 0.1, "hidden_size": 768, "initializer_range": 0.02, "intermediate_size": 3072, "layer_norm_eps": 1e-12, "max_position_embeddings": 512, "model_type": "bert", "num_attention_heads": 12, "num_hidden_layers": 12, "pad_token_id": 0, "position_embedding_type": "absolute", "type_vocab_size": 2, "vocab_size": 30522}, "eval_metrics": {"exact_match": 78.37275307473983, "f1": 86.39441106336629}, "path": "/data_2to/devel_data/nn_pruning/output/squad_test_aws/aws_nn-pruning-v10-a32-l20-dl0-5--2021-01-21--00-55-44/checkpoint-110660", "sparse_args": {"ampere_pruning_method": "disabled", "attention_block_cols": 32, "attention_block_rows": 32, "attention_lambda": 1.0, "attention_output_with_dense": 0, "attention_pruning_method": "sigmoied_threshold", "bias_mask": true, "dense_block_cols": 1, "dense_block_rows": 1, "dense_lambda": 0.5, "dense_pruning_method": "sigmoied_threshold:1d_alt", "distil_alpha_ce": 0.1, "distil_alpha_teacher": 0.9, "distil_teacher_name_or_path": "csarron/bert-base-uncased-squad-v1", "distil_temperature": 2.0, "final_ampere_temperature": 20.0, "final_threshold": 0.1, "final_warmup": 10, "initial_ampere_temperature": 0.0, "initial_threshold": 0, "initial_warmup": 1, "mask_init": "constant", "mask_scale": 0.0, "mask_scores_learning_rate": 0.01, "regularization": "l1", "regularization_final_lambda": 20.0}, "speed": {"cuda_eval_elapsed_time": 14.746898548126222, "eval_elapsed_time": 21.86237431317568}, "speedup": 2.61711931355729, "stats": {"layers": {"0": {"linear_attention_nnz": 519168, "linear_attention_total": 2359296, "linear_dense_nnz": 411648, "linear_dense_total": 4718592, "linear_nnz": 930816, "linear_total": 7077888, "nnz": 936364, "total": 7087872}, "1": {"linear_attention_nnz": 536576, "linear_attention_total": 2359296, "linear_dense_nnz": 592896, "linear_dense_total": 4718592, "linear_nnz": 1129472, "linear_total": 7077888, "nnz": 1135106, "total": 7087872}, "10": {"linear_attention_nnz": 356352, "linear_attention_total": 2359296, "linear_dense_nnz": 87552, "linear_dense_total": 4718592, "linear_nnz": 443904, "linear_total": 7077888, "nnz": 449209, "total": 7087872}, "11": {"linear_attention_nnz": 226304, "linear_attention_total": 2359296, "linear_dense_nnz": 199680, "linear_dense_total": 4718592, "linear_nnz": 425984, "linear_total": 7077888, "nnz": 431106, "total": 7087872}, "2": {"linear_attention_nnz": 667648, "linear_attention_total": 2359296, "linear_dense_nnz": 698880, "linear_dense_total": 4718592, "linear_nnz": 1366528, "linear_total": 7077888, "nnz": 1372487, "total": 7087872}, "3": {"linear_attention_nnz": 967680, "linear_attention_total": 2359296, "linear_dense_nnz": 714240, "linear_dense_total": 4718592, "linear_nnz": 1681920, "linear_total": 7077888, "nnz": 1688273, "total": 7087872}, "4": {"linear_attention_nnz": 835584, "linear_attention_total": 2359296, "linear_dense_nnz": 834048, "linear_dense_total": 4718592, "linear_nnz": 1669632, "linear_total": 7077888, "nnz": 1675967, "total": 7087872}, "5": {"linear_attention_nnz": 668672, "linear_attention_total": 2359296, "linear_dense_nnz": 743424, "linear_dense_total": 4718592, "linear_nnz": 1412096, "linear_total": 7077888, "nnz": 1418052, "total": 7087872}, "6": {"linear_attention_nnz": 653312, "linear_attention_total": 2359296, "linear_dense_nnz": 568320, "linear_dense_total": 4718592, "linear_nnz": 1221632, "linear_total": 7077888, "nnz": 1227506, "total": 7087872}, "7": {"linear_attention_nnz": 787456, "linear_attention_total": 2359296, "linear_dense_nnz": 450048, "linear_dense_total": 4718592, "linear_nnz": 1237504, "linear_total": 7077888, "nnz": 1243493, "total": 7087872}, "8": {"linear_attention_nnz": 493568, "linear_attention_total": 2359296, "linear_dense_nnz": 264192, "linear_dense_total": 4718592, "linear_nnz": 757760, "linear_total": 7077888, "nnz": 763404, "total": 7087872}, "9": {"linear_attention_nnz": 424960, "linear_attention_total": 2359296, "linear_dense_nnz": 101376, "linear_dense_total": 4718592, "linear_nnz": 526336, "linear_total": 7077888, "nnz": 531586, "total": 7087872}}, "linear_nnz": 12803584, "linear_sparsity": 84.92537133487654, "linear_total": 84934656, "nnz": 36711275, "pruned_heads": {"0": [0, 2, 4, 5, 6, 7, 9, 11], "1": [0, 2, 3, 5, 6, 7, 8, 9], "10": [1, 4, 5, 6, 7, 8, 9], "11": [0, 2, 3, 5, 6, 7, 8, 10, 11], "2": [1, 2, 4, 7, 8, 11], "3": [2, 4, 6, 7, 10], "4": [0, 1, 2, 6, 11], "5": [0, 1, 2, 5, 6, 7, 11], "6": [0, 2, 3, 4, 7, 10], "7": [1, 3, 6, 7, 11], "8": [0, 2, 3, 4, 6, 8], "9": [1, 3, 4, 5, 7, 9, 10]}, "total": 108893186, "total_sparsity": 66.28689420474849}, "training_args": {"_n_gpu": -1, "adafactor": false, "adam_beta1": 0.9, "adam_beta2": 0.999, "adam_epsilon": 1e-08, "dataloader_drop_last": false, "dataloader_num_workers": 0, "dataloader_pin_memory": true, "ddp_find_unused_parameters": null, "debug": false, "deepspeed": null, "disable_tqdm": false, "do_eval": 1, "do_predict": false, "do_train": 1, "eval_accumulation_steps": null, "eval_steps": 5000, "evaluation_strategy": "steps", "fp16": false, "fp16_backend": "auto", "fp16_full_eval": false, "fp16_opt_level": "O1", "gradient_accumulation_steps": 1, "greater_is_better": null, "group_by_length": false, "ignore_data_skip": false, "label_names": null, "label_smoothing_factor": 0.0, "learning_rate": 3e-05, "load_best_model_at_end": false, "local_rank": -1, "logging_dir": "/opt/ml/output", "logging_first_step": false, "logging_steps": 250, "logging_strategy": "steps", "lr_scheduler_type": "linear", "max_grad_norm": 1.0, "max_steps": -1, "metric_for_best_model": null, "no_cuda": false, "num_train_epochs": 20.0, "optimize_model_before_eval": "disabled", "output_dir": "/opt/ml/model", "overwrite_output_dir": 1, "past_index": -1, "per_device_eval_batch_size": 8, "per_device_train_batch_size": 16, "per_gpu_eval_batch_size": null, "per_gpu_train_batch_size": null, "prediction_loss_only": false, "remove_unused_columns": true, "report_to": null, "run_name": "/opt/ml/model", "save_steps": 5000, "save_strategy": "steps", "save_total_limit": 50, "seed": 17, "sharded_ddp": false, "skip_memory_metrics": false, "tpu_metrics_debug": false, "tpu_num_cores": null, "warmup_ratio": 0.0, "warmup_steps": 5400, "weight_decay": 0.0}}, "f1": 86.39441106336629, "fill_rate": 0.15074628665123457, "speedup": 2.61711931355729}}
{"speedup": 2.681246344578876, "f1": 86.20063710644014, "meta": {"annotate": "15", "cat_fun_name": "is_new_xp", "checkpoint": {"config": {"_name_or_path": "bert-base-uncased", "architectures": ["BertForQuestionAnswering"], "attention_probs_dropout_prob": 0.1, "gradient_checkpointing": false, "hidden_act": "gelu", "hidden_dropout_prob": 0.1, "hidden_size": 768, "initializer_range": 0.02, "intermediate_size": 3072, "layer_norm_eps": 1e-12, "max_position_embeddings": 512, "model_type": "bert", "num_attention_heads": 12, "num_hidden_layers": 12, "pad_token_id": 0, "position_embedding_type": "absolute", "type_vocab_size": 2, "vocab_size": 30522}, "eval_metrics": {"exact_match": 78.06054872280038, "f1": 86.20063710644014}, "path": "/data_2to/devel_data/nn_pruning/output/squad_test_aws/aws_nn-pruning-v10-a32-l30-dl0-25--2021-01-23--20-20-19/checkpoint-110660", "sparse_args": {"ampere_pruning_method": "disabled", "attention_block_cols": 32, "attention_block_rows": 32, "attention_lambda": 1.0, "attention_output_with_dense": 0, "attention_pruning_method": "sigmoied_threshold", "bias_mask": true, "dense_block_cols": 1, "dense_block_rows": 1, "dense_lambda": 0.25, "dense_pruning_method": "sigmoied_threshold:1d_alt", "distil_alpha_ce": 0.1, "distil_alpha_teacher": 0.9, "distil_teacher_name_or_path": "csarron/bert-base-uncased-squad-v1", "distil_temperature": 2.0, "final_ampere_temperature": 20.0, "final_threshold": 0.1, "final_warmup": 10, "initial_ampere_temperature": 0.0, "initial_threshold": 0, "initial_warmup": 1, "mask_init": "constant", "mask_scale": 0.0, "mask_scores_learning_rate": 0.01, "regularization": "l1", "regularization_final_lambda": 30.0}, "speed": {"cuda_eval_elapsed_time": 14.394198833465577, "eval_elapsed_time": 21.72890411503613}, "speedup": 2.681246344578876, "stats": {"layers": {"0": {"linear_attention_nnz": 455680, "linear_attention_total": 2359296, "linear_dense_nnz": 597504, "linear_dense_total": 4718592, "linear_nnz": 1053184, "linear_total": 7077888, "nnz": 1058789, "total": 7087872}, "1": {"linear_attention_nnz": 364544, "linear_attention_total": 2359296, "linear_dense_nnz": 854016, "linear_dense_total": 4718592, "linear_nnz": 1218560, "linear_total": 7077888, "nnz": 1224172, "total": 7087872}, "10": {"linear_attention_nnz": 286720, "linear_attention_total": 2359296, "linear_dense_nnz": 118272, "linear_dense_total": 4718592, "linear_nnz": 404992, "linear_total": 7077888, "nnz": 410093, "total": 7087872}, "11": {"linear_attention_nnz": 162816, "linear_attention_total": 2359296, "linear_dense_nnz": 276480, "linear_dense_total": 4718592, "linear_nnz": 439296, "linear_total": 7077888, "nnz": 444244, "total": 7087872}, "2": {"linear_attention_nnz": 529408, "linear_attention_total": 2359296, "linear_dense_nnz": 973824, "linear_dense_total": 4718592, "linear_nnz": 1503232, "linear_total": 7077888, "nnz": 1509178, "total": 7087872}, "3": {"linear_attention_nnz": 749568, "linear_attention_total": 2359296, "linear_dense_nnz": 964608, "linear_dense_total": 4718592, "linear_nnz": 1714176, "linear_total": 7077888, "nnz": 1720436, "total": 7087872}, "4": {"linear_attention_nnz": 578560, "linear_attention_total": 2359296, "linear_dense_nnz": 1047552, "linear_dense_total": 4718592, "linear_nnz": 1626112, "linear_total": 7077888, "nnz": 1632266, "total": 7087872}, "5": {"linear_attention_nnz": 600064, "linear_attention_total": 2359296, "linear_dense_nnz": 992256, "linear_dense_total": 4718592, "linear_nnz": 1592320, "linear_total": 7077888, "nnz": 1598438, "total": 7087872}, "6": {"linear_attention_nnz": 546816, "linear_attention_total": 2359296, "linear_dense_nnz": 775680, "linear_dense_total": 4718592, "linear_nnz": 1322496, "linear_total": 7077888, "nnz": 1328505, "total": 7087872}, "7": {"linear_attention_nnz": 686080, "linear_attention_total": 2359296, "linear_dense_nnz": 615936, "linear_dense_total": 4718592, "linear_nnz": 1302016, "linear_total": 7077888, "nnz": 1308113, "total": 7087872}, "8": {"linear_attention_nnz": 335872, "linear_attention_total": 2359296, "linear_dense_nnz": 342528, "linear_dense_total": 4718592, "linear_nnz": 678400, "linear_total": 7077888, "nnz": 683743, "total": 7087872}, "9": {"linear_attention_nnz": 358400, "linear_attention_total": 2359296, "linear_dense_nnz": 135168, "linear_dense_total": 4718592, "linear_nnz": 493568, "linear_total": 7077888, "nnz": 498776, "total": 7087872}}, "linear_nnz": 13348352, "linear_sparsity": 84.28397472993827, "linear_total": 84934656, "nnz": 37255475, "pruned_heads": {"0": [0, 2, 4, 5, 6, 7, 9, 11], "1": [0, 1, 2, 3, 5, 6, 7, 8, 9], "10": [1, 4, 5, 6, 7, 8, 9], "11": [0, 2, 3, 5, 6, 7, 8, 10, 11], "2": [1, 2, 3, 4, 5, 7, 8, 11], "3": [2, 4, 6, 7, 10], "4": [0, 1, 2, 6, 7, 11], "5": [0, 1, 2, 5, 6, 7, 11], "6": [0, 2, 3, 4, 7, 10], "7": [1, 3, 6, 7, 11], "8": [0, 1, 2, 3, 4, 5, 6, 7, 8], "9": [1, 3, 4, 5, 7, 9, 10]}, "total": 108893186, "total_sparsity": 65.78713841653968}, "training_args": {"_n_gpu": -1, "adafactor": false, "adam_beta1": 0.9, "adam_beta2": 0.999, "adam_epsilon": 1e-08, "dataloader_drop_last": false, "dataloader_num_workers": 0, "dataloader_pin_memory": true, "ddp_find_unused_parameters": null, "debug": false, "deepspeed": null, "disable_tqdm": false, "do_eval": 1, "do_predict": false, "do_train": 1, "eval_accumulation_steps": null, "eval_steps": 5000, "evaluation_strategy": "steps", "fp16": false, "fp16_backend": "auto", "fp16_full_eval": false, "fp16_opt_level": "O1", "gradient_accumulation_steps": 1, "greater_is_better": null, "group_by_length": false, "ignore_data_skip": false, "label_names": null, "label_smoothing_factor": 0.0, "learning_rate": 3e-05, "load_best_model_at_end": false, "local_rank": -1, "logging_dir": "/opt/ml/output", "logging_first_step": false, "logging_steps": 250, "logging_strategy": "steps", "lr_scheduler_type": "linear", "max_grad_norm": 1.0, "max_steps": -1, "metric_for_best_model": null, "no_cuda": false, "num_train_epochs": 20.0, "optimize_model_before_eval": "disabled", "output_dir": "/opt/ml/model", "overwrite_output_dir": 1, "past_index": -1, "per_device_eval_batch_size": 8, "per_device_train_batch_size": 16, "per_gpu_eval_batch_size": null, "per_gpu_train_batch_size": null, "prediction_loss_only": false, "remove_unused_columns": true, "report_to": null, "run_name": "/opt/ml/model", "save_steps": 5000, "save_strategy": "steps", "save_total_limit": 50, "seed": 17, "sharded_ddp": false, "skip_memory_metrics": false, "tpu_metrics_debug": false, "tpu_num_cores": null, "warmup_ratio": 0.0, "warmup_steps": 5400, "weight_decay": 0.0}}, "f1": 86.20063710644014, "fill_rate": 0.1571602527006174, "speedup": 2.681246344578876}}
{"speedup": 2.704854439028025, "f1": 86.11992485005756, "meta": {"annotate": "12", "cat_fun_name": "is_new_xp", "checkpoint": {"config": {"_name_or_path": "bert-base-uncased", "architectures": ["BertForQuestionAnswering"], "attention_probs_dropout_prob": 0.1, "gradient_checkpointing": false, "hidden_act": "gelu", "hidden_dropout_prob": 0.1, "hidden_size": 768, "initializer_range": 0.02, "intermediate_size": 3072, "layer_norm_eps": 1e-12, "max_position_embeddings": 512, "model_type": "bert", "num_attention_heads": 12, "num_hidden_layers": 12, "pad_token_id": 0, "position_embedding_type": "absolute", "type_vocab_size": 2, "vocab_size": 30522}, "eval_metrics": {"exact_match": 77.8240302743614, "f1": 86.11992485005756}, "path": "/data_2to/devel_data/nn_pruning/output/squad_test_aws/aws_nn-pruning-v10-a32-l20-dl1--2021-01-21--00-55-15/checkpoint-110660", "sparse_args": {"ampere_pruning_method": "disabled", "attention_block_cols": 32, "attention_block_rows": 32, "attention_lambda": 1.0, "attention_output_with_dense": 0, "attention_pruning_method": "sigmoied_threshold", "bias_mask": true, "dense_block_cols": 1, "dense_block_rows": 1, "dense_lambda": 1.0, "dense_pruning_method": "sigmoied_threshold:1d_alt", "distil_alpha_ce": 0.1, "distil_alpha_teacher": 0.9, "distil_teacher_name_or_path": "csarron/bert-base-uncased-squad-v1", "distil_temperature": 2.0, "final_ampere_temperature": 20.0, "final_threshold": 0.1, "final_warmup": 10, "initial_ampere_temperature": 0.0, "initial_threshold": 0, "initial_warmup": 1, "mask_init": "constant", "mask_scale": 0.0, "mask_scores_learning_rate": 0.01, "regularization": "l1", "regularization_final_lambda": 20.0}, "speed": {"cuda_eval_elapsed_time": 14.268565601348877, "eval_elapsed_time": 21.374552259687334}, "speedup": 2.704854439028025, "stats": {"layers": {"0": {"linear_attention_nnz": 550912, "linear_attention_total": 2359296, "linear_dense_nnz": 181248, "linear_dense_total": 4718592, "linear_nnz": 732160, "linear_total": 7077888, "nnz": 737654, "total": 7087872}, "1": {"linear_attention_nnz": 535552, "linear_attention_total": 2359296, "linear_dense_nnz": 299520, "linear_dense_total": 4718592, "linear_nnz": 835072, "linear_total": 7077888, "nnz": 840515, "total": 7087872}, "10": {"linear_attention_nnz": 364544, "linear_attention_total": 2359296, "linear_dense_nnz": 58368, "linear_dense_total": 4718592, "linear_nnz": 422912, "linear_total": 7077888, "nnz": 428102, "total": 7087872}, "11": {"linear_attention_nnz": 239616, "linear_attention_total": 2359296, "linear_dense_nnz": 96768, "linear_dense_total": 4718592, "linear_nnz": 336384, "linear_total": 7077888, "nnz": 341471, "total": 7087872}, "2": {"linear_attention_nnz": 721920, "linear_attention_total": 2359296, "linear_dense_nnz": 407040, "linear_dense_total": 4718592, "linear_nnz": 1128960, "linear_total": 7077888, "nnz": 1134729, "total": 7087872}, "3": {"linear_attention_nnz": 1111040, "linear_attention_total": 2359296, "linear_dense_nnz": 440832, "linear_dense_total": 4718592, "linear_nnz": 1551872, "linear_total": 7077888, "nnz": 1558207, "total": 7087872}, "4": {"linear_attention_nnz": 892928, "linear_attention_total": 2359296, "linear_dense_nnz": 496128, "linear_dense_total": 4718592, "linear_nnz": 1389056, "linear_total": 7077888, "nnz": 1395267, "total": 7087872}, "5": {"linear_attention_nnz": 663552, "linear_attention_total": 2359296, "linear_dense_nnz": 433152, "linear_dense_total": 4718592, "linear_nnz": 1096704, "linear_total": 7077888, "nnz": 1102458, "total": 7087872}, "6": {"linear_attention_nnz": 662528, "linear_attention_total": 2359296, "linear_dense_nnz": 337920, "linear_dense_total": 4718592, "linear_nnz": 1000448, "linear_total": 7077888, "nnz": 1006172, "total": 7087872}, "7": {"linear_attention_nnz": 801792, "linear_attention_total": 2359296, "linear_dense_nnz": 268800, "linear_dense_total": 4718592, "linear_nnz": 1070592, "linear_total": 7077888, "nnz": 1076463, "total": 7087872}, "8": {"linear_attention_nnz": 645120, "linear_attention_total": 2359296, "linear_dense_nnz": 158208, "linear_dense_total": 4718592, "linear_nnz": 803328, "linear_total": 7077888, "nnz": 809127, "total": 7087872}, "9": {"linear_attention_nnz": 424960, "linear_attention_total": 2359296, "linear_dense_nnz": 73728, "linear_dense_total": 4718592, "linear_nnz": 498688, "linear_total": 7077888, "nnz": 503952, "total": 7087872}}, "linear_nnz": 10866176, "linear_sparsity": 87.20642843364197, "linear_total": 84934656, "nnz": 34772839, "pruned_heads": {"0": [0, 2, 4, 5, 6, 7, 9, 11], "1": [0, 2, 3, 5, 6, 7, 8, 9], "10": [1, 4, 5, 6, 7, 8, 9], "11": [0, 2, 3, 5, 6, 7, 8, 10, 11], "2": [1, 2, 4, 7, 8, 11], "3": [2, 4, 6, 7], "4": [1, 2, 4, 6, 11], "5": [0, 1, 2, 5, 6, 7, 11], "6": [0, 2, 3, 4, 7, 10], "7": [1, 3, 6, 7, 11], "8": [0, 2, 3, 4, 8], "9": [1, 3, 4, 5, 7, 9, 10]}, "total": 108893186, "total_sparsity": 68.06702028169144}, "training_args": {"_n_gpu": -1, "adafactor": false, "adam_beta1": 0.9, "adam_beta2": 0.999, "adam_epsilon": 1e-08, "dataloader_drop_last": false, "dataloader_num_workers": 0, "dataloader_pin_memory": true, "ddp_find_unused_parameters": null, "debug": false, "deepspeed": null, "disable_tqdm": false, "do_eval": 1, "do_predict": false, "do_train": 1, "eval_accumulation_steps": null, "eval_steps": 5000, "evaluation_strategy": "steps", "fp16": false, "fp16_backend": "auto", "fp16_full_eval": false, "fp16_opt_level": "O1", "gradient_accumulation_steps": 1, "greater_is_better": null, "group_by_length": false, "ignore_data_skip": false, "label_names": null, "label_smoothing_factor": 0.0, "learning_rate": 3e-05, "load_best_model_at_end": false, "local_rank": -1, "logging_dir": "/opt/ml/output", "logging_first_step": false, "logging_steps": 250, "logging_strategy": "steps", "lr_scheduler_type": "linear", "max_grad_norm": 1.0, "max_steps": -1, "metric_for_best_model": null, "no_cuda": false, "num_train_epochs": 20.0, "optimize_model_before_eval": "disabled", "output_dir": "/opt/ml/model", "overwrite_output_dir": 1, "past_index": -1, "per_device_eval_batch_size": 8, "per_device_train_batch_size": 16, "per_gpu_eval_batch_size": null, "per_gpu_train_batch_size": null, "prediction_loss_only": false, "remove_unused_columns": true, "report_to": null, "run_name": "/opt/ml/model", "save_steps": 5000, "save_strategy": "steps", "save_total_limit": 50, "seed": 17, "sharded_ddp": false, "skip_memory_metrics": false, "tpu_metrics_debug": false, "tpu_num_cores": null, "warmup_ratio": 0.0, "warmup_steps": 5400, "weight_decay": 0.0}}, "f1": 86.11992485005756, "fill_rate": 0.1279357156635803, "speedup": 2.704854439028025}}
{"speedup": 2.860446087610368, "f1": 85.69020560735045, "meta": {"annotate": "12", "cat_fun_name": "is_new_xp", "checkpoint": {"config": {"_name_or_path": "bert-base-uncased", "architectures": ["BertForQuestionAnswering"], "attention_probs_dropout_prob": 0.1, "gradient_checkpointing": false, "hidden_act": "gelu", "hidden_dropout_prob": 0.1, "hidden_size": 768, "initializer_range": 0.02, "intermediate_size": 3072, "layer_norm_eps": 1e-12, "max_position_embeddings": 512, "model_type": "bert", "num_attention_heads": 12, "num_hidden_layers": 12, "pad_token_id": 0, "position_embedding_type": "absolute", "type_vocab_size": 2, "vocab_size": 30522}, "eval_metrics": {"exact_match": 77.37937559129612, "f1": 85.69020560735045}, "path": "/data_2to/devel_data/nn_pruning/output/squad_test_aws/aws_nn-pruning-v10-a32-l30-dl0-5--2021-01-23--20-19-50/checkpoint-110660", "sparse_args": {"ampere_pruning_method": "disabled", "attention_block_cols": 32, "attention_block_rows": 32, "attention_lambda": 1.0, "attention_output_with_dense": 0, "attention_pruning_method": "sigmoied_threshold", "bias_mask": true, "dense_block_cols": 1, "dense_block_rows": 1, "dense_lambda": 0.5, "dense_pruning_method": "sigmoied_threshold:1d_alt", "distil_alpha_ce": 0.1, "distil_alpha_teacher": 0.9, "distil_teacher_name_or_path": "csarron/bert-base-uncased-squad-v1", "distil_temperature": 2.0, "final_ampere_temperature": 20.0, "final_threshold": 0.1, "final_warmup": 10, "initial_ampere_temperature": 0.0, "initial_threshold": 0, "initial_warmup": 1, "mask_init": "constant", "mask_scale": 0.0, "mask_scores_learning_rate": 0.01, "regularization": "l1", "regularization_final_lambda": 30.0}, "speed": {"cuda_eval_elapsed_time": 13.492438529968261, "eval_elapsed_time": 20.86975116888061}, "speedup": 2.860446087610368, "stats": {"layers": {"0": {"linear_attention_nnz": 451584, "linear_attention_total": 2359296, "linear_dense_nnz": 290304, "linear_dense_total": 4718592, "linear_nnz": 741888, "linear_total": 7077888, "nnz": 747293, "total": 7087872}, "1": {"linear_attention_nnz": 495616, "linear_attention_total": 2359296, "linear_dense_nnz": 459264, "linear_dense_total": 4718592, "linear_nnz": 954880, "linear_total": 7077888, "nnz": 960395, "total": 7087872}, "10": {"linear_attention_nnz": 296960, "linear_attention_total": 2359296, "linear_dense_nnz": 73728, "linear_dense_total": 4718592, "linear_nnz": 370688, "linear_total": 7077888, "nnz": 375792, "total": 7087872}, "11": {"linear_attention_nnz": 194560, "linear_attention_total": 2359296, "linear_dense_nnz": 153600, "linear_dense_total": 4718592, "linear_nnz": 348160, "linear_total": 7077888, "nnz": 353092, "total": 7087872}, "2": {"linear_attention_nnz": 583680, "linear_attention_total": 2359296, "linear_dense_nnz": 557568, "linear_dense_total": 4718592, "linear_nnz": 1141248, "linear_total": 7077888, "nnz": 1147019, "total": 7087872}, "3": {"linear_attention_nnz": 789504, "linear_attention_total": 2359296, "linear_dense_nnz": 583680, "linear_dense_total": 4718592, "linear_nnz": 1373184, "linear_total": 7077888, "nnz": 1379228, "total": 7087872}, "4": {"linear_attention_nnz": 582656, "linear_attention_total": 2359296, "linear_dense_nnz": 665088, "linear_dense_total": 4718592, "linear_nnz": 1247744, "linear_total": 7077888, "nnz": 1253617, "total": 7087872}, "5": {"linear_attention_nnz": 548864, "linear_attention_total": 2359296, "linear_dense_nnz": 614400, "linear_dense_total": 4718592, "linear_nnz": 1163264, "linear_total": 7077888, "nnz": 1169040, "total": 7087872}, "6": {"linear_attention_nnz": 578560, "linear_attention_total": 2359296, "linear_dense_nnz": 463872, "linear_dense_total": 4718592, "linear_nnz": 1042432, "linear_total": 7077888, "nnz": 1048302, "total": 7087872}, "7": {"linear_attention_nnz": 715776, "linear_attention_total": 2359296, "linear_dense_nnz": 370176, "linear_dense_total": 4718592, "linear_nnz": 1085952, "linear_total": 7077888, "nnz": 1091889, "total": 7087872}, "8": {"linear_attention_nnz": 375808, "linear_attention_total": 2359296, "linear_dense_nnz": 235008, "linear_dense_total": 4718592, "linear_nnz": 610816, "linear_total": 7077888, "nnz": 616217, "total": 7087872}, "9": {"linear_attention_nnz": 347136, "linear_attention_total": 2359296, "linear_dense_nnz": 89088, "linear_dense_total": 4718592, "linear_nnz": 436224, "linear_total": 7077888, "nnz": 441306, "total": 7087872}}, "linear_nnz": 10516480, "linear_sparsity": 87.61815200617285, "linear_total": 84934656, "nnz": 34421912, "pruned_heads": {"0": [0, 2, 4, 5, 6, 7, 9, 11], "1": [0, 2, 3, 5, 6, 7, 8, 9], "10": [1, 4, 5, 6, 7, 8, 9], "11": [0, 2, 3, 5, 6, 7, 8, 10, 11], "2": [1, 2, 3, 4, 7, 8, 11], "3": [2, 3, 4, 6, 7, 10], "4": [0, 1, 2, 6, 7, 11], "5": [0, 1, 2, 4, 5, 6, 7, 11], "6": [0, 2, 3, 4, 7, 10], "7": [1, 3, 6, 7, 11], "8": [0, 1, 2, 3, 4, 5, 6, 8], "9": [1, 3, 4, 5, 7, 9, 10]}, "total": 108893186, "total_sparsity": 68.3892874619354}, "training_args": {"_n_gpu": -1, "adafactor": false, "adam_beta1": 0.9, "adam_beta2": 0.999, "adam_epsilon": 1e-08, "dataloader_drop_last": false, "dataloader_num_workers": 0, "dataloader_pin_memory": true, "ddp_find_unused_parameters": null, "debug": false, "deepspeed": null, "disable_tqdm": false, "do_eval": 1, "do_predict": false, "do_train": 1, "eval_accumulation_steps": null, "eval_steps": 5000, "evaluation_strategy": "steps", "fp16": false, "fp16_backend": "auto", "fp16_full_eval": false, "fp16_opt_level": "O1", "gradient_accumulation_steps": 1, "greater_is_better": null, "group_by_length": false, "ignore_data_skip": false, "label_names": null, "label_smoothing_factor": 0.0, "learning_rate": 3e-05, "load_best_model_at_end": false, "local_rank": -1, "logging_dir": "/opt/ml/output", "logging_first_step": false, "logging_steps": 250, "logging_strategy": "steps", "lr_scheduler_type": "linear", "max_grad_norm": 1.0, "max_steps": -1, "metric_for_best_model": null, "no_cuda": false, "num_train_epochs": 20.0, "optimize_model_before_eval": "disabled", "output_dir": "/opt/ml/model", "overwrite_output_dir": 1, "past_index": -1, "per_device_eval_batch_size": 8, "per_device_train_batch_size": 16, "per_gpu_eval_batch_size": null, "per_gpu_train_batch_size": null, "prediction_loss_only": false, "remove_unused_columns": true, "report_to": null, "run_name": "/opt/ml/model", "save_steps": 5000, "save_strategy": "steps", "save_total_limit": 50, "seed": 17, "sharded_ddp": false, "skip_memory_metrics": false, "tpu_metrics_debug": false, "tpu_num_cores": null, "warmup_ratio": 0.0, "warmup_steps": 5400, "weight_decay": 0.0}}, "f1": 85.69020560735045, "fill_rate": 0.12381847993827155, "speedup": 2.860446087610368}}
{"speedup": 2.86191312967017, "f1": 85.6109462422114, "meta": {"annotate": "13", "cat_fun_name": "is_new_xp", "checkpoint": {"config": {"_name_or_path": "bert-base-uncased", "architectures": ["BertForQuestionAnswering"], "attention_probs_dropout_prob": 0.1, "gradient_checkpointing": false, "hidden_act": "gelu", "hidden_dropout_prob": 0.1, "hidden_size": 768, "initializer_range": 0.02, "intermediate_size": 3072, "layer_norm_eps": 1e-12, "max_position_embeddings": 512, "model_type": "bert", "num_attention_heads": 12, "num_hidden_layers": 12, "pad_token_id": 0, "position_embedding_type": "absolute", "type_vocab_size": 2, "vocab_size": 30522}, "eval_metrics": {"exact_match": 77.18070009460737, "f1": 85.6109462422114}, "path": "/data_2to/devel_data/nn_pruning/output/squad_test3/hp_od-output__squad_test3_es-steps_nte20_ls250_est5000_rn-output__squad_test3_dpm-sigmoied_threshold:1d_alt_apme-sigmoied_threshold_aowd0_bm1_abr32_abc32_it0_fw10_r-l1_rfl40_dl0.25_dtnop-csarron__bert-base-uncased-squad-v1/checkpoint-110000", "sparse_args": {"ampere_pruning_method": "disabled", "attention_block_cols": 32, "attention_block_rows": 32, "attention_lambda": 1.0, "attention_output_with_dense": 0, "attention_pruning_method": "sigmoied_threshold", "bias_mask": true, "dense_block_cols": 1, "dense_block_rows": 1, "dense_lambda": 0.25, "dense_pruning_method": "sigmoied_threshold:1d_alt", "distil_alpha_ce": 0.1, "distil_alpha_teacher": 0.9, "distil_teacher_name_or_path": "csarron/bert-base-uncased-squad-v1", "distil_temperature": 2.0, "final_ampere_temperature": 20.0, "final_threshold": 0.1, "final_warmup": 10, "initial_ampere_temperature": 0.0, "initial_threshold": 0, "initial_warmup": 1, "mask_init": "constant", "mask_scale": 0.0, "mask_scores_learning_rate": 0.01, "regularization": "l1", "regularization_final_lambda": 40}, "speed": {"cuda_eval_elapsed_time": 13.485522186279297, "eval_elapsed_time": 20.651509277056903}, "speedup": 2.86191312967017, "stats": {"layers": {"0": {"linear_attention_nnz": 424960, "linear_attention_total": 2359296, "linear_dense_nnz": 482304, "linear_dense_total": 4718592, "linear_nnz": 907264, "linear_total": 7077888, "nnz": 912794, "total": 7087872}, "1": {"linear_attention_nnz": 367616, "linear_attention_total": 2359296, "linear_dense_nnz": 706560, "linear_dense_total": 4718592, "linear_nnz": 1074176, "linear_total": 7077888, "nnz": 1079692, "total": 7087872}, "10": {"linear_attention_nnz": 256000, "linear_attention_total": 2359296, "linear_dense_nnz": 121344, "linear_dense_total": 4718592, "linear_nnz": 377344, "linear_total": 7077888, "nnz": 382415, "total": 7087872}, "11": {"linear_attention_nnz": 146432, "linear_attention_total": 2359296, "linear_dense_nnz": 215040, "linear_dense_total": 4718592, "linear_nnz": 361472, "linear_total": 7077888, "nnz": 366316, "total": 7087872}, "2": {"linear_attention_nnz": 402432, "linear_attention_total": 2359296, "linear_dense_nnz": 850944, "linear_dense_total": 4718592, "linear_nnz": 1253376, "linear_total": 7077888, "nnz": 1259082, "total": 7087872}, "3": {"linear_attention_nnz": 681984, "linear_attention_total": 2359296, "linear_dense_nnz": 826368, "linear_dense_total": 4718592, "linear_nnz": 1508352, "linear_total": 7077888, "nnz": 1514458, "total": 7087872}, "4": {"linear_attention_nnz": 405504, "linear_attention_total": 2359296, "linear_dense_nnz": 923136, "linear_dense_total": 4718592, "linear_nnz": 1328640, "linear_total": 7077888, "nnz": 1334425, "total": 7087872}, "5": {"linear_attention_nnz": 542720, "linear_attention_total": 2359296, "linear_dense_nnz": 880128, "linear_dense_total": 4718592, "linear_nnz": 1422848, "linear_total": 7077888, "nnz": 1428861, "total": 7087872}, "6": {"linear_attention_nnz": 449536, "linear_attention_total": 2359296, "linear_dense_nnz": 645120, "linear_dense_total": 4718592, "linear_nnz": 1094656, "linear_total": 7077888, "nnz": 1100420, "total": 7087872}, "7": {"linear_attention_nnz": 577536, "linear_attention_total": 2359296, "linear_dense_nnz": 525312, "linear_dense_total": 4718592, "linear_nnz": 1102848, "linear_total": 7077888, "nnz": 1108726, "total": 7087872}, "8": {"linear_attention_nnz": 294912, "linear_attention_total": 2359296, "linear_dense_nnz": 333312, "linear_dense_total": 4718592, "linear_nnz": 628224, "linear_total": 7077888, "nnz": 633497, "total": 7087872}, "9": {"linear_attention_nnz": 320512, "linear_attention_total": 2359296, "linear_dense_nnz": 113664, "linear_dense_total": 4718592, "linear_nnz": 434176, "linear_total": 7077888, "nnz": 439306, "total": 7087872}}, "linear_nnz": 11493376, "linear_sparsity": 86.46797839506173, "linear_total": 84934656, "nnz": 35398714, "pruned_heads": {"0": [0, 2, 4, 5, 6, 7, 9, 11], "1": [0, 1, 2, 3, 5, 6, 7, 8, 9], "10": [1, 4, 5, 6, 7, 8, 9], "11": [0, 2, 3, 5, 6, 7, 8, 10, 11], "2": [1, 2, 3, 4, 5, 7, 8, 10, 11], "3": [2, 3, 4, 6, 7, 10], "4": [0, 1, 2, 6, 7, 8, 9, 11], "5": [0, 1, 2, 5, 6, 7, 11], "6": [0, 2, 3, 4, 6, 7, 10], "7": [1, 3, 6, 7, 11], "8": [0, 1, 2, 3, 4, 5, 6, 7, 8], "9": [1, 3, 4, 5, 7, 9, 10]}, "total": 108893186, "total_sparsity": 67.49225980035152}, "training_args": {"_n_gpu": -1, "adafactor": false, "adam_beta1": 0.9, "adam_beta2": 0.999, "adam_epsilon": 1e-08, "dataloader_drop_last": false, "dataloader_num_workers": 0, "dataloader_pin_memory": true, "ddp_find_unused_parameters": null, "debug": false, "deepspeed": null, "disable_tqdm": false, "do_eval": 1, "do_predict": false, "do_train": 1, "eval_accumulation_steps": null, "eval_steps": 5000, "evaluation_strategy": "steps", "fp16": false, "fp16_backend": "auto", "fp16_full_eval": false, "fp16_opt_level": "O1", "gradient_accumulation_steps": 1, "greater_is_better": null, "group_by_length": false, "ignore_data_skip": false, "label_names": null, "label_smoothing_factor": 0.0, "learning_rate": 3e-05, "load_best_model_at_end": false, "local_rank": -1, "logging_dir": "output/squad_test3", "logging_first_step": false, "logging_steps": 250, "logging_strategy": "steps", "lr_scheduler_type": "linear", "max_grad_norm": 1.0, "max_steps": -1, "metric_for_best_model": null, "no_cuda": false, "num_train_epochs": 20, "optimize_model_before_eval": "disabled", "output_dir": "output/squad_test3", "overwrite_output_dir": 1, "past_index": -1, "per_device_eval_batch_size": 8, "per_device_train_batch_size": 16, "per_gpu_eval_batch_size": null, "per_gpu_train_batch_size": null, "prediction_loss_only": false, "remove_unused_columns": true, "report_to": null, "run_name": "output/squad_test3", "save_steps": 5000, "save_strategy": "steps", "save_total_limit": 5, "seed": 17, "sharded_ddp": "", "skip_memory_metrics": false, "tpu_metrics_debug": false, "tpu_num_cores": null, "warmup_ratio": 0.0, "warmup_steps": 5400, "weight_decay": 0.0}}, "f1": 85.6109462422114, "fill_rate": 0.1353202160493826, "speedup": 2.86191312967017}}
