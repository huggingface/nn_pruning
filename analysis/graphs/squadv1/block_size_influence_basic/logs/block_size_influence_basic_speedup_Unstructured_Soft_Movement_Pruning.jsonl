{"speedup": 0.9840340185670864, "f1": 90.24019516114679, "meta": {"annotate": "30", "cat_fun_name": "is_improved_mvmt_pruning", "checkpoint": {"config": {"_name_or_path": "bert-base-uncased", "architectures": ["BertForQuestionAnswering"], "attention_probs_dropout_prob": 0.1, "gradient_checkpointing": false, "hidden_act": "gelu", "hidden_dropout_prob": 0.1, "hidden_size": 768, "initializer_range": 0.02, "intermediate_size": 3072, "layer_norm_eps": 1e-12, "max_position_embeddings": 512, "model_type": "bert", "num_attention_heads": 12, "num_hidden_layers": 12, "pad_token_id": 0, "position_embedding_type": "absolute", "type_vocab_size": 2, "vocab_size": 30522}, "eval_metrics": {"exact_match": 83.87890255439925, "f1": 90.24019516114679}, "path": "/data_2to/devel_data/nn_pruning/output/squad_test_8_mvp_lt/hp_od-__data_2to__devel_data__nn_pruning__output__squad_test_8_mvp_lt___es-steps_nte20_ls250_stl50_est5000_rn-__data_2to__devel_data__nn_pruning__output__squad_test_8_mvp_lt___dpm-si--5742d4278f871b20/checkpoint-105000", "sparse_args": {"ampere_pruning_method": "disabled", "attention_block_cols": 1, "attention_block_rows": 1, "attention_lambda": 1.0, "attention_output_with_dense": 0, "attention_pruning_method": "sigmoied_threshold", "bias_mask": true, "dense_block_cols": 1, "dense_block_rows": 1, "dense_lambda": 1.0, "dense_pruning_method": "sigmoied_threshold", "distil_alpha_ce": 0.1, "distil_alpha_teacher": 0.9, "distil_teacher_name_or_path": "bert-large-uncased-whole-word-masking-finetuned-squad", "distil_temperature": 2.0, "final_ampere_temperature": 20.0, "final_finetune": false, "final_threshold": 0.1, "final_warmup": 10, "gelu_patch": 0, "initial_ampere_temperature": 0.0, "initial_threshold": 0, "initial_warmup": 1, "layer_norm_patch": 0, "mask_init": "constant", "mask_scale": 0.0, "mask_scores_learning_rate": 0.01, "regularization": "l1", "regularization_final_lambda": 20}, "speed": {"cuda_eval_elapsed_time": 39.22058818817139, "eval_elapsed_time": 46.20080855116248}, "speedup": 0.9840340185670864, "stats": {"layers": {"0": {"linear_attention_nnz": 506421, "linear_attention_total": 2359296, "linear_dense_nnz": 2119553, "linear_dense_total": 4718592, "linear_nnz": 2625974, "linear_total": 7077888, "nnz": 2635887, "total": 7087872}, "1": {"linear_attention_nnz": 576671, "linear_attention_total": 2359296, "linear_dense_nnz": 2157695, "linear_dense_total": 4718592, "linear_nnz": 2734366, "linear_total": 7077888, "nnz": 2744311, "total": 7087872}, "10": {"linear_attention_nnz": 325235, "linear_attention_total": 2359296, "linear_dense_nnz": 597278, "linear_dense_total": 4718592, "linear_nnz": 922513, "linear_total": 7077888, "nnz": 931676, "total": 7087872}, "11": {"linear_attention_nnz": 195895, "linear_attention_total": 2359296, "linear_dense_nnz": 315779, "linear_dense_total": 4718592, "linear_nnz": 511674, "linear_total": 7077888, "nnz": 519723, "total": 7087872}, "2": {"linear_attention_nnz": 722482, "linear_attention_total": 2359296, "linear_dense_nnz": 2188133, "linear_dense_total": 4718592, "linear_nnz": 2910615, "linear_total": 7077888, "nnz": 2920599, "total": 7087872}, "3": {"linear_attention_nnz": 801394, "linear_attention_total": 2359296, "linear_dense_nnz": 2185014, "linear_dense_total": 4718592, "linear_nnz": 2986408, "linear_total": 7077888, "nnz": 2996347, "total": 7087872}, "4": {"linear_attention_nnz": 869061, "linear_attention_total": 2359296, "linear_dense_nnz": 2071237, "linear_dense_total": 4718592, "linear_nnz": 2940298, "linear_total": 7077888, "nnz": 2950272, "total": 7087872}, "5": {"linear_attention_nnz": 816637, "linear_attention_total": 2359296, "linear_dense_nnz": 2032020, "linear_dense_total": 4718592, "linear_nnz": 2848657, "linear_total": 7077888, "nnz": 2858639, "total": 7087872}, "6": {"linear_attention_nnz": 812906, "linear_attention_total": 2359296, "linear_dense_nnz": 1802564, "linear_dense_total": 4718592, "linear_nnz": 2615470, "linear_total": 7077888, "nnz": 2625454, "total": 7087872}, "7": {"linear_attention_nnz": 601681, "linear_attention_total": 2359296, "linear_dense_nnz": 1468047, "linear_dense_total": 4718592, "linear_nnz": 2069728, "linear_total": 7077888, "nnz": 2079319, "total": 7087872}, "8": {"linear_attention_nnz": 674649, "linear_attention_total": 2359296, "linear_dense_nnz": 1053978, "linear_dense_total": 4718592, "linear_nnz": 1728627, "linear_total": 7077888, "nnz": 1738609, "total": 7087872}, "9": {"linear_attention_nnz": 449718, "linear_attention_total": 2359296, "linear_dense_nnz": 674197, "linear_dense_total": 4718592, "linear_nnz": 1123915, "linear_total": 7077888, "nnz": 1133393, "total": 7087872}}, "linear_nnz": 26018245, "linear_sparsity": 69.36675059942552, "linear_total": 84934656, "nnz": 49972951, "pruned_heads": {"0": [], "1": [], "10": [], "11": [], "2": [], "3": [], "4": [], "5": [], "6": [], "7": [], "8": [], "9": []}, "total": 108893186, "total_sparsity": 54.10828460836843}, "training_args": {"_n_gpu": -1, "adafactor": false, "adam_beta1": 0.9, "adam_beta2": 0.999, "adam_epsilon": 1e-08, "dataloader_drop_last": false, "dataloader_num_workers": 0, "dataloader_pin_memory": true, "ddp_find_unused_parameters": null, "debug": false, "deepspeed": null, "disable_tqdm": false, "do_eval": 1, "do_predict": false, "do_train": 1, "eval_accumulation_steps": null, "eval_steps": 5000, "evaluation_strategy": "steps", "fp16": false, "fp16_backend": "auto", "fp16_full_eval": false, "fp16_opt_level": "O1", "gradient_accumulation_steps": 1, "greater_is_better": null, "group_by_length": false, "ignore_data_skip": false, "label_names": null, "label_smoothing_factor": 0.0, "learning_rate": 3e-05, "load_best_model_at_end": false, "local_rank": -1, "logging_dir": "/data_2to/devel_data/nn_pruning/output/squad_test_8_mvp_lt/", "logging_first_step": false, "logging_steps": 250, "logging_strategy": "steps", "lr_scheduler_type": "linear", "max_grad_norm": 1.0, "max_steps": -1, "metric_for_best_model": null, "no_cuda": false, "num_train_epochs": 20, "optimize_model_before_eval": "disabled", "output_dir": "/data_2to/devel_data/nn_pruning/output/squad_test_8_mvp_lt/", "overwrite_output_dir": 1, "past_index": -1, "per_device_eval_batch_size": 8, "per_device_train_batch_size": 16, "per_gpu_eval_batch_size": null, "per_gpu_train_batch_size": null, "prediction_loss_only": false, "remove_unused_columns": true, "report_to": null, "run_name": "/data_2to/devel_data/nn_pruning/output/squad_test_8_mvp_lt/", "save_steps": 5000, "save_strategy": "steps", "save_total_limit": 50, "seed": 17, "sharded_ddp": "", "skip_memory_metrics": false, "tpu_metrics_debug": false, "tpu_num_cores": null, "warmup_ratio": 0.0, "warmup_steps": 5400, "weight_decay": 0.0}}, "f1": 90.24019516114679, "fill_rate": 0.3063324940057448, "speedup": 0.9840340185670864}}
{"speedup": 1.026141974757969, "f1": 89.78322305629628, "meta": {"annotate": "19", "cat_fun_name": "is_improved_mvmt_pruning", "checkpoint": {"config": {"_name_or_path": "bert-base-uncased", "architectures": ["BertForQuestionAnswering"], "attention_probs_dropout_prob": 0.1, "gradient_checkpointing": false, "hidden_act": "gelu", "hidden_dropout_prob": 0.1, "hidden_size": 768, "initializer_range": 0.02, "intermediate_size": 3072, "layer_norm_eps": 1e-12, "max_position_embeddings": 512, "model_type": "bert", "num_attention_heads": 12, "num_hidden_layers": 12, "pad_token_id": 0, "position_embedding_type": "absolute", "type_vocab_size": 2, "vocab_size": 30522}, "eval_metrics": {"exact_match": 83.17880794701986, "f1": 89.78322305629628}, "path": "/data_2to/devel_data/nn_pruning/output/squad_test_8_mvp_lt/hp_od-__data_2to__devel_data__nn_pruning__output__squad_test_8_mvp_lt___es-steps_nte20_ls250_stl50_est5000_rn-__data_2to__devel_data__nn_pruning__output__squad_test_8_mvp_lt___dpm-si--45bf1e1da1b7299c/checkpoint-110000", "sparse_args": {"ampere_pruning_method": "disabled", "attention_block_cols": 1, "attention_block_rows": 1, "attention_lambda": 1.0, "attention_output_with_dense": 0, "attention_pruning_method": "sigmoied_threshold", "bias_mask": true, "dense_block_cols": 1, "dense_block_rows": 1, "dense_lambda": 1.0, "dense_pruning_method": "sigmoied_threshold", "distil_alpha_ce": 0.1, "distil_alpha_teacher": 0.9, "distil_teacher_name_or_path": "bert-large-uncased-whole-word-masking-finetuned-squad", "distil_temperature": 2.0, "final_ampere_temperature": 20.0, "final_finetune": false, "final_threshold": 0.1, "final_warmup": 10, "gelu_patch": 0, "initial_ampere_temperature": 0.0, "initial_threshold": 0, "initial_warmup": 1, "layer_norm_patch": 0, "mask_init": "constant", "mask_scale": 0.0, "mask_scores_learning_rate": 0.01, "regularization": "l1", "regularization_final_lambda": 40}, "speed": {"cuda_eval_elapsed_time": 37.61116293334961, "eval_elapsed_time": 44.6719565698877}, "speedup": 1.026141974757969, "stats": {"layers": {"0": {"linear_attention_nnz": 270490, "linear_attention_total": 2359296, "linear_dense_nnz": 1480949, "linear_dense_total": 4718592, "linear_nnz": 1751439, "linear_total": 7077888, "nnz": 1760894, "total": 7087872}, "1": {"linear_attention_nnz": 335933, "linear_attention_total": 2359296, "linear_dense_nnz": 1534020, "linear_dense_total": 4718592, "linear_nnz": 1869953, "linear_total": 7077888, "nnz": 1879366, "total": 7087872}, "10": {"linear_attention_nnz": 166873, "linear_attention_total": 2359296, "linear_dense_nnz": 247010, "linear_dense_total": 4718592, "linear_nnz": 413883, "linear_total": 7077888, "nnz": 422281, "total": 7087872}, "11": {"linear_attention_nnz": 93795, "linear_attention_total": 2359296, "linear_dense_nnz": 153368, "linear_dense_total": 4718592, "linear_nnz": 247163, "linear_total": 7077888, "nnz": 254059, "total": 7087872}, "2": {"linear_attention_nnz": 443918, "linear_attention_total": 2359296, "linear_dense_nnz": 1543955, "linear_dense_total": 4718592, "linear_nnz": 1987873, "linear_total": 7077888, "nnz": 1997593, "total": 7087872}, "3": {"linear_attention_nnz": 509017, "linear_attention_total": 2359296, "linear_dense_nnz": 1515526, "linear_dense_total": 4718592, "linear_nnz": 2024543, "linear_total": 7077888, "nnz": 2034242, "total": 7087872}, "4": {"linear_attention_nnz": 560867, "linear_attention_total": 2359296, "linear_dense_nnz": 1397000, "linear_dense_total": 4718592, "linear_nnz": 1957867, "linear_total": 7077888, "nnz": 1967760, "total": 7087872}, "5": {"linear_attention_nnz": 481964, "linear_attention_total": 2359296, "linear_dense_nnz": 1339614, "linear_dense_total": 4718592, "linear_nnz": 1821578, "linear_total": 7077888, "nnz": 1831430, "total": 7087872}, "6": {"linear_attention_nnz": 465111, "linear_attention_total": 2359296, "linear_dense_nnz": 1115521, "linear_dense_total": 4718592, "linear_nnz": 1580632, "linear_total": 7077888, "nnz": 1590485, "total": 7087872}, "7": {"linear_attention_nnz": 349655, "linear_attention_total": 2359296, "linear_dense_nnz": 836653, "linear_dense_total": 4718592, "linear_nnz": 1186308, "linear_total": 7077888, "nnz": 1195564, "total": 7087872}, "8": {"linear_attention_nnz": 347514, "linear_attention_total": 2359296, "linear_dense_nnz": 546212, "linear_dense_total": 4718592, "linear_nnz": 893726, "linear_total": 7077888, "nnz": 903465, "total": 7087872}, "9": {"linear_attention_nnz": 229122, "linear_attention_total": 2359296, "linear_dense_nnz": 295840, "linear_dense_total": 4718592, "linear_nnz": 524962, "linear_total": 7077888, "nnz": 533702, "total": 7087872}}, "linear_nnz": 16259927, "linear_sparsity": 80.85595707834503, "linear_total": 84934656, "nnz": 40209563, "pruned_heads": {"0": [], "1": [], "10": [1, 4], "11": [5], "2": [], "3": [], "4": [], "5": [], "6": [], "7": [], "8": [], "9": [4]}, "total": 108893186, "total_sparsity": 63.07430751452161}, "training_args": {"_n_gpu": -1, "adafactor": false, "adam_beta1": 0.9, "adam_beta2": 0.999, "adam_epsilon": 1e-08, "dataloader_drop_last": false, "dataloader_num_workers": 0, "dataloader_pin_memory": true, "ddp_find_unused_parameters": null, "debug": false, "deepspeed": null, "disable_tqdm": false, "do_eval": 1, "do_predict": false, "do_train": 1, "eval_accumulation_steps": null, "eval_steps": 5000, "evaluation_strategy": "steps", "fp16": false, "fp16_backend": "auto", "fp16_full_eval": false, "fp16_opt_level": "O1", "gradient_accumulation_steps": 1, "greater_is_better": null, "group_by_length": false, "ignore_data_skip": false, "label_names": null, "label_smoothing_factor": 0.0, "learning_rate": 3e-05, "load_best_model_at_end": false, "local_rank": -1, "logging_dir": "/data_2to/devel_data/nn_pruning/output/squad_test_8_mvp_lt/", "logging_first_step": false, "logging_steps": 250, "logging_strategy": "steps", "lr_scheduler_type": "linear", "max_grad_norm": 1.0, "max_steps": -1, "metric_for_best_model": null, "no_cuda": false, "num_train_epochs": 20, "optimize_model_before_eval": "disabled", "output_dir": "/data_2to/devel_data/nn_pruning/output/squad_test_8_mvp_lt/", "overwrite_output_dir": 1, "past_index": -1, "per_device_eval_batch_size": 8, "per_device_train_batch_size": 16, "per_gpu_eval_batch_size": null, "per_gpu_train_batch_size": null, "prediction_loss_only": false, "remove_unused_columns": true, "report_to": null, "run_name": "/data_2to/devel_data/nn_pruning/output/squad_test_8_mvp_lt/", "save_steps": 5000, "save_strategy": "steps", "save_total_limit": 50, "seed": 17, "sharded_ddp": "", "skip_memory_metrics": false, "tpu_metrics_debug": false, "tpu_num_cores": null, "warmup_ratio": 0.0, "warmup_steps": 5400, "weight_decay": 0.0}}, "f1": 89.78322305629628, "fill_rate": 0.1914404292165497, "speedup": 1.026141974757969}}
{"speedup": 1.095528107464865, "f1": 88.66959543954316, "meta": {"annotate": "11", "cat_fun_name": "is_improved_mvmt_pruning", "checkpoint": {"config": {"_name_or_path": "bert-base-uncased", "architectures": ["BertForQuestionAnswering"], "attention_probs_dropout_prob": 0.1, "gradient_checkpointing": false, "hidden_act": "gelu", "hidden_dropout_prob": 0.1, "hidden_size": 768, "initializer_range": 0.02, "intermediate_size": 3072, "layer_norm_eps": 1e-12, "max_position_embeddings": 512, "model_type": "bert", "num_attention_heads": 12, "num_hidden_layers": 12, "pad_token_id": 0, "position_embedding_type": "absolute", "type_vocab_size": 2, "vocab_size": 30522}, "eval_metrics": {"exact_match": 81.93945127719962, "f1": 88.66959543954316}, "path": "/data_2to/devel_data/nn_pruning/output/squad_test_8_mvp_lt/hp_od-__data_2to__devel_data__nn_pruning__output__squad_test_8_mvp_lt___es-steps_nte20_ls250_stl50_est5000_rn-__data_2to__devel_data__nn_pruning__output__squad_test_8_mvp_lt___dpm-si--3dbebc278974335e/checkpoint-100000", "sparse_args": {"ampere_pruning_method": "disabled", "attention_block_cols": 1, "attention_block_rows": 1, "attention_lambda": 1.0, "attention_output_with_dense": 0, "attention_pruning_method": "sigmoied_threshold", "bias_mask": true, "dense_block_cols": 1, "dense_block_rows": 1, "dense_lambda": 1.0, "dense_pruning_method": "sigmoied_threshold", "distil_alpha_ce": 0.1, "distil_alpha_teacher": 0.9, "distil_teacher_name_or_path": "bert-large-uncased-whole-word-masking-finetuned-squad", "distil_temperature": 2.0, "final_ampere_temperature": 20.0, "final_finetune": false, "final_threshold": 0.1, "final_warmup": 10, "gelu_patch": 0, "initial_ampere_temperature": 0.0, "initial_threshold": 0, "initial_warmup": 1, "layer_norm_patch": 0, "mask_init": "constant", "mask_scale": 0.0, "mask_scores_learning_rate": 0.01, "regularization": "l1", "regularization_final_lambda": 80}, "speed": {"cuda_eval_elapsed_time": 35.22903040313721, "eval_elapsed_time": 42.20514475926757}, "speedup": 1.095528107464865, "stats": {"layers": {"0": {"linear_attention_nnz": 159799, "linear_attention_total": 2359296, "linear_dense_nnz": 1019941, "linear_dense_total": 4718592, "linear_nnz": 1179740, "linear_total": 7077888, "nnz": 1188733, "total": 7087872}, "1": {"linear_attention_nnz": 225256, "linear_attention_total": 2359296, "linear_dense_nnz": 1060626, "linear_dense_total": 4718592, "linear_nnz": 1285882, "linear_total": 7077888, "nnz": 1294828, "total": 7087872}, "10": {"linear_attention_nnz": 95768, "linear_attention_total": 2359296, "linear_dense_nnz": 108189, "linear_dense_total": 4718592, "linear_nnz": 203957, "linear_total": 7077888, "nnz": 211096, "total": 7087872}, "11": {"linear_attention_nnz": 54825, "linear_attention_total": 2359296, "linear_dense_nnz": 81043, "linear_dense_total": 4718592, "linear_nnz": 135868, "linear_total": 7077888, "nnz": 142072, "total": 7087872}, "2": {"linear_attention_nnz": 297063, "linear_attention_total": 2359296, "linear_dense_nnz": 1050962, "linear_dense_total": 4718592, "linear_nnz": 1348025, "linear_total": 7077888, "nnz": 1357400, "total": 7087872}, "3": {"linear_attention_nnz": 344394, "linear_attention_total": 2359296, "linear_dense_nnz": 999457, "linear_dense_total": 4718592, "linear_nnz": 1343851, "linear_total": 7077888, "nnz": 1353282, "total": 7087872}, "4": {"linear_attention_nnz": 360638, "linear_attention_total": 2359296, "linear_dense_nnz": 868456, "linear_dense_total": 4718592, "linear_nnz": 1229094, "linear_total": 7077888, "nnz": 1238822, "total": 7087872}, "5": {"linear_attention_nnz": 279458, "linear_attention_total": 2359296, "linear_dense_nnz": 803587, "linear_dense_total": 4718592, "linear_nnz": 1083045, "linear_total": 7077888, "nnz": 1092686, "total": 7087872}, "6": {"linear_attention_nnz": 255911, "linear_attention_total": 2359296, "linear_dense_nnz": 634016, "linear_dense_total": 4718592, "linear_nnz": 889927, "linear_total": 7077888, "nnz": 899603, "total": 7087872}, "7": {"linear_attention_nnz": 204977, "linear_attention_total": 2359296, "linear_dense_nnz": 440993, "linear_dense_total": 4718592, "linear_nnz": 645970, "linear_total": 7077888, "nnz": 655018, "total": 7087872}, "8": {"linear_attention_nnz": 179070, "linear_attention_total": 2359296, "linear_dense_nnz": 265135, "linear_dense_total": 4718592, "linear_nnz": 444205, "linear_total": 7077888, "nnz": 453337, "total": 7087872}, "9": {"linear_attention_nnz": 124400, "linear_attention_total": 2359296, "linear_dense_nnz": 124282, "linear_dense_total": 4718592, "linear_nnz": 248682, "linear_total": 7077888, "nnz": 256304, "total": 7087872}}, "linear_nnz": 10038246, "linear_sparsity": 88.18121309633608, "linear_total": 84934656, "nnz": 33981903, "pruned_heads": {"0": [], "1": [], "10": [1, 2, 4, 5], "11": [8, 5], "2": [], "3": [], "4": [], "5": [], "6": [3], "7": [], "8": [0], "9": [1, 4, 5, 7, 10]}, "total": 108893186, "total_sparsity": 68.79336141381702}, "training_args": {"_n_gpu": -1, "adafactor": false, "adam_beta1": 0.9, "adam_beta2": 0.999, "adam_epsilon": 1e-08, "dataloader_drop_last": false, "dataloader_num_workers": 0, "dataloader_pin_memory": true, "ddp_find_unused_parameters": null, "debug": false, "deepspeed": null, "disable_tqdm": false, "do_eval": 1, "do_predict": false, "do_train": 1, "eval_accumulation_steps": null, "eval_steps": 5000, "evaluation_strategy": "steps", "fp16": false, "fp16_backend": "auto", "fp16_full_eval": false, "fp16_opt_level": "O1", "gradient_accumulation_steps": 1, "greater_is_better": null, "group_by_length": false, "ignore_data_skip": false, "label_names": null, "label_smoothing_factor": 0.0, "learning_rate": 3e-05, "load_best_model_at_end": false, "local_rank": -1, "logging_dir": "/data_2to/devel_data/nn_pruning/output/squad_test_8_mvp_lt/", "logging_first_step": false, "logging_steps": 250, "logging_strategy": "steps", "lr_scheduler_type": "linear", "max_grad_norm": 1.0, "max_steps": -1, "metric_for_best_model": null, "no_cuda": false, "num_train_epochs": 20, "optimize_model_before_eval": "disabled", "output_dir": "/data_2to/devel_data/nn_pruning/output/squad_test_8_mvp_lt/", "overwrite_output_dir": 1, "past_index": -1, "per_device_eval_batch_size": 8, "per_device_train_batch_size": 16, "per_gpu_eval_batch_size": null, "per_gpu_train_batch_size": null, "prediction_loss_only": false, "remove_unused_columns": true, "report_to": null, "run_name": "/data_2to/devel_data/nn_pruning/output/squad_test_8_mvp_lt/", "save_steps": 5000, "save_strategy": "steps", "save_total_limit": 50, "seed": 17, "sharded_ddp": "", "skip_memory_metrics": false, "tpu_metrics_debug": false, "tpu_num_cores": null, "warmup_ratio": 0.0, "warmup_steps": 5400, "weight_decay": 0.0}}, "f1": 88.66959543954316, "fill_rate": 0.11818786903663925, "speedup": 1.095528107464865}}
{"speedup": 1.1632636047982534, "f1": 88.11360890595924, "meta": {"annotate": "8", "cat_fun_name": "is_improved_mvmt_pruning", "checkpoint": {"config": {"_name_or_path": "bert-base-uncased", "architectures": ["BertForQuestionAnswering"], "attention_probs_dropout_prob": 0.1, "gradient_checkpointing": false, "hidden_act": "gelu", "hidden_dropout_prob": 0.1, "hidden_size": 768, "initializer_range": 0.02, "intermediate_size": 3072, "layer_norm_eps": 1e-12, "max_position_embeddings": 512, "model_type": "bert", "num_attention_heads": 12, "num_hidden_layers": 12, "pad_token_id": 0, "position_embedding_type": "absolute", "type_vocab_size": 2, "vocab_size": 30522}, "eval_metrics": {"exact_match": 80.93661305581836, "f1": 88.11360890595924}, "path": "/data_2to/devel_data/nn_pruning/output/squad_test_8_mvp_lt/hp_od-__data_2to__devel_data__nn_pruning__output__squad_test_8_mvp_lt___es-steps_nte20_ls250_stl50_est5000_rn-__data_2to__devel_data__nn_pruning__output__squad_test_8_mvp_lt___dpm-si--7fe43555f854fbb6/checkpoint-110000", "sparse_args": {"ampere_pruning_method": "disabled", "attention_block_cols": 1, "attention_block_rows": 1, "attention_lambda": 1.0, "attention_output_with_dense": 0, "attention_pruning_method": "sigmoied_threshold", "bias_mask": true, "dense_block_cols": 1, "dense_block_rows": 1, "dense_lambda": 1.0, "dense_pruning_method": "sigmoied_threshold", "distil_alpha_ce": 0.1, "distil_alpha_teacher": 0.9, "distil_teacher_name_or_path": "bert-large-uncased-whole-word-masking-finetuned-squad", "distil_temperature": 2.0, "final_ampere_temperature": 20.0, "final_finetune": false, "final_threshold": 0.1, "final_warmup": 10, "gelu_patch": 0, "initial_ampere_temperature": 0.0, "initial_threshold": 0, "initial_warmup": 1, "layer_norm_patch": 0, "mask_init": "constant", "mask_scale": 0.0, "mask_scores_learning_rate": 0.01, "regularization": "l1", "regularization_final_lambda": 120}, "speed": {"cuda_eval_elapsed_time": 33.17768461608887, "eval_elapsed_time": 40.18306041043252}, "speedup": 1.1632636047982534, "stats": {"layers": {"0": {"linear_attention_nnz": 108638, "linear_attention_total": 2359296, "linear_dense_nnz": 743508, "linear_dense_total": 4718592, "linear_nnz": 852146, "linear_total": 7077888, "nnz": 860873, "total": 7087872}, "1": {"linear_attention_nnz": 171340, "linear_attention_total": 2359296, "linear_dense_nnz": 780119, "linear_dense_total": 4718592, "linear_nnz": 951459, "linear_total": 7077888, "nnz": 960245, "total": 7087872}, "10": {"linear_attention_nnz": 67316, "linear_attention_total": 2359296, "linear_dense_nnz": 69353, "linear_dense_total": 4718592, "linear_nnz": 136669, "linear_total": 7077888, "nnz": 143162, "total": 7087872}, "11": {"linear_attention_nnz": 41497, "linear_attention_total": 2359296, "linear_dense_nnz": 55855, "linear_dense_total": 4718592, "linear_nnz": 97352, "linear_total": 7077888, "nnz": 103286, "total": 7087872}, "2": {"linear_attention_nnz": 221074, "linear_attention_total": 2359296, "linear_dense_nnz": 756625, "linear_dense_total": 4718592, "linear_nnz": 977699, "linear_total": 7077888, "nnz": 986901, "total": 7087872}, "3": {"linear_attention_nnz": 258229, "linear_attention_total": 2359296, "linear_dense_nnz": 705908, "linear_dense_total": 4718592, "linear_nnz": 964137, "linear_total": 7077888, "nnz": 973427, "total": 7087872}, "4": {"linear_attention_nnz": 255136, "linear_attention_total": 2359296, "linear_dense_nnz": 593338, "linear_dense_total": 4718592, "linear_nnz": 848474, "linear_total": 7077888, "nnz": 858037, "total": 7087872}, "5": {"linear_attention_nnz": 179994, "linear_attention_total": 2359296, "linear_dense_nnz": 531061, "linear_dense_total": 4718592, "linear_nnz": 711055, "linear_total": 7077888, "nnz": 720395, "total": 7087872}, "6": {"linear_attention_nnz": 165167, "linear_attention_total": 2359296, "linear_dense_nnz": 406391, "linear_dense_total": 4718592, "linear_nnz": 571558, "linear_total": 7077888, "nnz": 580963, "total": 7087872}, "7": {"linear_attention_nnz": 139907, "linear_attention_total": 2359296, "linear_dense_nnz": 272514, "linear_dense_total": 4718592, "linear_nnz": 412421, "linear_total": 7077888, "nnz": 421032, "total": 7087872}, "8": {"linear_attention_nnz": 113253, "linear_attention_total": 2359296, "linear_dense_nnz": 163778, "linear_dense_total": 4718592, "linear_nnz": 277031, "linear_total": 7077888, "nnz": 285536, "total": 7087872}, "9": {"linear_attention_nnz": 84915, "linear_attention_total": 2359296, "linear_dense_nnz": 71190, "linear_dense_total": 4718592, "linear_nnz": 156105, "linear_total": 7077888, "nnz": 162775, "total": 7087872}}, "linear_nnz": 6956106, "linear_sparsity": 91.81004983407479, "linear_total": 84934656, "nnz": 30895354, "pruned_heads": {"0": [9], "1": [], "10": [1, 2, 4], "11": [8, 11, 5, 7], "2": [8], "3": [2, 4], "4": [], "5": [1], "6": [2, 3], "7": [1, 7], "8": [0], "9": [1, 4, 5, 7, 10]}, "total": 108893186, "total_sparsity": 71.62783537254572}, "training_args": {"_n_gpu": -1, "adafactor": false, "adam_beta1": 0.9, "adam_beta2": 0.999, "adam_epsilon": 1e-08, "dataloader_drop_last": false, "dataloader_num_workers": 0, "dataloader_pin_memory": true, "ddp_find_unused_parameters": null, "debug": false, "deepspeed": null, "disable_tqdm": false, "do_eval": 1, "do_predict": false, "do_train": 1, "eval_accumulation_steps": null, "eval_steps": 5000, "evaluation_strategy": "steps", "fp16": false, "fp16_backend": "auto", "fp16_full_eval": false, "fp16_opt_level": "O1", "gradient_accumulation_steps": 1, "greater_is_better": null, "group_by_length": false, "ignore_data_skip": false, "label_names": null, "label_smoothing_factor": 0.0, "learning_rate": 3e-05, "load_best_model_at_end": false, "local_rank": -1, "logging_dir": "/data_2to/devel_data/nn_pruning/output/squad_test_8_mvp_lt/", "logging_first_step": false, "logging_steps": 250, "logging_strategy": "steps", "lr_scheduler_type": "linear", "max_grad_norm": 1.0, "max_steps": -1, "metric_for_best_model": null, "no_cuda": false, "num_train_epochs": 20, "optimize_model_before_eval": "disabled", "output_dir": "/data_2to/devel_data/nn_pruning/output/squad_test_8_mvp_lt/", "overwrite_output_dir": 1, "past_index": -1, "per_device_eval_batch_size": 8, "per_device_train_batch_size": 16, "per_gpu_eval_batch_size": null, "per_gpu_train_batch_size": null, "prediction_loss_only": false, "remove_unused_columns": true, "report_to": null, "run_name": "/data_2to/devel_data/nn_pruning/output/squad_test_8_mvp_lt/", "save_steps": 5000, "save_strategy": "steps", "save_total_limit": 50, "seed": 17, "sharded_ddp": "", "skip_memory_metrics": false, "tpu_metrics_debug": false, "tpu_num_cores": null, "warmup_ratio": 0.0, "warmup_steps": 5400, "weight_decay": 0.0}}, "f1": 88.11360890595924, "fill_rate": 0.08189950165925208, "speedup": 1.1632636047982534}}
{"speedup": 1.170038217254783, "f1": 87.64967103979136, "meta": {"annotate": "11", "cat_fun_name": "is_improved_mvmt_pruning", "checkpoint": {"config": {"_name_or_path": "bert-base-uncased", "architectures": ["BertForQuestionAnswering"], "attention_probs_dropout_prob": 0.1, "gradient_checkpointing": false, "hidden_act": "gelu", "hidden_dropout_prob": 0.1, "hidden_size": 768, "initializer_range": 0.02, "intermediate_size": 3072, "layer_norm_eps": 1e-12, "max_position_embeddings": 512, "model_type": "bert", "num_attention_heads": 12, "num_hidden_layers": 12, "pad_token_id": 0, "position_embedding_type": "absolute", "type_vocab_size": 2, "vocab_size": 30522}, "eval_metrics": {"exact_match": 79.89593188268685, "f1": 87.64967103979136}, "path": "/data_2to/devel_data/nn_pruning/output/squad_test3/hp_od-output__squad_test3_es-steps_nte20_ls250_est5000_rn-output__squad_test3_dpm-sigmoied_threshold_apme-sigmoied_threshold_abr1_abc1_it0_fw10_r-l1_rfl75_dtnop-csarron__bert-base-uncased-squad-v1/checkpoint-105000", "sparse_args": {"ampere_pruning_method": "disabled", "attention_block_cols": 1, "attention_block_rows": 1, "attention_pruning_method": "sigmoied_threshold", "dense_block_cols": 1, "dense_block_rows": 1, "dense_pruning_method": "sigmoied_threshold", "distil_alpha_ce": 0.1, "distil_alpha_teacher": 0.9, "distil_teacher_name_or_path": "csarron/bert-base-uncased-squad-v1", "distil_temperature": 2.0, "final_ampere_temperature": 20.0, "final_threshold": 0.1, "final_warmup": 10, "initial_ampere_temperature": 0.0, "initial_threshold": 0, "initial_warmup": 1, "mask_init": "constant", "mask_scale": 0.0, "mask_scores_learning_rate": 0.01, "regularization": "l1", "regularization_final_lambda": 75}, "speed": {"cuda_eval_elapsed_time": 32.98558323669434, "eval_elapsed_time": 40.38167083170265}, "speedup": 1.170038217254783, "stats": {"layers": {"0": {"linear_attention_nnz": 56754, "linear_attention_total": 2359296, "linear_dense_nnz": 1054479, "linear_dense_total": 4718592, "linear_nnz": 1111233, "linear_total": 7077888, "nnz": 1121217, "total": 7087872}, "1": {"linear_attention_nnz": 116764, "linear_attention_total": 2359296, "linear_dense_nnz": 1106103, "linear_dense_total": 4718592, "linear_nnz": 1222867, "linear_total": 7077888, "nnz": 1232851, "total": 7087872}, "10": {"linear_attention_nnz": 50915, "linear_attention_total": 2359296, "linear_dense_nnz": 121878, "linear_dense_total": 4718592, "linear_nnz": 172793, "linear_total": 7077888, "nnz": 182777, "total": 7087872}, "11": {"linear_attention_nnz": 28303, "linear_attention_total": 2359296, "linear_dense_nnz": 94314, "linear_dense_total": 4718592, "linear_nnz": 122617, "linear_total": 7077888, "nnz": 132601, "total": 7087872}, "2": {"linear_attention_nnz": 127558, "linear_attention_total": 2359296, "linear_dense_nnz": 1136881, "linear_dense_total": 4718592, "linear_nnz": 1264439, "linear_total": 7077888, "nnz": 1274423, "total": 7087872}, "3": {"linear_attention_nnz": 163709, "linear_attention_total": 2359296, "linear_dense_nnz": 1106395, "linear_dense_total": 4718592, "linear_nnz": 1270104, "linear_total": 7077888, "nnz": 1280088, "total": 7087872}, "4": {"linear_attention_nnz": 158018, "linear_attention_total": 2359296, "linear_dense_nnz": 1044282, "linear_dense_total": 4718592, "linear_nnz": 1202300, "linear_total": 7077888, "nnz": 1212284, "total": 7087872}, "5": {"linear_attention_nnz": 125746, "linear_attention_total": 2359296, "linear_dense_nnz": 1010449, "linear_dense_total": 4718592, "linear_nnz": 1136195, "linear_total": 7077888, "nnz": 1146179, "total": 7087872}, "6": {"linear_attention_nnz": 110023, "linear_attention_total": 2359296, "linear_dense_nnz": 861094, "linear_dense_total": 4718592, "linear_nnz": 971117, "linear_total": 7077888, "nnz": 981101, "total": 7087872}, "7": {"linear_attention_nnz": 113086, "linear_attention_total": 2359296, "linear_dense_nnz": 632989, "linear_dense_total": 4718592, "linear_nnz": 746075, "linear_total": 7077888, "nnz": 756059, "total": 7087872}, "8": {"linear_attention_nnz": 81879, "linear_attention_total": 2359296, "linear_dense_nnz": 407092, "linear_dense_total": 4718592, "linear_nnz": 488971, "linear_total": 7077888, "nnz": 498955, "total": 7087872}, "9": {"linear_attention_nnz": 77365, "linear_attention_total": 2359296, "linear_dense_nnz": 173330, "linear_dense_total": 4718592, "linear_nnz": 250695, "linear_total": 7077888, "nnz": 260679, "total": 7087872}}, "linear_nnz": 9959406, "linear_sparsity": 88.27403739646628, "linear_total": 84934656, "nnz": 33917936, "pruned_heads": {"0": [9], "1": [0, 8], "10": [8, 1, 4], "11": [8, 11, 5, 7], "2": [8, 4, 7], "3": [2, 4, 6], "4": [], "5": [1, 6, 7], "6": [2, 3], "7": [1, 11, 6, 7], "8": [0, 4, 5], "9": [1, 3, 4, 7, 9, 10]}, "total": 108893186, "total_sparsity": 68.85210429971255}, "training_args": {"_n_gpu": -1, "adafactor": false, "adam_beta1": 0.9, "adam_beta2": 0.999, "adam_epsilon": 1e-08, "dataloader_drop_last": false, "dataloader_num_workers": 0, "dataloader_pin_memory": true, "ddp_find_unused_parameters": null, "debug": false, "deepspeed": null, "disable_tqdm": false, "do_eval": 1, "do_predict": false, "do_train": 1, "eval_accumulation_steps": null, "eval_steps": 5000, "evaluation_strategy": "steps", "fp16": false, "fp16_backend": "auto", "fp16_full_eval": false, "fp16_opt_level": "O1", "gradient_accumulation_steps": 1, "greater_is_better": null, "group_by_length": false, "ignore_data_skip": false, "label_names": null, "label_smoothing_factor": 0.0, "learning_rate": 3e-05, "load_best_model_at_end": false, "local_rank": -1, "logging_dir": "output/squad_test3", "logging_first_step": false, "logging_steps": 250, "logging_strategy": "steps", "lr_scheduler_type": "linear", "max_grad_norm": 1.0, "max_steps": -1, "metric_for_best_model": null, "no_cuda": false, "num_train_epochs": 20, "output_dir": "output/squad_test3", "overwrite_output_dir": 1, "past_index": -1, "per_device_eval_batch_size": 8, "per_device_train_batch_size": 16, "per_gpu_eval_batch_size": null, "per_gpu_train_batch_size": null, "prediction_loss_only": false, "remove_unused_columns": true, "report_to": null, "run_name": "output/squad_test3", "save_steps": 5000, "save_strategy": "steps", "save_total_limit": 5, "seed": 17, "sharded_ddp": "", "skip_memory_metrics": false, "tpu_metrics_debug": false, "tpu_num_cores": null, "warmup_ratio": 0.0, "warmup_steps": 5400, "weight_decay": 0.0}}, "f1": 87.64967103979136, "fill_rate": 0.11725962603533713, "speedup": 1.170038217254783}}
{"speedup": 1.2607211638158147, "f1": 87.45347230995543, "meta": {"annotate": "6", "cat_fun_name": "is_improved_mvmt_pruning", "checkpoint": {"config": {"_name_or_path": "bert-base-uncased", "architectures": ["BertForQuestionAnswering"], "attention_probs_dropout_prob": 0.1, "gradient_checkpointing": false, "hidden_act": "gelu", "hidden_dropout_prob": 0.1, "hidden_size": 768, "initializer_range": 0.02, "intermediate_size": 3072, "layer_norm_eps": 1e-12, "max_position_embeddings": 512, "model_type": "bert", "num_attention_heads": 12, "num_hidden_layers": 12, "pad_token_id": 0, "position_embedding_type": "absolute", "type_vocab_size": 2, "vocab_size": 30522}, "eval_metrics": {"exact_match": 80.09460737937559, "f1": 87.45347230995543}, "path": "/data_2to/devel_data/nn_pruning/output/squad_test_8_mvp_lt/hp_od-__data_2to__devel_data__nn_pruning__output__squad_test_8_mvp_lt___es-steps_nte20_ls250_stl50_est5000_rn-__data_2to__devel_data__nn_pruning__output__squad_test_8_mvp_lt___dpm-si--7ebf7572d80fe282/checkpoint-110000", "sparse_args": {"ampere_pruning_method": "disabled", "attention_block_cols": 1, "attention_block_rows": 1, "attention_lambda": 1.0, "attention_output_with_dense": 0, "attention_pruning_method": "sigmoied_threshold", "bias_mask": true, "dense_block_cols": 1, "dense_block_rows": 1, "dense_lambda": 1.0, "dense_pruning_method": "sigmoied_threshold", "distil_alpha_ce": 0.1, "distil_alpha_teacher": 0.9, "distil_teacher_name_or_path": "bert-large-uncased-whole-word-masking-finetuned-squad", "distil_temperature": 2.0, "final_ampere_temperature": 20.0, "final_finetune": false, "final_threshold": 0.1, "final_warmup": 10, "gelu_patch": 0, "initial_ampere_temperature": 0.0, "initial_threshold": 0, "initial_warmup": 1, "layer_norm_patch": 0, "mask_init": "constant", "mask_scale": 0.0, "mask_scores_learning_rate": 0.01, "regularization": "l1", "regularization_final_lambda": 160}, "speed": {"cuda_eval_elapsed_time": 30.61294924926758, "eval_elapsed_time": 37.62639235612005}, "speedup": 1.2607211638158147, "stats": {"layers": {"0": {"linear_attention_nnz": 85933, "linear_attention_total": 2359296, "linear_dense_nnz": 599767, "linear_dense_total": 4718592, "linear_nnz": 685700, "linear_total": 7077888, "nnz": 694282, "total": 7087872}, "1": {"linear_attention_nnz": 146970, "linear_attention_total": 2359296, "linear_dense_nnz": 633851, "linear_dense_total": 4718592, "linear_nnz": 780821, "linear_total": 7077888, "nnz": 789490, "total": 7087872}, "10": {"linear_attention_nnz": 53976, "linear_attention_total": 2359296, "linear_dense_nnz": 51816, "linear_dense_total": 4718592, "linear_nnz": 105792, "linear_total": 7077888, "nnz": 111956, "total": 7087872}, "11": {"linear_attention_nnz": 35246, "linear_attention_total": 2359296, "linear_dense_nnz": 44570, "linear_dense_total": 4718592, "linear_nnz": 79816, "linear_total": 7077888, "nnz": 85561, "total": 7087872}, "2": {"linear_attention_nnz": 185080, "linear_attention_total": 2359296, "linear_dense_nnz": 607798, "linear_dense_total": 4718592, "linear_nnz": 792878, "linear_total": 7077888, "nnz": 802001, "total": 7087872}, "3": {"linear_attention_nnz": 215120, "linear_attention_total": 2359296, "linear_dense_nnz": 555649, "linear_dense_total": 4718592, "linear_nnz": 770769, "linear_total": 7077888, "nnz": 779934, "total": 7087872}, "4": {"linear_attention_nnz": 203907, "linear_attention_total": 2359296, "linear_dense_nnz": 453085, "linear_dense_total": 4718592, "linear_nnz": 656992, "linear_total": 7077888, "nnz": 666424, "total": 7087872}, "5": {"linear_attention_nnz": 135767, "linear_attention_total": 2359296, "linear_dense_nnz": 395091, "linear_dense_total": 4718592, "linear_nnz": 530858, "linear_total": 7077888, "nnz": 539768, "total": 7087872}, "6": {"linear_attention_nnz": 123379, "linear_attention_total": 2359296, "linear_dense_nnz": 299238, "linear_dense_total": 4718592, "linear_nnz": 422617, "linear_total": 7077888, "nnz": 431706, "total": 7087872}, "7": {"linear_attention_nnz": 111774, "linear_attention_total": 2359296, "linear_dense_nnz": 196632, "linear_dense_total": 4718592, "linear_nnz": 308406, "linear_total": 7077888, "nnz": 316679, "total": 7087872}, "8": {"linear_attention_nnz": 84158, "linear_attention_total": 2359296, "linear_dense_nnz": 114682, "linear_dense_total": 4718592, "linear_nnz": 198840, "linear_total": 7077888, "nnz": 206795, "total": 7087872}, "9": {"linear_attention_nnz": 68642, "linear_attention_total": 2359296, "linear_dense_nnz": 52118, "linear_dense_total": 4718592, "linear_nnz": 120760, "linear_total": 7077888, "nnz": 126954, "total": 7087872}}, "linear_nnz": 5454249, "linear_sparsity": 93.5782997696488, "linear_total": 84934656, "nnz": 29390272, "pruned_heads": {"0": [9], "1": [], "10": [1, 2, 4, 5], "11": [5, 7, 8, 10, 11], "2": [8, 4], "3": [2, 4, 6], "4": [], "5": [1, 6, 7], "6": [2, 3], "7": [1, 11, 6, 7], "8": [0, 4], "9": [1, 4, 5, 7, 9, 10]}, "total": 108893186, "total_sparsity": 73.00999899112144}, "training_args": {"_n_gpu": -1, "adafactor": false, "adam_beta1": 0.9, "adam_beta2": 0.999, "adam_epsilon": 1e-08, "dataloader_drop_last": false, "dataloader_num_workers": 0, "dataloader_pin_memory": true, "ddp_find_unused_parameters": null, "debug": false, "deepspeed": null, "disable_tqdm": false, "do_eval": 1, "do_predict": false, "do_train": 1, "eval_accumulation_steps": null, "eval_steps": 5000, "evaluation_strategy": "steps", "fp16": false, "fp16_backend": "auto", "fp16_full_eval": false, "fp16_opt_level": "O1", "gradient_accumulation_steps": 1, "greater_is_better": null, "group_by_length": false, "ignore_data_skip": false, "label_names": null, "label_smoothing_factor": 0.0, "learning_rate": 3e-05, "load_best_model_at_end": false, "local_rank": -1, "logging_dir": "/data_2to/devel_data/nn_pruning/output/squad_test_8_mvp_lt/", "logging_first_step": false, "logging_steps": 250, "logging_strategy": "steps", "lr_scheduler_type": "linear", "max_grad_norm": 1.0, "max_steps": -1, "metric_for_best_model": null, "no_cuda": false, "num_train_epochs": 20, "optimize_model_before_eval": "disabled", "output_dir": "/data_2to/devel_data/nn_pruning/output/squad_test_8_mvp_lt/", "overwrite_output_dir": 1, "past_index": -1, "per_device_eval_batch_size": 8, "per_device_train_batch_size": 16, "per_gpu_eval_batch_size": null, "per_gpu_train_batch_size": null, "prediction_loss_only": false, "remove_unused_columns": true, "report_to": null, "run_name": "/data_2to/devel_data/nn_pruning/output/squad_test_8_mvp_lt/", "save_steps": 5000, "save_strategy": "steps", "save_total_limit": 50, "seed": 17, "sharded_ddp": "", "skip_memory_metrics": false, "tpu_metrics_debug": false, "tpu_num_cores": null, "warmup_ratio": 0.0, "warmup_steps": 5400, "weight_decay": 0.0}}, "f1": 87.45347230995543, "fill_rate": 0.06421700230351202, "speedup": 1.2607211638158147}}
{"speedup": 1.3349999991845345, "f1": 86.50729252303553, "meta": {"annotate": "4", "cat_fun_name": "is_improved_mvmt_pruning", "checkpoint": {"config": {"_name_or_path": "bert-base-uncased", "architectures": ["BertForQuestionAnswering"], "attention_probs_dropout_prob": 0.1, "gradient_checkpointing": false, "hidden_act": "gelu", "hidden_dropout_prob": 0.1, "hidden_size": 768, "initializer_range": 0.02, "intermediate_size": 3072, "layer_norm_eps": 1e-12, "max_position_embeddings": 512, "model_type": "bert", "num_attention_heads": 12, "num_hidden_layers": 12, "pad_token_id": 0, "position_embedding_type": "absolute", "type_vocab_size": 2, "vocab_size": 30522}, "eval_metrics": {"exact_match": 78.42005676442763, "f1": 86.50729252303553}, "path": "/data_2to/devel_data/nn_pruning/output/squad_test_8_mvp_lt/hp_od-__data_2to__devel_data__nn_pruning__output__squad_test_8_mvp_lt___es-steps_nte20_ls250_stl50_est5000_rn-__data_2to__devel_data__nn_pruning__output__squad_test_8_mvp_lt___dpm-sig--51ab88e6fe9e0cb/checkpoint-110000", "sparse_args": {"ampere_pruning_method": "disabled", "attention_block_cols": 1, "attention_block_rows": 1, "attention_lambda": 1.0, "attention_output_with_dense": 0, "attention_pruning_method": "sigmoied_threshold", "bias_mask": true, "dense_block_cols": 1, "dense_block_rows": 1, "dense_lambda": 1.0, "dense_pruning_method": "sigmoied_threshold", "distil_alpha_ce": 0.1, "distil_alpha_teacher": 0.9, "distil_teacher_name_or_path": "bert-large-uncased-whole-word-masking-finetuned-squad", "distil_temperature": 2.0, "final_ampere_temperature": 20.0, "final_finetune": false, "final_threshold": 0.1, "final_warmup": 10, "gelu_patch": 0, "initial_ampere_temperature": 0.0, "initial_threshold": 0, "initial_warmup": 1, "layer_norm_patch": 0, "mask_init": "constant", "mask_scale": 0.0, "mask_scores_learning_rate": 0.01, "regularization": "l1", "regularization_final_lambda": 240}, "speed": {"cuda_eval_elapsed_time": 28.90965769958496, "eval_elapsed_time": 35.917956955730915}, "speedup": 1.3349999991845345, "stats": {"layers": {"0": {"linear_attention_nnz": 59018, "linear_attention_total": 2359296, "linear_dense_nnz": 429594, "linear_dense_total": 4718592, "linear_nnz": 488612, "linear_total": 7077888, "nnz": 496889, "total": 7087872}, "1": {"linear_attention_nnz": 117573, "linear_attention_total": 2359296, "linear_dense_nnz": 452265, "linear_dense_total": 4718592, "linear_nnz": 569838, "linear_total": 7077888, "nnz": 578325, "total": 7087872}, "10": {"linear_attention_nnz": 41874, "linear_attention_total": 2359296, "linear_dense_nnz": 36903, "linear_dense_total": 4718592, "linear_nnz": 78777, "linear_total": 7077888, "nnz": 84672, "total": 7087872}, "11": {"linear_attention_nnz": 27872, "linear_attention_total": 2359296, "linear_dense_nnz": 32456, "linear_dense_total": 4718592, "linear_nnz": 60328, "linear_total": 7077888, "nnz": 65863, "total": 7087872}, "2": {"linear_attention_nnz": 144344, "linear_attention_total": 2359296, "linear_dense_nnz": 429183, "linear_dense_total": 4718592, "linear_nnz": 573527, "linear_total": 7077888, "nnz": 582495, "total": 7087872}, "3": {"linear_attention_nnz": 168864, "linear_attention_total": 2359296, "linear_dense_nnz": 379065, "linear_dense_total": 4718592, "linear_nnz": 547929, "linear_total": 7077888, "nnz": 556868, "total": 7087872}, "4": {"linear_attention_nnz": 140816, "linear_attention_total": 2359296, "linear_dense_nnz": 300856, "linear_dense_total": 4718592, "linear_nnz": 441672, "linear_total": 7077888, "nnz": 450547, "total": 7087872}, "5": {"linear_attention_nnz": 93231, "linear_attention_total": 2359296, "linear_dense_nnz": 250434, "linear_dense_total": 4718592, "linear_nnz": 343665, "linear_total": 7077888, "nnz": 352041, "total": 7087872}, "6": {"linear_attention_nnz": 81345, "linear_attention_total": 2359296, "linear_dense_nnz": 193259, "linear_dense_total": 4718592, "linear_nnz": 274604, "linear_total": 7077888, "nnz": 282887, "total": 7087872}, "7": {"linear_attention_nnz": 83004, "linear_attention_total": 2359296, "linear_dense_nnz": 127052, "linear_dense_total": 4718592, "linear_nnz": 210056, "linear_total": 7077888, "nnz": 217609, "total": 7087872}, "8": {"linear_attention_nnz": 56265, "linear_attention_total": 2359296, "linear_dense_nnz": 72037, "linear_dense_total": 4718592, "linear_nnz": 128302, "linear_total": 7077888, "nnz": 135460, "total": 7087872}, "9": {"linear_attention_nnz": 50559, "linear_attention_total": 2359296, "linear_dense_nnz": 35373, "linear_dense_total": 4718592, "linear_nnz": 85932, "linear_total": 7077888, "nnz": 91704, "total": 7087872}}, "linear_nnz": 3803242, "linear_sparsity": 95.52215529076847, "linear_total": 84934656, "nnz": 27734082, "pruned_heads": {"0": [9], "1": [8, 5], "10": [1, 2, 4, 5, 6, 7], "11": [5, 7, 8, 10, 11], "2": [8, 4, 7], "3": [2, 4, 6], "4": [], "5": [1, 6, 7], "6": [2, 3], "7": [1, 11, 6, 7], "8": [0, 4], "9": [1, 3, 4, 5, 7, 9, 10]}, "total": 108893186, "total_sparsity": 74.53092978655249}, "training_args": {"_n_gpu": -1, "adafactor": false, "adam_beta1": 0.9, "adam_beta2": 0.999, "adam_epsilon": 1e-08, "dataloader_drop_last": false, "dataloader_num_workers": 0, "dataloader_pin_memory": true, "ddp_find_unused_parameters": null, "debug": false, "deepspeed": null, "disable_tqdm": false, "do_eval": 1, "do_predict": false, "do_train": 1, "eval_accumulation_steps": null, "eval_steps": 5000, "evaluation_strategy": "steps", "fp16": false, "fp16_backend": "auto", "fp16_full_eval": false, "fp16_opt_level": "O1", "gradient_accumulation_steps": 1, "greater_is_better": null, "group_by_length": false, "ignore_data_skip": false, "label_names": null, "label_smoothing_factor": 0.0, "learning_rate": 3e-05, "load_best_model_at_end": false, "local_rank": -1, "logging_dir": "/data_2to/devel_data/nn_pruning/output/squad_test_8_mvp_lt/", "logging_first_step": false, "logging_steps": 250, "logging_strategy": "steps", "lr_scheduler_type": "linear", "max_grad_norm": 1.0, "max_steps": -1, "metric_for_best_model": null, "no_cuda": false, "num_train_epochs": 20, "optimize_model_before_eval": "disabled", "output_dir": "/data_2to/devel_data/nn_pruning/output/squad_test_8_mvp_lt/", "overwrite_output_dir": 1, "past_index": -1, "per_device_eval_batch_size": 8, "per_device_train_batch_size": 16, "per_gpu_eval_batch_size": null, "per_gpu_train_batch_size": null, "prediction_loss_only": false, "remove_unused_columns": true, "report_to": null, "run_name": "/data_2to/devel_data/nn_pruning/output/squad_test_8_mvp_lt/", "save_steps": 5000, "save_strategy": "steps", "save_total_limit": 50, "seed": 17, "sharded_ddp": "", "skip_memory_metrics": false, "tpu_metrics_debug": false, "tpu_num_cores": null, "warmup_ratio": 0.0, "warmup_steps": 5400, "weight_decay": 0.0}}, "f1": 86.50729252303553, "fill_rate": 0.04477844709231538, "speedup": 1.3349999991845345}}
{"speedup": 1.3926143255719736, "f1": 85.66626983371626, "meta": {"annotate": "4", "cat_fun_name": "is_improved_mvmt_pruning", "checkpoint": {"config": {"_name_or_path": "bert-base-uncased", "architectures": ["BertForQuestionAnswering"], "attention_probs_dropout_prob": 0.1, "gradient_checkpointing": false, "hidden_act": "gelu", "hidden_dropout_prob": 0.1, "hidden_size": 768, "initializer_range": 0.02, "intermediate_size": 3072, "layer_norm_eps": 1e-12, "max_position_embeddings": 512, "model_type": "bert", "num_attention_heads": 12, "num_hidden_layers": 12, "pad_token_id": 0, "position_embedding_type": "absolute", "type_vocab_size": 2, "vocab_size": 30522}, "eval_metrics": {"exact_match": 77.39829706717124, "f1": 85.66626983371626}, "path": "/data_2to/devel_data/nn_pruning/output/squad_test3/hp_od-output__squad_test3_es-steps_nte20_ls250_est5000_rn-output__squad_test3_dpm-sigmoied_threshold_apme-sigmoied_threshold_abr1_abc1_it0_fw10_r-l1_rfl225_dtnop-csarron__bert-base-uncased-squad-v1/checkpoint-110000", "sparse_args": {"ampere_pruning_method": "disabled", "attention_block_cols": 1, "attention_block_rows": 1, "attention_pruning_method": "sigmoied_threshold", "dense_block_cols": 1, "dense_block_rows": 1, "dense_pruning_method": "sigmoied_threshold", "distil_alpha_ce": 0.1, "distil_alpha_teacher": 0.9, "distil_teacher_name_or_path": "csarron/bert-base-uncased-squad-v1", "distil_temperature": 2.0, "final_ampere_temperature": 20.0, "final_threshold": 0.1, "final_warmup": 10, "initial_ampere_temperature": 0.0, "initial_threshold": 0, "initial_warmup": 1, "mask_init": "constant", "mask_scale": 0.0, "mask_scores_learning_rate": 0.01, "regularization": "l1", "regularization_final_lambda": 225}, "speed": {"cuda_eval_elapsed_time": 27.713626304626466, "eval_elapsed_time": 35.06419681990519}, "speedup": 1.3926143255719736, "stats": {"layers": {"0": {"linear_attention_nnz": 18728, "linear_attention_total": 2359296, "linear_dense_nnz": 446655, "linear_dense_total": 4718592, "linear_nnz": 465383, "linear_total": 7077888, "nnz": 475367, "total": 7087872}, "1": {"linear_attention_nnz": 63059, "linear_attention_total": 2359296, "linear_dense_nnz": 464338, "linear_dense_total": 4718592, "linear_nnz": 527397, "linear_total": 7077888, "nnz": 537381, "total": 7087872}, "10": {"linear_attention_nnz": 21311, "linear_attention_total": 2359296, "linear_dense_nnz": 43332, "linear_dense_total": 4718592, "linear_nnz": 64643, "linear_total": 7077888, "nnz": 74627, "total": 7087872}, "11": {"linear_attention_nnz": 17233, "linear_attention_total": 2359296, "linear_dense_nnz": 36806, "linear_dense_total": 4718592, "linear_nnz": 54039, "linear_total": 7077888, "nnz": 64023, "total": 7087872}, "2": {"linear_attention_nnz": 53761, "linear_attention_total": 2359296, "linear_dense_nnz": 462731, "linear_dense_total": 4718592, "linear_nnz": 516492, "linear_total": 7077888, "nnz": 526476, "total": 7087872}, "3": {"linear_attention_nnz": 84624, "linear_attention_total": 2359296, "linear_dense_nnz": 430348, "linear_dense_total": 4718592, "linear_nnz": 514972, "linear_total": 7077888, "nnz": 524956, "total": 7087872}, "4": {"linear_attention_nnz": 58345, "linear_attention_total": 2359296, "linear_dense_nnz": 384869, "linear_dense_total": 4718592, "linear_nnz": 443214, "linear_total": 7077888, "nnz": 453198, "total": 7087872}, "5": {"linear_attention_nnz": 50615, "linear_attention_total": 2359296, "linear_dense_nnz": 346306, "linear_dense_total": 4718592, "linear_nnz": 396921, "linear_total": 7077888, "nnz": 406905, "total": 7087872}, "6": {"linear_attention_nnz": 41344, "linear_attention_total": 2359296, "linear_dense_nnz": 277660, "linear_dense_total": 4718592, "linear_nnz": 319004, "linear_total": 7077888, "nnz": 328988, "total": 7087872}, "7": {"linear_attention_nnz": 47420, "linear_attention_total": 2359296, "linear_dense_nnz": 201763, "linear_dense_total": 4718592, "linear_nnz": 249183, "linear_total": 7077888, "nnz": 259167, "total": 7087872}, "8": {"linear_attention_nnz": 27562, "linear_attention_total": 2359296, "linear_dense_nnz": 133500, "linear_dense_total": 4718592, "linear_nnz": 161062, "linear_total": 7077888, "nnz": 171046, "total": 7087872}, "9": {"linear_attention_nnz": 34151, "linear_attention_total": 2359296, "linear_dense_nnz": 47554, "linear_dense_total": 4718592, "linear_nnz": 81705, "linear_total": 7077888, "nnz": 91689, "total": 7087872}}, "linear_nnz": 3794015, "linear_sparsity": 95.5330189363456, "linear_total": 84934656, "nnz": 27752545, "pruned_heads": {"0": [9, 2], "1": [8, 2], "10": [1, 2, 4, 5, 6, 8, 9], "11": [5, 7, 8, 10, 11], "2": [1, 4, 7, 8, 11], "3": [2, 4, 6], "4": [6, 7], "5": [1, 5, 6, 7, 11], "6": [0, 10, 2, 3], "7": [1, 3, 6, 7, 11], "8": [0, 2, 4, 5, 6], "9": [1, 3, 4, 5, 7, 9, 10]}, "total": 108893186, "total_sparsity": 74.51397463933142}, "training_args": {"_n_gpu": -1, "adafactor": false, "adam_beta1": 0.9, "adam_beta2": 0.999, "adam_epsilon": 1e-08, "dataloader_drop_last": false, "dataloader_num_workers": 0, "dataloader_pin_memory": true, "ddp_find_unused_parameters": null, "debug": false, "deepspeed": null, "disable_tqdm": false, "do_eval": 1, "do_predict": false, "do_train": 1, "eval_accumulation_steps": null, "eval_steps": 5000, "evaluation_strategy": "steps", "fp16": false, "fp16_backend": "auto", "fp16_full_eval": false, "fp16_opt_level": "O1", "gradient_accumulation_steps": 1, "greater_is_better": null, "group_by_length": false, "ignore_data_skip": false, "label_names": null, "label_smoothing_factor": 0.0, "learning_rate": 3e-05, "load_best_model_at_end": false, "local_rank": -1, "logging_dir": "output/squad_test3", "logging_first_step": false, "logging_steps": 250, "logging_strategy": "steps", "lr_scheduler_type": "linear", "max_grad_norm": 1.0, "max_steps": -1, "metric_for_best_model": null, "no_cuda": false, "num_train_epochs": 20, "optimize_model_before_eval": "disabled", "output_dir": "output/squad_test3", "overwrite_output_dir": 1, "past_index": -1, "per_device_eval_batch_size": 8, "per_device_train_batch_size": 16, "per_gpu_eval_batch_size": null, "per_gpu_train_batch_size": null, "prediction_loss_only": false, "remove_unused_columns": true, "report_to": null, "run_name": "output/squad_test3", "save_steps": 5000, "save_strategy": "steps", "save_total_limit": 5, "seed": 17, "sharded_ddp": "", "skip_memory_metrics": false, "tpu_metrics_debug": false, "tpu_num_cores": null, "warmup_ratio": 0.0, "warmup_steps": 5400, "weight_decay": 0.0}}, "f1": 85.66626983371626, "fill_rate": 0.04466981063654396, "speedup": 1.3926143255719736}}
{"speedup": 1.5170581452285046, "f1": 85.40699359564026, "meta": {"annotate": "3", "cat_fun_name": "is_improved_mvmt_pruning", "checkpoint": {"config": {"_name_or_path": "bert-base-uncased", "architectures": ["BertForQuestionAnswering"], "attention_probs_dropout_prob": 0.1, "gradient_checkpointing": false, "hidden_act": "gelu", "hidden_dropout_prob": 0.1, "hidden_size": 768, "initializer_range": 0.02, "intermediate_size": 3072, "layer_norm_eps": 1e-12, "max_position_embeddings": 512, "model_type": "bert", "num_attention_heads": 12, "num_hidden_layers": 12, "pad_token_id": 0, "position_embedding_type": "absolute", "type_vocab_size": 2, "vocab_size": 30522}, "eval_metrics": {"exact_match": 76.98202459791864, "f1": 85.40699359564026}, "path": "/data_2to/devel_data/nn_pruning/output/squad_test3/hp_od-output__squad_test3_es-steps_nte20_ls250_est5000_rn-output__squad_test3_dpm-sigmoied_threshold_apme-sigmoied_threshold_abr1_abc1_it0_fw10_r-l1_rfl300_dtnop-csarron__bert-base-uncased-squad-v1/checkpoint-110000", "sparse_args": {"ampere_pruning_method": "disabled", "attention_block_cols": 1, "attention_block_rows": 1, "attention_pruning_method": "sigmoied_threshold", "dense_block_cols": 1, "dense_block_rows": 1, "dense_pruning_method": "sigmoied_threshold", "distil_alpha_ce": 0.1, "distil_alpha_teacher": 0.9, "distil_teacher_name_or_path": "csarron/bert-base-uncased-squad-v1", "distil_temperature": 2.0, "final_ampere_temperature": 20.0, "final_threshold": 0.1, "final_warmup": 10, "initial_ampere_temperature": 0.0, "initial_threshold": 0, "initial_warmup": 1, "mask_init": "constant", "mask_scale": 0.0, "mask_scores_learning_rate": 0.01, "regularization": "l1", "regularization_final_lambda": 300}, "speed": {"cuda_eval_elapsed_time": 25.440285942077637, "eval_elapsed_time": 32.748252402991056}, "speedup": 1.5170581452285046, "stats": {"layers": {"0": {"linear_attention_nnz": 13195, "linear_attention_total": 2359296, "linear_dense_nnz": 344662, "linear_dense_total": 4718592, "linear_nnz": 357857, "linear_total": 7077888, "nnz": 367841, "total": 7087872}, "1": {"linear_attention_nnz": 53357, "linear_attention_total": 2359296, "linear_dense_nnz": 352125, "linear_dense_total": 4718592, "linear_nnz": 405482, "linear_total": 7077888, "nnz": 415466, "total": 7087872}, "10": {"linear_attention_nnz": 18747, "linear_attention_total": 2359296, "linear_dense_nnz": 34723, "linear_dense_total": 4718592, "linear_nnz": 53470, "linear_total": 7077888, "nnz": 63454, "total": 7087872}, "11": {"linear_attention_nnz": 15957, "linear_attention_total": 2359296, "linear_dense_nnz": 30412, "linear_dense_total": 4718592, "linear_nnz": 46369, "linear_total": 7077888, "nnz": 56353, "total": 7087872}, "2": {"linear_attention_nnz": 43981, "linear_attention_total": 2359296, "linear_dense_nnz": 351138, "linear_dense_total": 4718592, "linear_nnz": 395119, "linear_total": 7077888, "nnz": 405103, "total": 7087872}, "3": {"linear_attention_nnz": 71058, "linear_attention_total": 2359296, "linear_dense_nnz": 323059, "linear_dense_total": 4718592, "linear_nnz": 394117, "linear_total": 7077888, "nnz": 404101, "total": 7087872}, "4": {"linear_attention_nnz": 47705, "linear_attention_total": 2359296, "linear_dense_nnz": 287668, "linear_dense_total": 4718592, "linear_nnz": 335373, "linear_total": 7077888, "nnz": 345357, "total": 7087872}, "5": {"linear_attention_nnz": 40348, "linear_attention_total": 2359296, "linear_dense_nnz": 252178, "linear_dense_total": 4718592, "linear_nnz": 292526, "linear_total": 7077888, "nnz": 302510, "total": 7087872}, "6": {"linear_attention_nnz": 33002, "linear_attention_total": 2359296, "linear_dense_nnz": 205112, "linear_dense_total": 4718592, "linear_nnz": 238114, "linear_total": 7077888, "nnz": 248098, "total": 7087872}, "7": {"linear_attention_nnz": 38753, "linear_attention_total": 2359296, "linear_dense_nnz": 150138, "linear_dense_total": 4718592, "linear_nnz": 188891, "linear_total": 7077888, "nnz": 198875, "total": 7087872}, "8": {"linear_attention_nnz": 22052, "linear_attention_total": 2359296, "linear_dense_nnz": 101313, "linear_dense_total": 4718592, "linear_nnz": 123365, "linear_total": 7077888, "nnz": 133349, "total": 7087872}, "9": {"linear_attention_nnz": 28498, "linear_attention_total": 2359296, "linear_dense_nnz": 35917, "linear_dense_total": 4718592, "linear_nnz": 64415, "linear_total": 7077888, "nnz": 74399, "total": 7087872}}, "linear_nnz": 2895098, "linear_sparsity": 96.59138196780358, "linear_total": 84934656, "nnz": 26853628, "pruned_heads": {"0": [9, 2], "1": [0, 8, 2, 6], "10": [1, 2, 4, 5, 6, 8, 9], "11": [5, 7, 8, 10, 11], "2": [1, 4, 7, 8, 11], "3": [2, 4, 6], "4": [0, 11, 6, 7], "5": [1, 2, 5, 6, 7, 11], "6": [0, 10, 2, 3], "7": [1, 3, 6, 7, 11], "8": [0, 2, 4, 5, 6, 8], "9": [1, 3, 4, 5, 7, 9, 10]}, "total": 108893186, "total_sparsity": 75.33947808267818}, "training_args": {"_n_gpu": -1, "adafactor": false, "adam_beta1": 0.9, "adam_beta2": 0.999, "adam_epsilon": 1e-08, "dataloader_drop_last": false, "dataloader_num_workers": 0, "dataloader_pin_memory": true, "ddp_find_unused_parameters": null, "debug": false, "deepspeed": null, "disable_tqdm": false, "do_eval": 1, "do_predict": false, "do_train": 1, "eval_accumulation_steps": null, "eval_steps": 5000, "evaluation_strategy": "steps", "fp16": false, "fp16_backend": "auto", "fp16_full_eval": false, "fp16_opt_level": "O1", "gradient_accumulation_steps": 1, "greater_is_better": null, "group_by_length": false, "ignore_data_skip": false, "label_names": null, "label_smoothing_factor": 0.0, "learning_rate": 3e-05, "load_best_model_at_end": false, "local_rank": -1, "logging_dir": "output/squad_test3", "logging_first_step": false, "logging_steps": 250, "logging_strategy": "steps", "lr_scheduler_type": "linear", "max_grad_norm": 1.0, "max_steps": -1, "metric_for_best_model": null, "no_cuda": false, "num_train_epochs": 20, "optimize_model_before_eval": "disabled", "output_dir": "output/squad_test3", "overwrite_output_dir": 1, "past_index": -1, "per_device_eval_batch_size": 8, "per_device_train_batch_size": 16, "per_gpu_eval_batch_size": null, "per_gpu_train_batch_size": null, "prediction_loss_only": false, "remove_unused_columns": true, "report_to": null, "run_name": "output/squad_test3", "save_steps": 5000, "save_strategy": "steps", "save_total_limit": 5, "seed": 17, "sharded_ddp": "", "skip_memory_metrics": false, "tpu_metrics_debug": false, "tpu_num_cores": null, "warmup_ratio": 0.0, "warmup_steps": 5400, "weight_decay": 0.0}}, "f1": 85.40699359564026, "fill_rate": 0.0340861803219642, "speedup": 1.5170581452285046}}
