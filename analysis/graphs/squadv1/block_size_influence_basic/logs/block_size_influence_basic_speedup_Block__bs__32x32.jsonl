{"speedup": 1.559464313363606, "f1": 87.36378709007766, "meta": {"annotate": "38", "cat_fun_name": "is_full_block", "checkpoint": {"config": {"_name_or_path": "bert-base-uncased", "architectures": ["BertForQuestionAnswering"], "attention_probs_dropout_prob": 0.1, "gradient_checkpointing": false, "hidden_act": "gelu", "hidden_dropout_prob": 0.1, "hidden_size": 768, "initializer_range": 0.02, "intermediate_size": 3072, "layer_norm_eps": 1e-12, "max_position_embeddings": 512, "model_type": "bert", "num_attention_heads": 12, "num_hidden_layers": 12, "pad_token_id": 0, "position_embedding_type": "absolute", "type_vocab_size": 2, "vocab_size": 30522}, "eval_metrics": {"exact_match": 79.90539262062441, "f1": 87.36378709007766}, "path": "/data_2to/devel_data/nn_pruning/output/squad_test3/hp_od-output__squad_test3_es-steps_nte20_ls250_stl50_est5000_rn-output__squad_test3_dpm-sigmoied_threshold_apme-sigmoied_threshold_aowd0_bm1_dbr32_dbc32_abr32_abc32_it0_fw10_r-l1_rfl10_dtnop-csarron__bert-base-uncased-squad-v1/checkpoint-90000", "sparse_args": {"ampere_pruning_method": "disabled", "attention_block_cols": 32, "attention_block_rows": 32, "attention_lambda": 1.0, "attention_output_with_dense": 0, "attention_pruning_method": "sigmoied_threshold", "bias_mask": true, "dense_block_cols": 32, "dense_block_rows": 32, "dense_lambda": 1.0, "dense_pruning_method": "sigmoied_threshold", "distil_alpha_ce": 0.1, "distil_alpha_teacher": 0.9, "distil_teacher_name_or_path": "csarron/bert-base-uncased-squad-v1", "distil_temperature": 2.0, "final_ampere_temperature": 20.0, "final_threshold": 0.1, "final_warmup": 10, "initial_ampere_temperature": 0.0, "initial_threshold": 0, "initial_warmup": 1, "mask_init": "constant", "mask_scale": 0.0, "mask_scores_learning_rate": 0.01, "regularization": "l1", "regularization_final_lambda": 10}, "speed": {"cuda_eval_elapsed_time": 24.748493873596193, "eval_elapsed_time": 32.03074289299548}, "speedup": 1.559464313363606, "stats": {"layers": {"0": {"linear_attention_nnz": 949248, "linear_attention_total": 2359296, "linear_dense_nnz": 1635328, "linear_dense_total": 4718592, "linear_nnz": 2584576, "linear_total": 7077888, "nnz": 2591936, "total": 7087872}, "1": {"linear_attention_nnz": 750592, "linear_attention_total": 2359296, "linear_dense_nnz": 2048000, "linear_dense_total": 4718592, "linear_nnz": 2798592, "linear_total": 7077888, "nnz": 2805952, "total": 7087872}, "10": {"linear_attention_nnz": 509952, "linear_attention_total": 2359296, "linear_dense_nnz": 352256, "linear_dense_total": 4718592, "linear_nnz": 862208, "linear_total": 7077888, "nnz": 868096, "total": 7087872}, "11": {"linear_attention_nnz": 363520, "linear_attention_total": 2359296, "linear_dense_nnz": 420864, "linear_dense_total": 4718592, "linear_nnz": 784384, "linear_total": 7077888, "nnz": 790208, "total": 7087872}, "2": {"linear_attention_nnz": 1123328, "linear_attention_total": 2359296, "linear_dense_nnz": 2895872, "linear_dense_total": 4718592, "linear_nnz": 4019200, "linear_total": 7077888, "nnz": 4027808, "total": 7087872}, "3": {"linear_attention_nnz": 1306624, "linear_attention_total": 2359296, "linear_dense_nnz": 2967552, "linear_dense_total": 4718592, "linear_nnz": 4274176, "linear_total": 7077888, "nnz": 4282976, "total": 7087872}, "4": {"linear_attention_nnz": 1475584, "linear_attention_total": 2359296, "linear_dense_nnz": 3105792, "linear_dense_total": 4718592, "linear_nnz": 4581376, "linear_total": 7077888, "nnz": 4590592, "total": 7087872}, "5": {"linear_attention_nnz": 1285120, "linear_attention_total": 2359296, "linear_dense_nnz": 2934784, "linear_dense_total": 4718592, "linear_nnz": 4219904, "linear_total": 7077888, "nnz": 4229024, "total": 7087872}, "6": {"linear_attention_nnz": 1235968, "linear_attention_total": 2359296, "linear_dense_nnz": 2500608, "linear_dense_total": 4718592, "linear_nnz": 3736576, "linear_total": 7077888, "nnz": 3745056, "total": 7087872}, "7": {"linear_attention_nnz": 983040, "linear_attention_total": 2359296, "linear_dense_nnz": 1604608, "linear_dense_total": 4718592, "linear_nnz": 2587648, "linear_total": 7077888, "nnz": 2594944, "total": 7087872}, "8": {"linear_attention_nnz": 965632, "linear_attention_total": 2359296, "linear_dense_nnz": 661504, "linear_dense_total": 4718592, "linear_nnz": 1627136, "linear_total": 7077888, "nnz": 1633888, "total": 7087872}, "9": {"linear_attention_nnz": 650240, "linear_attention_total": 2359296, "linear_dense_nnz": 230400, "linear_dense_total": 4718592, "linear_nnz": 880640, "linear_total": 7077888, "nnz": 886432, "total": 7087872}}, "linear_nnz": 32956416, "linear_sparsity": 61.19791666666667, "linear_total": 84934656, "nnz": 56885634, "pruned_heads": {"0": [0, 2, 4, 5, 6, 7], "1": [0, 2, 3, 5, 6, 7, 8], "10": [1, 4, 5, 6, 7, 8], "11": [0, 2, 5, 7, 8, 11], "2": [8, 4, 7], "3": [2, 4, 6], "4": [1, 2], "5": [1, 2, 6], "6": [2, 3, 7], "7": [1, 3, 6, 7, 11], "8": [0, 8, 3, 4], "9": [1, 4, 5, 7, 9, 10]}, "total": 108893186, "total_sparsity": 47.76015277944021}, "training_args": {"_n_gpu": -1, "adafactor": false, "adam_beta1": 0.9, "adam_beta2": 0.999, "adam_epsilon": 1e-08, "dataloader_drop_last": false, "dataloader_num_workers": 0, "dataloader_pin_memory": true, "ddp_find_unused_parameters": null, "debug": false, "deepspeed": null, "disable_tqdm": false, "do_eval": 1, "do_predict": false, "do_train": 1, "eval_accumulation_steps": null, "eval_steps": 5000, "evaluation_strategy": "steps", "fp16": false, "fp16_backend": "auto", "fp16_full_eval": false, "fp16_opt_level": "O1", "gradient_accumulation_steps": 1, "greater_is_better": null, "group_by_length": false, "ignore_data_skip": false, "label_names": null, "label_smoothing_factor": 0.0, "learning_rate": 3e-05, "load_best_model_at_end": false, "local_rank": -1, "logging_dir": "output/squad_test3", "logging_first_step": false, "logging_steps": 250, "logging_strategy": "steps", "lr_scheduler_type": "linear", "max_grad_norm": 1.0, "max_steps": -1, "metric_for_best_model": null, "no_cuda": false, "num_train_epochs": 20, "optimize_model_before_eval": "disabled", "output_dir": "output/squad_test3", "overwrite_output_dir": 1, "past_index": -1, "per_device_eval_batch_size": 8, "per_device_train_batch_size": 16, "per_gpu_eval_batch_size": null, "per_gpu_train_batch_size": null, "prediction_loss_only": false, "remove_unused_columns": true, "report_to": null, "run_name": "output/squad_test3", "save_steps": 5000, "save_strategy": "steps", "save_total_limit": 50, "seed": 17, "sharded_ddp": "", "skip_memory_metrics": false, "tpu_metrics_debug": false, "tpu_num_cores": null, "warmup_ratio": 0.0, "warmup_steps": 5400, "weight_decay": 0.0}}, "f1": 87.36378709007766, "fill_rate": 0.38802083333333326, "speedup": 1.559464313363606}}
{"speedup": 1.599770932365684, "f1": 87.30735739624531, "meta": {"annotate": "37", "cat_fun_name": "is_full_block", "checkpoint": {"config": {"_name_or_path": "bert-base-uncased", "architectures": ["BertForQuestionAnswering"], "attention_probs_dropout_prob": 0.1, "gradient_checkpointing": false, "hidden_act": "gelu", "hidden_dropout_prob": 0.1, "hidden_size": 768, "initializer_range": 0.02, "intermediate_size": 3072, "layer_norm_eps": 1e-12, "max_position_embeddings": 512, "model_type": "bert", "num_attention_heads": 12, "num_hidden_layers": 12, "pad_token_id": 0, "position_embedding_type": "absolute", "type_vocab_size": 2, "vocab_size": 30522}, "eval_metrics": {"exact_match": 79.82024597918638, "f1": 87.30735739624531}, "path": "/data_2to/devel_data/nn_pruning/output/squad_test3/hp_od-output__squad_test3_es-steps_nte20_ls250_stl50_est5000_rn-output__squad_test3_dpm-sigmoied_threshold_apme-sigmoied_threshold_aowd0_bm1_dbr32_dbc32_abr32_abc32_it0_fw10_r-l1_rfl10_dtnop-csarron__bert-base-uncased-squad-v1/checkpoint-110000", "sparse_args": {"ampere_pruning_method": "disabled", "attention_block_cols": 32, "attention_block_rows": 32, "attention_lambda": 1.0, "attention_output_with_dense": 0, "attention_pruning_method": "sigmoied_threshold", "bias_mask": true, "dense_block_cols": 32, "dense_block_rows": 32, "dense_lambda": 1.0, "dense_pruning_method": "sigmoied_threshold", "distil_alpha_ce": 0.1, "distil_alpha_teacher": 0.9, "distil_teacher_name_or_path": "csarron/bert-base-uncased-squad-v1", "distil_temperature": 2.0, "final_ampere_temperature": 20.0, "final_threshold": 0.1, "final_warmup": 10, "initial_ampere_temperature": 0.0, "initial_threshold": 0, "initial_warmup": 1, "mask_init": "constant", "mask_scale": 0.0, "mask_scores_learning_rate": 0.01, "regularization": "l1", "regularization_final_lambda": 10}, "speed": {"cuda_eval_elapsed_time": 24.124949531555178, "eval_elapsed_time": 31.406295038294047}, "speedup": 1.599770932365684, "stats": {"layers": {"0": {"linear_attention_nnz": 889856, "linear_attention_total": 2359296, "linear_dense_nnz": 1492992, "linear_dense_total": 4718592, "linear_nnz": 2382848, "linear_total": 7077888, "nnz": 2390080, "total": 7087872}, "1": {"linear_attention_nnz": 717824, "linear_attention_total": 2359296, "linear_dense_nnz": 1850368, "linear_dense_total": 4718592, "linear_nnz": 2568192, "linear_total": 7077888, "nnz": 2575360, "total": 7087872}, "10": {"linear_attention_nnz": 489472, "linear_attention_total": 2359296, "linear_dense_nnz": 328704, "linear_dense_total": 4718592, "linear_nnz": 818176, "linear_total": 7077888, "nnz": 824096, "total": 7087872}, "11": {"linear_attention_nnz": 331776, "linear_attention_total": 2359296, "linear_dense_nnz": 388096, "linear_dense_total": 4718592, "linear_nnz": 719872, "linear_total": 7077888, "nnz": 725696, "total": 7087872}, "2": {"linear_attention_nnz": 1113088, "linear_attention_total": 2359296, "linear_dense_nnz": 2802688, "linear_dense_total": 4718592, "linear_nnz": 3915776, "linear_total": 7077888, "nnz": 3924128, "total": 7087872}, "3": {"linear_attention_nnz": 1297408, "linear_attention_total": 2359296, "linear_dense_nnz": 2961408, "linear_dense_total": 4718592, "linear_nnz": 4258816, "linear_total": 7077888, "nnz": 4267520, "total": 7087872}, "4": {"linear_attention_nnz": 1402880, "linear_attention_total": 2359296, "linear_dense_nnz": 2897920, "linear_dense_total": 4718592, "linear_nnz": 4300800, "linear_total": 7077888, "nnz": 4309792, "total": 7087872}, "5": {"linear_attention_nnz": 1157120, "linear_attention_total": 2359296, "linear_dense_nnz": 2873344, "linear_dense_total": 4718592, "linear_nnz": 4030464, "linear_total": 7077888, "nnz": 4039136, "total": 7087872}, "6": {"linear_attention_nnz": 1187840, "linear_attention_total": 2359296, "linear_dense_nnz": 2473984, "linear_dense_total": 4718592, "linear_nnz": 3661824, "linear_total": 7077888, "nnz": 3670208, "total": 7087872}, "7": {"linear_attention_nnz": 979968, "linear_attention_total": 2359296, "linear_dense_nnz": 1527808, "linear_dense_total": 4718592, "linear_nnz": 2507776, "linear_total": 7077888, "nnz": 2514976, "total": 7087872}, "8": {"linear_attention_nnz": 952320, "linear_attention_total": 2359296, "linear_dense_nnz": 610304, "linear_dense_total": 4718592, "linear_nnz": 1562624, "linear_total": 7077888, "nnz": 1569312, "total": 7087872}, "9": {"linear_attention_nnz": 642048, "linear_attention_total": 2359296, "linear_dense_nnz": 223232, "linear_dense_total": 4718592, "linear_nnz": 865280, "linear_total": 7077888, "nnz": 871008, "total": 7087872}}, "linear_nnz": 31592448, "linear_sparsity": 62.80381944444444, "linear_total": 84934656, "nnz": 55520034, "pruned_heads": {"0": [0, 2, 4, 5, 6, 7], "1": [0, 2, 3, 5, 6, 7, 8], "10": [1, 4, 5, 6, 7, 8], "11": [0, 2, 5, 7, 8, 11], "2": [8, 4, 7], "3": [2, 4, 6], "4": [1, 2], "5": [1, 2, 6, 7], "6": [2, 3, 7], "7": [1, 3, 6, 7, 11], "8": [0, 8, 3, 4], "9": [1, 4, 5, 7, 9, 10]}, "total": 108893186, "total_sparsity": 49.0142257386059}, "training_args": {"_n_gpu": -1, "adafactor": false, "adam_beta1": 0.9, "adam_beta2": 0.999, "adam_epsilon": 1e-08, "dataloader_drop_last": false, "dataloader_num_workers": 0, "dataloader_pin_memory": true, "ddp_find_unused_parameters": null, "debug": false, "deepspeed": null, "disable_tqdm": false, "do_eval": 1, "do_predict": false, "do_train": 1, "eval_accumulation_steps": null, "eval_steps": 5000, "evaluation_strategy": "steps", "fp16": false, "fp16_backend": "auto", "fp16_full_eval": false, "fp16_opt_level": "O1", "gradient_accumulation_steps": 1, "greater_is_better": null, "group_by_length": false, "ignore_data_skip": false, "label_names": null, "label_smoothing_factor": 0.0, "learning_rate": 3e-05, "load_best_model_at_end": false, "local_rank": -1, "logging_dir": "output/squad_test3", "logging_first_step": false, "logging_steps": 250, "logging_strategy": "steps", "lr_scheduler_type": "linear", "max_grad_norm": 1.0, "max_steps": -1, "metric_for_best_model": null, "no_cuda": false, "num_train_epochs": 20, "optimize_model_before_eval": "disabled", "output_dir": "output/squad_test3", "overwrite_output_dir": 1, "past_index": -1, "per_device_eval_batch_size": 8, "per_device_train_batch_size": 16, "per_gpu_eval_batch_size": null, "per_gpu_train_batch_size": null, "prediction_loss_only": false, "remove_unused_columns": true, "report_to": null, "run_name": "output/squad_test3", "save_steps": 5000, "save_strategy": "steps", "save_total_limit": 50, "seed": 17, "sharded_ddp": "", "skip_memory_metrics": false, "tpu_metrics_debug": false, "tpu_num_cores": null, "warmup_ratio": 0.0, "warmup_steps": 5400, "weight_decay": 0.0}}, "f1": 87.30735739624531, "fill_rate": 0.3719618055555556, "speedup": 1.599770932365684}}
{"speedup": 1.9655458674518098, "f1": 85.97854187426412, "meta": {"annotate": "25", "cat_fun_name": "is_full_block", "checkpoint": {"config": {"_name_or_path": "bert-base-uncased", "architectures": ["BertForQuestionAnswering"], "attention_probs_dropout_prob": 0.1, "gradient_checkpointing": false, "hidden_act": "gelu", "hidden_dropout_prob": 0.1, "hidden_size": 768, "initializer_range": 0.02, "intermediate_size": 3072, "layer_norm_eps": 1e-12, "max_position_embeddings": 512, "model_type": "bert", "num_attention_heads": 12, "num_hidden_layers": 12, "pad_token_id": 0, "position_embedding_type": "absolute", "type_vocab_size": 2, "vocab_size": 30522}, "eval_metrics": {"exact_match": 77.92809839167455, "f1": 85.97854187426412}, "path": "/data_2to/devel_data/nn_pruning/output/squad_test3/hp_od-output__squad_test3_es-steps_nte20_ls250_stl50_est5000_rn-output__squad_test3_dpm-sigmoied_threshold_apme-sigmoied_threshold_aowd0_bm1_dbr32_dbc32_abr32_abc32_it0_fw10_r-l1_rfl20_dtnop-csarron__bert-base-uncased-squad-v1/checkpoint-90000", "sparse_args": {"ampere_pruning_method": "disabled", "attention_block_cols": 32, "attention_block_rows": 32, "attention_lambda": 1.0, "attention_output_with_dense": 0, "attention_pruning_method": "sigmoied_threshold", "bias_mask": true, "dense_block_cols": 32, "dense_block_rows": 32, "dense_lambda": 1.0, "dense_pruning_method": "sigmoied_threshold", "distil_alpha_ce": 0.1, "distil_alpha_teacher": 0.9, "distil_teacher_name_or_path": "csarron/bert-base-uncased-squad-v1", "distil_temperature": 2.0, "final_ampere_temperature": 20.0, "final_threshold": 0.1, "final_warmup": 10, "initial_ampere_temperature": 0.0, "initial_threshold": 0, "initial_warmup": 1, "mask_init": "constant", "mask_scale": 0.0, "mask_scores_learning_rate": 0.01, "regularization": "l1", "regularization_final_lambda": 20}, "speed": {"cuda_eval_elapsed_time": 19.635457836151122, "eval_elapsed_time": 26.92565976222977}, "speedup": 1.9655458674518098, "stats": {"layers": {"0": {"linear_attention_nnz": 679936, "linear_attention_total": 2359296, "linear_dense_nnz": 869376, "linear_dense_total": 4718592, "linear_nnz": 1549312, "linear_total": 7077888, "nnz": 1555808, "total": 7087872}, "1": {"linear_attention_nnz": 599040, "linear_attention_total": 2359296, "linear_dense_nnz": 1269760, "linear_dense_total": 4718592, "linear_nnz": 1868800, "linear_total": 7077888, "nnz": 1875328, "total": 7087872}, "10": {"linear_attention_nnz": 379904, "linear_attention_total": 2359296, "linear_dense_nnz": 282624, "linear_dense_total": 4718592, "linear_nnz": 662528, "linear_total": 7077888, "nnz": 668000, "total": 7087872}, "11": {"linear_attention_nnz": 258048, "linear_attention_total": 2359296, "linear_dense_nnz": 290816, "linear_dense_total": 4718592, "linear_nnz": 548864, "linear_total": 7077888, "nnz": 554208, "total": 7087872}, "2": {"linear_attention_nnz": 875520, "linear_attention_total": 2359296, "linear_dense_nnz": 1863680, "linear_dense_total": 4718592, "linear_nnz": 2739200, "linear_total": 7077888, "nnz": 2746656, "total": 7087872}, "3": {"linear_attention_nnz": 1137664, "linear_attention_total": 2359296, "linear_dense_nnz": 1950720, "linear_dense_total": 4718592, "linear_nnz": 3088384, "linear_total": 7077888, "nnz": 3096256, "total": 7087872}, "4": {"linear_attention_nnz": 1033216, "linear_attention_total": 2359296, "linear_dense_nnz": 1787904, "linear_dense_total": 4718592, "linear_nnz": 2821120, "linear_total": 7077888, "nnz": 2828864, "total": 7087872}, "5": {"linear_attention_nnz": 850944, "linear_attention_total": 2359296, "linear_dense_nnz": 1858560, "linear_dense_total": 4718592, "linear_nnz": 2709504, "linear_total": 7077888, "nnz": 2717024, "total": 7087872}, "6": {"linear_attention_nnz": 798720, "linear_attention_total": 2359296, "linear_dense_nnz": 1426432, "linear_dense_total": 4718592, "linear_nnz": 2225152, "linear_total": 7077888, "nnz": 2232160, "total": 7087872}, "7": {"linear_attention_nnz": 878592, "linear_attention_total": 2359296, "linear_dense_nnz": 987136, "linear_dense_total": 4718592, "linear_nnz": 1865728, "linear_total": 7077888, "nnz": 1872352, "total": 7087872}, "8": {"linear_attention_nnz": 782336, "linear_attention_total": 2359296, "linear_dense_nnz": 267264, "linear_dense_total": 4718592, "linear_nnz": 1049600, "linear_total": 7077888, "nnz": 1055808, "total": 7087872}, "9": {"linear_attention_nnz": 504832, "linear_attention_total": 2359296, "linear_dense_nnz": 144384, "linear_dense_total": 4718592, "linear_nnz": 649216, "linear_total": 7077888, "nnz": 654528, "total": 7087872}}, "linear_nnz": 21777408, "linear_sparsity": 74.35980902777779, "linear_total": 84934656, "nnz": 45695714, "pruned_heads": {"0": [0, 2, 4, 5, 6, 7], "1": [0, 2, 3, 5, 6, 7, 8, 9], "10": [1, 4, 5, 6, 7, 8], "11": [0, 2, 5, 6, 7, 8, 10, 11], "2": [2, 4, 7, 8, 11], "3": [2, 4, 6, 7], "4": [0, 1, 2, 11], "5": [1, 2, 5, 6, 7, 11], "6": [0, 2, 3, 4, 7], "7": [1, 3, 6, 7, 11], "8": [0, 8, 3, 4], "9": [1, 4, 5, 7, 9, 10]}, "total": 108893186, "total_sparsity": 58.036204395746125}, "training_args": {"_n_gpu": -1, "adafactor": false, "adam_beta1": 0.9, "adam_beta2": 0.999, "adam_epsilon": 1e-08, "dataloader_drop_last": false, "dataloader_num_workers": 0, "dataloader_pin_memory": true, "ddp_find_unused_parameters": null, "debug": false, "deepspeed": null, "disable_tqdm": false, "do_eval": 1, "do_predict": false, "do_train": 1, "eval_accumulation_steps": null, "eval_steps": 5000, "evaluation_strategy": "steps", "fp16": false, "fp16_backend": "auto", "fp16_full_eval": false, "fp16_opt_level": "O1", "gradient_accumulation_steps": 1, "greater_is_better": null, "group_by_length": false, "ignore_data_skip": false, "label_names": null, "label_smoothing_factor": 0.0, "learning_rate": 3e-05, "load_best_model_at_end": false, "local_rank": -1, "logging_dir": "output/squad_test3", "logging_first_step": false, "logging_steps": 250, "logging_strategy": "steps", "lr_scheduler_type": "linear", "max_grad_norm": 1.0, "max_steps": -1, "metric_for_best_model": null, "no_cuda": false, "num_train_epochs": 20, "optimize_model_before_eval": "disabled", "output_dir": "output/squad_test3", "overwrite_output_dir": 1, "past_index": -1, "per_device_eval_batch_size": 8, "per_device_train_batch_size": 16, "per_gpu_eval_batch_size": null, "per_gpu_train_batch_size": null, "prediction_loss_only": false, "remove_unused_columns": true, "report_to": null, "run_name": "output/squad_test3", "save_steps": 5000, "save_strategy": "steps", "save_total_limit": 50, "seed": 17, "sharded_ddp": "", "skip_memory_metrics": false, "tpu_metrics_debug": false, "tpu_num_cores": null, "warmup_ratio": 0.0, "warmup_steps": 5400, "weight_decay": 0.0}}, "f1": 85.97854187426412, "fill_rate": 0.2564019097222221, "speedup": 1.9655458674518098}}
{"speedup": 2.0054680821187447, "f1": 85.84893170709621, "meta": {"annotate": "24", "cat_fun_name": "is_full_block", "checkpoint": {"config": {"_name_or_path": "bert-base-uncased", "architectures": ["BertForQuestionAnswering"], "attention_probs_dropout_prob": 0.1, "gradient_checkpointing": false, "hidden_act": "gelu", "hidden_dropout_prob": 0.1, "hidden_size": 768, "initializer_range": 0.02, "intermediate_size": 3072, "layer_norm_eps": 1e-12, "max_position_embeddings": 512, "model_type": "bert", "num_attention_heads": 12, "num_hidden_layers": 12, "pad_token_id": 0, "position_embedding_type": "absolute", "type_vocab_size": 2, "vocab_size": 30522}, "eval_metrics": {"exact_match": 77.8713339640492, "f1": 85.84893170709621}, "path": "/data_2to/devel_data/nn_pruning/output/squad_test3/hp_od-output__squad_test3_es-steps_nte20_ls250_stl50_est5000_rn-output__squad_test3_dpm-sigmoied_threshold_apme-sigmoied_threshold_aowd0_bm1_dbr32_dbc32_abr32_abc32_it0_fw10_r-l1_rfl20_dtnop-csarron__bert-base-uncased-squad-v1/checkpoint-110000", "sparse_args": {"ampere_pruning_method": "disabled", "attention_block_cols": 32, "attention_block_rows": 32, "attention_lambda": 1.0, "attention_output_with_dense": 0, "attention_pruning_method": "sigmoied_threshold", "bias_mask": true, "dense_block_cols": 32, "dense_block_rows": 32, "dense_lambda": 1.0, "dense_pruning_method": "sigmoied_threshold", "distil_alpha_ce": 0.1, "distil_alpha_teacher": 0.9, "distil_teacher_name_or_path": "csarron/bert-base-uncased-squad-v1", "distil_temperature": 2.0, "final_ampere_temperature": 20.0, "final_threshold": 0.1, "final_warmup": 10, "initial_ampere_temperature": 0.0, "initial_threshold": 0, "initial_warmup": 1, "mask_init": "constant", "mask_scale": 0.0, "mask_scores_learning_rate": 0.01, "regularization": "l1", "regularization_final_lambda": 20}, "speed": {"cuda_eval_elapsed_time": 19.24458102798462, "eval_elapsed_time": 26.45731420116499}, "speedup": 2.0054680821187447, "stats": {"layers": {"0": {"linear_attention_nnz": 647168, "linear_attention_total": 2359296, "linear_dense_nnz": 789504, "linear_dense_total": 4718592, "linear_nnz": 1436672, "linear_total": 7077888, "nnz": 1443040, "total": 7087872}, "1": {"linear_attention_nnz": 591872, "linear_attention_total": 2359296, "linear_dense_nnz": 1206272, "linear_dense_total": 4718592, "linear_nnz": 1798144, "linear_total": 7077888, "nnz": 1804608, "total": 7087872}, "10": {"linear_attention_nnz": 359424, "linear_attention_total": 2359296, "linear_dense_nnz": 263168, "linear_dense_total": 4718592, "linear_nnz": 622592, "linear_total": 7077888, "nnz": 628000, "total": 7087872}, "11": {"linear_attention_nnz": 240640, "linear_attention_total": 2359296, "linear_dense_nnz": 271360, "linear_dense_total": 4718592, "linear_nnz": 512000, "linear_total": 7077888, "nnz": 517312, "total": 7087872}, "2": {"linear_attention_nnz": 843776, "linear_attention_total": 2359296, "linear_dense_nnz": 1739776, "linear_dense_total": 4718592, "linear_nnz": 2583552, "linear_total": 7077888, "nnz": 2590848, "total": 7087872}, "3": {"linear_attention_nnz": 1118208, "linear_attention_total": 2359296, "linear_dense_nnz": 1857536, "linear_dense_total": 4718592, "linear_nnz": 2975744, "linear_total": 7077888, "nnz": 2983488, "total": 7087872}, "4": {"linear_attention_nnz": 913408, "linear_attention_total": 2359296, "linear_dense_nnz": 1760256, "linear_dense_total": 4718592, "linear_nnz": 2673664, "linear_total": 7077888, "nnz": 2681056, "total": 7087872}, "5": {"linear_attention_nnz": 791552, "linear_attention_total": 2359296, "linear_dense_nnz": 1718272, "linear_dense_total": 4718592, "linear_nnz": 2509824, "linear_total": 7077888, "nnz": 2517088, "total": 7087872}, "6": {"linear_attention_nnz": 755712, "linear_attention_total": 2359296, "linear_dense_nnz": 1330176, "linear_dense_total": 4718592, "linear_nnz": 2085888, "linear_total": 7077888, "nnz": 2092864, "total": 7087872}, "7": {"linear_attention_nnz": 827392, "linear_attention_total": 2359296, "linear_dense_nnz": 904192, "linear_dense_total": 4718592, "linear_nnz": 1731584, "linear_total": 7077888, "nnz": 1738144, "total": 7087872}, "8": {"linear_attention_nnz": 726016, "linear_attention_total": 2359296, "linear_dense_nnz": 257024, "linear_dense_total": 4718592, "linear_nnz": 983040, "linear_total": 7077888, "nnz": 989184, "total": 7087872}, "9": {"linear_attention_nnz": 464896, "linear_attention_total": 2359296, "linear_dense_nnz": 118784, "linear_dense_total": 4718592, "linear_nnz": 583680, "linear_total": 7077888, "nnz": 588928, "total": 7087872}}, "linear_nnz": 20496384, "linear_sparsity": 75.86805555555556, "linear_total": 84934656, "nnz": 44413282, "pruned_heads": {"0": [0, 2, 4, 5, 6, 7], "1": [0, 2, 3, 5, 6, 7, 8, 9], "10": [1, 4, 5, 6, 7, 8], "11": [0, 2, 5, 6, 7, 8, 10, 11], "2": [2, 4, 7, 8, 11], "3": [2, 4, 6, 7], "4": [0, 1, 2, 6, 11], "5": [1, 2, 5, 6, 7, 11], "6": [0, 2, 3, 4, 7], "7": [1, 3, 6, 7, 11], "8": [0, 8, 3, 4], "9": [1, 4, 5, 7, 9, 10]}, "total": 108893186, "total_sparsity": 59.21390159343854}, "training_args": {"_n_gpu": -1, "adafactor": false, "adam_beta1": 0.9, "adam_beta2": 0.999, "adam_epsilon": 1e-08, "dataloader_drop_last": false, "dataloader_num_workers": 0, "dataloader_pin_memory": true, "ddp_find_unused_parameters": null, "debug": false, "deepspeed": null, "disable_tqdm": false, "do_eval": 1, "do_predict": false, "do_train": 1, "eval_accumulation_steps": null, "eval_steps": 5000, "evaluation_strategy": "steps", "fp16": false, "fp16_backend": "auto", "fp16_full_eval": false, "fp16_opt_level": "O1", "gradient_accumulation_steps": 1, "greater_is_better": null, "group_by_length": false, "ignore_data_skip": false, "label_names": null, "label_smoothing_factor": 0.0, "learning_rate": 3e-05, "load_best_model_at_end": false, "local_rank": -1, "logging_dir": "output/squad_test3", "logging_first_step": false, "logging_steps": 250, "logging_strategy": "steps", "lr_scheduler_type": "linear", "max_grad_norm": 1.0, "max_steps": -1, "metric_for_best_model": null, "no_cuda": false, "num_train_epochs": 20, "optimize_model_before_eval": "disabled", "output_dir": "output/squad_test3", "overwrite_output_dir": 1, "past_index": -1, "per_device_eval_batch_size": 8, "per_device_train_batch_size": 16, "per_gpu_eval_batch_size": null, "per_gpu_train_batch_size": null, "prediction_loss_only": false, "remove_unused_columns": true, "report_to": null, "run_name": "output/squad_test3", "save_steps": 5000, "save_strategy": "steps", "save_total_limit": 50, "seed": 17, "sharded_ddp": "", "skip_memory_metrics": false, "tpu_metrics_debug": false, "tpu_num_cores": null, "warmup_ratio": 0.0, "warmup_steps": 5400, "weight_decay": 0.0}}, "f1": 85.84893170709621, "fill_rate": 0.24131944444444442, "speedup": 2.0054680821187447}}
{"speedup": 2.2874144573134694, "f1": 85.3167029862563, "meta": {"annotate": "18", "cat_fun_name": "is_full_block", "checkpoint": {"config": {"_name_or_path": "bert-base-uncased", "architectures": ["BertForQuestionAnswering"], "attention_probs_dropout_prob": 0.1, "gradient_checkpointing": false, "hidden_act": "gelu", "hidden_dropout_prob": 0.1, "hidden_size": 768, "initializer_range": 0.02, "intermediate_size": 3072, "layer_norm_eps": 1e-12, "max_position_embeddings": 512, "model_type": "bert", "num_attention_heads": 12, "num_hidden_layers": 12, "pad_token_id": 0, "position_embedding_type": "absolute", "type_vocab_size": 2, "vocab_size": 30522}, "eval_metrics": {"exact_match": 76.79280983916746, "f1": 85.3167029862563}, "path": "/data_2to/devel_data/nn_pruning/output/squad_test3/hp_od-output__squad_test3_es-steps_nte20_ls250_stl50_est5000_rn-output__squad_test3_dpm-sigmoied_threshold_apme-sigmoied_threshold_aowd0_bm1_dbr32_dbc32_abr32_abc32_it0_fw10_r-l1_rfl30_dtnop-csarron__bert-base-uncased-squad-v1/checkpoint-105000", "sparse_args": {"ampere_pruning_method": "disabled", "attention_block_cols": 32, "attention_block_rows": 32, "attention_lambda": 1.0, "attention_output_with_dense": 0, "attention_pruning_method": "sigmoied_threshold", "bias_mask": true, "dense_block_cols": 32, "dense_block_rows": 32, "dense_lambda": 1.0, "dense_pruning_method": "sigmoied_threshold", "distil_alpha_ce": 0.1, "distil_alpha_teacher": 0.9, "distil_teacher_name_or_path": "csarron/bert-base-uncased-squad-v1", "distil_temperature": 2.0, "final_ampere_temperature": 20.0, "final_threshold": 0.1, "final_warmup": 10, "initial_ampere_temperature": 0.0, "initial_threshold": 0, "initial_warmup": 1, "mask_init": "constant", "mask_scale": 0.0, "mask_scores_learning_rate": 0.01, "regularization": "l1", "regularization_final_lambda": 30}, "speed": {"cuda_eval_elapsed_time": 16.872496753692626, "eval_elapsed_time": 24.01387820020318}, "speedup": 2.2874144573134694, "stats": {"layers": {"0": {"linear_attention_nnz": 512000, "linear_attention_total": 2359296, "linear_dense_nnz": 512000, "linear_dense_total": 4718592, "linear_nnz": 1024000, "linear_total": 7077888, "nnz": 1029984, "total": 7087872}, "1": {"linear_attention_nnz": 551936, "linear_attention_total": 2359296, "linear_dense_nnz": 685056, "linear_dense_total": 4718592, "linear_nnz": 1236992, "linear_total": 7077888, "nnz": 1242912, "total": 7087872}, "10": {"linear_attention_nnz": 304128, "linear_attention_total": 2359296, "linear_dense_nnz": 197632, "linear_dense_total": 4718592, "linear_nnz": 501760, "linear_total": 7077888, "nnz": 506976, "total": 7087872}, "11": {"linear_attention_nnz": 197632, "linear_attention_total": 2359296, "linear_dense_nnz": 220160, "linear_dense_total": 4718592, "linear_nnz": 417792, "linear_total": 7077888, "nnz": 422880, "total": 7087872}, "2": {"linear_attention_nnz": 722944, "linear_attention_total": 2359296, "linear_dense_nnz": 1211392, "linear_dense_total": 4718592, "linear_nnz": 1934336, "linear_total": 7077888, "nnz": 1940960, "total": 7087872}, "3": {"linear_attention_nnz": 954368, "linear_attention_total": 2359296, "linear_dense_nnz": 1397760, "linear_dense_total": 4718592, "linear_nnz": 2352128, "linear_total": 7077888, "nnz": 2359232, "total": 7087872}, "4": {"linear_attention_nnz": 790528, "linear_attention_total": 2359296, "linear_dense_nnz": 1238016, "linear_dense_total": 4718592, "linear_nnz": 2028544, "linear_total": 7077888, "nnz": 2035424, "total": 7087872}, "5": {"linear_attention_nnz": 584704, "linear_attention_total": 2359296, "linear_dense_nnz": 1295360, "linear_dense_total": 4718592, "linear_nnz": 1880064, "linear_total": 7077888, "nnz": 1886784, "total": 7087872}, "6": {"linear_attention_nnz": 608256, "linear_attention_total": 2359296, "linear_dense_nnz": 1018880, "linear_dense_total": 4718592, "linear_nnz": 1627136, "linear_total": 7077888, "nnz": 1633600, "total": 7087872}, "7": {"linear_attention_nnz": 740352, "linear_attention_total": 2359296, "linear_dense_nnz": 576512, "linear_dense_total": 4718592, "linear_nnz": 1316864, "linear_total": 7077888, "nnz": 1323104, "total": 7087872}, "8": {"linear_attention_nnz": 510976, "linear_attention_total": 2359296, "linear_dense_nnz": 162816, "linear_dense_total": 4718592, "linear_nnz": 673792, "linear_total": 7077888, "nnz": 679488, "total": 7087872}, "9": {"linear_attention_nnz": 357376, "linear_attention_total": 2359296, "linear_dense_nnz": 94208, "linear_dense_total": 4718592, "linear_nnz": 451584, "linear_total": 7077888, "nnz": 456544, "total": 7087872}}, "linear_nnz": 15444992, "linear_sparsity": 81.81544174382715, "linear_total": 84934656, "nnz": 39356610, "pruned_heads": {"0": [0, 2, 4, 5, 6, 7, 9], "1": [0, 2, 3, 5, 6, 7, 8, 9], "10": [1, 4, 5, 6, 7, 8], "11": [0, 2, 5, 6, 7, 8, 10, 11], "2": [1, 2, 4, 7, 8, 11], "3": [2, 4, 6, 7, 10], "4": [0, 1, 2, 6, 11], "5": [0, 1, 2, 5, 6, 7, 11], "6": [0, 2, 3, 4, 7, 10], "7": [1, 3, 6, 7, 11], "8": [0, 2, 3, 4, 6, 8], "9": [1, 3, 4, 5, 7, 9, 10]}, "total": 108893186, "total_sparsity": 63.85760078688487}, "training_args": {"_n_gpu": -1, "adafactor": false, "adam_beta1": 0.9, "adam_beta2": 0.999, "adam_epsilon": 1e-08, "dataloader_drop_last": false, "dataloader_num_workers": 0, "dataloader_pin_memory": true, "ddp_find_unused_parameters": null, "debug": false, "deepspeed": null, "disable_tqdm": false, "do_eval": 1, "do_predict": false, "do_train": 1, "eval_accumulation_steps": null, "eval_steps": 5000, "evaluation_strategy": "steps", "fp16": false, "fp16_backend": "auto", "fp16_full_eval": false, "fp16_opt_level": "O1", "gradient_accumulation_steps": 1, "greater_is_better": null, "group_by_length": false, "ignore_data_skip": false, "label_names": null, "label_smoothing_factor": 0.0, "learning_rate": 3e-05, "load_best_model_at_end": false, "local_rank": -1, "logging_dir": "output/squad_test3", "logging_first_step": false, "logging_steps": 250, "logging_strategy": "steps", "lr_scheduler_type": "linear", "max_grad_norm": 1.0, "max_steps": -1, "metric_for_best_model": null, "no_cuda": false, "num_train_epochs": 20, "optimize_model_before_eval": "disabled", "output_dir": "output/squad_test3", "overwrite_output_dir": 1, "past_index": -1, "per_device_eval_batch_size": 8, "per_device_train_batch_size": 16, "per_gpu_eval_batch_size": null, "per_gpu_train_batch_size": null, "prediction_loss_only": false, "remove_unused_columns": true, "report_to": null, "run_name": "output/squad_test3", "save_steps": 5000, "save_strategy": "steps", "save_total_limit": 50, "seed": 17, "sharded_ddp": "", "skip_memory_metrics": false, "tpu_metrics_debug": false, "tpu_num_cores": null, "warmup_ratio": 0.0, "warmup_steps": 5400, "weight_decay": 0.0}}, "f1": 85.3167029862563, "fill_rate": 0.18184558256172845, "speedup": 2.2874144573134694}}
{"speedup": 2.289378243109522, "f1": 85.17930403802184, "meta": {"annotate": "17", "cat_fun_name": "is_full_block", "checkpoint": {"config": {"_name_or_path": "bert-base-uncased", "architectures": ["BertForQuestionAnswering"], "attention_probs_dropout_prob": 0.1, "gradient_checkpointing": false, "hidden_act": "gelu", "hidden_dropout_prob": 0.1, "hidden_size": 768, "initializer_range": 0.02, "intermediate_size": 3072, "layer_norm_eps": 1e-12, "max_position_embeddings": 512, "model_type": "bert", "num_attention_heads": 12, "num_hidden_layers": 12, "pad_token_id": 0, "position_embedding_type": "absolute", "type_vocab_size": 2, "vocab_size": 30522}, "eval_metrics": {"exact_match": 77.04824976348155, "f1": 85.17930403802184}, "path": "/data_2to/devel_data/nn_pruning/output/squad_test3/hp_od-output__squad_test3_es-steps_nte20_ls250_stl50_est5000_rn-output__squad_test3_dpm-sigmoied_threshold_apme-sigmoied_threshold_aowd0_bm1_dbr32_dbc32_abr32_abc32_it0_fw10_r-l1_rfl30_dtnop-csarron__bert-base-uncased-squad-v1/checkpoint-110000", "sparse_args": {"ampere_pruning_method": "disabled", "attention_block_cols": 32, "attention_block_rows": 32, "attention_lambda": 1.0, "attention_output_with_dense": 0, "attention_pruning_method": "sigmoied_threshold", "bias_mask": true, "dense_block_cols": 32, "dense_block_rows": 32, "dense_lambda": 1.0, "dense_pruning_method": "sigmoied_threshold", "distil_alpha_ce": 0.1, "distil_alpha_teacher": 0.9, "distil_teacher_name_or_path": "csarron/bert-base-uncased-squad-v1", "distil_temperature": 2.0, "final_ampere_temperature": 20.0, "final_threshold": 0.1, "final_warmup": 10, "initial_ampere_temperature": 0.0, "initial_threshold": 0, "initial_warmup": 1, "mask_init": "constant", "mask_scale": 0.0, "mask_scores_learning_rate": 0.01, "regularization": "l1", "regularization_final_lambda": 30}, "speed": {"cuda_eval_elapsed_time": 16.85802384185791, "eval_elapsed_time": 24.0219326200895}, "speedup": 2.289378243109522, "stats": {"layers": {"0": {"linear_attention_nnz": 513024, "linear_attention_total": 2359296, "linear_dense_nnz": 519168, "linear_dense_total": 4718592, "linear_nnz": 1032192, "linear_total": 7077888, "nnz": 1038176, "total": 7087872}, "1": {"linear_attention_nnz": 523264, "linear_attention_total": 2359296, "linear_dense_nnz": 692224, "linear_dense_total": 4718592, "linear_nnz": 1215488, "linear_total": 7077888, "nnz": 1221408, "total": 7087872}, "10": {"linear_attention_nnz": 312320, "linear_attention_total": 2359296, "linear_dense_nnz": 206848, "linear_dense_total": 4718592, "linear_nnz": 519168, "linear_total": 7077888, "nnz": 524256, "total": 7087872}, "11": {"linear_attention_nnz": 186368, "linear_attention_total": 2359296, "linear_dense_nnz": 215040, "linear_dense_total": 4718592, "linear_nnz": 401408, "linear_total": 7077888, "nnz": 406528, "total": 7087872}, "2": {"linear_attention_nnz": 683008, "linear_attention_total": 2359296, "linear_dense_nnz": 1239040, "linear_dense_total": 4718592, "linear_nnz": 1922048, "linear_total": 7077888, "nnz": 1928672, "total": 7087872}, "3": {"linear_attention_nnz": 945152, "linear_attention_total": 2359296, "linear_dense_nnz": 1374208, "linear_dense_total": 4718592, "linear_nnz": 2319360, "linear_total": 7077888, "nnz": 2326464, "total": 7087872}, "4": {"linear_attention_nnz": 809984, "linear_attention_total": 2359296, "linear_dense_nnz": 1235968, "linear_dense_total": 4718592, "linear_nnz": 2045952, "linear_total": 7077888, "nnz": 2052832, "total": 7087872}, "5": {"linear_attention_nnz": 581632, "linear_attention_total": 2359296, "linear_dense_nnz": 1265664, "linear_dense_total": 4718592, "linear_nnz": 1847296, "linear_total": 7077888, "nnz": 1854016, "total": 7087872}, "6": {"linear_attention_nnz": 600064, "linear_attention_total": 2359296, "linear_dense_nnz": 1007616, "linear_dense_total": 4718592, "linear_nnz": 1607680, "linear_total": 7077888, "nnz": 1614176, "total": 7087872}, "7": {"linear_attention_nnz": 708608, "linear_attention_total": 2359296, "linear_dense_nnz": 578560, "linear_dense_total": 4718592, "linear_nnz": 1287168, "linear_total": 7077888, "nnz": 1293408, "total": 7087872}, "8": {"linear_attention_nnz": 473088, "linear_attention_total": 2359296, "linear_dense_nnz": 158720, "linear_dense_total": 4718592, "linear_nnz": 631808, "linear_total": 7077888, "nnz": 637472, "total": 7087872}, "9": {"linear_attention_nnz": 352256, "linear_attention_total": 2359296, "linear_dense_nnz": 90112, "linear_dense_total": 4718592, "linear_nnz": 442368, "linear_total": 7077888, "nnz": 447232, "total": 7087872}}, "linear_nnz": 15271936, "linear_sparsity": 82.0191936728395, "linear_total": 84934656, "nnz": 39183362, "pruned_heads": {"0": [0, 2, 4, 5, 6, 7, 9], "1": [0, 2, 3, 5, 6, 7, 8, 9], "10": [1, 4, 5, 6, 7, 8], "11": [0, 2, 5, 6, 7, 8, 10, 11], "2": [1, 2, 4, 7, 8, 11], "3": [2, 4, 6, 7, 10], "4": [0, 1, 2, 6, 11], "5": [0, 1, 2, 5, 6, 7, 11], "6": [0, 2, 3, 4, 7, 10], "7": [1, 3, 6, 7, 11], "8": [0, 2, 3, 4, 6, 8], "9": [1, 3, 4, 5, 7, 9, 10]}, "total": 108893186, "total_sparsity": 64.01669981444019}, "training_args": {"_n_gpu": -1, "adafactor": false, "adam_beta1": 0.9, "adam_beta2": 0.999, "adam_epsilon": 1e-08, "dataloader_drop_last": false, "dataloader_num_workers": 0, "dataloader_pin_memory": true, "ddp_find_unused_parameters": null, "debug": false, "deepspeed": null, "disable_tqdm": false, "do_eval": 1, "do_predict": false, "do_train": 1, "eval_accumulation_steps": null, "eval_steps": 5000, "evaluation_strategy": "steps", "fp16": false, "fp16_backend": "auto", "fp16_full_eval": false, "fp16_opt_level": "O1", "gradient_accumulation_steps": 1, "greater_is_better": null, "group_by_length": false, "ignore_data_skip": false, "label_names": null, "label_smoothing_factor": 0.0, "learning_rate": 3e-05, "load_best_model_at_end": false, "local_rank": -1, "logging_dir": "output/squad_test3", "logging_first_step": false, "logging_steps": 250, "logging_strategy": "steps", "lr_scheduler_type": "linear", "max_grad_norm": 1.0, "max_steps": -1, "metric_for_best_model": null, "no_cuda": false, "num_train_epochs": 20, "optimize_model_before_eval": "disabled", "output_dir": "output/squad_test3", "overwrite_output_dir": 1, "past_index": -1, "per_device_eval_batch_size": 8, "per_device_train_batch_size": 16, "per_gpu_eval_batch_size": null, "per_gpu_train_batch_size": null, "prediction_loss_only": false, "remove_unused_columns": true, "report_to": null, "run_name": "output/squad_test3", "save_steps": 5000, "save_strategy": "steps", "save_total_limit": 50, "seed": 17, "sharded_ddp": "", "skip_memory_metrics": false, "tpu_metrics_debug": false, "tpu_num_cores": null, "warmup_ratio": 0.0, "warmup_steps": 5400, "weight_decay": 0.0}}, "f1": 85.17930403802184, "fill_rate": 0.17980806327160492, "speedup": 2.289378243109522}}
