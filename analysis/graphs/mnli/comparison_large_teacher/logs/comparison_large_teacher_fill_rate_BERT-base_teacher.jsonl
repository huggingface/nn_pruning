{"fill_rate": 0.34212239583333326, "matched": 83.70860927152319, "meta": {"annotate": "34", "cat_fun_name": "is_new_xp", "checkpoint": {"config": {"_name_or_path": "/home/lagunas/devel/hf/nn_pruning/nn_pruning/analysis/tmp_finetune", "architectures": ["BertForSequenceClassification"], "attention_probs_dropout_prob": 0.1, "finetuning_task": "mnli", "gradient_checkpointing": false, "hidden_act": "gelu", "hidden_dropout_prob": 0.1, "hidden_size": 768, "id2label": {"0": "contradiction", "1": "entailment", "2": "neutral"}, "initializer_range": 0.02, "intermediate_size": 3072, "label2id": {"contradiction": 0, "entailment": 1, "neutral": 2}, "layer_norm_eps": 1e-12, "max_position_embeddings": 512, "model_type": "bert", "num_attention_heads": 12, "num_hidden_layers": 12, "pad_token_id": 0, "position_embedding_type": "absolute", "pruned_heads": {"0": [2, 4, 7, 9, 11], "1": [0, 2, 3, 5, 6, 7, 8], "10": [0, 1, 4, 5, 6, 7, 8, 9], "11": [0, 1, 11, 7], "2": [4, 5, 7, 8, 11], "3": [2, 4, 6, 7], "4": [8, 1, 11], "5": [1, 2, 11], "6": [11, 10, 3], "7": [2, 4, 6, 7, 11], "8": [0, 10, 6], "9": [1, 3, 4, 5, 7, 9]}, "type_vocab_size": 2, "vocab_size": 30522}, "eval_metrics": {"eval_accuracy": 0.8370860927152318, "eval_loss": 0.5330445170402527}, "eval_metrics_mm": {"eval_accuracy": 0.8408258746948739, "eval_loss": 0.5096385478973389}, "path": "/data_2to/devel_data/nn_pruning/output/mnli_test_final_fine_tune/fine_tuned_hp_od-output__mnli_test2___pdtbs32_pdebs128_nte12_ws12000_rn-output__mnli_test2___fw4_rfl5/checkpoint-65000", "source_checkpoint": "/data_2to/devel_data/nn_pruning/output/mnli_test2/hp_od-output__mnli_test2___pdtbs32_pdebs128_nte12_ws12000_rn-output__mnli_test2___fw4_rfl5/checkpoint-135000", "sparse_args": {"ampere_pruning_method": "disabled", "attention_block_cols": 1, "attention_block_rows": 1, "attention_lambda": 1.0, "attention_output_with_dense": 0, "attention_pruning_method": "topK", "bias_mask": true, "dense_block_cols": 1, "dense_block_rows": 1, "dense_lambda": 1.0, "dense_pruning_method": "topK", "distil_alpha_ce": 0.1, "distil_alpha_teacher": 0.9, "distil_teacher_name_or_path": "aloxatel/bert-base-mnli", "distil_temperature": 2.0, "final_ampere_temperature": 20.0, "final_finetune": 1, "final_threshold": 0.5, "final_warmup": 0, "initial_ampere_temperature": 0.0, "initial_threshold": 1.0, "initial_warmup": 0, "mask_init": "constant", "mask_scale": 0.0, "mask_scores_learning_rate": 0.01, "regularization": "", "regularization_final_lambda": 0}, "speed": {"cuda_eval_elapsed_time": 24.553811492919923, "eval_elapsed_time": 26.061392509378493}, "speed_mm": {"cuda_eval_elapsed_time": 24.65311068725586, "eval_elapsed_time": 26.166672149673104}, "speedup": 1.9994637396181068, "stats": {"layers": {"0": {"linear_attention_nnz": 1376256, "linear_attention_total": 2359296, "linear_dense_nnz": 970752, "linear_dense_total": 4718592, "linear_nnz": 2347008, "linear_total": 7077888, "nnz": 2353592, "total": 7086912}, "1": {"linear_attention_nnz": 983040, "linear_attention_total": 2359296, "linear_dense_nnz": 1047552, "linear_dense_total": 4718592, "linear_nnz": 2030592, "linear_total": 7077888, "nnz": 2036842, "total": 7086528}, "10": {"linear_attention_nnz": 786432, "linear_attention_total": 2359296, "linear_dense_nnz": 165888, "linear_dense_total": 4718592, "linear_nnz": 952320, "linear_total": 7077888, "nnz": 957804, "total": 7086336}, "11": {"linear_attention_nnz": 1572864, "linear_attention_total": 2359296, "linear_dense_nnz": 56832, "linear_dense_total": 4718592, "linear_nnz": 1629696, "linear_total": 7077888, "nnz": 1635877, "total": 7087104}, "2": {"linear_attention_nnz": 1376256, "linear_attention_total": 2359296, "linear_dense_nnz": 1325568, "linear_dense_total": 4718592, "linear_nnz": 2701824, "linear_total": 7077888, "nnz": 2708639, "total": 7086912}, "3": {"linear_attention_nnz": 1572864, "linear_attention_total": 2359296, "linear_dense_nnz": 1611264, "linear_dense_total": 4718592, "linear_nnz": 3184128, "linear_total": 7077888, "nnz": 3191321, "total": 7087104}, "4": {"linear_attention_nnz": 1769472, "linear_attention_total": 2359296, "linear_dense_nnz": 1666560, "linear_dense_total": 4718592, "linear_nnz": 3436032, "linear_total": 7077888, "nnz": 3443453, "total": 7087296}, "5": {"linear_attention_nnz": 1769472, "linear_attention_total": 2359296, "linear_dense_nnz": 1433088, "linear_dense_total": 4718592, "linear_nnz": 3202560, "linear_total": 7077888, "nnz": 3209829, "total": 7087296}, "6": {"linear_attention_nnz": 1769472, "linear_attention_total": 2359296, "linear_dense_nnz": 1281024, "linear_dense_total": 4718592, "linear_nnz": 3050496, "linear_total": 7077888, "nnz": 3057666, "total": 7087296}, "7": {"linear_attention_nnz": 1376256, "linear_attention_total": 2359296, "linear_dense_nnz": 1118208, "linear_dense_total": 4718592, "linear_nnz": 2494464, "linear_total": 7077888, "nnz": 2501144, "total": 7086912}, "8": {"linear_attention_nnz": 1769472, "linear_attention_total": 2359296, "linear_dense_nnz": 800256, "linear_dense_total": 4718592, "linear_nnz": 2569728, "linear_total": 7077888, "nnz": 2576585, "total": 7087296}, "9": {"linear_attention_nnz": 1179648, "linear_attention_total": 2359296, "linear_dense_nnz": 279552, "linear_dense_total": 4718592, "linear_nnz": 1459200, "linear_total": 7077888, "nnz": 1465142, "total": 7086720}}, "linear_nnz": 29058048, "linear_sparsity": 65.78776041666667, "linear_total": 84934656, "nnz": 53567977, "pruned_heads": {"0": [2, 4, 7, 9, 11], "1": [0, 2, 3, 5, 6, 7, 8], "10": [0, 1, 4, 5, 6, 7, 8, 9], "11": [0, 1, 11, 7], "2": [4, 5, 7, 8, 11], "3": [2, 4, 6, 7], "4": [8, 1, 11], "5": [1, 2, 11], "6": [11, 10, 3], "7": [2, 4, 6, 7, 11], "8": [0, 10, 6], "9": [1, 3, 4, 5, 7, 9]}, "total": 109473795, "total_sparsity": 51.0677628376727}, "training_args": {"adam_beta1": 0.9, "adam_beta2": 0.999, "adam_epsilon": 1e-08, "dataloader_drop_last": false, "dataloader_num_workers": 0, "debug": false, "disable_tqdm": false, "do_eval": 1, "do_predict": false, "do_train": 1, "eval_accumulation_steps": null, "eval_steps": 5000, "evaluation_strategy": "steps", "fp16": false, "fp16_opt_level": "O1", "gradient_accumulation_steps": 1, "greater_is_better": null, "ignore_data_skip": false, "label_names": null, "learning_rate": 3e-05, "load_best_model_at_end": false, "local_rank": -1, "logging_dir": "/data_2to/devel_data/nn_pruning/output/mnli_test_final_fine_tune/fine_tuned_hp_od-output__mnli_test2___pdtbs32_pdebs128_nte12_ws12000_rn-output__mnli_test2___fw4_rfl5", "logging_first_step": false, "logging_steps": 250, "max_grad_norm": 1.0, "max_steps": -1, "metric_for_best_model": null, "model_parallel": false, "no_cuda": false, "num_train_epochs": 6, "optimize_model_before_eval": "disabled", "output_dir": "/data_2to/devel_data/nn_pruning/output/mnli_test_final_fine_tune/fine_tuned_hp_od-output__mnli_test2___pdtbs32_pdebs128_nte12_ws12000_rn-output__mnli_test2___fw4_rfl5", "overwrite_output_dir": 1, "past_index": -1, "per_device_eval_batch_size": 128, "per_device_train_batch_size": 32, "per_gpu_eval_batch_size": null, "per_gpu_train_batch_size": null, "prediction_loss_only": false, "remove_unused_columns": true, "run_name": "/data_2to/devel_data/nn_pruning/output/mnli_test_final_fine_tune/fine_tuned_hp_od-output__mnli_test2___pdtbs32_pdebs128_nte12_ws12000_rn-output__mnli_test2___fw4_rfl5", "save_steps": 5000, "save_total_limit": 50, "seed": 17, "tpu_metrics_debug": false, "tpu_num_cores": null, "warmup_steps": 10, "weight_decay": 0.0}}, "fill_rate": 0.34212239583333326, "matched": 83.70860927152319, "mismatched": 84.0825874694874, "speedup": 1.9994637396181068}}
{"fill_rate": 0.2529296875, "matched": 83.04635761589404, "meta": {"annotate": "25", "cat_fun_name": "is_new_xp", "checkpoint": {"config": {"_name_or_path": "/home/lagunas/devel/hf/nn_pruning/nn_pruning/analysis/tmp_finetune", "architectures": ["BertForSequenceClassification"], "attention_probs_dropout_prob": 0.1, "finetuning_task": "mnli", "gradient_checkpointing": false, "hidden_act": "gelu", "hidden_dropout_prob": 0.1, "hidden_size": 768, "id2label": {"0": "contradiction", "1": "entailment", "2": "neutral"}, "initializer_range": 0.02, "intermediate_size": 3072, "label2id": {"contradiction": 0, "entailment": 1, "neutral": 2}, "layer_norm_eps": 1e-12, "max_position_embeddings": 512, "model_type": "bert", "num_attention_heads": 12, "num_hidden_layers": 12, "pad_token_id": 0, "position_embedding_type": "absolute", "pruned_heads": {"0": [0, 2, 4, 6, 7, 9, 11], "1": [0, 2, 3, 5, 6, 7, 8], "10": [1, 2, 4, 5, 6, 7, 8, 9], "11": [0, 1, 2, 7], "2": [4, 5, 7, 8, 11], "3": [1, 2, 4, 6, 7, 8], "4": [0, 1, 2, 8, 10, 11], "5": [1, 2, 11, 6], "6": [2, 3, 4, 10, 11], "7": [2, 4, 6, 7, 11], "8": [0, 5, 6, 7, 8, 10], "9": [1, 2, 3, 4, 5, 7, 9]}, "type_vocab_size": 2, "vocab_size": 30522}, "eval_metrics": {"eval_accuracy": 0.8304635761589404, "eval_loss": 0.5648419260978699}, "eval_metrics_mm": {"eval_accuracy": 0.8360455655004069, "eval_loss": 0.5434430241584778}, "path": "/data_2to/devel_data/nn_pruning/output/mnli_test_final_fine_tune/fine_tuned_hp_od-output__mnli_test2___pdtbs32_pdebs128_nte12_ws12000_rn-output__mnli_test2___fw4/checkpoint-73632", "source_checkpoint": "/data_2to/devel_data/nn_pruning/output/mnli_test2/hp_od-output__mnli_test2___pdtbs32_pdebs128_nte12_ws12000_rn-output__mnli_test2___fw4/checkpoint-145000", "sparse_args": {"ampere_pruning_method": "disabled", "attention_block_cols": 1, "attention_block_rows": 1, "attention_lambda": 1.0, "attention_output_with_dense": 0, "attention_pruning_method": "topK", "bias_mask": true, "dense_block_cols": 1, "dense_block_rows": 1, "dense_lambda": 1.0, "dense_pruning_method": "topK", "distil_alpha_ce": 0.1, "distil_alpha_teacher": 0.9, "distil_teacher_name_or_path": "aloxatel/bert-base-mnli", "distil_temperature": 2.0, "final_ampere_temperature": 20.0, "final_finetune": 1, "final_threshold": 0.5, "final_warmup": 0, "initial_ampere_temperature": 0.0, "initial_threshold": 1.0, "initial_warmup": 0, "mask_init": "constant", "mask_scale": 0.0, "mask_scores_learning_rate": 0.01, "regularization": "", "regularization_final_lambda": 0}, "speed": {"cuda_eval_elapsed_time": 20.46962840270996, "eval_elapsed_time": 21.966628784313798}, "speed_mm": {"cuda_eval_elapsed_time": 20.541734985351564, "eval_elapsed_time": 22.030214177444577}, "speedup": 2.398404835869523, "stats": {"layers": {"0": {"linear_attention_nnz": 983040, "linear_attention_total": 2359296, "linear_dense_nnz": 474624, "linear_dense_total": 4718592, "linear_nnz": 1457664, "linear_total": 7077888, "nnz": 1463541, "total": 7086528}, "1": {"linear_attention_nnz": 983040, "linear_attention_total": 2359296, "linear_dense_nnz": 568320, "linear_dense_total": 4718592, "linear_nnz": 1551360, "linear_total": 7077888, "nnz": 1557298, "total": 7086528}, "10": {"linear_attention_nnz": 786432, "linear_attention_total": 2359296, "linear_dense_nnz": 109056, "linear_dense_total": 4718592, "linear_nnz": 895488, "linear_total": 7077888, "nnz": 900935, "total": 7086336}, "11": {"linear_attention_nnz": 1572864, "linear_attention_total": 2359296, "linear_dense_nnz": 33792, "linear_dense_total": 4718592, "linear_nnz": 1606656, "linear_total": 7077888, "nnz": 1612822, "total": 7087104}, "2": {"linear_attention_nnz": 1376256, "linear_attention_total": 2359296, "linear_dense_nnz": 798720, "linear_dense_total": 4718592, "linear_nnz": 2174976, "linear_total": 7077888, "nnz": 2181448, "total": 7086912}, "3": {"linear_attention_nnz": 1179648, "linear_attention_total": 2359296, "linear_dense_nnz": 996864, "linear_dense_total": 4718592, "linear_nnz": 2176512, "linear_total": 7077888, "nnz": 2182921, "total": 7086720}, "4": {"linear_attention_nnz": 1179648, "linear_attention_total": 2359296, "linear_dense_nnz": 1010688, "linear_dense_total": 4718592, "linear_nnz": 2190336, "linear_total": 7077888, "nnz": 2196754, "total": 7086720}, "5": {"linear_attention_nnz": 1572864, "linear_attention_total": 2359296, "linear_dense_nnz": 838656, "linear_dense_total": 4718592, "linear_nnz": 2411520, "linear_total": 7077888, "nnz": 2418210, "total": 7087104}, "6": {"linear_attention_nnz": 1376256, "linear_attention_total": 2359296, "linear_dense_nnz": 769536, "linear_dense_total": 4718592, "linear_nnz": 2145792, "linear_total": 7077888, "nnz": 2152245, "total": 7086912}, "7": {"linear_attention_nnz": 1376256, "linear_attention_total": 2359296, "linear_dense_nnz": 680448, "linear_dense_total": 4718592, "linear_nnz": 2056704, "linear_total": 7077888, "nnz": 2063099, "total": 7086912}, "8": {"linear_attention_nnz": 1179648, "linear_attention_total": 2359296, "linear_dense_nnz": 477696, "linear_dense_total": 4718592, "linear_nnz": 1657344, "linear_total": 7077888, "nnz": 1663415, "total": 7086720}, "9": {"linear_attention_nnz": 983040, "linear_attention_total": 2359296, "linear_dense_nnz": 175104, "linear_dense_total": 4718592, "linear_nnz": 1158144, "linear_total": 7077888, "nnz": 1163826, "total": 7086528}}, "linear_nnz": 21482496, "linear_sparsity": 74.70703125, "linear_total": 84934656, "nnz": 45986597, "pruned_heads": {"0": [0, 2, 4, 6, 7, 9, 11], "1": [0, 2, 3, 5, 6, 7, 8], "10": [1, 2, 4, 5, 6, 7, 8, 9], "11": [0, 1, 2, 7], "2": [4, 5, 7, 8, 11], "3": [1, 2, 4, 6, 7, 8], "4": [0, 1, 2, 8, 10, 11], "5": [1, 2, 11, 6], "6": [2, 3, 4, 10, 11], "7": [2, 4, 6, 7, 11], "8": [0, 5, 6, 7, 8, 10], "9": [1, 2, 3, 4, 5, 7, 9]}, "total": 109471107, "total_sparsity": 57.99202341125499}, "training_args": {"adam_beta1": 0.9, "adam_beta2": 0.999, "adam_epsilon": 1e-08, "dataloader_drop_last": false, "dataloader_num_workers": 0, "debug": false, "disable_tqdm": false, "do_eval": 1, "do_predict": false, "do_train": 1, "eval_accumulation_steps": null, "eval_steps": 5000, "evaluation_strategy": "steps", "fp16": false, "fp16_opt_level": "O1", "gradient_accumulation_steps": 1, "greater_is_better": null, "ignore_data_skip": false, "label_names": null, "learning_rate": 3e-05, "load_best_model_at_end": false, "local_rank": -1, "logging_dir": "/data_2to/devel_data/nn_pruning/output/mnli_test_final_fine_tune/fine_tuned_hp_od-output__mnli_test2___pdtbs32_pdebs128_nte12_ws12000_rn-output__mnli_test2___fw4", "logging_first_step": false, "logging_steps": 250, "max_grad_norm": 1.0, "max_steps": -1, "metric_for_best_model": null, "model_parallel": false, "no_cuda": false, "num_train_epochs": 6, "optimize_model_before_eval": "disabled", "output_dir": "/data_2to/devel_data/nn_pruning/output/mnli_test_final_fine_tune/fine_tuned_hp_od-output__mnli_test2___pdtbs32_pdebs128_nte12_ws12000_rn-output__mnli_test2___fw4", "overwrite_output_dir": 1, "past_index": -1, "per_device_eval_batch_size": 128, "per_device_train_batch_size": 32, "per_gpu_eval_batch_size": null, "per_gpu_train_batch_size": null, "prediction_loss_only": false, "remove_unused_columns": true, "run_name": "/data_2to/devel_data/nn_pruning/output/mnli_test_final_fine_tune/fine_tuned_hp_od-output__mnli_test2___pdtbs32_pdebs128_nte12_ws12000_rn-output__mnli_test2___fw4", "save_steps": 5000, "save_total_limit": 50, "seed": 17, "tpu_metrics_debug": false, "tpu_num_cores": null, "warmup_steps": 10, "weight_decay": 0.0}}, "fill_rate": 0.2529296875, "matched": 83.04635761589404, "mismatched": 83.60455655004068, "speedup": 2.398404835869523}}
{"fill_rate": 0.18093532986111116, "matched": 82.68976057055526, "meta": {"annotate": "18", "cat_fun_name": "is_new_xp", "checkpoint": {"config": {"_name_or_path": "/home/lagunas/devel/hf/nn_pruning/nn_pruning/analysis/tmp_finetune", "architectures": ["BertForSequenceClassification"], "attention_probs_dropout_prob": 0.1, "finetuning_task": "mnli", "gradient_checkpointing": false, "hidden_act": "gelu", "hidden_dropout_prob": 0.1, "hidden_size": 768, "id2label": {"0": "contradiction", "1": "entailment", "2": "neutral"}, "initializer_range": 0.02, "intermediate_size": 3072, "label2id": {"contradiction": 0, "entailment": 1, "neutral": 2}, "layer_norm_eps": 1e-12, "max_position_embeddings": 512, "model_type": "bert", "num_attention_heads": 12, "num_hidden_layers": 12, "pad_token_id": 0, "position_embedding_type": "absolute", "pruned_heads": {"0": [0, 1, 2, 4, 6, 7, 9, 11], "1": [0, 2, 3, 5, 6, 7, 8, 9], "10": [1, 2, 4, 5, 6, 7, 8, 9], "11": [0, 1, 2, 6, 7, 10, 11], "2": [0, 1, 3, 4, 5, 7, 8, 11], "3": [1, 2, 3, 4, 6, 7, 8], "4": [0, 1, 2, 4, 8, 10, 11], "5": [1, 2, 5, 6, 11], "6": [2, 3, 4, 6, 7, 10, 11], "7": [2, 3, 4, 5, 6, 7, 11], "8": [0, 3, 5, 6, 7, 8, 10], "9": [0, 1, 2, 3, 4, 5, 7, 9]}, "type_vocab_size": 2, "vocab_size": 30522}, "eval_metrics": {"eval_accuracy": 0.8268976057055527, "eval_loss": 0.5891618132591248}, "eval_metrics_mm": {"eval_accuracy": 0.8271969080553295, "eval_loss": 0.5817938446998596}, "path": "/data_2to/devel_data/nn_pruning/output/mnli_test_final_fine_tune/fine_tuned_hp_od-output__mnli_test2___pdtbs32_pdebs128_nte12_ws12000_rn-output__mnli_test2___fw4_rfl20/checkpoint-70000", "source_checkpoint": "/data_2to/devel_data/nn_pruning/output/mnli_test2/hp_od-output__mnli_test2___pdtbs32_pdebs128_nte12_ws12000_rn-output__mnli_test2___fw4_rfl20/checkpoint-100000", "sparse_args": {"ampere_pruning_method": "disabled", "attention_block_cols": 1, "attention_block_rows": 1, "attention_lambda": 1.0, "attention_output_with_dense": 0, "attention_pruning_method": "topK", "bias_mask": true, "dense_block_cols": 1, "dense_block_rows": 1, "dense_lambda": 1.0, "dense_pruning_method": "topK", "distil_alpha_ce": 0.1, "distil_alpha_teacher": 0.9, "distil_teacher_name_or_path": "aloxatel/bert-base-mnli", "distil_temperature": 2.0, "final_ampere_temperature": 20.0, "final_finetune": 1, "final_threshold": 0.5, "final_warmup": 0, "initial_ampere_temperature": 0.0, "initial_threshold": 1.0, "initial_warmup": 0, "mask_init": "constant", "mask_scale": 0.0, "mask_scores_learning_rate": 0.01, "regularization": "", "regularization_final_lambda": 0}, "speed": {"cuda_eval_elapsed_time": 17.147825485229493, "eval_elapsed_time": 18.60521282814443}, "speed_mm": {"cuda_eval_elapsed_time": 16.814879684448243, "eval_elapsed_time": 18.297247163951397}, "speedup": 2.8630134935651097, "stats": {"layers": {"0": {"linear_attention_nnz": 786432, "linear_attention_total": 2359296, "linear_dense_nnz": 268800, "linear_dense_total": 4718592, "linear_nnz": 1055232, "linear_total": 7077888, "nnz": 1060783, "total": 7086336}, "1": {"linear_attention_nnz": 786432, "linear_attention_total": 2359296, "linear_dense_nnz": 304128, "linear_dense_total": 4718592, "linear_nnz": 1090560, "linear_total": 7077888, "nnz": 1096134, "total": 7086336}, "10": {"linear_attention_nnz": 786432, "linear_attention_total": 2359296, "linear_dense_nnz": 70656, "linear_dense_total": 4718592, "linear_nnz": 857088, "linear_total": 7077888, "nnz": 862510, "total": 7086336}, "11": {"linear_attention_nnz": 983040, "linear_attention_total": 2359296, "linear_dense_nnz": 23040, "linear_dense_total": 4718592, "linear_nnz": 1006080, "linear_total": 7077888, "nnz": 1011663, "total": 7086528}, "2": {"linear_attention_nnz": 786432, "linear_attention_total": 2359296, "linear_dense_nnz": 459264, "linear_dense_total": 4718592, "linear_nnz": 1245696, "linear_total": 7077888, "nnz": 1251371, "total": 7086336}, "3": {"linear_attention_nnz": 983040, "linear_attention_total": 2359296, "linear_dense_nnz": 614400, "linear_dense_total": 4718592, "linear_nnz": 1597440, "linear_total": 7077888, "nnz": 1603408, "total": 7086528}, "4": {"linear_attention_nnz": 983040, "linear_attention_total": 2359296, "linear_dense_nnz": 602112, "linear_dense_total": 4718592, "linear_nnz": 1585152, "linear_total": 7077888, "nnz": 1591112, "total": 7086528}, "5": {"linear_attention_nnz": 1376256, "linear_attention_total": 2359296, "linear_dense_nnz": 489984, "linear_dense_total": 4718592, "linear_nnz": 1866240, "linear_total": 7077888, "nnz": 1872511, "total": 7086912}, "6": {"linear_attention_nnz": 983040, "linear_attention_total": 2359296, "linear_dense_nnz": 436224, "linear_dense_total": 4718592, "linear_nnz": 1419264, "linear_total": 7077888, "nnz": 1425116, "total": 7086528}, "7": {"linear_attention_nnz": 983040, "linear_attention_total": 2359296, "linear_dense_nnz": 453120, "linear_dense_total": 4718592, "linear_nnz": 1436160, "linear_total": 7077888, "nnz": 1442023, "total": 7086528}, "8": {"linear_attention_nnz": 983040, "linear_attention_total": 2359296, "linear_dense_nnz": 327168, "linear_dense_total": 4718592, "linear_nnz": 1310208, "linear_total": 7077888, "nnz": 1315989, "total": 7086528}, "9": {"linear_attention_nnz": 786432, "linear_attention_total": 2359296, "linear_dense_nnz": 112128, "linear_dense_total": 4718592, "linear_nnz": 898560, "linear_total": 7077888, "nnz": 904009, "total": 7086336}}, "linear_nnz": 15367680, "linear_sparsity": 81.90646701388889, "linear_total": 84934656, "nnz": 39866712, "pruned_heads": {"0": [0, 1, 2, 4, 6, 7, 9, 11], "1": [0, 2, 3, 5, 6, 7, 8, 9], "10": [1, 2, 4, 5, 6, 7, 8, 9], "11": [0, 1, 2, 6, 7, 10, 11], "2": [0, 1, 3, 4, 5, 7, 8, 11], "3": [1, 2, 3, 4, 6, 7, 8], "4": [0, 1, 2, 4, 8, 10, 11], "5": [1, 2, 5, 6, 11], "6": [2, 3, 4, 6, 7, 10, 11], "7": [2, 3, 4, 5, 6, 7, 11], "8": [0, 3, 5, 6, 7, 8, 10], "9": [0, 1, 2, 3, 4, 5, 7, 9]}, "total": 109467843, "total_sparsity": 63.581348725396914}, "training_args": {"adam_beta1": 0.9, "adam_beta2": 0.999, "adam_epsilon": 1e-08, "dataloader_drop_last": false, "dataloader_num_workers": 0, "debug": false, "disable_tqdm": false, "do_eval": 1, "do_predict": false, "do_train": 1, "eval_accumulation_steps": null, "eval_steps": 5000, "evaluation_strategy": "steps", "fp16": false, "fp16_opt_level": "O1", "gradient_accumulation_steps": 1, "greater_is_better": null, "ignore_data_skip": false, "label_names": null, "learning_rate": 3e-05, "load_best_model_at_end": false, "local_rank": -1, "logging_dir": "/data_2to/devel_data/nn_pruning/output/mnli_test_final_fine_tune/fine_tuned_hp_od-output__mnli_test2___pdtbs32_pdebs128_nte12_ws12000_rn-output__mnli_test2___fw4_rfl20", "logging_first_step": false, "logging_steps": 250, "max_grad_norm": 1.0, "max_steps": -1, "metric_for_best_model": null, "model_parallel": false, "no_cuda": false, "num_train_epochs": 6, "optimize_model_before_eval": "disabled", "output_dir": "/data_2to/devel_data/nn_pruning/output/mnli_test_final_fine_tune/fine_tuned_hp_od-output__mnli_test2___pdtbs32_pdebs128_nte12_ws12000_rn-output__mnli_test2___fw4_rfl20", "overwrite_output_dir": 1, "past_index": -1, "per_device_eval_batch_size": 128, "per_device_train_batch_size": 32, "per_gpu_eval_batch_size": null, "per_gpu_train_batch_size": null, "prediction_loss_only": false, "remove_unused_columns": true, "run_name": "/data_2to/devel_data/nn_pruning/output/mnli_test_final_fine_tune/fine_tuned_hp_od-output__mnli_test2___pdtbs32_pdebs128_nte12_ws12000_rn-output__mnli_test2___fw4_rfl20", "save_steps": 5000, "save_total_limit": 50, "seed": 17, "tpu_metrics_debug": false, "tpu_num_cores": null, "warmup_steps": 10, "weight_decay": 0.0}}, "fill_rate": 0.18093532986111116, "matched": 82.68976057055526, "mismatched": 82.71969080553295, "speedup": 2.8630134935651097}}
{"fill_rate": 0.12286603009259256, "matched": 81.02903718797758, "meta": {"annotate": "12", "cat_fun_name": "is_new_xp", "checkpoint": {"config": {"_name_or_path": "/home/lagunas/devel/hf/nn_pruning/nn_pruning/analysis/tmp_finetune", "architectures": ["BertForSequenceClassification"], "attention_probs_dropout_prob": 0.1, "finetuning_task": "mnli", "gradient_checkpointing": false, "hidden_act": "gelu", "hidden_dropout_prob": 0.1, "hidden_size": 768, "id2label": {"0": "contradiction", "1": "entailment", "2": "neutral"}, "initializer_range": 0.02, "intermediate_size": 3072, "label2id": {"contradiction": 0, "entailment": 1, "neutral": 2}, "layer_norm_eps": 1e-12, "max_position_embeddings": 512, "model_type": "bert", "num_attention_heads": 12, "num_hidden_layers": 12, "pad_token_id": 0, "position_embedding_type": "absolute", "pruned_heads": {"0": [0, 1, 2, 4, 5, 6, 7, 8, 9, 11], "1": [0, 1, 2, 3, 5, 6, 7, 8, 9], "10": [0, 1, 2, 4, 5, 6, 7, 8, 9], "11": [0, 1, 2, 6, 7, 10, 11], "2": [1, 3, 4, 5, 7, 8, 9, 11], "3": [1, 2, 3, 4, 6, 7, 8, 10], "4": [0, 1, 2, 4, 6, 7, 8, 10, 11], "5": [1, 2, 4, 5, 6, 9, 11], "6": [1, 2, 3, 4, 6, 7, 9, 10, 11], "7": [2, 3, 4, 5, 6, 7, 9, 11], "8": [0, 2, 3, 5, 6, 7, 8, 10, 11], "9": [0, 1, 2, 3, 4, 5, 7, 9]}, "type_vocab_size": 2, "vocab_size": 30522}, "eval_metrics": {"eval_accuracy": 0.8102903718797758, "eval_loss": 0.6519557237625122}, "eval_metrics_mm": {"eval_accuracy": 0.8132628152969894, "eval_loss": 0.63445645570755}, "path": "/data_2to/devel_data/nn_pruning/output/mnli_test_final_fine_tune/fine_tuned_hp_od-output__mnli_test2___pdtbs32_pdebs128_nte12_ws12000_rn-output__mnli_test2___fw4_rfl40/checkpoint-73632", "source_checkpoint": "/data_2to/devel_data/nn_pruning/output/mnli_test2/hp_od-output__mnli_test2___pdtbs32_pdebs128_nte12_ws12000_rn-output__mnli_test2___fw4_rfl40/checkpoint-140000", "sparse_args": {"ampere_pruning_method": "disabled", "attention_block_cols": 1, "attention_block_rows": 1, "attention_lambda": 1.0, "attention_output_with_dense": 0, "attention_pruning_method": "topK", "bias_mask": true, "dense_block_cols": 1, "dense_block_rows": 1, "dense_lambda": 1.0, "dense_pruning_method": "topK", "distil_alpha_ce": 0.1, "distil_alpha_teacher": 0.9, "distil_teacher_name_or_path": "aloxatel/bert-base-mnli", "distil_temperature": 2.0, "final_ampere_temperature": 20.0, "final_finetune": 1, "final_threshold": 0.5, "final_warmup": 0, "initial_ampere_temperature": 0.0, "initial_threshold": 1.0, "initial_warmup": 0, "mask_init": "constant", "mask_scale": 0.0, "mask_scores_learning_rate": 0.01, "regularization": "", "regularization_final_lambda": 0}, "speed": {"cuda_eval_elapsed_time": 14.28297381591797, "eval_elapsed_time": 15.819611034356058}, "speed_mm": {"cuda_eval_elapsed_time": 13.850817779541016, "eval_elapsed_time": 15.406974045559764}, "speedup": 3.4372712841353343, "stats": {"layers": {"0": {"linear_attention_nnz": 393216, "linear_attention_total": 2359296, "linear_dense_nnz": 93696, "linear_dense_total": 4718592, "linear_nnz": 486912, "linear_total": 7077888, "nnz": 491965, "total": 7085952}, "1": {"linear_attention_nnz": 589824, "linear_attention_total": 2359296, "linear_dense_nnz": 98304, "linear_dense_total": 4718592, "linear_nnz": 688128, "linear_total": 7077888, "nnz": 693376, "total": 7086144}, "10": {"linear_attention_nnz": 589824, "linear_attention_total": 2359296, "linear_dense_nnz": 46080, "linear_dense_total": 4718592, "linear_nnz": 635904, "linear_total": 7077888, "nnz": 641118, "total": 7086144}, "11": {"linear_attention_nnz": 983040, "linear_attention_total": 2359296, "linear_dense_nnz": 23040, "linear_dense_total": 4718592, "linear_nnz": 1006080, "linear_total": 7077888, "nnz": 1011663, "total": 7086528}, "2": {"linear_attention_nnz": 786432, "linear_attention_total": 2359296, "linear_dense_nnz": 192000, "linear_dense_total": 4718592, "linear_nnz": 978432, "linear_total": 7077888, "nnz": 983933, "total": 7086336}, "3": {"linear_attention_nnz": 786432, "linear_attention_total": 2359296, "linear_dense_nnz": 285696, "linear_dense_total": 4718592, "linear_nnz": 1072128, "linear_total": 7077888, "nnz": 1077690, "total": 7086336}, "4": {"linear_attention_nnz": 589824, "linear_attention_total": 2359296, "linear_dense_nnz": 279552, "linear_dense_total": 4718592, "linear_nnz": 869376, "linear_total": 7077888, "nnz": 874742, "total": 7086144}, "5": {"linear_attention_nnz": 983040, "linear_attention_total": 2359296, "linear_dense_nnz": 225792, "linear_dense_total": 4718592, "linear_nnz": 1208832, "linear_total": 7077888, "nnz": 1214547, "total": 7086528}, "6": {"linear_attention_nnz": 589824, "linear_attention_total": 2359296, "linear_dense_nnz": 213504, "linear_dense_total": 4718592, "linear_nnz": 803328, "linear_total": 7077888, "nnz": 808651, "total": 7086144}, "7": {"linear_attention_nnz": 786432, "linear_attention_total": 2359296, "linear_dense_nnz": 254976, "linear_dense_total": 4718592, "linear_nnz": 1041408, "linear_total": 7077888, "nnz": 1046950, "total": 7086336}, "8": {"linear_attention_nnz": 589824, "linear_attention_total": 2359296, "linear_dense_nnz": 199680, "linear_dense_total": 4718592, "linear_nnz": 789504, "linear_total": 7077888, "nnz": 794818, "total": 7086144}, "9": {"linear_attention_nnz": 786432, "linear_attention_total": 2359296, "linear_dense_nnz": 69120, "linear_dense_total": 4718592, "linear_nnz": 855552, "linear_total": 7077888, "nnz": 860973, "total": 7086336}}, "linear_nnz": 10435584, "linear_sparsity": 87.71339699074075, "linear_total": 84934656, "nnz": 34930509, "pruned_heads": {"0": [0, 1, 2, 4, 5, 6, 7, 8, 9, 11], "1": [0, 1, 2, 3, 5, 6, 7, 8, 9], "10": [0, 1, 2, 4, 5, 6, 7, 8, 9], "11": [0, 1, 2, 6, 7, 10, 11], "2": [1, 3, 4, 5, 7, 8, 9, 11], "3": [1, 2, 3, 4, 6, 7, 8, 10], "4": [0, 1, 2, 4, 6, 7, 8, 10, 11], "5": [1, 2, 4, 5, 6, 9, 11], "6": [1, 2, 3, 4, 6, 7, 9, 10, 11], "7": [2, 3, 4, 5, 6, 7, 9, 11], "8": [0, 2, 3, 5, 6, 7, 8, 10, 11], "9": [0, 1, 2, 3, 4, 5, 7, 9]}, "total": 109465155, "total_sparsity": 68.08983735509258}, "training_args": {"adam_beta1": 0.9, "adam_beta2": 0.999, "adam_epsilon": 1e-08, "dataloader_drop_last": false, "dataloader_num_workers": 0, "debug": false, "disable_tqdm": false, "do_eval": 1, "do_predict": false, "do_train": 1, "eval_accumulation_steps": null, "eval_steps": 5000, "evaluation_strategy": "steps", "fp16": false, "fp16_opt_level": "O1", "gradient_accumulation_steps": 1, "greater_is_better": null, "ignore_data_skip": false, "label_names": null, "learning_rate": 3e-05, "load_best_model_at_end": false, "local_rank": -1, "logging_dir": "/data_2to/devel_data/nn_pruning/output/mnli_test_final_fine_tune/fine_tuned_hp_od-output__mnli_test2___pdtbs32_pdebs128_nte12_ws12000_rn-output__mnli_test2___fw4_rfl40", "logging_first_step": false, "logging_steps": 250, "max_grad_norm": 1.0, "max_steps": -1, "metric_for_best_model": null, "model_parallel": false, "no_cuda": false, "num_train_epochs": 6, "optimize_model_before_eval": "disabled", "output_dir": "/data_2to/devel_data/nn_pruning/output/mnli_test_final_fine_tune/fine_tuned_hp_od-output__mnli_test2___pdtbs32_pdebs128_nte12_ws12000_rn-output__mnli_test2___fw4_rfl40", "overwrite_output_dir": 1, "past_index": -1, "per_device_eval_batch_size": 128, "per_device_train_batch_size": 32, "per_gpu_eval_batch_size": null, "per_gpu_train_batch_size": null, "prediction_loss_only": false, "remove_unused_columns": true, "run_name": "/data_2to/devel_data/nn_pruning/output/mnli_test_final_fine_tune/fine_tuned_hp_od-output__mnli_test2___pdtbs32_pdebs128_nte12_ws12000_rn-output__mnli_test2___fw4_rfl40", "save_steps": 5000, "save_total_limit": 50, "seed": 17, "tpu_metrics_debug": false, "tpu_num_cores": null, "warmup_steps": 10, "weight_decay": 0.0}}, "fill_rate": 0.12286603009259256, "matched": 81.02903718797758, "mismatched": 81.32628152969895, "speedup": 3.4372712841353343}}
