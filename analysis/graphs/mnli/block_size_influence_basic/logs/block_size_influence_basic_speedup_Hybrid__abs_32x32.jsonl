{"speedup": 1.9946948904542998, "matched": 83.19918492103923, "meta": {"annotate": "26", "cat_fun_name": "is_new_xp", "checkpoint": {"config": {"_name_or_path": "bert-base-uncased", "architectures": ["BertForSequenceClassification"], "attention_probs_dropout_prob": 0.1, "finetuning_task": "mnli", "gradient_checkpointing": false, "hidden_act": "gelu", "hidden_dropout_prob": 0.1, "hidden_size": 768, "id2label": {"0": "contradiction", "1": "entailment", "2": "neutral"}, "initializer_range": 0.02, "intermediate_size": 3072, "label2id": {"contradiction": 0, "entailment": 1, "neutral": 2}, "layer_norm_eps": 1e-12, "max_position_embeddings": 512, "model_type": "bert", "num_attention_heads": 12, "num_hidden_layers": 12, "pad_token_id": 0, "position_embedding_type": "absolute", "type_vocab_size": 2, "vocab_size": 30522}, "eval_metrics": {"eval_accuracy": 0.8319918492103923, "eval_loss": 0.5823615193367004}, "eval_metrics_mm": {"eval_accuracy": 0.8361472742066721, "eval_loss": 0.5584035515785217}, "path": "/data_2to/devel_data/nn_pruning/output/mnli_test2/hp_od-output__mnli_test2___pdtbs32_pdebs128_nte12_ws12000_rn-output__mnli_test2___fw4_rfl5/checkpoint-135000", "sparse_args": {"ampere_pruning_method": "disabled", "attention_block_cols": 32, "attention_block_rows": 32, "attention_lambda": 1.0, "attention_output_with_dense": 0, "attention_pruning_method": "sigmoied_threshold", "bias_mask": true, "dense_block_cols": 1, "dense_block_rows": 1, "dense_lambda": 1.0, "dense_pruning_method": "sigmoied_threshold:1d_alt", "distil_alpha_ce": 0.1, "distil_alpha_teacher": 0.9, "distil_teacher_name_or_path": "aloxatel/bert-base-mnli", "distil_temperature": 2.0, "final_ampere_temperature": 20.0, "final_finetune": false, "final_threshold": 0.1, "final_warmup": 4, "initial_ampere_temperature": 0.0, "initial_threshold": 0, "initial_warmup": 1, "mask_init": "constant", "mask_scale": 0.0, "mask_scores_learning_rate": 0.01, "regularization": "l1", "regularization_final_lambda": 5}, "speed": {"cuda_eval_elapsed_time": 24.612513916015626, "eval_elapsed_time": 26.227325464598835}, "speed_mm": {"cuda_eval_elapsed_time": 24.69035372924805, "eval_elapsed_time": 26.292322852648795}, "speedup": 1.9946948904542998, "stats": {"layers": {"0": {"linear_attention_nnz": 877568, "linear_attention_total": 2359296, "linear_dense_nnz": 970752, "linear_dense_total": 4718592, "linear_nnz": 1848320, "linear_total": 7077888, "nnz": 1854648, "total": 7087872}, "1": {"linear_attention_nnz": 743424, "linear_attention_total": 2359296, "linear_dense_nnz": 1047552, "linear_dense_total": 4718592, "linear_nnz": 1790976, "linear_total": 7077888, "nnz": 1797162, "total": 7087872}, "10": {"linear_attention_nnz": 352256, "linear_attention_total": 2359296, "linear_dense_nnz": 165888, "linear_dense_total": 4718592, "linear_nnz": 518144, "linear_total": 7077888, "nnz": 523372, "total": 7087872}, "11": {"linear_attention_nnz": 250880, "linear_attention_total": 2359296, "linear_dense_nnz": 56832, "linear_dense_total": 4718592, "linear_nnz": 307712, "linear_total": 7077888, "nnz": 313253, "total": 7087872}, "2": {"linear_attention_nnz": 1091584, "linear_attention_total": 2359296, "linear_dense_nnz": 1325568, "linear_dense_total": 4718592, "linear_nnz": 2417152, "linear_total": 7077888, "nnz": 2423935, "total": 7087872}, "3": {"linear_attention_nnz": 1209344, "linear_attention_total": 2359296, "linear_dense_nnz": 1611264, "linear_dense_total": 4718592, "linear_nnz": 2820608, "linear_total": 7077888, "nnz": 2827769, "total": 7087872}, "4": {"linear_attention_nnz": 1282048, "linear_attention_total": 2359296, "linear_dense_nnz": 1666560, "linear_dense_total": 4718592, "linear_nnz": 2948608, "linear_total": 7077888, "nnz": 2955965, "total": 7087872}, "5": {"linear_attention_nnz": 1424384, "linear_attention_total": 2359296, "linear_dense_nnz": 1433088, "linear_dense_total": 4718592, "linear_nnz": 2857472, "linear_total": 7077888, "nnz": 2864741, "total": 7087872}, "6": {"linear_attention_nnz": 1209344, "linear_attention_total": 2359296, "linear_dense_nnz": 1281024, "linear_dense_total": 4718592, "linear_nnz": 2490368, "linear_total": 7077888, "nnz": 2497378, "total": 7087872}, "7": {"linear_attention_nnz": 1010688, "linear_attention_total": 2359296, "linear_dense_nnz": 1118208, "linear_dense_total": 4718592, "linear_nnz": 2128896, "linear_total": 7077888, "nnz": 2135480, "total": 7087872}, "8": {"linear_attention_nnz": 947200, "linear_attention_total": 2359296, "linear_dense_nnz": 800256, "linear_dense_total": 4718592, "linear_nnz": 1747456, "linear_total": 7077888, "nnz": 1754025, "total": 7087872}, "9": {"linear_attention_nnz": 655360, "linear_attention_total": 2359296, "linear_dense_nnz": 279552, "linear_dense_total": 4718592, "linear_nnz": 934912, "linear_total": 7077888, "nnz": 940598, "total": 7087872}}, "linear_nnz": 22810624, "linear_sparsity": 73.14332561728395, "linear_total": 84934656, "nnz": 47318409, "pruned_heads": {"0": [2, 4, 7, 9, 11], "1": [0, 2, 3, 5, 6, 7, 8], "10": [0, 1, 4, 5, 6, 7, 8, 9], "11": [0, 1, 11, 7], "2": [4, 5, 7, 8, 11], "3": [2, 4, 6, 7], "4": [8, 1, 11], "5": [1, 2, 11], "6": [11, 10, 3], "7": [2, 4, 6, 7, 11], "8": [0, 10, 6], "9": [1, 3, 4, 5, 7, 9]}, "total": 109484547, "total_sparsity": 56.78074185208987}, "training_args": {"adam_beta1": 0.9, "adam_beta2": 0.999, "adam_epsilon": 1e-08, "dataloader_drop_last": false, "dataloader_num_workers": 0, "debug": false, "disable_tqdm": false, "do_eval": 1, "do_predict": false, "do_train": 1, "eval_accumulation_steps": null, "eval_steps": 5000, "evaluation_strategy": "steps", "fp16": false, "fp16_opt_level": "O1", "gradient_accumulation_steps": 1, "greater_is_better": null, "ignore_data_skip": false, "label_names": null, "learning_rate": 3e-05, "load_best_model_at_end": false, "local_rank": -1, "logging_dir": "output/mnli_test2/", "logging_first_step": false, "logging_steps": 250, "max_grad_norm": 1.0, "max_steps": -1, "metric_for_best_model": null, "model_parallel": false, "no_cuda": false, "num_train_epochs": 12, "optimize_model_before_eval": "disabled", "output_dir": "output/mnli_test2/", "overwrite_output_dir": 1, "past_index": -1, "per_device_eval_batch_size": 128, "per_device_train_batch_size": 32, "per_gpu_eval_batch_size": null, "per_gpu_train_batch_size": null, "prediction_loss_only": false, "remove_unused_columns": true, "run_name": "output/mnli_test2/", "save_steps": 5000, "save_total_limit": 50, "seed": 17, "tpu_metrics_debug": false, "tpu_num_cores": null, "warmup_steps": 12000, "weight_decay": 0.0}}, "fill_rate": 0.2685667438271605, "matched": 83.19918492103923, "mismatched": 83.61472742066721, "speedup": 1.9946948904542998}}
{"speedup": 2.0018744207135466, "matched": 83.13805399898115, "meta": {"annotate": "26", "cat_fun_name": "is_new_xp", "checkpoint": {"config": {"_name_or_path": "bert-base-uncased", "architectures": ["BertForSequenceClassification"], "attention_probs_dropout_prob": 0.1, "finetuning_task": "mnli", "gradient_checkpointing": false, "hidden_act": "gelu", "hidden_dropout_prob": 0.1, "hidden_size": 768, "id2label": {"0": "contradiction", "1": "entailment", "2": "neutral"}, "initializer_range": 0.02, "intermediate_size": 3072, "label2id": {"contradiction": 0, "entailment": 1, "neutral": 2}, "layer_norm_eps": 1e-12, "max_position_embeddings": 512, "model_type": "bert", "num_attention_heads": 12, "num_hidden_layers": 12, "pad_token_id": 0, "position_embedding_type": "absolute", "type_vocab_size": 2, "vocab_size": 30522}, "eval_metrics": {"eval_accuracy": 0.8313805399898115, "eval_loss": 0.5729787349700928}, "eval_metrics_mm": {"eval_accuracy": 0.8360455655004069, "eval_loss": 0.5526318550109863}, "path": "/data_2to/devel_data/nn_pruning/output/mnli_test2/hp_od-output__mnli_test2___pdtbs32_pdebs128_nte12_ws12000_rn-output__mnli_test2___fw4_rfl5/checkpoint-140000", "sparse_args": {"ampere_pruning_method": "disabled", "attention_block_cols": 32, "attention_block_rows": 32, "attention_lambda": 1.0, "attention_output_with_dense": 0, "attention_pruning_method": "sigmoied_threshold", "bias_mask": true, "dense_block_cols": 1, "dense_block_rows": 1, "dense_lambda": 1.0, "dense_pruning_method": "sigmoied_threshold:1d_alt", "distil_alpha_ce": 0.1, "distil_alpha_teacher": 0.9, "distil_teacher_name_or_path": "aloxatel/bert-base-mnli", "distil_temperature": 2.0, "final_ampere_temperature": 20.0, "final_finetune": false, "final_threshold": 0.1, "final_warmup": 4, "initial_ampere_temperature": 0.0, "initial_threshold": 0, "initial_warmup": 1, "mask_init": "constant", "mask_scale": 0.0, "mask_scores_learning_rate": 0.01, "regularization": "l1", "regularization_final_lambda": 5}, "speed": {"cuda_eval_elapsed_time": 24.52424349975586, "eval_elapsed_time": 26.1085445843637}, "speed_mm": {"cuda_eval_elapsed_time": 24.615995880126952, "eval_elapsed_time": 26.190075170248747}, "speedup": 2.0018744207135466, "stats": {"layers": {"0": {"linear_attention_nnz": 848896, "linear_attention_total": 2359296, "linear_dense_nnz": 969216, "linear_dense_total": 4718592, "linear_nnz": 1818112, "linear_total": 7077888, "nnz": 1824439, "total": 7087872}, "1": {"linear_attention_nnz": 713728, "linear_attention_total": 2359296, "linear_dense_nnz": 1046016, "linear_dense_total": 4718592, "linear_nnz": 1759744, "linear_total": 7077888, "nnz": 1765929, "total": 7087872}, "10": {"linear_attention_nnz": 345088, "linear_attention_total": 2359296, "linear_dense_nnz": 165888, "linear_dense_total": 4718592, "linear_nnz": 510976, "linear_total": 7077888, "nnz": 516172, "total": 7087872}, "11": {"linear_attention_nnz": 256000, "linear_attention_total": 2359296, "linear_dense_nnz": 56832, "linear_dense_total": 4718592, "linear_nnz": 312832, "linear_total": 7077888, "nnz": 318373, "total": 7087872}, "2": {"linear_attention_nnz": 1096704, "linear_attention_total": 2359296, "linear_dense_nnz": 1324032, "linear_dense_total": 4718592, "linear_nnz": 2420736, "linear_total": 7077888, "nnz": 2427518, "total": 7087872}, "3": {"linear_attention_nnz": 1229824, "linear_attention_total": 2359296, "linear_dense_nnz": 1609728, "linear_dense_total": 4718592, "linear_nnz": 2839552, "linear_total": 7077888, "nnz": 2846712, "total": 7087872}, "4": {"linear_attention_nnz": 1285120, "linear_attention_total": 2359296, "linear_dense_nnz": 1666560, "linear_dense_total": 4718592, "linear_nnz": 2951680, "linear_total": 7077888, "nnz": 2959037, "total": 7087872}, "5": {"linear_attention_nnz": 1414144, "linear_attention_total": 2359296, "linear_dense_nnz": 1430016, "linear_dense_total": 4718592, "linear_nnz": 2844160, "linear_total": 7077888, "nnz": 2851427, "total": 7087872}, "6": {"linear_attention_nnz": 1159168, "linear_attention_total": 2359296, "linear_dense_nnz": 1281024, "linear_dense_total": 4718592, "linear_nnz": 2440192, "linear_total": 7077888, "nnz": 2447202, "total": 7087872}, "7": {"linear_attention_nnz": 993280, "linear_attention_total": 2359296, "linear_dense_nnz": 1112064, "linear_dense_total": 4718592, "linear_nnz": 2105344, "linear_total": 7077888, "nnz": 2111924, "total": 7087872}, "8": {"linear_attention_nnz": 915456, "linear_attention_total": 2359296, "linear_dense_nnz": 798720, "linear_dense_total": 4718592, "linear_nnz": 1714176, "linear_total": 7077888, "nnz": 1720744, "total": 7087872}, "9": {"linear_attention_nnz": 636928, "linear_attention_total": 2359296, "linear_dense_nnz": 279552, "linear_dense_total": 4718592, "linear_nnz": 916480, "linear_total": 7077888, "nnz": 922166, "total": 7087872}}, "linear_nnz": 22633984, "linear_sparsity": 73.35129726080247, "linear_total": 84934656, "nnz": 47141726, "pruned_heads": {"0": [2, 4, 7, 9, 11], "1": [0, 2, 3, 5, 6, 7, 8], "10": [0, 1, 4, 5, 6, 7, 8, 9], "11": [0, 1, 11, 7], "2": [4, 5, 7, 8, 11], "3": [2, 4, 6, 7], "4": [8, 1, 11], "5": [1, 2, 11], "6": [11, 10, 3], "7": [2, 4, 6, 7, 11], "8": [0, 10, 6], "9": [1, 3, 4, 5, 7, 9]}, "total": 109484547, "total_sparsity": 56.94211896405801}, "training_args": {"adam_beta1": 0.9, "adam_beta2": 0.999, "adam_epsilon": 1e-08, "dataloader_drop_last": false, "dataloader_num_workers": 0, "debug": false, "disable_tqdm": false, "do_eval": 1, "do_predict": false, "do_train": 1, "eval_accumulation_steps": null, "eval_steps": 5000, "evaluation_strategy": "steps", "fp16": false, "fp16_opt_level": "O1", "gradient_accumulation_steps": 1, "greater_is_better": null, "ignore_data_skip": false, "label_names": null, "learning_rate": 3e-05, "load_best_model_at_end": false, "local_rank": -1, "logging_dir": "output/mnli_test2/", "logging_first_step": false, "logging_steps": 250, "max_grad_norm": 1.0, "max_steps": -1, "metric_for_best_model": null, "model_parallel": false, "no_cuda": false, "num_train_epochs": 12, "optimize_model_before_eval": "disabled", "output_dir": "output/mnli_test2/", "overwrite_output_dir": 1, "past_index": -1, "per_device_eval_batch_size": 128, "per_device_train_batch_size": 32, "per_gpu_eval_batch_size": null, "per_gpu_train_batch_size": null, "prediction_loss_only": false, "remove_unused_columns": true, "run_name": "output/mnli_test2/", "save_steps": 5000, "save_total_limit": 50, "seed": 17, "tpu_metrics_debug": false, "tpu_num_cores": null, "warmup_steps": 12000, "weight_decay": 0.0}}, "fill_rate": 0.2664870273919753, "matched": 83.13805399898115, "mismatched": 83.60455655004068, "speedup": 2.0018744207135466}}
{"speedup": 2.002662075247167, "matched": 83.03616912888437, "meta": {"annotate": "26", "cat_fun_name": "is_new_xp", "checkpoint": {"config": {"_name_or_path": "bert-base-uncased", "architectures": ["BertForSequenceClassification"], "attention_probs_dropout_prob": 0.1, "finetuning_task": "mnli", "gradient_checkpointing": false, "hidden_act": "gelu", "hidden_dropout_prob": 0.1, "hidden_size": 768, "id2label": {"0": "contradiction", "1": "entailment", "2": "neutral"}, "initializer_range": 0.02, "intermediate_size": 3072, "label2id": {"contradiction": 0, "entailment": 1, "neutral": 2}, "layer_norm_eps": 1e-12, "max_position_embeddings": 512, "model_type": "bert", "num_attention_heads": 12, "num_hidden_layers": 12, "pad_token_id": 0, "position_embedding_type": "absolute", "type_vocab_size": 2, "vocab_size": 30522}, "eval_metrics": {"eval_accuracy": 0.8303616912888436, "eval_loss": 0.5739728212356567}, "eval_metrics_mm": {"eval_accuracy": 0.8365541090317331, "eval_loss": 0.5615866780281067}, "path": "/data_2to/devel_data/nn_pruning/output/mnli_test2/hp_od-output__mnli_test2___pdtbs32_pdebs128_nte12_ws12000_rn-output__mnli_test2___fw4_rfl5/checkpoint-145000", "sparse_args": {"ampere_pruning_method": "disabled", "attention_block_cols": 32, "attention_block_rows": 32, "attention_lambda": 1.0, "attention_output_with_dense": 0, "attention_pruning_method": "sigmoied_threshold", "bias_mask": true, "dense_block_cols": 1, "dense_block_rows": 1, "dense_lambda": 1.0, "dense_pruning_method": "sigmoied_threshold:1d_alt", "distil_alpha_ce": 0.1, "distil_alpha_teacher": 0.9, "distil_teacher_name_or_path": "aloxatel/bert-base-mnli", "distil_temperature": 2.0, "final_ampere_temperature": 20.0, "final_finetune": false, "final_threshold": 0.1, "final_warmup": 4, "initial_ampere_temperature": 0.0, "initial_threshold": 0, "initial_warmup": 1, "mask_init": "constant", "mask_scale": 0.0, "mask_scores_learning_rate": 0.01, "regularization": "l1", "regularization_final_lambda": 5}, "speed": {"cuda_eval_elapsed_time": 24.514598022460937, "eval_elapsed_time": 26.127468508668244}, "speed_mm": {"cuda_eval_elapsed_time": 24.603808868408205, "eval_elapsed_time": 26.16779050324112}, "speedup": 2.002662075247167, "stats": {"layers": {"0": {"linear_attention_nnz": 867328, "linear_attention_total": 2359296, "linear_dense_nnz": 967680, "linear_dense_total": 4718592, "linear_nnz": 1835008, "linear_total": 7077888, "nnz": 1841334, "total": 7087872}, "1": {"linear_attention_nnz": 719872, "linear_attention_total": 2359296, "linear_dense_nnz": 1046016, "linear_dense_total": 4718592, "linear_nnz": 1765888, "linear_total": 7077888, "nnz": 1772073, "total": 7087872}, "10": {"linear_attention_nnz": 343040, "linear_attention_total": 2359296, "linear_dense_nnz": 165888, "linear_dense_total": 4718592, "linear_nnz": 508928, "linear_total": 7077888, "nnz": 514124, "total": 7087872}, "11": {"linear_attention_nnz": 252928, "linear_attention_total": 2359296, "linear_dense_nnz": 56832, "linear_dense_total": 4718592, "linear_nnz": 309760, "linear_total": 7077888, "nnz": 315301, "total": 7087872}, "2": {"linear_attention_nnz": 1071104, "linear_attention_total": 2359296, "linear_dense_nnz": 1324032, "linear_dense_total": 4718592, "linear_nnz": 2395136, "linear_total": 7077888, "nnz": 2401918, "total": 7087872}, "3": {"linear_attention_nnz": 1240064, "linear_attention_total": 2359296, "linear_dense_nnz": 1609728, "linear_dense_total": 4718592, "linear_nnz": 2849792, "linear_total": 7077888, "nnz": 2856952, "total": 7087872}, "4": {"linear_attention_nnz": 1287168, "linear_attention_total": 2359296, "linear_dense_nnz": 1666560, "linear_dense_total": 4718592, "linear_nnz": 2953728, "linear_total": 7077888, "nnz": 2961085, "total": 7087872}, "5": {"linear_attention_nnz": 1409024, "linear_attention_total": 2359296, "linear_dense_nnz": 1428480, "linear_dense_total": 4718592, "linear_nnz": 2837504, "linear_total": 7077888, "nnz": 2844770, "total": 7087872}, "6": {"linear_attention_nnz": 1172480, "linear_attention_total": 2359296, "linear_dense_nnz": 1281024, "linear_dense_total": 4718592, "linear_nnz": 2453504, "linear_total": 7077888, "nnz": 2460482, "total": 7087872}, "7": {"linear_attention_nnz": 995328, "linear_attention_total": 2359296, "linear_dense_nnz": 1112064, "linear_dense_total": 4718592, "linear_nnz": 2107392, "linear_total": 7077888, "nnz": 2113940, "total": 7087872}, "8": {"linear_attention_nnz": 897024, "linear_attention_total": 2359296, "linear_dense_nnz": 798720, "linear_dense_total": 4718592, "linear_nnz": 1695744, "linear_total": 7077888, "nnz": 1702280, "total": 7087872}, "9": {"linear_attention_nnz": 650240, "linear_attention_total": 2359296, "linear_dense_nnz": 279552, "linear_dense_total": 4718592, "linear_nnz": 929792, "linear_total": 7077888, "nnz": 935478, "total": 7087872}}, "linear_nnz": 22642176, "linear_sparsity": 73.34165219907408, "linear_total": 84934656, "nnz": 47149820, "pruned_heads": {"0": [2, 4, 7, 9, 11], "1": [0, 2, 3, 5, 6, 7, 8], "10": [0, 1, 4, 5, 6, 7, 8, 9], "11": [0, 1, 11, 7], "2": [4, 5, 7, 8, 11], "3": [2, 4, 6, 7], "4": [8, 1, 11], "5": [1, 2, 11], "6": [11, 10, 3], "7": [2, 4, 6, 7, 11], "8": [0, 10, 6], "9": [1, 3, 4, 5, 7, 9]}, "total": 109484547, "total_sparsity": 56.934726139936444}, "training_args": {"adam_beta1": 0.9, "adam_beta2": 0.999, "adam_epsilon": 1e-08, "dataloader_drop_last": false, "dataloader_num_workers": 0, "debug": false, "disable_tqdm": false, "do_eval": 1, "do_predict": false, "do_train": 1, "eval_accumulation_steps": null, "eval_steps": 5000, "evaluation_strategy": "steps", "fp16": false, "fp16_opt_level": "O1", "gradient_accumulation_steps": 1, "greater_is_better": null, "ignore_data_skip": false, "label_names": null, "learning_rate": 3e-05, "load_best_model_at_end": false, "local_rank": -1, "logging_dir": "output/mnli_test2/", "logging_first_step": false, "logging_steps": 250, "max_grad_norm": 1.0, "max_steps": -1, "metric_for_best_model": null, "model_parallel": false, "no_cuda": false, "num_train_epochs": 12, "optimize_model_before_eval": "disabled", "output_dir": "output/mnli_test2/", "overwrite_output_dir": 1, "past_index": -1, "per_device_eval_batch_size": 128, "per_device_train_batch_size": 32, "per_gpu_eval_batch_size": null, "per_gpu_train_batch_size": null, "prediction_loss_only": false, "remove_unused_columns": true, "run_name": "output/mnli_test2/", "save_steps": 5000, "save_total_limit": 50, "seed": 17, "tpu_metrics_debug": false, "tpu_num_cores": null, "warmup_steps": 12000, "weight_decay": 0.0}}, "fill_rate": 0.2665834780092592, "matched": 83.03616912888437, "mismatched": 83.6554109031733, "speedup": 2.002662075247167}}
{"speedup": 2.4005750580789247, "matched": 82.27203260315844, "meta": {"annotate": "17", "cat_fun_name": "is_new_xp", "checkpoint": {"config": {"_name_or_path": "bert-base-uncased", "architectures": ["BertForSequenceClassification"], "attention_probs_dropout_prob": 0.1, "finetuning_task": "mnli", "gradient_checkpointing": false, "hidden_act": "gelu", "hidden_dropout_prob": 0.1, "hidden_size": 768, "id2label": {"0": "contradiction", "1": "entailment", "2": "neutral"}, "initializer_range": 0.02, "intermediate_size": 3072, "label2id": {"contradiction": 0, "entailment": 1, "neutral": 2}, "layer_norm_eps": 1e-12, "max_position_embeddings": 512, "model_type": "bert", "num_attention_heads": 12, "num_hidden_layers": 12, "pad_token_id": 0, "position_embedding_type": "absolute", "type_vocab_size": 2, "vocab_size": 30522}, "eval_metrics": {"eval_accuracy": 0.8227203260315843, "eval_loss": 0.6198351383209229}, "eval_metrics_mm": {"eval_accuracy": 0.82740032546786, "eval_loss": 0.5863709449768066}, "path": "/data_2to/devel_data/nn_pruning/output/mnli_test2/hp_od-output__mnli_test2___pdtbs32_pdebs128_nte12_ws12000_rn-output__mnli_test2___fw4/checkpoint-145000", "sparse_args": {"ampere_pruning_method": "disabled", "attention_block_cols": 32, "attention_block_rows": 32, "attention_lambda": 1.0, "attention_output_with_dense": 0, "attention_pruning_method": "sigmoied_threshold", "bias_mask": true, "dense_block_cols": 1, "dense_block_rows": 1, "dense_lambda": 1.0, "dense_pruning_method": "sigmoied_threshold:1d_alt", "distil_alpha_ce": 0.1, "distil_alpha_teacher": 0.9, "distil_teacher_name_or_path": "aloxatel/bert-base-mnli", "distil_temperature": 2.0, "final_ampere_temperature": 20.0, "final_finetune": false, "final_threshold": 0.1, "final_warmup": 4, "initial_ampere_temperature": 0.0, "initial_threshold": 0, "initial_warmup": 1, "mask_init": "constant", "mask_scale": 0.0, "mask_scores_learning_rate": 0.01, "regularization": "l1", "regularization_final_lambda": 10}, "speed": {"cuda_eval_elapsed_time": 20.451122985839845, "eval_elapsed_time": 22.043534694239497}, "speed_mm": {"cuda_eval_elapsed_time": 20.540529357910156, "eval_elapsed_time": 22.19288508500904}, "speedup": 2.4005750580789247, "stats": {"layers": {"0": {"linear_attention_nnz": 685056, "linear_attention_total": 2359296, "linear_dense_nnz": 474624, "linear_dense_total": 4718592, "linear_nnz": 1159680, "linear_total": 7077888, "nnz": 1165493, "total": 7087872}, "1": {"linear_attention_nnz": 683008, "linear_attention_total": 2359296, "linear_dense_nnz": 568320, "linear_dense_total": 4718592, "linear_nnz": 1251328, "linear_total": 7077888, "nnz": 1257138, "total": 7087872}, "10": {"linear_attention_nnz": 254976, "linear_attention_total": 2359296, "linear_dense_nnz": 109056, "linear_dense_total": 4718592, "linear_nnz": 364032, "linear_total": 7077888, "nnz": 368999, "total": 7087872}, "11": {"linear_attention_nnz": 188416, "linear_attention_total": 2359296, "linear_dense_nnz": 33792, "linear_dense_total": 4718592, "linear_nnz": 222208, "linear_total": 7077888, "nnz": 227638, "total": 7087872}, "2": {"linear_attention_nnz": 931840, "linear_attention_total": 2359296, "linear_dense_nnz": 798720, "linear_dense_total": 4718592, "linear_nnz": 1730560, "linear_total": 7077888, "nnz": 1736872, "total": 7087872}, "3": {"linear_attention_nnz": 891904, "linear_attention_total": 2359296, "linear_dense_nnz": 996864, "linear_dense_total": 4718592, "linear_nnz": 1888768, "linear_total": 7077888, "nnz": 1895209, "total": 7087872}, "4": {"linear_attention_nnz": 847872, "linear_attention_total": 2359296, "linear_dense_nnz": 1010688, "linear_dense_total": 4718592, "linear_nnz": 1858560, "linear_total": 7077888, "nnz": 1864914, "total": 7087872}, "5": {"linear_attention_nnz": 1118208, "linear_attention_total": 2359296, "linear_dense_nnz": 838656, "linear_dense_total": 4718592, "linear_nnz": 1956864, "linear_total": 7077888, "nnz": 1963554, "total": 7087872}, "6": {"linear_attention_nnz": 805888, "linear_attention_total": 2359296, "linear_dense_nnz": 769536, "linear_dense_total": 4718592, "linear_nnz": 1575424, "linear_total": 7077888, "nnz": 1581653, "total": 7087872}, "7": {"linear_attention_nnz": 816128, "linear_attention_total": 2359296, "linear_dense_nnz": 680448, "linear_dense_total": 4718592, "linear_nnz": 1496576, "linear_total": 7077888, "nnz": 1502779, "total": 7087872}, "8": {"linear_attention_nnz": 562176, "linear_attention_total": 2359296, "linear_dense_nnz": 477696, "linear_dense_total": 4718592, "linear_nnz": 1039872, "linear_total": 7077888, "nnz": 1045815, "total": 7087872}, "9": {"linear_attention_nnz": 506880, "linear_attention_total": 2359296, "linear_dense_nnz": 175104, "linear_dense_total": 4718592, "linear_nnz": 681984, "linear_total": 7077888, "nnz": 687442, "total": 7087872}}, "linear_nnz": 15225856, "linear_sparsity": 82.07344714506173, "linear_total": 84934656, "nnz": 39727589, "pruned_heads": {"0": [0, 2, 4, 6, 7, 9, 11], "1": [0, 2, 3, 5, 6, 7, 8], "10": [1, 2, 4, 5, 6, 7, 8, 9], "11": [0, 1, 2, 7], "2": [4, 5, 7, 8, 11], "3": [1, 2, 4, 6, 7, 8], "4": [0, 1, 2, 8, 10, 11], "5": [1, 2, 11, 6], "6": [2, 3, 4, 10, 11], "7": [2, 4, 6, 7, 11], "8": [0, 5, 6, 7, 8, 10], "9": [1, 2, 3, 4, 5, 7, 9]}, "total": 109484547, "total_sparsity": 63.713976000649666}, "training_args": {"adam_beta1": 0.9, "adam_beta2": 0.999, "adam_epsilon": 1e-08, "dataloader_drop_last": false, "dataloader_num_workers": 0, "debug": false, "disable_tqdm": false, "do_eval": 1, "do_predict": false, "do_train": 1, "eval_accumulation_steps": null, "eval_steps": 5000, "evaluation_strategy": "steps", "fp16": false, "fp16_opt_level": "O1", "gradient_accumulation_steps": 1, "greater_is_better": null, "ignore_data_skip": false, "label_names": null, "learning_rate": 3e-05, "load_best_model_at_end": false, "local_rank": -1, "logging_dir": "output/mnli_test2/", "logging_first_step": false, "logging_steps": 250, "max_grad_norm": 1.0, "max_steps": -1, "metric_for_best_model": null, "model_parallel": false, "no_cuda": false, "num_train_epochs": 12, "optimize_model_before_eval": "disabled", "output_dir": "output/mnli_test2/", "overwrite_output_dir": 1, "past_index": -1, "per_device_eval_batch_size": 128, "per_device_train_batch_size": 32, "per_gpu_eval_batch_size": null, "per_gpu_train_batch_size": null, "prediction_loss_only": false, "remove_unused_columns": true, "run_name": "output/mnli_test2/", "save_steps": 5000, "save_total_limit": 50, "seed": 17, "tpu_metrics_debug": false, "tpu_num_cores": null, "warmup_steps": 12000, "weight_decay": 0.0}}, "fill_rate": 0.1792655285493826, "matched": 82.27203260315844, "mismatched": 82.740032546786, "speedup": 2.4005750580789247}}
{"speedup": 2.8975278910432105, "matched": 81.67091186958737, "meta": {"annotate": "12", "cat_fun_name": "is_new_xp", "checkpoint": {"config": {"_name_or_path": "bert-base-uncased", "architectures": ["BertForSequenceClassification"], "attention_probs_dropout_prob": 0.1, "finetuning_task": "mnli", "gradient_checkpointing": false, "hidden_act": "gelu", "hidden_dropout_prob": 0.1, "hidden_size": 768, "id2label": {"0": "contradiction", "1": "entailment", "2": "neutral"}, "initializer_range": 0.02, "intermediate_size": 3072, "label2id": {"contradiction": 0, "entailment": 1, "neutral": 2}, "layer_norm_eps": 1e-12, "max_position_embeddings": 512, "model_type": "bert", "num_attention_heads": 12, "num_hidden_layers": 12, "pad_token_id": 0, "position_embedding_type": "absolute", "type_vocab_size": 2, "vocab_size": 30522}, "eval_metrics": {"eval_accuracy": 0.8167091186958737, "eval_loss": 0.6105015277862549}, "eval_metrics_mm": {"eval_accuracy": 0.8164157851912124, "eval_loss": 0.5977670550346375}, "path": "/data_2to/devel_data/nn_pruning/output/mnli_test2/hp_od-output__mnli_test2___pdtbs32_pdebs128_nte12_ws12000_rn-output__mnli_test2___fw4_rfl20/checkpoint-100000", "sparse_args": {"ampere_pruning_method": "disabled", "attention_block_cols": 32, "attention_block_rows": 32, "attention_lambda": 1.0, "attention_output_with_dense": 0, "attention_pruning_method": "sigmoied_threshold", "bias_mask": true, "dense_block_cols": 1, "dense_block_rows": 1, "dense_lambda": 1.0, "dense_pruning_method": "sigmoied_threshold:1d_alt", "distil_alpha_ce": 0.1, "distil_alpha_teacher": 0.9, "distil_teacher_name_or_path": "aloxatel/bert-base-mnli", "distil_temperature": 2.0, "final_ampere_temperature": 20.0, "final_finetune": false, "final_threshold": 0.1, "final_warmup": 4, "initial_ampere_temperature": 0.0, "initial_threshold": 0, "initial_warmup": 1, "mask_init": "constant", "mask_scale": 0.0, "mask_scores_learning_rate": 0.01, "regularization": "l1", "regularization_final_lambda": 20}, "speed": {"cuda_eval_elapsed_time": 16.94356623840332, "eval_elapsed_time": 18.50567529629916}, "speed_mm": {"cuda_eval_elapsed_time": 16.96883401489258, "eval_elapsed_time": 18.56157809589058}, "speedup": 2.8975278910432105, "stats": {"layers": {"0": {"linear_attention_nnz": 555008, "linear_attention_total": 2359296, "linear_dense_nnz": 268800, "linear_dense_total": 4718592, "linear_nnz": 823808, "linear_total": 7077888, "nnz": 829295, "total": 7087872}, "1": {"linear_attention_nnz": 592896, "linear_attention_total": 2359296, "linear_dense_nnz": 304128, "linear_dense_total": 4718592, "linear_nnz": 897024, "linear_total": 7077888, "nnz": 902566, "total": 7087872}, "10": {"linear_attention_nnz": 230400, "linear_attention_total": 2359296, "linear_dense_nnz": 70656, "linear_dense_total": 4718592, "linear_nnz": 301056, "linear_total": 7077888, "nnz": 306030, "total": 7087872}, "11": {"linear_attention_nnz": 133120, "linear_attention_total": 2359296, "linear_dense_nnz": 23040, "linear_dense_total": 4718592, "linear_nnz": 156160, "linear_total": 7077888, "nnz": 161199, "total": 7087872}, "2": {"linear_attention_nnz": 582656, "linear_attention_total": 2359296, "linear_dense_nnz": 459264, "linear_dense_total": 4718592, "linear_nnz": 1041920, "linear_total": 7077888, "nnz": 1047499, "total": 7087872}, "3": {"linear_attention_nnz": 742400, "linear_attention_total": 2359296, "linear_dense_nnz": 614400, "linear_dense_total": 4718592, "linear_nnz": 1356800, "linear_total": 7077888, "nnz": 1362736, "total": 7087872}, "4": {"linear_attention_nnz": 730112, "linear_attention_total": 2359296, "linear_dense_nnz": 602112, "linear_dense_total": 4718592, "linear_nnz": 1332224, "linear_total": 7077888, "nnz": 1338120, "total": 7087872}, "5": {"linear_attention_nnz": 840704, "linear_attention_total": 2359296, "linear_dense_nnz": 489984, "linear_dense_total": 4718592, "linear_nnz": 1330688, "linear_total": 7077888, "nnz": 1336799, "total": 7087872}, "6": {"linear_attention_nnz": 523264, "linear_attention_total": 2359296, "linear_dense_nnz": 436224, "linear_dense_total": 4718592, "linear_nnz": 959488, "linear_total": 7077888, "nnz": 965116, "total": 7087872}, "7": {"linear_attention_nnz": 568320, "linear_attention_total": 2359296, "linear_dense_nnz": 453120, "linear_dense_total": 4718592, "linear_nnz": 1021440, "linear_total": 7077888, "nnz": 1027079, "total": 7087872}, "8": {"linear_attention_nnz": 483328, "linear_attention_total": 2359296, "linear_dense_nnz": 327168, "linear_dense_total": 4718592, "linear_nnz": 810496, "linear_total": 7077888, "nnz": 816085, "total": 7087872}, "9": {"linear_attention_nnz": 376832, "linear_attention_total": 2359296, "linear_dense_nnz": 112128, "linear_dense_total": 4718592, "linear_nnz": 488960, "linear_total": 7077888, "nnz": 494185, "total": 7087872}}, "linear_nnz": 10520064, "linear_sparsity": 87.61393229166666, "linear_total": 84934656, "nnz": 35016792, "pruned_heads": {"0": [0, 1, 2, 4, 6, 7, 9, 11], "1": [0, 2, 3, 5, 6, 7, 8, 9], "10": [1, 2, 4, 5, 6, 7, 8, 9], "11": [0, 1, 2, 6, 7, 10, 11], "2": [0, 1, 3, 4, 5, 7, 8, 11], "3": [1, 2, 3, 4, 6, 7, 8], "4": [0, 1, 2, 4, 8, 10, 11], "5": [1, 2, 5, 6, 11], "6": [2, 3, 4, 6, 7, 10, 11], "7": [2, 3, 4, 5, 6, 7, 11], "8": [0, 3, 5, 6, 7, 8, 10], "9": [0, 1, 2, 3, 4, 5, 7, 9]}, "total": 109484547, "total_sparsity": 68.01668092941007}, "training_args": {"adam_beta1": 0.9, "adam_beta2": 0.999, "adam_epsilon": 1e-08, "dataloader_drop_last": false, "dataloader_num_workers": 0, "debug": false, "disable_tqdm": false, "do_eval": 1, "do_predict": false, "do_train": 1, "eval_accumulation_steps": null, "eval_steps": 5000, "evaluation_strategy": "steps", "fp16": false, "fp16_opt_level": "O1", "gradient_accumulation_steps": 1, "greater_is_better": null, "ignore_data_skip": false, "label_names": null, "learning_rate": 3e-05, "load_best_model_at_end": false, "local_rank": -1, "logging_dir": "output/mnli_test2/", "logging_first_step": false, "logging_steps": 250, "max_grad_norm": 1.0, "max_steps": -1, "metric_for_best_model": null, "model_parallel": false, "no_cuda": false, "num_train_epochs": 12, "optimize_model_before_eval": "disabled", "output_dir": "output/mnli_test2/", "overwrite_output_dir": 1, "past_index": -1, "per_device_eval_batch_size": 128, "per_device_train_batch_size": 32, "per_gpu_eval_batch_size": null, "per_gpu_train_batch_size": null, "prediction_loss_only": false, "remove_unused_columns": true, "run_name": "output/mnli_test2/", "save_steps": 5000, "save_total_limit": 50, "seed": 17, "tpu_metrics_debug": false, "tpu_num_cores": null, "warmup_steps": 12000, "weight_decay": 0.0}}, "fill_rate": 0.12386067708333348, "matched": 81.67091186958737, "mismatched": 81.64157851912124, "speedup": 2.8975278910432105}}
{"speedup": 2.9707750898055454, "matched": 81.37544574630667, "meta": {"annotate": "11", "cat_fun_name": "is_new_xp", "checkpoint": {"config": {"_name_or_path": "bert-base-uncased", "architectures": ["BertForSequenceClassification"], "attention_probs_dropout_prob": 0.1, "finetuning_task": "mnli", "gradient_checkpointing": false, "hidden_act": "gelu", "hidden_dropout_prob": 0.1, "hidden_size": 768, "id2label": {"0": "contradiction", "1": "entailment", "2": "neutral"}, "initializer_range": 0.02, "intermediate_size": 3072, "label2id": {"contradiction": 0, "entailment": 1, "neutral": 2}, "layer_norm_eps": 1e-12, "max_position_embeddings": 512, "model_type": "bert", "num_attention_heads": 12, "num_hidden_layers": 12, "pad_token_id": 0, "position_embedding_type": "absolute", "type_vocab_size": 2, "vocab_size": 30522}, "eval_metrics": {"eval_accuracy": 0.8137544574630667, "eval_loss": 0.6326338052749634}, "eval_metrics_mm": {"eval_accuracy": 0.8127542717656632, "eval_loss": 0.6192973852157593}, "path": "/data_2to/devel_data/nn_pruning/output/mnli_test2/hp_od-output__mnli_test2___pdtbs32_pdebs128_nte12_ws12000_rn-output__mnli_test2___fw4_rfl20/checkpoint-130000", "sparse_args": {"ampere_pruning_method": "disabled", "attention_block_cols": 32, "attention_block_rows": 32, "attention_lambda": 1.0, "attention_output_with_dense": 0, "attention_pruning_method": "sigmoied_threshold", "bias_mask": true, "dense_block_cols": 1, "dense_block_rows": 1, "dense_lambda": 1.0, "dense_pruning_method": "sigmoied_threshold:1d_alt", "distil_alpha_ce": 0.1, "distil_alpha_teacher": 0.9, "distil_teacher_name_or_path": "aloxatel/bert-base-mnli", "distil_temperature": 2.0, "final_ampere_temperature": 20.0, "final_finetune": false, "final_threshold": 0.1, "final_warmup": 4, "initial_ampere_temperature": 0.0, "initial_threshold": 0, "initial_warmup": 1, "mask_init": "constant", "mask_scale": 0.0, "mask_scores_learning_rate": 0.01, "regularization": "l1", "regularization_final_lambda": 20}, "speed": {"cuda_eval_elapsed_time": 16.52580699157715, "eval_elapsed_time": 18.086638130247593}, "speed_mm": {"cuda_eval_elapsed_time": 16.60585534667969, "eval_elapsed_time": 18.22978367190808}, "speedup": 2.9707750898055454, "stats": {"layers": {"0": {"linear_attention_nnz": 495616, "linear_attention_total": 2359296, "linear_dense_nnz": 224256, "linear_dense_total": 4718592, "linear_nnz": 719872, "linear_total": 7077888, "nnz": 725266, "total": 7087872}, "1": {"linear_attention_nnz": 540672, "linear_attention_total": 2359296, "linear_dense_nnz": 258048, "linear_dense_total": 4718592, "linear_nnz": 798720, "linear_total": 7077888, "nnz": 804168, "total": 7087872}, "10": {"linear_attention_nnz": 223232, "linear_attention_total": 2359296, "linear_dense_nnz": 64512, "linear_dense_total": 4718592, "linear_nnz": 287744, "linear_total": 7077888, "nnz": 292714, "total": 7087872}, "11": {"linear_attention_nnz": 118784, "linear_attention_total": 2359296, "linear_dense_nnz": 23040, "linear_dense_total": 4718592, "linear_nnz": 141824, "linear_total": 7077888, "nnz": 146831, "total": 7087872}, "2": {"linear_attention_nnz": 570368, "linear_attention_total": 2359296, "linear_dense_nnz": 413184, "linear_dense_total": 4718592, "linear_nnz": 983552, "linear_total": 7077888, "nnz": 989101, "total": 7087872}, "3": {"linear_attention_nnz": 688128, "linear_attention_total": 2359296, "linear_dense_nnz": 571392, "linear_dense_total": 4718592, "linear_nnz": 1259520, "linear_total": 7077888, "nnz": 1265364, "total": 7087872}, "4": {"linear_attention_nnz": 663552, "linear_attention_total": 2359296, "linear_dense_nnz": 556032, "linear_dense_total": 4718592, "linear_nnz": 1219584, "linear_total": 7077888, "nnz": 1225418, "total": 7087872}, "5": {"linear_attention_nnz": 753664, "linear_attention_total": 2359296, "linear_dense_nnz": 450048, "linear_dense_total": 4718592, "linear_nnz": 1203712, "linear_total": 7077888, "nnz": 1209765, "total": 7087872}, "6": {"linear_attention_nnz": 525312, "linear_attention_total": 2359296, "linear_dense_nnz": 405504, "linear_dense_total": 4718592, "linear_nnz": 930816, "linear_total": 7077888, "nnz": 936424, "total": 7087872}, "7": {"linear_attention_nnz": 524288, "linear_attention_total": 2359296, "linear_dense_nnz": 411648, "linear_dense_total": 4718592, "linear_nnz": 935936, "linear_total": 7077888, "nnz": 941548, "total": 7087872}, "8": {"linear_attention_nnz": 355328, "linear_attention_total": 2359296, "linear_dense_nnz": 307200, "linear_dense_total": 4718592, "linear_nnz": 662528, "linear_total": 7077888, "nnz": 667976, "total": 7087872}, "9": {"linear_attention_nnz": 385024, "linear_attention_total": 2359296, "linear_dense_nnz": 102912, "linear_dense_total": 4718592, "linear_nnz": 487936, "linear_total": 7077888, "nnz": 493059, "total": 7087872}}, "linear_nnz": 9631744, "linear_sparsity": 88.6598186728395, "linear_total": 84934656, "nnz": 34127717, "pruned_heads": {"0": [0, 1, 2, 4, 6, 7, 9, 11], "1": [0, 2, 3, 5, 6, 7, 8, 9], "10": [1, 2, 4, 5, 6, 7, 8, 9], "11": [0, 1, 2, 6, 7, 10, 11], "2": [0, 1, 3, 4, 5, 7, 8, 11], "3": [1, 2, 3, 4, 6, 7, 8], "4": [0, 1, 2, 4, 8, 10, 11], "5": [1, 2, 5, 6, 11], "6": [2, 3, 4, 6, 7, 10, 11], "7": [2, 3, 4, 5, 6, 7, 11], "8": [0, 2, 3, 5, 6, 7, 8, 10], "9": [0, 1, 2, 3, 4, 5, 7, 9]}, "total": 109484547, "total_sparsity": 68.8287361685846}, "training_args": {"adam_beta1": 0.9, "adam_beta2": 0.999, "adam_epsilon": 1e-08, "dataloader_drop_last": false, "dataloader_num_workers": 0, "debug": false, "disable_tqdm": false, "do_eval": 1, "do_predict": false, "do_train": 1, "eval_accumulation_steps": null, "eval_steps": 5000, "evaluation_strategy": "steps", "fp16": false, "fp16_opt_level": "O1", "gradient_accumulation_steps": 1, "greater_is_better": null, "ignore_data_skip": false, "label_names": null, "learning_rate": 3e-05, "load_best_model_at_end": false, "local_rank": -1, "logging_dir": "output/mnli_test2/", "logging_first_step": false, "logging_steps": 250, "max_grad_norm": 1.0, "max_steps": -1, "metric_for_best_model": null, "model_parallel": false, "no_cuda": false, "num_train_epochs": 12, "optimize_model_before_eval": "disabled", "output_dir": "output/mnli_test2/", "overwrite_output_dir": 1, "past_index": -1, "per_device_eval_batch_size": 128, "per_device_train_batch_size": 32, "per_gpu_eval_batch_size": null, "per_gpu_train_batch_size": null, "prediction_loss_only": false, "remove_unused_columns": true, "run_name": "output/mnli_test2/", "save_steps": 5000, "save_total_limit": 50, "seed": 17, "tpu_metrics_debug": false, "tpu_num_cores": null, "warmup_steps": 12000, "weight_decay": 0.0}}, "fill_rate": 0.11340181327160492, "matched": 81.37544574630667, "mismatched": 81.27542717656631, "speedup": 2.9707750898055454}}
{"speedup": 2.9812930987603186, "matched": 81.29393785022924, "meta": {"annotate": "11", "cat_fun_name": "is_new_xp", "checkpoint": {"config": {"_name_or_path": "bert-base-uncased", "architectures": ["BertForSequenceClassification"], "attention_probs_dropout_prob": 0.1, "finetuning_task": "mnli", "gradient_checkpointing": false, "hidden_act": "gelu", "hidden_dropout_prob": 0.1, "hidden_size": 768, "id2label": {"0": "contradiction", "1": "entailment", "2": "neutral"}, "initializer_range": 0.02, "intermediate_size": 3072, "label2id": {"contradiction": 0, "entailment": 1, "neutral": 2}, "layer_norm_eps": 1e-12, "max_position_embeddings": 512, "model_type": "bert", "num_attention_heads": 12, "num_hidden_layers": 12, "pad_token_id": 0, "position_embedding_type": "absolute", "type_vocab_size": 2, "vocab_size": 30522}, "eval_metrics": {"eval_accuracy": 0.8129393785022924, "eval_loss": 0.6277854442596436}, "eval_metrics_mm": {"eval_accuracy": 0.8157038242473555, "eval_loss": 0.6225855350494385}, "path": "/data_2to/devel_data/nn_pruning/output/mnli_test2/hp_od-output__mnli_test2___pdtbs32_pdebs128_nte12_ws12000_rn-output__mnli_test2___fw4_rfl20/checkpoint-140000", "sparse_args": {"ampere_pruning_method": "disabled", "attention_block_cols": 32, "attention_block_rows": 32, "attention_lambda": 1.0, "attention_output_with_dense": 0, "attention_pruning_method": "sigmoied_threshold", "bias_mask": true, "dense_block_cols": 1, "dense_block_rows": 1, "dense_lambda": 1.0, "dense_pruning_method": "sigmoied_threshold:1d_alt", "distil_alpha_ce": 0.1, "distil_alpha_teacher": 0.9, "distil_teacher_name_or_path": "aloxatel/bert-base-mnli", "distil_temperature": 2.0, "final_ampere_temperature": 20.0, "final_finetune": false, "final_threshold": 0.1, "final_warmup": 4, "initial_ampere_temperature": 0.0, "initial_threshold": 0, "initial_warmup": 1, "mask_init": "constant", "mask_scale": 0.0, "mask_scores_learning_rate": 0.01, "regularization": "l1", "regularization_final_lambda": 20}, "speed": {"cuda_eval_elapsed_time": 16.467503906250002, "eval_elapsed_time": 18.033160428516567}, "speed_mm": {"cuda_eval_elapsed_time": 16.515043060302734, "eval_elapsed_time": 18.09035024512559}, "speedup": 2.9812930987603186, "stats": {"layers": {"0": {"linear_attention_nnz": 482304, "linear_attention_total": 2359296, "linear_dense_nnz": 221184, "linear_dense_total": 4718592, "linear_nnz": 703488, "linear_total": 7077888, "nnz": 708848, "total": 7087872}, "1": {"linear_attention_nnz": 527360, "linear_attention_total": 2359296, "linear_dense_nnz": 256512, "linear_dense_total": 4718592, "linear_nnz": 783872, "linear_total": 7077888, "nnz": 789319, "total": 7087872}, "10": {"linear_attention_nnz": 214016, "linear_attention_total": 2359296, "linear_dense_nnz": 64512, "linear_dense_total": 4718592, "linear_nnz": 278528, "linear_total": 7077888, "nnz": 283530, "total": 7087872}, "11": {"linear_attention_nnz": 117760, "linear_attention_total": 2359296, "linear_dense_nnz": 23040, "linear_dense_total": 4718592, "linear_nnz": 140800, "linear_total": 7077888, "nnz": 145807, "total": 7087872}, "2": {"linear_attention_nnz": 563200, "linear_attention_total": 2359296, "linear_dense_nnz": 411648, "linear_dense_total": 4718592, "linear_nnz": 974848, "linear_total": 7077888, "nnz": 980396, "total": 7087872}, "3": {"linear_attention_nnz": 677888, "linear_attention_total": 2359296, "linear_dense_nnz": 569856, "linear_dense_total": 4718592, "linear_nnz": 1247744, "linear_total": 7077888, "nnz": 1253587, "total": 7087872}, "4": {"linear_attention_nnz": 664576, "linear_attention_total": 2359296, "linear_dense_nnz": 552960, "linear_dense_total": 4718592, "linear_nnz": 1217536, "linear_total": 7077888, "nnz": 1223368, "total": 7087872}, "5": {"linear_attention_nnz": 712704, "linear_attention_total": 2359296, "linear_dense_nnz": 445440, "linear_dense_total": 4718592, "linear_nnz": 1158144, "linear_total": 7077888, "nnz": 1164194, "total": 7087872}, "6": {"linear_attention_nnz": 510976, "linear_attention_total": 2359296, "linear_dense_nnz": 405504, "linear_dense_total": 4718592, "linear_nnz": 916480, "linear_total": 7077888, "nnz": 922088, "total": 7087872}, "7": {"linear_attention_nnz": 504832, "linear_attention_total": 2359296, "linear_dense_nnz": 410112, "linear_dense_total": 4718592, "linear_nnz": 914944, "linear_total": 7077888, "nnz": 920555, "total": 7087872}, "8": {"linear_attention_nnz": 344064, "linear_attention_total": 2359296, "linear_dense_nnz": 304128, "linear_dense_total": 4718592, "linear_nnz": 648192, "linear_total": 7077888, "nnz": 653638, "total": 7087872}, "9": {"linear_attention_nnz": 374784, "linear_attention_total": 2359296, "linear_dense_nnz": 102912, "linear_dense_total": 4718592, "linear_nnz": 477696, "linear_total": 7077888, "nnz": 482851, "total": 7087872}}, "linear_nnz": 9462272, "linear_sparsity": 88.85935088734568, "linear_total": 84934656, "nnz": 33958264, "pruned_heads": {"0": [0, 1, 2, 4, 6, 7, 8, 9, 11], "1": [0, 2, 3, 5, 6, 7, 8, 9], "10": [1, 2, 4, 5, 6, 7, 8, 9], "11": [0, 1, 2, 6, 7, 10, 11], "2": [0, 1, 3, 4, 5, 7, 8, 11], "3": [1, 2, 3, 4, 6, 7, 8], "4": [0, 1, 2, 4, 8, 10, 11], "5": [1, 2, 5, 6, 11], "6": [2, 3, 4, 6, 7, 10, 11], "7": [2, 3, 4, 5, 6, 7, 11], "8": [0, 2, 3, 5, 6, 7, 8, 10], "9": [0, 1, 2, 3, 4, 5, 7, 9]}, "total": 109484547, "total_sparsity": 68.98350960889485}, "training_args": {"adam_beta1": 0.9, "adam_beta2": 0.999, "adam_epsilon": 1e-08, "dataloader_drop_last": false, "dataloader_num_workers": 0, "debug": false, "disable_tqdm": false, "do_eval": 1, "do_predict": false, "do_train": 1, "eval_accumulation_steps": null, "eval_steps": 5000, "evaluation_strategy": "steps", "fp16": false, "fp16_opt_level": "O1", "gradient_accumulation_steps": 1, "greater_is_better": null, "ignore_data_skip": false, "label_names": null, "learning_rate": 3e-05, "load_best_model_at_end": false, "local_rank": -1, "logging_dir": "output/mnli_test2/", "logging_first_step": false, "logging_steps": 250, "max_grad_norm": 1.0, "max_steps": -1, "metric_for_best_model": null, "model_parallel": false, "no_cuda": false, "num_train_epochs": 12, "optimize_model_before_eval": "disabled", "output_dir": "output/mnli_test2/", "overwrite_output_dir": 1, "past_index": -1, "per_device_eval_batch_size": 128, "per_device_train_batch_size": 32, "per_gpu_eval_batch_size": null, "per_gpu_train_batch_size": null, "prediction_loss_only": false, "remove_unused_columns": true, "run_name": "output/mnli_test2/", "save_steps": 5000, "save_total_limit": 50, "seed": 17, "tpu_metrics_debug": false, "tpu_num_cores": null, "warmup_steps": 12000, "weight_decay": 0.0}}, "fill_rate": 0.1114064911265431, "matched": 81.29393785022924, "mismatched": 81.57038242473556, "speedup": 2.9812930987603186}}
{"speedup": 3.3300349445225725, "matched": 80.58074375955171, "meta": {"annotate": "8", "cat_fun_name": "is_new_xp", "checkpoint": {"config": {"_name_or_path": "bert-base-uncased", "architectures": ["BertForSequenceClassification"], "attention_probs_dropout_prob": 0.1, "finetuning_task": "mnli", "gradient_checkpointing": false, "hidden_act": "gelu", "hidden_dropout_prob": 0.1, "hidden_size": 768, "id2label": {"0": "contradiction", "1": "entailment", "2": "neutral"}, "initializer_range": 0.02, "intermediate_size": 3072, "label2id": {"contradiction": 0, "entailment": 1, "neutral": 2}, "layer_norm_eps": 1e-12, "max_position_embeddings": 512, "model_type": "bert", "num_attention_heads": 12, "num_hidden_layers": 12, "pad_token_id": 0, "position_embedding_type": "absolute", "type_vocab_size": 2, "vocab_size": 30522}, "eval_metrics": {"eval_accuracy": 0.8058074375955171, "eval_loss": 0.6541752219200134}, "eval_metrics_mm": {"eval_accuracy": 0.807160292921074, "eval_loss": 0.6403667330741882}, "path": "/data_2to/devel_data/nn_pruning/output/mnli_test2/hp_od-output__mnli_test2___pdtbs32_pdebs128_nte12_ws12000_rn-output__mnli_test2___fw4_rfl30/checkpoint-135000", "sparse_args": {"ampere_pruning_method": "disabled", "attention_block_cols": 32, "attention_block_rows": 32, "attention_lambda": 1.0, "attention_output_with_dense": 0, "attention_pruning_method": "sigmoied_threshold", "bias_mask": true, "dense_block_cols": 1, "dense_block_rows": 1, "dense_lambda": 1.0, "dense_pruning_method": "sigmoied_threshold:1d_alt", "distil_alpha_ce": 0.1, "distil_alpha_teacher": 0.9, "distil_teacher_name_or_path": "aloxatel/bert-base-mnli", "distil_temperature": 2.0, "final_ampere_temperature": 20.0, "final_finetune": false, "final_threshold": 0.1, "final_warmup": 4, "initial_ampere_temperature": 0.0, "initial_threshold": 0, "initial_warmup": 1, "mask_init": "constant", "mask_scale": 0.0, "mask_scores_learning_rate": 0.01, "regularization": "l1", "regularization_final_lambda": 30}, "speed": {"cuda_eval_elapsed_time": 14.742925094604493, "eval_elapsed_time": 16.3213126398623}, "speed_mm": {"cuda_eval_elapsed_time": 14.796650604248047, "eval_elapsed_time": 16.36922346521169}, "speedup": 3.3300349445225725, "stats": {"layers": {"0": {"linear_attention_nnz": 428032, "linear_attention_total": 2359296, "linear_dense_nnz": 139776, "linear_dense_total": 4718592, "linear_nnz": 567808, "linear_total": 7077888, "nnz": 573051, "total": 7087872}, "1": {"linear_attention_nnz": 418816, "linear_attention_total": 2359296, "linear_dense_nnz": 176640, "linear_dense_total": 4718592, "linear_nnz": 595456, "linear_total": 7077888, "nnz": 600723, "total": 7087872}, "10": {"linear_attention_nnz": 165888, "linear_attention_total": 2359296, "linear_dense_nnz": 58368, "linear_dense_total": 4718592, "linear_nnz": 224256, "linear_total": 7077888, "nnz": 228966, "total": 7087872}, "11": {"linear_attention_nnz": 99328, "linear_attention_total": 2359296, "linear_dense_nnz": 23040, "linear_dense_total": 4718592, "linear_nnz": 122368, "linear_total": 7077888, "nnz": 127183, "total": 7087872}, "2": {"linear_attention_nnz": 532480, "linear_attention_total": 2359296, "linear_dense_nnz": 270336, "linear_dense_total": 4718592, "linear_nnz": 802816, "linear_total": 7077888, "nnz": 808272, "total": 7087872}, "3": {"linear_attention_nnz": 450560, "linear_attention_total": 2359296, "linear_dense_nnz": 397824, "linear_dense_total": 4718592, "linear_nnz": 848384, "linear_total": 7077888, "nnz": 853891, "total": 7087872}, "4": {"linear_attention_nnz": 565248, "linear_attention_total": 2359296, "linear_dense_nnz": 351744, "linear_dense_total": 4718592, "linear_nnz": 916992, "linear_total": 7077888, "nnz": 922597, "total": 7087872}, "5": {"linear_attention_nnz": 437248, "linear_attention_total": 2359296, "linear_dense_nnz": 299520, "linear_dense_total": 4718592, "linear_nnz": 736768, "linear_total": 7077888, "nnz": 742211, "total": 7087872}, "6": {"linear_attention_nnz": 317440, "linear_attention_total": 2359296, "linear_dense_nnz": 287232, "linear_dense_total": 4718592, "linear_nnz": 604672, "linear_total": 7077888, "nnz": 609883, "total": 7087872}, "7": {"linear_attention_nnz": 346112, "linear_attention_total": 2359296, "linear_dense_nnz": 317952, "linear_dense_total": 4718592, "linear_nnz": 664064, "linear_total": 7077888, "nnz": 669391, "total": 7087872}, "8": {"linear_attention_nnz": 238592, "linear_attention_total": 2359296, "linear_dense_nnz": 230400, "linear_dense_total": 4718592, "linear_nnz": 468992, "linear_total": 7077888, "nnz": 474102, "total": 7087872}, "9": {"linear_attention_nnz": 340992, "linear_attention_total": 2359296, "linear_dense_nnz": 86016, "linear_dense_total": 4718592, "linear_nnz": 427008, "linear_total": 7077888, "nnz": 432088, "total": 7087872}}, "linear_nnz": 6979584, "linear_sparsity": 91.7824074074074, "linear_total": 84934656, "nnz": 31472441, "pruned_heads": {"0": [0, 1, 2, 4, 6, 7, 8, 9, 11], "1": [0, 2, 3, 5, 6, 7, 8, 9], "10": [0, 1, 2, 4, 5, 6, 7, 8, 9], "11": [0, 1, 2, 6, 7, 10, 11], "2": [0, 1, 3, 4, 5, 7, 8, 11], "3": [1, 2, 3, 4, 6, 7, 8, 10], "4": [0, 1, 2, 4, 6, 8, 10, 11], "5": [1, 2, 4, 5, 6, 9, 11], "6": [1, 2, 3, 4, 6, 7, 9, 10, 11], "7": [2, 3, 4, 5, 6, 7, 9, 11], "8": [0, 2, 3, 5, 6, 7, 8, 10, 11], "9": [0, 1, 2, 3, 4, 5, 7, 9]}, "total": 109484547, "total_sparsity": 71.25398801713999}, "training_args": {"adam_beta1": 0.9, "adam_beta2": 0.999, "adam_epsilon": 1e-08, "dataloader_drop_last": false, "dataloader_num_workers": 0, "debug": false, "disable_tqdm": false, "do_eval": 1, "do_predict": false, "do_train": 1, "eval_accumulation_steps": null, "eval_steps": 5000, "evaluation_strategy": "steps", "fp16": false, "fp16_opt_level": "O1", "gradient_accumulation_steps": 1, "greater_is_better": null, "ignore_data_skip": false, "label_names": null, "learning_rate": 3e-05, "load_best_model_at_end": false, "local_rank": -1, "logging_dir": "output/mnli_test2/", "logging_first_step": false, "logging_steps": 250, "max_grad_norm": 1.0, "max_steps": -1, "metric_for_best_model": null, "model_parallel": false, "no_cuda": false, "num_train_epochs": 12, "optimize_model_before_eval": "disabled", "output_dir": "output/mnli_test2/", "overwrite_output_dir": 1, "past_index": -1, "per_device_eval_batch_size": 128, "per_device_train_batch_size": 32, "per_gpu_eval_batch_size": null, "per_gpu_train_batch_size": null, "prediction_loss_only": false, "remove_unused_columns": true, "run_name": "output/mnli_test2/", "save_steps": 5000, "save_total_limit": 50, "seed": 17, "tpu_metrics_debug": false, "tpu_num_cores": null, "warmup_steps": 12000, "weight_decay": 0.0}}, "fill_rate": 0.08217592592592593, "matched": 80.58074375955171, "mismatched": 80.71602929210741, "speedup": 3.3300349445225725}}
{"speedup": 3.509180092206226, "matched": 80.539989811513, "meta": {"annotate": "6", "cat_fun_name": "is_new_xp", "checkpoint": {"config": {"_name_or_path": "bert-base-uncased", "architectures": ["BertForSequenceClassification"], "attention_probs_dropout_prob": 0.1, "finetuning_task": "mnli", "gradient_checkpointing": false, "hidden_act": "gelu", "hidden_dropout_prob": 0.1, "hidden_size": 768, "id2label": {"0": "contradiction", "1": "entailment", "2": "neutral"}, "initializer_range": 0.02, "intermediate_size": 3072, "label2id": {"contradiction": 0, "entailment": 1, "neutral": 2}, "layer_norm_eps": 1e-12, "max_position_embeddings": 512, "model_type": "bert", "num_attention_heads": 12, "num_hidden_layers": 12, "pad_token_id": 0, "position_embedding_type": "absolute", "type_vocab_size": 2, "vocab_size": 30522}, "eval_metrics": {"eval_accuracy": 0.8053998981151299, "eval_loss": 0.6555120944976807}, "eval_metrics_mm": {"eval_accuracy": 0.8049227013832384, "eval_loss": 0.6468992829322815}, "path": "/data_2to/devel_data/nn_pruning/output/mnli_test2/hp_od-output__mnli_test2___pdtbs32_pdebs128_nte12_ws12000_rn-output__mnli_test2___fw4_rfl40/checkpoint-140000", "sparse_args": {"ampere_pruning_method": "disabled", "attention_block_cols": 32, "attention_block_rows": 32, "attention_lambda": 1.0, "attention_output_with_dense": 0, "attention_pruning_method": "sigmoied_threshold", "bias_mask": true, "dense_block_cols": 1, "dense_block_rows": 1, "dense_lambda": 1.0, "dense_pruning_method": "sigmoied_threshold:1d_alt", "distil_alpha_ce": 0.1, "distil_alpha_teacher": 0.9, "distil_teacher_name_or_path": "aloxatel/bert-base-mnli", "distil_temperature": 2.0, "final_ampere_temperature": 20.0, "final_finetune": false, "final_threshold": 0.1, "final_warmup": 4, "initial_ampere_temperature": 0.0, "initial_threshold": 0, "initial_warmup": 1, "mask_init": "constant", "mask_scale": 0.0, "mask_scores_learning_rate": 0.01, "regularization": "l1", "regularization_final_lambda": 40}, "speed": {"cuda_eval_elapsed_time": 13.990292449951172, "eval_elapsed_time": 15.553386124782264}, "speed_mm": {"cuda_eval_elapsed_time": 14.01429052734375, "eval_elapsed_time": 15.591836652718484}, "speedup": 3.509180092206226, "stats": {"layers": {"0": {"linear_attention_nnz": 362496, "linear_attention_total": 2359296, "linear_dense_nnz": 93696, "linear_dense_total": 4718592, "linear_nnz": 456192, "linear_total": 7077888, "nnz": 461309, "total": 7087872}, "1": {"linear_attention_nnz": 310272, "linear_attention_total": 2359296, "linear_dense_nnz": 98304, "linear_dense_total": 4718592, "linear_nnz": 408576, "linear_total": 7077888, "nnz": 413600, "total": 7087872}, "10": {"linear_attention_nnz": 116736, "linear_attention_total": 2359296, "linear_dense_nnz": 46080, "linear_dense_total": 4718592, "linear_nnz": 162816, "linear_total": 7077888, "nnz": 167390, "total": 7087872}, "11": {"linear_attention_nnz": 86016, "linear_attention_total": 2359296, "linear_dense_nnz": 23040, "linear_dense_total": 4718592, "linear_nnz": 109056, "linear_total": 7077888, "nnz": 113871, "total": 7087872}, "2": {"linear_attention_nnz": 515072, "linear_attention_total": 2359296, "linear_dense_nnz": 192000, "linear_dense_total": 4718592, "linear_nnz": 707072, "linear_total": 7077888, "nnz": 712413, "total": 7087872}, "3": {"linear_attention_nnz": 431104, "linear_attention_total": 2359296, "linear_dense_nnz": 285696, "linear_dense_total": 4718592, "linear_nnz": 716800, "linear_total": 7077888, "nnz": 722202, "total": 7087872}, "4": {"linear_attention_nnz": 323584, "linear_attention_total": 2359296, "linear_dense_nnz": 279552, "linear_dense_total": 4718592, "linear_nnz": 603136, "linear_total": 7077888, "nnz": 608406, "total": 7087872}, "5": {"linear_attention_nnz": 361472, "linear_attention_total": 2359296, "linear_dense_nnz": 225792, "linear_dense_total": 4718592, "linear_nnz": 587264, "linear_total": 7077888, "nnz": 592627, "total": 7087872}, "6": {"linear_attention_nnz": 272384, "linear_attention_total": 2359296, "linear_dense_nnz": 213504, "linear_dense_total": 4718592, "linear_nnz": 485888, "linear_total": 7077888, "nnz": 491019, "total": 7087872}, "7": {"linear_attention_nnz": 269312, "linear_attention_total": 2359296, "linear_dense_nnz": 254976, "linear_dense_total": 4718592, "linear_nnz": 524288, "linear_total": 7077888, "nnz": 529510, "total": 7087872}, "8": {"linear_attention_nnz": 183296, "linear_attention_total": 2359296, "linear_dense_nnz": 199680, "linear_dense_total": 4718592, "linear_nnz": 382976, "linear_total": 7077888, "nnz": 387970, "total": 7087872}, "9": {"linear_attention_nnz": 272384, "linear_attention_total": 2359296, "linear_dense_nnz": 69120, "linear_dense_total": 4718592, "linear_nnz": 341504, "linear_total": 7077888, "nnz": 346445, "total": 7087872}}, "linear_nnz": 5485568, "linear_sparsity": 93.54142554012346, "linear_total": 84934656, "nnz": 29976845, "pruned_heads": {"0": [0, 1, 2, 4, 5, 6, 7, 8, 9, 11], "1": [0, 1, 2, 3, 5, 6, 7, 8, 9], "10": [0, 1, 2, 4, 5, 6, 7, 8, 9], "11": [0, 1, 2, 6, 7, 10, 11], "2": [1, 3, 4, 5, 7, 8, 9, 11], "3": [1, 2, 3, 4, 6, 7, 8, 10], "4": [0, 1, 2, 4, 6, 7, 8, 10, 11], "5": [1, 2, 4, 5, 6, 9, 11], "6": [1, 2, 3, 4, 6, 7, 9, 10, 11], "7": [2, 3, 4, 5, 6, 7, 9, 11], "8": [0, 2, 3, 5, 6, 7, 8, 10, 11], "9": [0, 1, 2, 3, 4, 5, 7, 9]}, "total": 109484547, "total_sparsity": 72.62002189222191}, "training_args": {"adam_beta1": 0.9, "adam_beta2": 0.999, "adam_epsilon": 1e-08, "dataloader_drop_last": false, "dataloader_num_workers": 0, "debug": false, "disable_tqdm": false, "do_eval": 1, "do_predict": false, "do_train": 1, "eval_accumulation_steps": null, "eval_steps": 5000, "evaluation_strategy": "steps", "fp16": false, "fp16_opt_level": "O1", "gradient_accumulation_steps": 1, "greater_is_better": null, "ignore_data_skip": false, "label_names": null, "learning_rate": 3e-05, "load_best_model_at_end": false, "local_rank": -1, "logging_dir": "output/mnli_test2/", "logging_first_step": false, "logging_steps": 250, "max_grad_norm": 1.0, "max_steps": -1, "metric_for_best_model": null, "model_parallel": false, "no_cuda": false, "num_train_epochs": 12, "optimize_model_before_eval": "disabled", "output_dir": "output/mnli_test2/", "overwrite_output_dir": 1, "past_index": -1, "per_device_eval_batch_size": 128, "per_device_train_batch_size": 32, "per_gpu_eval_batch_size": null, "per_gpu_train_batch_size": null, "prediction_loss_only": false, "remove_unused_columns": true, "run_name": "output/mnli_test2/", "save_steps": 5000, "save_total_limit": 50, "seed": 17, "tpu_metrics_debug": false, "tpu_num_cores": null, "warmup_steps": 12000, "weight_decay": 0.0}}, "fill_rate": 0.06458574459876543, "matched": 80.539989811513, "mismatched": 80.49227013832385, "speedup": 3.509180092206226}}
